0	Convert XML data to a list of URLs by parsing the XML structure and extracting URL elements from 'durl' tags.
1	Downloads Dailymotion videos by URL, extracting video information from HTML content, selecting the best available quality, and downloading the video to the specified output directory.
2	Downloads Sina videos by URL, handling different video ID formats and downloading by video ID or vkey. Supports merging and info-only modes.
3	Formats text with ANSI color codes and effects, returning an escaped string with specified colors if running in an ANSI terminal, otherwise returns the original text.
4	Print a log message to standard error with optional color formatting.
5	Function `e` prints an error message with yellow bold formatting and optionally exits the program with a specified exit code.
6	Function `wtf` prints a message in red and bold to the log, then exits the program with the specified exit code (defaults to 1).
7	Detect operating system by checking system string and specific file content, returning 'cygwin', 'mac', 'linux', 'wsl', 'windows', 'bsd', or 'unknown'.
8	Downloads videos from a Vimeo channel URL by extracting the channel ID and calling the channel ID download function.
9	Function `ckplayer_get_info_by_xml` parses XML content from CKPlayer API and extracts video information, returning a dictionary with keys 'title', 'links', 'size', and 'flashvars'. It uses `ET.XML` to parse the XML and `dictify` to convert it to a dictionary structure, then extracts the relevant fields from the parsed data. The function handles cases where fields might be missing by checking for the presence of '_text' keys before accessing them.
10	Function `get_video_url_from_video_id` generates a video URL from a given video ID by performing URL splicing and encoding operations. It uses a predefined lookup table and a custom hash-like algorithm to compute a parameter `s`, ensuring it's non-negative. The function returns a complete video URL with encoded parameters. Note: the code contains references to undefined functions like `unsigned_right_shitf` and `random.random`, which need to be implemented for proper execution.
11	Function `get_mgtv_real_url(url)` takes a URL string and returns a tuple containing:
1. The real M3U URL 
2. Total segments size
3. List of segment URLs

The function:
- Fetches content from the input URL and extracts M3U info
- Builds base URL from the M3U URL components
- Retrieves the actual M3U content 
- Parses segments from M3U content, combining base URL with segment filenames
- Calculates total size using EXT-MGTV-File-SIZE tags
- Returns the M3U URL, total size, and list of complete segment URLs
12	Converts a string to a valid filename by removing or replacing characters that are invalid on the target operating system, trimming to 80 characters, and handling special cases for Windows, Mac (HFS+), and POSIX systems.
13	Downloads CBS videos by URL using theplatform_download_by_pid function with video information extracted from the page HTML.
14	Override the original download method to support JSON output, info display, and stream downloading with optional caption handling. It handles different kwargs flags like 'json_output', 'info_only', 'stream_id', 'index', 'output_dir', 'merge', and 'caption' to control behavior. When downloading, it selects the appropriate stream based on stream_id or defaults to the best quality, then uses ffmpeg to download the URL with specified output directory and merge options. If captions are requested, it saves them in SRT format for each available language.
15	Downloads Acfun video by vid using the appropriate extractor based on source type, and handles danmaku download if requested.
16	Scans through a string for substrings matched by multiple regex patterns and returns all matches in a single list.
17	Parses a URL's query string to extract and return the value of a specified parameter. If the parameter is not found or an error occurs, it returns None.
18	Gets the content of a URL by sending an HTTP GET request with optional headers and decoding support for gzip/deflate compression and character encodings. Returns the response content as a string.
19	Posts content to a URL via HTTP POST request with support for headers, data encoding, compression handling, and character set decoding.
20	Parses a host string to extract hostname and port number. If the input is a numeric string, it's treated as a port number with hostname "0.0.0.0". If the input doesn't contain a protocol prefix, it's prefixed with "//" before parsing. Returns a tuple of (hostname, port), where hostname defaults to "0.0.0.0" and port defaults to 0 if not specified.
21	Function to retrieve room ID from a showroom room URL key by fetching the webpage and extracting the room ID from the HTML content.
22	Get a proper title with courseid+topicID+partID from JSON content using topic and part indices.
23	Downloads an entire course by iterating through all topics and parts, reusing API calls for efficiency. Takes JSON API content, output directory, merge flag, and info_only flag as parameters, and downloads each topic-part combination using the existing API infrastructure.
24	Downloads a specific part of a course by its topic and part index using BokeCC video ID extracted from JSON API content.
25	Checks if a task is either queued or running in this executor.

**Parameters:**
- task_instance: TaskInstance

**Returns:** 
True if the task is known to this executor
26	Returns and flushes events from the event buffer. If dag_ids is specified, only returns events for those DAG IDs; otherwise returns all events. Clears the buffer of returned events.
27	Returns a snowflake.connection object by establishing a connection using configuration parameters retrieved from _get_conn_params().
28	Returns AWS credentials (access key ID and secret access key) from a Snowflake connection's extra parameters. Retrieves credentials from the connection object's extra_dejson dictionary if available.
29	Fetches a field from extras by constructing a full field name with 'extra__grpc__' prefix, returning the field value if it exists or a default value if not found.
30	Copies data using psycopg2's copy_expert method, handling missing input files by creating empty files when needed.
31	Dumps a database table into a tab-delimited file using COPY TO STDOUT command.
32	Uploads a file to Google Cloud Storage using the specified bucket, object name, and file path.
33	Gets the maximum partition value for a specified Hive table.

This function retrieves the maximum partition value from a Hive table by connecting to the Hive metastore. It supports both dotted notation for table names (e.g., "database.table") and explicit schema parameters. The function allows filtering partitions using a filter_map and can specify which field to get the maximum value from.

Parameters:
- table (str): The hive table name, supports dot notation "database.table"
- schema (str): The hive schema (ignored if table uses dot notation)
- field (str): The field to get max value from (auto-inferred if single partition field)
- filter_map (dict): Map of partition key-value pairs to filter candidates
- metastore_conn_id (str): Hive metastore connection ID

Returns:
str: The maximum partition value found

Example:
max_partition('airflow.static_babynames_partitioned') returns '2015-01-01'
34	Returns a MySQL connection object configured with connection details from Airflow's connection manager, including user credentials, host, database, port, charset, cursor type, SSL settings, and local infile options.
35	Returns the state of a TaskInstance at the command line.
>>> airflow task_state tutorial sleep 2015-01-01
success
36	This function continuously monitors and manages the worker processes of a Gunicorn master process. It ensures the number of running workers matches the expected count by sending SIGTTIN (to add workers) and SIGTTOU (to remove workers) signals. The function handles worker refresh cycles, waits for worker readiness, and gracefully terminates workers when needed. It includes timeout handling and will shut down the webserver if communication with the master process fails. The monitoring loop maintains a state diagram where workers are added in batches and removed gracefully, with special handling for cases where workers may have died or are not responding as expected.
37	Retrieves connection to Cloud Translate, returning a Google Cloud Translate client object. Creates and caches the client instance using provided credentials if it doesn't already exist.
38	Translates strings or lists of strings into a target language using Google Cloud Translation API, with optional formatting, source language specification, and model selection. Returns translation results with detected source language, translated text, input value, and model information.
39	Retrieves information about a Cloud SQL instance by calling the instances().get() API method with the specified project ID and instance ID, and returns the instance resource as a dictionary.
40	Creates a new Cloud SQL instance using the provided configuration body and waits for the operation to complete.
41	Updates settings of a Cloud SQL instance using patch API, requires full body content, waits for operation completion.
42	Deletes a Cloud SQL instance and waits for the operation to complete.
43	Retrieves a Cloud SQL database resource from a specified instance, with optional project ID parameter, returning the database resource as a dictionary.
44	Creates a new database inside a Cloud SQL instance by making an insert API call and waiting for the operation to complete.
45	Updates a database resource inside a Cloud SQL instance using patch semantics. Supports optional project ID parameter and waits for the operation to complete.
46	Deletes a database from a Cloud SQL instance and waits for the operation to complete.
47	Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump or CSV file.
48	Starts the Cloud SQL Proxy by downloading it if needed, creating necessary directories, and executing the proxy process with specified parameters. Raises exceptions if the proxy is already running, fails to start, or encounters errors during startup. Returns successfully when the proxy is ready for new connections.
49	Stops the running SQL proxy process and performs cleanup operations including removing the socket directory, downloaded proxy file (if applicable), and generated credentials file. Raises AirflowException if the proxy is not started yet.
50	Returns the version of the Cloud SQL Proxy by executing the proxy version command and parsing the output.
51	Creates a new connection record in the database with a randomly generated ID, using the appropriate connection parameters (proxy, TCP, UNIX sockets, SSL) based on the connection URI. The method parses the connection URI and adds the new connection to the session, then commits the transaction.
52	Retrieves a database connection from the Connection table based on the connection ID. Returns the connection object if found, otherwise returns None.
53	Delete a dynamically created connection from the Connection table based on the connection ID. If the connection exists, it is removed from the database and changes are committed. If the connection doesn't exist, a log message is recorded indicating that the connection was already deleted. The operation uses the provided SQLAlchemy session for database interaction.
54	Retrieves the Cloud SQL Proxy runner for managing proxy lifecycle per task. Raises AirflowException if use_proxy is False. Returns a CloudSqlProxyRunner instance configured with proxy settings.
55	Returns the appropriate database hook (Postgres or MySQL) for connecting to Google Cloud SQL, initializing it with the specified connection ID and database schema.
56	Clean up database hook after it was used, specifically handling PostgreSQL database notices by logging them if they exist.
57	Reserves a free TCP port for Cloud SQL Proxy by creating a socket bound to localhost with port 0, then retrieves the assigned port number.
58	Normalizes a Machine Learning Engine job ID by replacing invalid characters with underscores and adding a leading 'z_' prefix if the job ID starts with a digit or template.
59	Extract error code from FTP exception by matching error code pattern and converting to integer, returning original exception if conversion fails.
60	Remove any existing DAG runs for the perf test DAGs by querying and deleting records from the DagRun table that match the specified DAG IDs.
61	Remove any existing task instances for the perf test DAGs by querying and deleting them from the database session.
62	Set the pause state of DAGs in the test by toggling the `is_paused` attribute for all DAGs specified in `DAG_IDS` and commit the changes to the database.
63	Print operational metrics for the scheduler test, including performance data for successful task instances and warnings for incomplete ones.
64	Override the scheduler heartbeat to determine when the test is complete. It queries for successful task instances, calculates the total number of expected task instances based on DAG schedules, and when either all tasks are complete or maximum runtime is reached, it prints statistics, pauses the DAGs, and exits.
65	Invoke a Lambda function with the specified payload and configuration parameters, returning the invocation response.
66	Creates three chained operators for model evaluation: prediction, summary, and validation. The prediction operator performs batch prediction using Cloud ML Engine, the summary operator processes results using Dataflow, and the validation operator validates the summary using a provided validation function. Returns a tuple of the three operators.
67	Creates a directory and all intermediate directories with specified permissions, ignoring umask. If the directory already exists, does nothing. Handles potential OSError by re-raising only if the path is not an existing directory. Restores original umask in the finally block.
68	Converts a string to a float if possible, otherwise returns the original string.
69	Converts a naive datetime object to an aware datetime object in the specified timezone.

This function takes a naive datetime (without timezone information) and makes it timezone-aware by adding timezone information. It handles different timezone implementations (pytz, pendulum, or simple timezone objects) and raises a ValueError if the input datetime is already timezone-aware. The function also properly handles Python 3.6's 'fold' parameter for DST transitions.

Parameters:
- value: datetime object (must be naive)
- timezone: timezone object (defaults to TIMEZONE if None)

Returns:
- timezone-aware datetime object

Raises:
- ValueError: if input datetime is already timezone-aware
70	Converts an aware datetime object to a naive datetime object in the specified timezone.

Args:
    value (datetime): An aware datetime object to be made naive
    timezone (timezone, optional): The timezone to convert to. Defaults to TIMEZONE global variable.

Returns:
    datetime: A naive datetime object in the specified timezone

Raises:
    ValueError: If the input datetime is already naive

The function first validates that the input datetime is aware, then converts it to the specified timezone using astimezone(), and finally creates a new naive datetime object with the same date and time values but without timezone information.
71	Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified

Returns: datetime.datetime
72	Establishes a connection to a Druid broker using connection details from Airflow's connection manager and returns the connection object.
73	Returns an HTTP session for use with requests, configured with optional connection details and headers. The session includes base URL construction from connection parameters, authentication if provided, and additional headers from both connection extras and explicit headers parameter.
74	Performs an HTTP request to the specified endpoint with optional data, headers, and extra options, handling different HTTP methods appropriately and returning the response after processing.
75	Checks the HTTP response status code and raises an AirflowException for non-2XX or 3XX status codes, logging error details including response text for non-GET/HEAD requests.
76	Executes an HTTP request using the provided session and checks the response. Handles connection errors by logging a warning and re-raising the exception. Supports extra options for timeout, SSL verification, proxies, certificates, streaming, redirects, and response checking. Returns the response object.
77	Creates and tears down a database session with automatic commit, rollback, and cleanup handling.
78	A function decorator that automatically provides a database session to the decorated function if one is not already provided. If a session is passed as an argument, it uses the provided session. Otherwise, it creates a new session using `create_session()` and passes it to the function, ensuring the session is properly closed after use.
79	Clears the database by dropping all tables and removing migration versioning, then reinitializes the database.
80	Returns a formatted error message from a DatabaseError exception, extracting error name and message from the exception's message attribute when available, otherwise returns the string representation of the exception.
81	Get a set of records from Presto by executing HQL query with optional parameters, handling database errors by raising PrestoException with formatted error messages.
82	Get a pandas dataframe from a SQL query by executing the query and converting the results into a DataFrame with appropriate column names.
83	Execute a Presto SQL statement. Can be used to create views.
84	Inserts a set of tuples into a specified table with optional target fields mapping.
85	Return a Cosmos DB client, initializing one if it doesn't already exist.
86	Checks if a collection exists in CosmosDB by querying for a container with the specified collection name in the given database. Returns True if the collection exists, False otherwise. Raises AirflowBadRequest if collection_name is None.
87	Creates a new collection in the CosmosDB database if it doesn't already exist, raising an error if the collection name is None.
88	Checks if a database exists in CosmosDB by querying for a database with the specified name. Returns True if the database exists, False otherwise. Raises AirflowBadRequest if database_name is None.
89	Creates a new database in CosmosDB if it doesn't already exist, raising an AirflowBadRequest exception if the database name is None.
90	Deletes an existing database in CosmosDB by calling the DeleteDatabase method with the database link obtained from the database name. Raises AirflowBadRequest if the database name is None.
91	Deletes an existing collection in the CosmosDB database after validating that the collection name is not None. Raises AirflowBadRequest if collection name is None. Uses the internal connection to execute the deletion operation.
92	Inserts a list of new documents into an existing CosmosDB collection, raising an exception for empty documents and returning the created documents.
93	Delete an existing document from a CosmosDB collection using the specified document ID, with optional database and collection name parameters. Raises AirflowBadRequest if no document ID is provided.
94	Get a document from an existing collection in the CosmosDB database by document ID, returning None if the document is not found.
95	Get a list of documents from an existing collection in the CosmosDB database via SQL query. Raises AirflowBadRequest if SQL query string is None. Returns list of documents or None if HTTP failure occurs.
96	Returns a Cloud Function object by name using the Google Cloud Functions API.
97	Creates a new Cloud Function in the specified location using the provided body parameters, waits for the operation to complete, and returns None.
98	Updates a Cloud Function using the specified update mask by making a PATCH request to the cloud functions API and waiting for the operation to complete.
99	Uploads a zip file containing function sources to Google Cloud Functions.

This function generates an upload URL using the `generateUploadUrl` API method and then uploads the specified zip file to that URL. The upload includes appropriate headers to specify the content type as application/zip and sets the content length range. The function returns the upload URL that was generated.

Parameters:
- location (str): The location where the function will be created
- zip_path (str): Path to the .zip file containing the function sources
- project_id (str, optional): Google Cloud Project ID. Uses default if not provided

Returns:
- str: The upload URL returned by generateUploadUrl method

The function handles the complete upload process including URL generation and file transmission to Google Cloud Functions.
100	Deletes a specified Cloud Function by name and waits for the deletion operation to complete.
101	Returns dependency statuses for a task instance, with global checks for all dependencies. Handles cases where all dependencies or task dependencies should be ignored based on the dependency context. Yields dependency status objects from the private _get_dep_statuses method.
102	Returns whether the dependency is met for a given task instance by checking if all dependency statuses are passing.
103	Returns an iterable of strings explaining why this dependency wasn't met for a given task instance.
104	Parses an S3 configuration file to extract credentials in various formats (boto, s3cmd, AWS SDK). Supports specifying a profile for AWS format configs. Returns access key and secret key as a tuple. Raises AirflowException if file cannot be read or if credentials are missing/invalid.
105	Get the underlying `botocore.Credentials` object containing access_key, secret_key, and token attributes for the specified region.
106	Returns a Vertica connection object using connection details from Airflow's connection manager, configuring user, password, database, host, and port parameters.
107	Flushes all logging output by writing any buffered log messages to the logger and clearing the buffer.
108	Function that checks if a file path points to a zip archive and returns the archive path if it exists, otherwise returns the original file path.
109	Traverses a directory to find Python files, with optional safety checks for Airflow DAG definitions. It respects `.airflowignore` files for excluding paths, handles zip files, and can optionally include example DAGs. Returns a list of Python file paths that match the criteria.
110	Construct a TaskInstance from the database using the primary key components (dag_id, task_id, execution_date). Optionally locks the record for update if lock_for_update is True. Returns the TaskInstance object or None if not found.
111	Launches the DagFileProcessorManager processor and starts the DAG parsing loop in the manager.
112	Send termination signal to DAG parsing processor manager to stop all DAG file processors.
113	Helper method to clean up DAG file processors and exit gracefully upon receiving a signal by logging the exit, terminating processes, ending operations, and exiting with success status.
114	Starts the DAG file processing manager in either async or sync mode with specified parallelism and file processing intervals.
115	Parse DAG files repeatedly in a standalone loop, handling signals, refreshing DAG directory, processing files, updating statistics, and controlling loop timing.
116	Method: start_in_sync

Summary: Continuously parses DAG files in a loop controlled by DagParsingSignal. The method listens for agent heartbeat messages and processes DAG files when received. It refreshes the DAG directory, handles heartbeat signals, processes simple DAGs, updates statistics, and waits for completion. The loop terminates when receiving TERMINATE_MANAGER signal or when max runs are reached, sending appropriate completion signals back to the agent.
117	Refreshes DAG file paths from the DAG directory if the elapsed time since last refresh exceeds the specified interval, then updates file paths and clears old import errors.
118	Prints processing statistics at regular intervals to monitor file processing speed.
119	Clears import errors for files that no longer exist by filtering out errors whose filenames are not in the current file paths and deleting them from the database.
120	This method logs statistics about the processing of DAG definition files. It collects and formats information such as file paths, process IDs, current runtime, last runtime, and last run timestamps for each file. The stats are sorted by last runtime duration and displayed in a tabulated format along with metrics sent to Stats. The method helps monitor the performance and execution status of DAG file processing in Airflow.
121	Update file paths and clean up processors for deleted files.
122	Waits until all processors are finished by sleeping in a loop until each processor's done flag is True.
123	This method periodically processes DAG definition files by managing a pool of processors. It identifies finished processors, collects resulting SimpleDags, and starts new processors for queued file paths, while handling process limits and zombie detection. Returns a list of newly created SimpleDags from finished processing cycles.
124	Summary: The `end` method terminates all child processes when the parent process exits to prevent orphaned processes. It first attempts to terminate processes gracefully using SIGTERM with a 5-second timeout, then resorts to SIGKILL for any remaining processes that didn't terminate. The method ensures it only targets actual child processes by checking process ownership and uses logging to track the termination process.
125	Creates and configures an SSH client connection to a remote host using paramiko, handling host key verification, authentication, and connection parameters. Returns the configured SSH client object.
126	Creates a transfer job that runs periodically by making a request to the storage transfer service API with the provided body parameters, injecting the project ID if necessary, and executing the request with specified retry attempts. Returns the created transfer job details as a dictionary.
127	Gets the latest state of a long-running operation in Google Storage Transfer Service by calling the transferJobs().get() API method with the specified job name and project ID, then executes the request with the configured number of retries. Returns the Transfer Job as a dictionary.
128	Lists long-running operations in Google Storage Transfer Service that match the specified filter, returning a list of transfer jobs.
129	Updates a periodic transfer job with the specified job name and request body, injecting project ID if necessary, and returns the updated TransferJob object.
130	Deletes a transfer job using a soft delete approach, marking it for garbage collection after 30 days. Takes a job name and optional project ID as parameters, returns None.
131	Cancels a transfer operation in Google Storage Transfer Service by calling the transferOperations().cancel() API endpoint with the specified operation name and executes it with the configured number of retries.
132	Pauses a transfer operation in Google Storage Transfer Service by calling the transferOperations.pause() API endpoint with the specified operation name and retry configuration.
133	Resumes a transfer operation in Google Storage Transfer Service by calling the resume API endpoint with the specified operation name and retry configuration.
134	Waits for a transfer job to reach an expected status state, polling periodically until timeout is reached. Returns when job reaches expected status or raises AirflowException on timeout.
135	Returns all task reschedules for a given task instance and try number, ordered by ID in ascending order.
136	Returns the number of available slots by subtracting used slots (running and queued tasks) from total slots in the pool.
137	Runs a shell command and returns its stdout. If the command fails (non-zero exit code), raises an AirflowConfigException with error details including the command, return code, output, and stderr. Uses subprocess to execute the command safely with proper encoding handling.
138	Remove an option from either the main configuration or default configuration (or both) if it exists in the specified section.
139	Returns the section as a dictionary with value type conversion. Values are converted to int, float, bool as required. Environment variables with the section prefix are also considered. Returns None if section doesn't exist.
140	Allocate IDs for incomplete keys using the Cloud Datastore API and return a list of full keys.
141	Begins a new transaction by calling the Cloud Datastore API's beginTransaction endpoint and returns the transaction handle.
142	Commit a transaction in Google Cloud Datastore by sending a commit request with the specified body and return the response.
143	Lookup entities by key using the Datastore REST API, supporting read consistency options and transactions. Takes a list of keys and optional read consistency or transaction parameters, makes a lookup request to the Google Cloud Datastore API, and returns the response body containing the found entities.
144	Rolls back a specified transaction by making a REST API call to the Cloud Datastore rollback endpoint, using the provided transaction ID and connection parameters.
145	Runs a query for entities using the Datastore API and returns the batch of query results.
146	Gets the latest state of a long-running operation by calling the Cloud Datastore operations API endpoint with the specified operation name and returns the operation resource as a dictionary.
147	Deletes a long-running operation resource by name and returns the response from the API call.
148	Polls a backup operation's state at specified intervals until completion. Returns the final operation result when state is no longer 'PROCESSING'.
149	Exports entities from Cloud Datastore to a specified Cloud Storage bucket with optional filtering and labeling. Returns a resource operation instance representing the export job.
150	Import a backup from Cloud Storage to Cloud Datastore using the Admin API, specifying bucket, file, and optional filtering/labeling parameters, and return the operation resource.
151	Publish a message to a specified topic or endpoint using the provided target ARN. The method takes a target ARN (either TopicArn or EndpointArn) and a message string, wraps the message in a JSON structure with 'default' key, and publishes it using the connection object. Returns the result of the publish operation.
152	Fetches the hostname using a configurable callable from config, falling back to `socket.getfqdn()` if no callable is configured.
153	Retrieves connection to Cloud Natural Language service.

Returns: Cloud Natural Language service object
Return type: google.cloud.language_v1.LanguageServiceClient
154	Analyzes named entities in text, returning entity types, salience, mentions, and other properties. Takes a document as input and optional parameters for encoding type, retry policy, timeout, and metadata. Returns an AnalyzeEntitiesResponse object containing the entity analysis results.
155	A convenience method that combines sentiment analysis, entity analysis, and syntax analysis features into a single call to the Natural Language API, returning annotated text results with specified features and optional configuration parameters.
156	Classifies a document into categories using the language API client. Takes a document parameter (either dict or Document type), optional retry, timeout, and metadata parameters, and returns an AnalyzeEntitiesResponse object. The method retrieves a client connection and delegates the classification task to the client's classify_text method.
157	Gets template fields for a specific operator class by importing the module and class, then retrieving the template_fields attribute. Raises RoleException if module, class, or template_fields cannot be found.
158	A role that allows including a list of template fields within text, useful for operator usage guides. It takes a class name as input, retrieves its template fields, and displays them as a comma-separated list of literal blocks. Returns a node containing the formatted template fields or an error message if the class name is invalid.
159	Dispose ORM database connections by closing the connection pool, removing the current session, and disposing the engine while resetting the global variables to None.
160	Adds DAGS_FOLDER, config directory, and PLUGINS_FOLDER to Python's sys.path if they are not already present, ensuring these Airflow subfolders are available on the classpath for module imports.
161	Checks if a Celery task has finished execution by pulling the result from XCom using the target task ID and returning whether the result is ready.
162	Return true if the ticket cache contains "conf" information incompatible with Sun Java Krb5LoginModule in Java6.
163	Transforms a SQLAlchemy model instance into a dictionary, converting datetime objects to ISO format strings. Returns None for None input, otherwise returns a dictionary with column names as keys and their values from the model instance.
164	Generator function that yields successive chunks of a specified size from a list of items, raising ValueError for non-positive chunk sizes.
165	Reduce an iterable by splitting it into chunks and applying a reducer function to each chunk sequentially.
166	Creates a dependency chain between tasks by setting downstream relationships in sequence.
167	Returns a pretty ascii table from tuples, with optional headers if namedtuple is used. Handles both string and integer data types with proper alignment.
168	Given a task instance, try number, and filename template, this function returns the rendered log filename by either using Jinja templating or Python string formatting. It parses the template string, creates a context with task information, and renders the filename accordingly.
169	Returns a Google Cloud Dataproc service object by authorizing and building the API client.
170	Waits for a Google Cloud Dataproc operation to complete by creating a DataProcOperation object and calling wait_for_done() on it.
171	Deep string coerce function that converts content or dictionary values to strings, throwing an exception for non-string/numeric types. It recursively processes lists, tuples, and dictionaries while maintaining JSON path tracking for error reporting. Used to ensure JSON fields contain only string values for template rendering compatibility.
172	Handles Airflow + Databricks lifecycle for a Databricks operator by managing run execution, monitoring status, and handling success/failure cases with proper logging and XCom pushing.
173	Run a Pig script using the Pig CLI by creating a temporary file, executing the Pig command with optional properties, and returning the output. If verbose is True, logs the command and output lines. Raises an AirflowException if the Pig command fails.
174	Fetch and return the state of a given Celery task with timeout protection, returning either a tuple of (task_key, state) or an ExceptionWithTraceback object containing the error details.
175	Returns the number of Celery tasks each worker process should send, calculated by dividing the total tasks by parallelism and rounding up, with a minimum value of 1.
176	Returns the number of Celery tasks to send to each worker process, calculated as the total number of tasks divided by the parallelism factor, with a minimum value of 1.
177	Returns the current value for a key from Variable storage, or sets and returns a default value if the key doesn't exist. If the key exists, returns its current value; if not, stores the default value and returns it. Raises ValueError if no default is provided. Supports JSON serialization based on the deserialize_json parameter.
178	Returns a Google MLEngine service object initialized with authorized HTTP connection.
179	Creates and launches a MLEngine job, waiting for it to reach a terminal state. If a job with the same ID already exists, it either reuses it (if no validation function is provided or the validation passes) or raises an error. Returns the job object once it reaches a terminal state (including FAILED or CANCELLED).
180	Gets a MLEngine job by project ID and job ID, with retry logic for quota failures. Returns the job object or raises HttpError.
181	Waits for a job to reach a terminal state (SUCCEEDED, FAILED, or CANCELLED) by periodically checking its state with specified interval between checks. Raises ValueError if interval is not positive. Returns the final job object when terminal state is reached.
182	Creates a version on Google Cloud ML Engine and returns the operation status. The method constructs a request to create a version under a specified project and model, then polls the operation status using exponential backoff until completion or error. Returns the final operation response after successful creation.
183	Sets a specified version as the default for a given project and model, blocking until the operation completes. Returns the response on success or raises an HttpError on failure.
184	Lists all available versions of a specified model in a project, handling pagination to retrieve all versions. Returns a list of version objects.
185	Deletes a specified version of a model and waits for the operation to complete, returning the final status after polling with exponential backoff.
186	Create a Model and block until the operation is finished. Raises ValueError if model name is empty. Returns the result of the create operation.
187	Gets a Model by project ID and model name, blocking until completion. Raises ValueError if model_name is empty. Returns the model data or None if not found.
188	Writes batch items to a DynamoDB table using batch_writer with provisioned throughput capacity, returning True on success or raising AirflowException on failure.
189	Integrates plugins into the execution context by adding executor modules to system modules and global namespace.
190	Creates and returns a singleton instance of the configured executor, initializing it only if it doesn't already exist. The executor is retrieved from configuration and logged for debugging purposes.
191	Creates a new instance of the specified executor by name, checking built-in executors first and then looking for plugin executors if needed.
192	Handles error callbacks for Segment integration by logging the error and raising an AirflowException.
193	Returns a Microsoft SQL Server connection object using connection details from Airflow's connection manager and pymssql library.
194	Trigger a new DAG run with optional run_id, configuration, and execution date parameters. Handles JSON data parsing, validates execution date format, and manages Airflow exceptions with appropriate HTTP responses. Returns success message with created DAG run information.
195	Delete all database records related to a specified DAG. Returns a JSON response with the number of removed records or an error message if the operation fails.
196	Returns a JSON response containing a task's public instance variables as key-value pairs, where keys are field names and values are their string representations. If the task cannot be found, it logs the error and returns a JSON error response with the appropriate status code.
197	Get all pools and return them as JSON, or return an error response if an AirflowException occurs.
198	Create a pool by retrieving JSON parameters from the request and calling the pool API. If an AirflowException occurs, log the error and return a JSON response with the error message and status code. Otherwise, return the pool data in JSON format.
199	Delete a pool by name and return pool information or error response.
200	Creates or updates a container group with the specified properties in the given resource group.
201	Get the state and exitcode of a container group, returning a tuple with (state, exitcode, details). If exitcode is unknown, returns 0.
202	Get the messages of a container group by retrieving its instance view events.

**Parameters:**
- `resource_group` (str): The name of the resource group
- `name` (str): The name of the container group

**Returns:**
- list[str]: A list of event messages from the container group's instance view
203	Get the tail from logs of a container group and return a list of log messages.

**Parameters:**
- resource_group (str): The name of the resource group
- name (str): The name of the container group
- tail (int): The size of the tail (default: 1000)

**Returns:**
- list[str]: A list of log messages
204	Delete a container group by calling the delete method on the container_groups resource with the specified resource group and name parameters.
205	Test if a container group exists in a resource group by iterating through all container groups and checking for a match.
206	Function decorator that fills unspecified arguments from default_args and provides detailed error messages for missing required arguments.
207	Constructs an ingest query for loading data from HDFS TSV files into Druid. The query includes configuration for data schema, parsing specifications, granularity, metric and dimension definitions, tuning parameters, and input specifications. It handles backward compatibility between `num_shards` and `target_partition_size`, sets default values when necessary, and incorporates optional job properties and Hadoop dependencies. Returns a dictionary representing the complete ingest query structure.
208	Check for messages on subscribed Redis channels and write the message to XCom with key 'message'. Returns True if a message is available, False otherwise.
209	Returns a set of dag runs for the given search criteria, allowing filtering by dag_id, run_id, execution_date, state, external_trigger, and backfill options.
210	Returns the task instances for this dag run, filtered by optional state and partial DAG settings.
211	Returns the task instance specified by task_id for this dag run by querying the TaskInstance model with the dag_id, execution_date, and task_id filters.
212	Returns the previous DagRun instance for the same DAG that occurred before the current execution date, or None if no previous DagRun exists.
213	Returns the previous SCHEDULED DagRun for the current dag run, if one exists.
214	Updates the state of a DagRun based on the state of its TaskInstances, determining if the run is successful, failed, or still running.
215	Verifies DagRun integrity by checking for removed or missing tasks. It marks tasks as removed if they no longer exist in the DAG, restores tasks previously marked as removed if they're back in the DAG, and creates TaskInstance records for missing tasks in the DAG.
216	Function `jenkins_request_with_headers` executes a Jenkins request and returns both the response body and headers. It accepts a Jenkins server object and a request object as parameters. The function handles various exceptions including HTTP errors (401, 403, 404, 500), timeouts, and URL errors, converting them to specific Jenkins exceptions. The return value is a dictionary containing the decoded response body and the response headers.
217	Given a context, this function returns a dictionary of Airflow context variables that can be used to reconstruct relationships between DAGs, DAG runs, tasks, and task instances. The keys can be formatted in either 'abc.def.ghi' format (default) or 'ABC_DEF_GHI' format based on the in_env_var_format parameter. The function extracts and returns values for DAG ID, task ID, execution date, and DAG run ID from the provided context.
218	This function conditionally triggers a remote DAG based on a parameter value. It retrieves a condition parameter from the context, checks if it's truthy, and if so, sets up the DAG run payload with a message from the parameters and returns the configured dag_run_obj. If the condition is false, the function implicitly returns None, preventing the trigger.
219	Sends a single datapoint metric to DataDog with optional tags, type, and interval parameters, then validates and returns the response.
220	Queries Datadog for a specific metric within a time range and returns the results.

**Parameters:**
- `query` (str): The Datadog query to execute
- `from_seconds_ago` (int): Start time in seconds ago
- `to_seconds_ago` (int): End time in seconds ago

**Returns:** 
- Metric query response data

**Notes:**
- Uses current time as reference point
- Validates response before returning
- Time range is calculated as [now - from_seconds_ago, now - to_seconds_ago]
221	Retrieves a DAG from the dictionary, refreshing it if expired. For subdags, it refreshes the parent DAG instead. If the DAG is missing or expired, it reprocesses the source file and updates the DAG dictionary accordingly. Returns the requested DAG or None if not found.
222	Method: kill_zombies

Summary: Marks zombie tasks as failed by handling their failure with a specific error message indicating they were detected as zombies. The method iterates through provided zombie task instances, validates their existence in the current DagBag, and calls handle_failure on each task instance to update its state and log the zombie killing action. Finally, it commits the database session.

Parameters:
- zombies: List of zombie task instances to kill
- session: Database session (optional)

Returns: None

Side effects: Updates task instance states in the database, logs zombie killing actions, and increments a statistics counter.
223	Adds a DAG to the bag and recursively processes its subdags, detecting cycles and handling exceptions during DAG loading.
224	Collects DAGs from a specified folder by searching for Python modules, importing them, and adding them to the dagbag collection. It processes each Python file in the directory, measures loading time, and records statistics. Supports safe mode and example DAG inclusion based on configuration. Ignores files matching patterns in `.airflowignore` files. Logs performance metrics and import errors.
225	```python
def dagbag_report(self):
    """Prints a report around DagBag loading stats"""
    report = textwrap.dedent("""\n
    -------------------------------------------------------------------
    DagBag loading stats for {dag_folder}
    -------------------------------------------------------------------
    Number of DAGs: {dag_num}
    Total task number: {task_num}
    DagBag parsing time: {duration}
    {table}
    """)
    stats = self.dagbag_stats
    return report.format(
        dag_folder=self.dag_folder,
        duration=sum([o.duration for o in stats]),
        dag_num=sum([o.dag_num for o in stats]),
        task_num=sum([o.task_num for o in stats]),
        table=pprinttable(stats),
    )
```

Summary: Generates a formatted report showing DagBag loading statistics including number of DAGs, total tasks, parsing time, and detailed parsing stats table.
226	Add or subtract days from a YYYY-MM-DD date string.

:param ds: anchor date in ``YYYY-MM-DD`` format to add to
:type ds: str
:param days: number of days to add to the ds, you can use negative values
:type days: int

>>> ds_add('2015-01-01', 5)
'2015-01-06'
>>> ds_add('2015-01-06', -5)
'2015-01-01'

Returns the resulting date as a string in YYYY-MM-DD format.
227	Function that converts date strings from one format to another using datetime parsing and formatting. Takes an input date string, parses it according to input_format, and returns it formatted according to output_format.
228	Method: `poke(self, context)`

Summary: 
Pokes a directory to check if it contains files matching a specified regex pattern. Returns a boolean value indicating whether matching files were found. The method lists files in the specified directory, filters for regular files that match the regex pattern (after removing the directory path prefix), applies additional filtering for ignored extensions and file size constraints, and returns True if any matching files remain after all filters are applied.
229	Method: poke

Summary: Checks if a directory exists and meets specific criteria based on whether it should be empty or non-empty. For empty directories, it verifies the directory path exists with exactly one item (the directory itself). For non-empty directories, it checks that there's at least one file (excluding the directory entry) and that the first file entry is of file type 'f'.

Parameters: context (context object)

Returns: Boolean value indicating whether the directory meets the specified criteria

Side effects: Logs information about the poke operation using self.log.info
230	Clears a set of task instances, setting running ones to SHUTDOWN state and others to NONE state. If activate_dag_runs is True, also activates associated DAG runs. Returns job IDs of running tasks that were shut down.
231	Return the try number for when this task will actually run, incrementing by 1 if not currently running.
232	Generates a shell command to execute a task instance with specified parameters like DAG ID, task ID, execution date, and various execution options such as marking success, ignoring dependencies, running locally, etc.
233	Get the current state of a task instance from the database by querying with the dag_id, task_id, and execution_date. If a session is provided, use it for the query; otherwise, create a new session. Return the state if found, otherwise return None.
234	Forces the task instance's state to FAILED in the database by setting the state attribute to State.FAILED, merging the instance into the session, and committing the transaction while logging the failure.
235	Refreshes the task instance from the database using the primary key, updating all instance attributes with the latest values. Optionally locks the record for update. Returns the updated task instance or None if not found.
236	Clears all XCom data from the database for the specific task instance based on dag_id, task_id, and execution_date.
237	Returns a tuple containing (dag_id, task_id, execution_date, try_number) that uniquely identifies the task instance.
238	Checks whether all dependent tasks of this task instance have completed successfully. Returns True if there are no dependents or if all dependents have succeeded, False otherwise. Used by wait_for_downstream to ensure downstream tasks complete before processing the next schedule.
239	Get the datetime for the next retry attempt with exponential backoff support, calculating delay based on try number and task configuration.
240	Checks if the task instance is ready for retry by verifying it's in UP_FOR_RETRY state and the next retry time has passed.
241	Returns True if the task's pool has no open slots available, False otherwise. Checks if the task has a pool assigned, queries the pool database to find the pool by name, and then determines if there are open slots using the pool's open_slots method. If no pool is found or the pool has no open slots, returns True indicating the pool is full.
242	Returns the DagRun object for this TaskInstance by querying the database using the dag_id and execution_date filters.
243	Pushes a value to XCom with the specified key for tasks to pull. The value is pickled and stored in the database. Optionally, an execution date can be provided to delay visibility of the XCom until that date. Raises a ValueError if the execution_date is in the past.
244	Pulls XCom values based on specified criteria, returning the most recent matching value(s) for given task(s) and key, with options to include prior dates and filter by DAG.
245	Initializes the run context with optional raw mode setting and context configuration.
246	Closes the logger, uploads the local log file to remote storage (Wasb), and optionally deletes the local copy. Prevents multiple uploads by checking if the logger is already closed. Reads the local log file, appends its contents to the remote file, and removes the local directory if configured to do so.
247	Retrieves connection to Google Compute Engine.

Returns:
    Google Compute Engine services object (dict)
248	Starts an existing Compute Engine instance in Google Cloud Platform and waits for the operation to complete. Takes zone, resource_id, and optional project_id as parameters, makes an API call to start the instance, and then waits for the operation to finish. Raises AirflowException if the response doesn't contain the expected 'name' field.
249	Sets the machine type of a Compute Engine instance by executing the setMachineType API call and waiting for the operation to complete. Takes zone, resource_id, and body parameters (with optional project_id) and returns None after successful completion.
250	Retrieves an instance template by project ID and resource ID from Google Cloud Platform, using the Compute Engine API. Accepts keyword arguments only. Returns the instance template as a dictionary object matching the Compute Engine API v1 instanceTemplates format. Uses the default project ID from the GCP connection if none is provided.
251	Inserts an instance template using the provided body specification and waits for the operation to complete. Accepts optional request_id for idempotence and project_id for specifying the Google Cloud Platform project. Returns None after successful insertion and waiting.
252	Retrieves an Instance Group Manager resource from Google Cloud Platform by project ID, zone, and resource ID, returning its representation as a dictionary object.
253	Patches an Instance Group Manager with the specified body and waits for the operation to complete. Takes zone, resource_id, and body as required parameters, plus optional request_id and project_id. Returns None after successful patching and operation completion.
254	Waits for a GCE operation to complete by polling its status. Returns successfully when operation reaches DONE status, raises AirflowException if the operation fails with error details. Handles both global and zone-specific operations.
255	Check if a bucket exists by attempting to head the bucket. Returns True if successful, False otherwise while logging any error messages.
256	Creates an Amazon S3 bucket in a specified region, handling the special case of 'us-east-1' which doesn't require a LocationConstraint parameter.
257	Checks if a given prefix exists in a specified bucket by first ensuring the prefix ends with the delimiter, then splitting the prefix to get the previous level, listing prefixes at that level, and finally checking if the full prefix exists in the listed prefixes. Returns True if the prefix exists, False otherwise.
258	Lists prefixes in a bucket under a specified prefix with optional delimiter and pagination parameters. Returns a list of prefix strings if results are found, otherwise returns None.
259	Lists keys in an S3 bucket with specified prefix and delimiter, supporting pagination and limiting maximum items returned.
260	Checks if a key exists in an S3 bucket. Returns True if the key exists, False otherwise. If no bucket name is provided, it parses the S3 URL to extract the bucket name and key. Logs any error messages encountered during the check.
261	Returns a boto3.s3.Object for the specified key and bucket name by loading the object from S3.
262	Reads a key from S3 and returns its content as a UTF-8 decoded string.
263	Method: select_key

Summary: Reads an S3 key using S3 Select to retrieve a subset of data based on a query expression. The method supports CSV serialization by default and parses S3 URLs when bucket name is not provided. It returns the decoded payload from the S3 Select response as a string.

Parameters:
- key (str): S3 key pointing to the file
- bucket_name (str, optional): Name of the bucket containing the file
- expression (str): S3 Select expression (defaults to 'SELECT * FROM S3Object')
- expression_type (str): S3 Select expression type (defaults to 'SQL')
- input_serialization (dict, optional): Input data serialization format (defaults to CSV)
- output_serialization (dict, optional): Output data serialization format (defaults to CSV)

Returns: str - Retrieved subset of original data from S3 Select operation

See Also: S3 Select API documentation for parameter details
264	Checks if a key matching a wildcard expression exists in a bucket. Returns True if the key exists, False otherwise.
265	Returns a boto3.s3.Object object matching the wildcard expression by first parsing the S3 URL to extract bucket name and key, then listing keys with the given prefix, and finally filtering the matching keys using fnmatch.
266	Loads a local file to S3 with optional encryption and overwrite protection.
267	Loads a string to S3 by encoding it and using the existing load_bytes method to handle the actual upload process.
268	Loads bytes data to S3 with optional encryption and replacement controls. Takes bytes data, S3 key, and bucket name as required parameters, with optional flags for replacing existing keys and server-side encryption. Uses boto client to upload the data. Raises ValueError if key exists and replace=False. Returns None.
269	Loads a file-like object to S3 with optional encryption and overwrite protection.
270	Copies an object from a source S3 location to a destination S3 location. The method accepts either full S3 URLs or relative paths for both source and destination, automatically parsing URLs when needed. It supports specifying source version IDs for versioned objects. The S3 connection must have access to both buckets. Returns the response from the S3 copy operation.
271	Queries Cassandra using the configured connection and CQL statement, returns a cursor to the query results.
272	Converts a user type to a RECORD format with n fields by converting each attribute to its corresponding BQ data type.
273	Send an email with HTML content using SendGrid, supporting attachments, CC, BCC, sandbox mode, and custom arguments.
274	Retrieves a connection to Google Cloud Speech service, creating and caching a SpeechClient instance if one doesn't already exist. Returns the SpeechClient object for interacting with the Cloud Speech API.
275	Method: recognize_speech

Summary: 
Recognizes audio input using Google Cloud Speech-to-Text API. Takes audio data and recognition configuration as parameters, sends them to the speech recognition service, and returns the transcription results. Supports optional retry and timeout configurations for the API request.

Parameters:
- config: Recognition configuration specifying how to process the request (RecognitionConfig object or dict)
- audio: Audio data to be recognized (RecognitionAudio object or dict)
- retry: Optional retry object for handling request retries
- timeout: Optional timeout value in seconds for the request

Returns: Recognition response containing the transcribed text

Side effects: Logs the recognized speech result and returns the API response object
276	Executes a Spark SQL query by initializing a SparkSqlHook with provided parameters and running the query.
277	Load AirflowPlugin subclasses from entrypoints and ensure no duplicates are loaded.
278	Check whether a potential object is a valid subclass of AirflowPlugin class, ensuring it's not the base AirflowPlugin class itself, has passed validation, and is not already in the existing plugins list.
279	Sets task instances to skipped state for a given DAG run or execution date. If a DAG run is provided, updates existing TaskInstance records in the database. If no DAG run exists, creates new TaskInstance records with skipped state. Handles both cases with appropriate session management and commit operations.
280	Return an AzureDLFileSystem object by establishing a connection using Azure credentials and account information from the connection settings.
281	Check if a file exists on Azure Data Lake by attempting to glob the file path. Returns True if exactly one file is found, False otherwise. Handles FileNotFoundError exceptions by returning False.
282	Upload a file or files to Azure Data Lake using multithreading.

This method uploads files from a local path to a specified remote path in Azure Data Lake. It supports uploading single files, entire directories recursively, or using glob patterns. The upload process utilizes multiple threads for improved performance and allows customization of buffer and block sizes for optimal transfer performance.

Parameters:
- local_path: Local file, directory, or glob pattern to upload
- remote_path: Target location in Azure Data Lake (directory for multiple files)
- nthreads: Number of threads to use for uploading (default 64)
- overwrite: Whether to overwrite existing files (default True)
- buffersize: Internal buffer size in bytes (default 4194304)
- blocksize: Block size in bytes for each API call (default 4194304)

The method internally uses ADLUploader from the multithread module to handle the actual upload process with the provided configuration.
283	List files in Azure Data Lake Storage using the specified path, supporting both glob patterns (with *) and direct paths.
284	Execute a Presto query on Athena by connecting to the hook, running the query with specified parameters, and polling the query status. Raise exceptions if the query fails or exceeds maximum retry attempts.
285	Uncompress gz and bz2 files by reading compressed data and writing to a temporary uncompressed file in the specified destination directory. Returns the path of the created uncompressed file. Raises NotImplementedError for unsupported file extensions.
286	Queries MSSQL database using provided connection ID and SQL statement, returns a cursor object with results.
287	A decorator that adds action logging to CLI functions, executing pre-execution and post-execution logging callbacks with detailed metrics including command information, timing, user details, and optional execution context.
288	Builds a metrics dictionary from function arguments containing CLI command information, including sub-command, start datetime, full command, user, DAG ID, task ID, execution date, and hostname. Creates a log entry with this information and returns the complete metrics dictionary.
289	Create a cgroup at the specified path by recursively navigating/creating directories in the cgroup hierarchy. Returns the Node associated with the final cgroup in the path.
290	Delete the specified cgroup at the given path by traversing the cgroup tree structure and removing the leaf node. If any element in the path doesn't exist, log a warning and return without deleting.
291	The `_parse_host` function is designed to robustly handle improper host connection settings by extracting and returning only the hostname portion from a given host string. It uses `urlparse.urlparse()` to parse the host and retrieve the hostname, effectively stripping out protocols (like "https://") when present. If the host string doesn't contain a protocol, it returns the host unchanged. This ensures that both formatted URLs like "https://xx.cloud.databricks.com" and plain hostnames like "xx.cloud.databricks.com" are properly normalized to just the hostname component.
292	Performs an API call with retries, handling both token and basic authentication. Supports GET and POST methods, parses the response as JSON on success, and raises AirflowException on failure after retry limits are exceeded.
293	Returns a Salesforce connection, establishing one if not already connected.
294	Make a query to Salesforce and return the results.

**Parameters:**
- `query` (str): The query to make to Salesforce

**Returns:**
- dict: The query result containing totalSize and done status

**Example:**
```python
results = make_query("SELECT Id, Name FROM Account")
# Returns: {'totalSize': 100, 'done': True, ...}
```
295	Get the description/schema of a Salesforce object including metadata.
296	Get a list of all available fields for a Salesforce object by describing the object and extracting field names.
297	Get all instances of a Salesforce object with specified fields.

This method constructs a SOQL query to retrieve data from Salesforce by:
- Taking an object name and fields as parameters
- Building a SELECT query string with the specified fields and object
- Logging the query (showing truncated version if too long)
- Executing the query through make_query() and returning results

Parameters:
- obj (str): Salesforce object name to query
- fields (iterable): Fields to retrieve from the object

Returns:
- dict: Query results from Salesforce

Example: get_object_from_salesforce('Account', ['Id', 'Name', 'Email'])
298	Convert a dataframe column to UNIX timestamps, handling datetime conversion with error management and preserving original index.
299	Write query results to a file in CSV, JSON, or NDJSON format with optional datetime timestamp coercion and time tracking. Handles data type conversions, especially for datetime fields, and cleans string data for CSV output. Returns the dataframe that was written to file.
300	Returns a PyMongo Client connection, establishing it if necessary. If a client already exists, returns the existing one. Otherwise, creates a new client with SSL options configured if SSL is enabled, then returns the new client.
301	Fetches a MongoDB collection object for querying using the specified database or default connection schema.
302	Replaces multiple documents in a MongoDB collection using bulk operations. Takes a list of new documents and optional filter documents, performs ReplaceOne operations for each pair, and returns the bulk write result. If no filter documents are provided, uses the _id fields from the replacement documents as filters. Supports upsert functionality and additional MongoDB options through kwargs.
303	Checks a mail folder for emails containing attachments with a specified name, returning True if found and False if not.
304	Retrieves mail attachments from a specified mail folder by attachment name. Supports regex matching, latest-only retrieval, and configurable handling when no attachments are found. Returns a list of tuples containing attachment filenames and their payloads.
305	Downloads email attachments by name from a specified mail folder to a local directory. Supports regex matching, downloading only latest attachment, and configurable handling when no attachments are found.
306	Gets all attachments by name for the mail, optionally checking regex patterns and returning only the first match if specified. Returns a list of tuples containing attachment names and payloads.
307	Returns a tuple containing the part's filename and decoded payload by calling get_filename() and get_payload(decode=True) on the part object.
308	Write batch records to Kinesis Firehose and return the response.
309	Determines whether a task instance is ready to be rescheduled based on its state and reschedule requests. Returns a passing status if the task is not in a reschedulable state, has no reschedule requests, or is ready for reschedule. Returns a failing status if the task is not ready for reschedule but will be automatically rescheduled in the future.
310	Send an email using the backend specified in EMAIL_BACKEND configuration, with support for HTML content, file attachments, and optional CC/BCC recipients. The function handles email address parsing and supports dry run mode for testing.
311	Send an email with HTML content via SMTP, supporting attachments, CC, BCC, and dryrun mode.
312	Process DateTime values from database ensuring UTC timezone conversion, handling both timezone-naive and timezone-aware datetime objects by converting them to UTC timezone.
313	Check if a blob exists on Azure Blob Storage and return True if it exists, False otherwise.
314	Check if a prefix exists on Azure Blob storage by listing blobs with the specified prefix and returning True if any matches are found, False otherwise.
315	Upload a string to Azure Blob Storage.

**Parameters:**
- `string_data` (str): String to load
- `container_name` (str): Name of the container
- `blob_name` (str): Name of the blob
- `**kwargs`: Optional keyword arguments for `BlockBlobService.create_blob_from_text()`

**Returns:**
- None

**Side effects:**
- Creates/updates a blob in Azure Blob Storage with the provided string data
316	Read a file from Azure Blob Storage and return its content as a string.
317	Delete a file or multiple files (when using prefix) from Azure Blob Storage. If ignore_if_missing is False and no blobs are found, raises AirflowException. Logs each deletion operation.
318	Function `mlsd` lists directory contents using the MLSD command (RFC-3659) in a standardized format. It takes a connection object, optional path, and optional facts list. Returns a generator yielding tuples of (filename, facts_dictionary) for each file. The facts dictionary contains metadata like type, size, and permissions depending on the server and requested facts. Uses OPTS MLST to specify desired facts and handles both specified paths and current directory listing.
319	Returns an FTP connection object, establishing a new connection if one doesn't already exist.
320	Returns a list of files on the remote system from the specified directory path.
321	Transfers a remote file to a local location, writing to a file path or file-like buffer. If no callback is provided, data is written directly to the output handle; otherwise, the callback handles data processing and writing. The remote file path is split into directory and filename, the working directory is changed to the remote path, and the file is retrieved using the RETR command. If a file path is provided and an output handle is created, it is closed after the transfer.
322	Transfers a local file to a specified remote location via FTP. If the input is a file path, it reads from that location; if it's a file-like buffer, it reads from the buffer without closing it. The method handles the remote directory navigation and binary file upload using the FTP connection.
323	Returns a datetime object representing the last modification time of a remote file by parsing the MDTM command response.
324	Execute a Discord webhook notification by creating and calling a DiscordWebhookHook with specified parameters.
325	Return a FileService object initialized with connection details from the configured connection.
326	Check if a directory exists on Azure File Share and return True if it exists, False otherwise.
327	Check if a file exists on Azure File Share and return True if it exists, False otherwise.
328	Return the list of directories and files stored on a Azure File Share.
329	Create a new directory on an Azure File Share and return a list of files and directories.
330	Upload a file to Azure File Share using the specified file path, share name, directory name, and file name, with optional keyword arguments for additional configuration.
331	Uploads a string to Azure File Share.

**Parameters:**
- `string_data` (str): String to load
- `share_name` (str): Name of the share
- `directory_name` (str): Name of the directory
- `file_name` (str): Name of the file
- `**kwargs`: Optional keyword arguments for `FileService.create_file_from_text()`

**Returns:** None

**Side effects:** Creates a file in Azure File Share containing the provided string data
332	Uploads a stream to Azure File Share.

**Parameters:**
- `stream`: Opened file/stream to upload as the file content
- `share_name`: Name of the share
- `directory_name`: Name of the directory
- `file_name`: Name of the file
- `count`: Size of the stream in bytes
- `**kwargs`: Optional keyword arguments for `FileService.create_file_from_stream()`

**Returns:** None

**Side effects:** Creates a file in Azure File Share from the provided stream data
333	Returns a Google Cloud Storage service object, creating it if it doesn't already exist.
334	Copies an object from one bucket to another, with optional renaming of the destination bucket or object. Raises ValueError if both destination parameters are the same as source parameters or if source parameters are empty. Uses Google Cloud Storage client to perform the copy operation and logs the result.
335	Downloads a file from Google Cloud Storage. If filename is provided, writes the file to that local path and returns the file content as bytes. If no filename is provided, returns the file content as bytes.
336	Uploads a local file to Google Cloud Storage with optional gzip compression. The method takes a local file path and uploads it to the specified GCS bucket with the given object name and MIME type. If gzip=True, the file is compressed before upload and the temporary compressed file is deleted after upload. The method logs the successful upload operation.
337	Checks if a file exists in Google Cloud Storage by verifying the existence of a blob in the specified bucket. Returns True if the file exists, False otherwise.
338	Checks if a blob in Google Cloud Storage was updated after a given timestamp. Returns True if the blob's update time is later than the provided timestamp, False otherwise.
339	Deletes an object from the specified bucket using the GCS client. Takes bucket name and object name as parameters, retrieves the bucket and blob, then deletes the blob. Logs a success message upon completion.
340	List all objects from a bucket with optional filtering criteria.

Parameters:
- bucket_name (str): The name of the bucket to list objects from
- versions (bool): If True, list all versions of the objects
- max_results (int): Maximum count of items to return in a single page of responses
- prefix (str): Prefix string to filter objects by name
- delimiter (str): Delimiter to filter objects (e.g., '.csv')

Returns:
- list: A stream of object names matching the filtering criteria

The method uses the Google Cloud Storage client to list blobs with the specified parameters, handling pagination to collect all results. It supports listing all versions of objects, filtering by prefix, and using delimiters for object filtering.
341	Gets the size of a file in Google Cloud Storage by connecting to the bucket, retrieving the blob, and returning its size in bytes.
342	Gets the CRC32c checksum of an object in Google Cloud Storage by connecting to the client, retrieving the specified bucket and blob, reloading the blob to ensure latest data, and returning the CRC32c checksum value while logging the operation.
343	Gets the MD5 hash of an object in Google Cloud Storage by connecting to the client, retrieving the bucket and blob, reloading the blob to ensure current data, and returning the MD5 hash value while logging the operation.
344	Creates a new Google Cloud Storage bucket with specified parameters including name, storage class, location, and labels. Returns the bucket's ID on successful creation.
345	Composes a list of existing objects into a new object in the same storage bucket.

**Parameters:**
- `bucket_name` (str): The name of the bucket containing the source objects and storing the composed destination object
- `source_objects` (list): The list of source objects to be composed into a single object
- `destination_object` (str): The path of the destination object

**Raises:**
- `ValueError`: If source_objects is empty, or if bucket_name or destination_object is empty

**Notes:**
- Supports up to 32 objects in a single composition operation
- Uses Google Cloud Storage JSON API v1 objects/compose endpoint
- Logs the composition process and completion status
346	Returns True if a training job's secondary status message has changed between job descriptions.

The function compares the most recent secondary status messages from current and previous job descriptions. It extracts the last status message from the SecondaryStatusTransitions list in each description and returns True if they differ, False otherwise. If there are no secondary status transitions in the current description, it returns False. The function handles cases where previous job description or secondary status transitions might be None or empty.
347	Returns a formatted string containing the start time and secondary training job status messages by comparing current and previous job descriptions, showing only new status transitions.
348	Tar the local file or directory and upload to S3.

Parameters:
- path (str): local file or directory
- key (str): S3 key
- bucket (str): S3 bucket

Returns:
- None
349	Extract S3 operations from configuration and execute create bucket and upload operations using S3 hook.
350	Check if an S3 URL exists by verifying both the bucket and key/prefix exist in the bucket. Raises AirflowException if the bucket doesn't exist or if the key/prefix doesn't exist in the bucket. Returns True if the S3 URL is valid and exists.
351	Establishes an AWS CloudWatch Logs connection with retry configuration for training log retrieval. Returns a CloudWatchLogs.Client object.
352	Creates a training job with the specified configuration and optionally waits for completion, logging status updates during the process. Returns the response from the training job creation.
353	Create a hyperparameter tuning job with the given configuration and optionally wait for completion. Returns the response from the tuning job creation.
354	Create a transform job with optional waiting for completion and status checking.

Parameters:
- config (dict): The configuration for the transform job
- wait_for_completion (bool): Whether to wait for job completion (default: True)
- check_interval (int): Status check interval in seconds (default: 30)
- max_ingestion_time (int): Maximum execution time in seconds (default: None)

Returns:
- A response to the transform job creation

The method validates S3 URLs, creates the transform job, and optionally waits for completion while monitoring the job status.
355	Create an endpoint with optional waiting for completion and status checking.

**Parameters:**
- config (dict): The configuration for the endpoint
- wait_for_completion (bool): Whether to wait until the endpoint finishes creation (default: True)
- check_interval (int): Status check interval in seconds (default: 30)
- max_ingestion_time (int): Maximum allowed time in seconds before timeout (default: None)

**Returns:**
- A response to the endpoint creation request

**Behavior:**
Creates an endpoint using the provided configuration. If wait_for_completion is True, it will monitor the endpoint status until completion or timeout occurs. Returns the creation response immediately if waiting is disabled.
356	Describes a training job and prints its CloudWatch logs. It handles log stream creation, iterates through log events, and updates the training job status. Returns the updated state, description, and last describe job call time.
357	Check the status of a SageMaker job by periodically polling its state until completion or failure, with optional timeout enforcement.
358	Method: `check_training_status_with_log`

Summary: This method monitors and displays the logs for a specified SageMaker training job, optionally waiting for the job to complete. It tracks the job's status, manages log stream positions, and handles job completion or failure states. The method supports configurable polling intervals, maximum ingestion time limits, and provides detailed logging of the training job's progress and final billing information.

Key functionality:
- Displays training job logs with optional real-time tailing
- Manages log streams and positions during monitoring
- Implements state machine for job status checking (TAILING, JOB_COMPLETE, COMPLETE)
- Enforces maximum ingestion time limits
- Handles job completion and failure scenarios
- Calculates and logs billable training time
- Raises exceptions for jobs exceeding time limits or failing states
359	Execute a Python dataflow job by uploading the Python file to Google Cloud Storage, formatting Dataflow options from camelCase to snake_case, and starting the dataflow job using the DataFlowHook.
360	Run database migrations in offline mode by configuring context with URL and target metadata, then executing migrations within a transaction.
361	Run database migrations in online mode by creating a connection and executing migrations within a transaction.
362	Deletes the specified Cloud Bigtable instance. Raises google.api_core.exceptions.NotFound if the instance does not exist. If the instance exists, it calls the delete() method on the instance; otherwise, it logs an info message and exits.
363	Creates a new Bigtable instance with specified configuration including main and optional replica clusters, instance type, labels, and storage settings, then returns the created instance.
364	Creates a Cloud Bigtable table with the specified parameters, raising AlreadyExists if it already exists. Supports optional initial split keys and column families configuration.
365	Deletes the specified table in Cloud Bigtable. Raises google.api_core.exceptions.NotFound if the table does not exist.

**Parameters:**
- **instance_id** (str): The ID of the Cloud Bigtable instance
- **table_id** (str): The ID of the table in Cloud Bigtable  
- **project_id** (str, optional): Google Cloud Platform project ID where the BigTable exists. If None, uses default project from GCP connection

**Returns:** None

**Side effects:** Deletes the table from Cloud Bigtable storage
366	Updates the number of nodes in a specified Cloud Bigtable cluster. Takes an Instance object, cluster ID string, and desired number of nodes integer as parameters. Raises NotFound exception if cluster doesn't exist. Uses Cluster object to modify serve_nodes property and calls update() method to apply changes.
367	This function prepares a command list for executing Hive or Beeline CLI commands based on connection parameters and configuration settings. It determines whether to use Beeline instead of Hive, constructs JDBC URLs with appropriate authentication parameters (including Kerberos principal and proxy user settings), and builds the final command by combining the binary name, extra parameters, and hive parameters. The function handles various authentication methods including Kerberos and basic authentication, and properly formats the command for execution.
368	This function prepares a list of Hive configuration parameters from a dictionary of key-value pairs, formatted for use with Hive's command-line interface. It takes a dictionary `d` as input and returns a list of strings where each key-value pair is formatted as "-hiveconf key=value". If the input dictionary is empty, it returns an empty list. The function uses `as_flattened_list` and `zip` to efficiently create the parameter list.

Example:
```
{"hive.exec.dynamic.partition": "true", "hive.exec.dynamic.partition.mode": "nonstrict"}
 ["-hiveconf", "hive.exec.dynamic.partition=true", "-hiveconf", "hive.exec.dynamic.partition.mode=nonstrict"]
```
369	Loads a pandas DataFrame into a Hive table by converting it to CSV format and then loading it using a temporary file. Infers Hive data types from DataFrame dtypes if not explicitly provided, and supports custom delimiters, encoding, and additional pandas/pandas_kwargs parameters. Uses a temporary directory to manage the intermediate CSV file.
370	Loads a local file into a Hive table with optional table creation, partitioning, and overwrite capabilities. Supports custom field definitions, table properties, and can recreate the table on each execution. Uses textfile storage format and includes error handling for missing field dictionaries when creating tables.
371	Returns a Hive thrift client configured with appropriate authentication based on security settings. The method sets up a connection to the metastore using either Kerberos GSSAPI authentication or basic NOSASL authentication, depending on the configuration, and returns an HMSClient instance.
372	Checks whether a partition with a given name exists in a Hive table.

**Parameters:**
- `schema` (str): Name of hive schema (database) that table belongs to
- `table` (str): Name of hive table that partition belongs to  
- `partition_name` (str): Name of the partition to check for (eg `a=b/c=d`)

**Returns:**
- bool: True if partition exists, False otherwise

**Example:**
```python
hh = HiveMetastoreHook()
hh.check_for_named_partition('airflow', 'static_babynames_partitioned', "ds=2015-01-01")
# Returns: True
```
373	Check if a table exists in the specified database by attempting to retrieve it. Returns True if the table exists, False otherwise.
374	Returns a Hive connection object using the specified schema, handling authentication mechanisms like NONE, KERBEROS, and GSSAPI, and falling back to 'airflow' username when needed.
375	Get results of the provided HQL in target schema, returning a dictionary with data (list of results) and header.
376	Execute HQL in target schema and write results to a CSV file with specified formatting options.
377	Get a set of records from a Hive query by executing the provided HQL statement and returning the result data.

**Parameters:**
- `hql` (str or list): The HQL statement to be executed
- `schema` (str): Target schema name, defaults to 'default'
- `hive_conf` (dict): Additional Hive configuration options

**Returns:**
- list: The result data from the Hive execution

**Example:**
```python
hh = HiveServer2Hook()
sql = "SELECT * FROM airflow.static_babynames LIMIT 100"
records = hh.get_records(sql)
len(records)  # Returns 100
```
378	Get a pandas dataframe from a Hive query by executing HQL and converting results to DataFrame with proper column headers.
379	Retrieves a connection to the Cloud Vision service, returning a Google Cloud Vision client object. If a client already exists, it returns the existing one; otherwise, it creates a new client using the service credentials.
380	Get Dingding endpoint for sending message, constructs the API URL using the connection token from Airflow connection configuration.
381	Send Dingding message with validation of message type and error handling for failed sends.
382	Helper method that binds parameters to a SQL query by converting them to appropriate string representations, handling None values as 'NULL', strings with quotes, and other types as string conversions, then formats the operation string with these parameters.
383	Helper method that escapes parameters to a SQL query by replacing special characters with their escaped versions.
384	Helper method that casts a BigQuery row to the appropriate data types. This is useful because BigQuery returns all fields as strings. Converts string representations to their proper data types based on the specified BigQuery type, handling None values, integers, floats, timestamps, and booleans with appropriate validation.
385	Function to validate that a value has the expected type, raising a TypeError if the type is incorrect.
386	Returns a BigQuery PEP 249 connection object using the service, project, and configuration settings.
387	Returns a BigQuery service object by authorizing HTTP access and building the service with the 'bigquery' API version 'v2'.
388	Checks if a table exists in Google BigQuery by attempting to retrieve it and returning True if found, False if not found (HTTP 404), or raising the exception if it's a different error.
389	Creates a new empty table or view in a BigQuery dataset with optional schema, time partitioning, clustering, and labels. Accepts parameters for project ID, dataset ID, table ID, schema fields, time partitioning configuration, cluster fields, labels, view definition, and retry settings. Returns None upon successful creation.
390	Patch information in an existing BigQuery table by updating specified fields. The method constructs a table resource object with provided parameters and sends a patch request to the BigQuery API. It supports updating table properties such as description, expiration time, schema, labels, time partitioning, view definition, and partition filter requirements. The method only updates fields that are explicitly provided in the request, leaving other fields unchanged. Returns a success message upon successful patching or raises an AirflowException if the operation fails.
391	Cancel all started BigQuery queries that have not yet completed by attempting to cancel the running job, waiting for the cancellation to finish, and logging the status throughout the process.
392	Delete an existing table from a dataset. If the table doesn't exist and ignore_if_missing is False, raise an exception. If ignore_if_missing is True, log a message and continue. The table is specified by a dotted string in the format `<project>.<dataset>.<table>` or `<project>:<dataset>.<table>`.
393	Upserts a table in BigQuery by either updating an existing table or creating a new one if it doesn't exist. First checks if the table exists in the specified dataset, and if found, updates it; otherwise, creates a new table. This operation is not atomic as BigQuery doesn't natively support table upserts. Returns the result of the update or insert operation.
394	Grant authorized view access for a dataset to a view table, checking if access already exists and avoiding clobbering simultaneous updates. Returns the updated dataset resource.
395	Method returns dataset_resource if dataset exists, otherwise raises 404 error. Takes dataset_id (required str) and project_id (optional str) as parameters. Validates dataset_id is a non-empty string, uses default project_id if not provided. Makes API call to BigQuery datasets().get() method with retry logic, logs the dataset resource, and returns the resource. Raises AirflowException with error details if HttpError occurs during the API call.
396	Method that retrieves all BigQuery datasets in a specified project, returning a list of dataset objects with their metadata including location, ID, and references. Raises AirflowException if the BigQuery API request fails.
397	Inserts multiple rows into a BigQuery table using the insertAll API. Supports options to ignore unknown values, skip invalid rows, and fail on error. Logs insertion progress and errors, raising AirflowException on failure when configured to do so.
398	Executes a BigQuery query with optional parameters and returns the job ID.
399	Executes a BigQuery query multiple times with different parameters by iterating through a sequence of parameter dictionaries and calling execute() for each set of parameters.
400	Helper method for fetchone that returns the next row from a buffer, paginating through results when buffer is empty.
401	Queries Postgres and returns a cursor to the results.
402	Create all intermediate directories in a remote host using SFTP client, handling parent directories recursively if they don't exist.
403	Create a queue using the connection object with the specified name and attributes, returning queue information.
404	Send a message to an SQS queue with specified parameters including queue URL, message body, delay seconds, and message attributes. Returns the response from the SQS send_message operation.
405	Run the task command using subprocess with optional wrapper tokens and argument joining. Returns the process object.
406	Method `on_finish` is a callback that cleans up a configuration file after the object finishes running. If a configuration path exists and the file exists, it removes the file using either regular `os.remove` or `sudo rm` depending on whether the object is configured to run as a user. The method closes file descriptors after the removal process.
407	Parse command line options and process commands for nvd3 chart generation, including verbose output control.
408	Generate HTML header content by concatenating CSS and JavaScript assets, but only inject JavaScript assets once per session using a global initialization flag.
409	Generate HTML div with SVG element, setting width and height styles based on input parameters, and store the resulting HTML in self.container.
410	Method: `buildjschart`

Summary: Generates JavaScript code for creating a chart by building the chart data and tooltip functionality. The method initializes an empty JavaScript chart string, sets up a default tooltip condition if none was explicitly defined, and converts the chart series data into JSON format for JavaScript consumption.

Key operations:
- Initializes `self.jschart` as empty string
- Sets default tooltip condition string if not previously configured
- Converts `self.series` data to JSON format and stores in `self.series_js`
411	Creates an X-axis with optional formatting, labeling, and date handling capabilities, then adds it to the axis list. Supports custom formatting, AM/PM formatting, and date formatting with time formatting functions. Flags the axis as date type when appropriate and creates a secondary x-axis for focus enablement.
412	Create a Y-axis with optional label, formatting, and custom format settings, then add it to the axis list.
413	Returns a SQLite connection object by establishing a connection using the stored connection ID and host information.
414	A decorator that logs user actions by creating a log entry with event name, user information, and request parameters when the decorated function is called.
415	**Summary:**

A decorator function `gzipped` that compresses HTTP response data using gzip compression. It checks if the client accepts gzip encoding, and if so, compresses the response content and sets appropriate headers including `Content-Encoding: gzip`, `Vary: Accept-Encoding`, and updated `Content-Length`. The decorator wraps a Flask view function and applies compression only when the client supports it and the response is eligible for compression.
416	Returns the last dag run for a given dag_id, or None if none exists. Optionally filters out externally triggered runs.
417	Creates a dag run from this dag including the tasks associated with this dag. Returns the dag run.

**Parameters:**
- `run_id` (str): defines the run id for this dag run
- `execution_date` (datetime.datetime): the execution date of this dag run
- `state` (airflow.utils.state.State): the state of the dag run
- `start_date` (datetime.datetime): the date this dag run should be evaluated
- `external_trigger` (bool): whether this dag run is externally triggered
- `session` (sqlalchemy.orm.session.Session): database session

**Returns:**
- The created dag run object
418	Publishes a message to an SQS queue using the provided configuration and returns the result from the send_message operation.
419	Returns a JSON response from a JSON serializable Python object with proper formatting and status code.
420	Opens a file, treating paths with .zip suffixes as zip archives and opening files inside them. Returns a file object either from the standard `io.open` or from `ZipFile.open` depending on whether the path points to a zip archive.
421	Function to generate a unique cache key based on request path and arguments.
422	Returns the Gcp Video Intelligence Service client, creating it if it doesn't already exist.
423	Performs video annotation using the Video Intelligence API, supporting both URI and content-based inputs with various annotation features and optional cloud region specification.
424	Get Opsgenie API key from connection password for creating alerts, raising AirflowException if not found.
425	Method `get_conn` creates and returns a requests session configured with the base URL and headers from the HTTP connection. It retrieves connection details using `self.get_connection`, sets the base URL to either the connection host or a default Opsgenie API URL, and updates the session headers with any provided headers. The method overrides the parent HttpHook's get_conn to use only base_url and headers without generic parameters.
426	Execute the Opsgenie Alert call with the provided payload, using the API key for authorization and sending a POST request to the v2/alerts endpoint.
427	Constructs an Opsgenie JSON payload by combining relevant parameters into a dictionary. Returns a dictionary containing all non-empty attributes from a predefined list of keys.
428	Method executes an Opsgenie alert by calling OpsgenieAlertHook with built payload.
429	Returns an existing AWS connection or creates a new one if it doesn't exist, returning a boto3 session.
430	Run a Presto query on Athena with the specified configuration and return the query execution ID.
431	Fetch the status of a submitted Athena query and return its state, or None if an error occurs.
432	Polls the status of a submitted Athena query until it reaches a final state or maximum attempts are reached. Returns the final query state.
433	Returns an SFTP connection object, establishing a new connection if one doesn't already exist. The connection uses specified parameters including host, port, username, and authentication methods (password or private key), with optional compression and host key checking.
434	Handles Zendesk API rate limit exceptions by sleeping for the specified retry time (defaulting to 60 seconds) and logging the pause.
435	Call Zendesk API and return results, with optional pagination and side-loading support. Handles rate limiting by waiting and retrying. Supports retrieving all pages of results or just the first page.
436	Retrieves partition values for a specified table in a Glue catalog database, with optional filtering and pagination support. Returns a set of tuples representing partition values, where each tuple contains the partition column values for a specific partition. Supports pagination through page_size and max_items parameters, and allows filtering using an expression parameter that follows AWS Glue partition filtering syntax. The method handles pagination automatically and aggregates all matching partition values into a set of tuples.
437	Get table information from AWS Glue Catalog.

This method retrieves detailed information about a specific table from the AWS Glue Data Catalog. It connects to the Glue service using the existing connection and fetches the table metadata for the specified database and table name.

:param database_name: Name of the Hive database (schema) that contains the table
:type database_name: str
:param table_name: Name of the Hive table to retrieve information for
:type table_name: str
:rtype: dict
:return: Dictionary containing the table metadata information

Example:
>>> hook = AwsGlueCatalogHook()
>>> table_info = hook.get_table('my_database', 'my_table')
>>> print(table_info['Name'])
'my_table'
438	Get the physical location of a Hive table by retrieving its storage descriptor location from the table metadata.
439	Return status of a cluster given its identifier, or 'cluster_not_found' if the cluster doesn't exist.
440	Delete a Redshift cluster and optionally create a final snapshot. Returns the deleted cluster details or None if deletion fails.
441	Gets a list of snapshots for a specified cluster, filters out snapshots with no status, and sorts them by creation time in descending order. Returns the sorted snapshots list or None if no snapshots exist.
442	Restores a Redshift cluster from a specified snapshot. Takes a cluster identifier and snapshot identifier as parameters and returns the restored cluster object. Returns None if no cluster is returned in the response.
443	Creates a snapshot of a specified cluster with the given snapshot and cluster identifiers, returning the snapshot details or None if unsuccessful.
444	Method `execute` handles Slack API execution without causing DAG failure even if API calls are unsuccessful. It constructs API call parameters if needed and uses SlackHook to make the API call.
445	Creates an EMR job flow using configuration from EMR connection with optional overrides. Raises AirflowException if emr_conn_id is not set. Combines connection extra_dejson config with job_flow_overrides and calls run_job_flow method. Returns the response from run_job_flow.
446	Filters HDFS file results by minimum file size threshold. Takes a list of file dictionaries and returns only those files whose size (in MB) meets or exceeds the specified minimum size. Logs debug information about the filtering process and returns the filtered list of files.
447	Filters a list of HDFS file dictionaries to exclude files with specified ignored extensions when ignore_copying is True. Uses regex pattern matching to identify and remove files whose paths match the ignored extensions, logging the filtering process and returning the filtered result list.
448	Executes a MongoDB query (either aggregate or find), transforms the results, converts them to JSON format, and loads them into S3. Returns True upon successful completion.
449	Get pool by a given name, raising AirflowBadRequest for empty names and PoolNotFound for non-existent pools.
450	Create a pool with the specified name, slots, and description. If a pool with the given name already exists, update its slots and description. Raise AirflowBadRequest if the name is empty or slots is not a valid integer.
451	Delete a pool by name, raising exceptions for empty names or non-existent pools, and return the deleted pool object.
452	Converts a Python dictionary to protobuf format by first converting the dictionary to a JSON string and then parsing it into the provided protobuf object.

**Parameters:**
- py_dict (dict): The dictionary to convert
- proto (protobuf): The protobuf object to merge with the dictionary

**Returns:**
- protobuf: A parsed protobuf object in the provided proto format

**Raises:**
- ParseError: On JSON parsing problems
453	Waits for a Google Cloud operation to complete by periodically polling its status until completion or failure, with appropriate error handling for failed operations.
454	Fetches an operation from Google Cloud by name and project ID, returning the updated operation object.
455	Append labels to a Cluster Protobuf object with validation, replacing dots and plus signs with hyphens in the label value.
456	Creates a GKE cluster with the specified configuration, handling both dict and Cluster protobuf inputs. Returns the cluster's URL on success, or the existing cluster's URL if it already exists. Supports retry and timeout configurations, and automatically adds an Airflow version label to the cluster.
457	Gets details of specified cluster and returns its self_link.
458	Returns the Discord webhook endpoint by either using a manually provided endpoint or fetching it from a connection's extra parameters. Validates that the endpoint matches the expected Discord webhook format. Raises AirflowException if no valid endpoint or connection ID is provided, or if the endpoint format is invalid.
459	Constructs a Discord JSON payload with optional username, avatar URL, and TTS settings, validates message length, and returns the payload as a JSON string.
460	Execute a Discord webhook call with optional proxy support by building a payload and making an HTTP request.
461	Encrypts a plaintext message using Google Cloud KMS with optional authenticated data and returns the base 64 encoded ciphertext.
462	Imports a table from a remote location to HDFS with specified options like target directory, file type, columns, and where clause. Supports append mode, direct connector usage, custom drivers, and extra import options. Executes the sqoop import command using the provided parameters.
463	Imports a query from RDBMS to HDFS with specified configuration options.
464	Exports a Hive table to a remote location using Sqoop with specified import options and configuration parameters.
465	Retrieves connection to Cloud Text to Speech.

Returns: Google Cloud Text to Speech client object.
Return type: google.cloud.texttospeech_v1.TextToSpeechClient
466	Synthesizes text input into speech audio using Google Cloud Text-to-Speech API with specified voice and audio configurations. Takes input text, voice parameters, and audio configuration as inputs, and returns a SynthesizeSpeechResponse object containing the synthesized audio data. Supports optional retry and timeout configurations for the API request.
467	Closes the logger and uploads the local log file to remote S3 storage if upload_on_close is enabled. Prevents duplicate uploads by checking if the logger is already closed. Reads the local log file, writes it to S3, and marks the logger as closed.
468	Returns a list containing the configuration for a GitSync init container if DAGs are to be retrieved via Git, otherwise returns an empty list. The init container is configured with environment variables for git synchronization, volume mounts for the DAGs directory, and optional SSH and known_hosts configurations.
469	Defines environment variables for the pod executor, including Airflow configuration and DAGs folder settings.
470	Defines any necessary secrets for the pod executor by creating Secret objects from kube_secrets configuration and env_from_secret_ref, returning a list of worker_secrets.
471	Defines and returns a security context dictionary with optional runAsUser, fsGroup, and default fsGroup value of 65533 when using git ssh keypair authentication.
472	Get link to Qubole command result page by constructing URL from connection host and command ID pulled from XCom.
473	The `heartbeat` method updates a job's timestamp in the database to indicate it's still active, enabling system-level monitoring and external job termination. It calculates sleep time to maintain a steady heartbeat rate based on the configured interval, then updates the latest heartbeat time. The method also checks for shutdown state to kill the job if needed and executes a heartbeat callback. It handles database sessions and includes error handling for operational errors, with a unit test mode that skips the sleep logic.
474	Launches a multiprocessing process to handle file processing tasks including DAG handling, zombie task management, and.logging. Returns the created process object.
475	Launches the process and starts processing the DAG by creating a DagFileProcessor instance with specified parameters and setting the start time.
476	Check if the process launched to process this file is done.

:return: whether the process is finished running
:rtype: bool
477	Helper method to clean up processor_agent and exit gracefully upon receiving a signal, preventing orphan processes.
478	Updates import errors for DAGs in a DagBag by clearing previous errors and recording new ones, then commits the changes to the database session.
479	This method schedules tasks for a single DAG by processing active DAG runs and adding runnable task instances to a queue. It first identifies running DAG runs, filters out future executions and backfill runs, and updates their states. For each active DAG run, it retrieves task instances that are ready to run (NONE, UP_FOR_RETRY, or UP_FOR_RESCHEDULE) and checks if their dependencies are met. If dependencies are satisfied, the task instances are added to the provided queue for execution. The method respects the DAG's max_active_runs limit and ensures proper session management throughout the process.
480	Sets task instances to a new state if their associated DAG runs are not in RUNNING state, handling both SQLite and non-SQLite database cases with appropriate session management and logging.
481	Get concurrency maps for task instances in given states.

Returns two dictionaries:
- dag_map: maps dag_id to total count of task instances in given states
- task_map: maps (dag_id, task_id) tuples to count of task instances in given states

Filters task instances by states parameter and groups results by task_id and dag_id.
482	Changes the state of specified task instances to 'QUEUED' atomically if they are in acceptable states, and returns them in SimpleTaskInstance format. Filters task instances by DAG ID, task ID, and execution date, and uses database locking to ensure atomicity. Logs the changed tasks and returns the updated task instances.
483	Enqueues task instances that are in 'queued' state with the executor. For each task instance, it generates an execution command using the associated DAG information, then queues the command with the specified priority and queue settings using the executor's queue_command method. The method logs the enqueue operation with relevant task information.
484	Executes TaskInstances that should be run by the scheduler by: 1) selecting executable TIs based on priority and constraints, 2) atomically changing their states, and 3) enqueuing them in the executor, returning the count of TIs with changed states.
485	Sets tasks that failed to execute back to SCHEDULED state to prevent hanging tasks, by querying queued tasks and updating their state in the database.
486	Process executor events by responding to task state changes, logging execution details, and handling task completion events (success/failure) by updating TaskInstance states and managing external task terminations.
487	Process a Python file containing Airflow DAGs by executing it, syncing DAGs to the database, creating task instances, handling errors, and killing zombie tasks. Returns a list of SimpleDag objects representing the DAGs found in the file.
488	Updates task counters based on their current state, moving them between running, succeeded, skipped, failed, or to_run collections as appropriate, and handles special states like retry, reschedule, and concurrency limits by either re-adding them to the task queue or logging warnings.
489	Method `_manage_executor_state` checks if the executor's reported state matches the actual state of running task instances. It iterates through the executor's event buffer, verifies each task instance against the running dictionary, refreshes the task instance from the database, and logs warnings or errors when there are state mismatches between the executor and the task instance, particularly when the executor reports a task as FAILED or SUCCESS while the task instance is still RUNNING or QUEUED.
490	Returns a DAG run for the given run date, creating a new one if necessary while respecting the max_active_runs limit. If an existing DAG run is found, it returns that run. If the max_active_runs limit is reached, returns None. The returned DAG run is set to RUNNING state.
491	Returns a map of task instance keys to task instance objects for tasks to run in a given DAG run, handling orphaned tasks and setting appropriate states.
492	Executes DAG runs for given dates and their task instances using the provided executor. Computes dag runs and task instances for specified run dates, processes them through the backfill workflow, and tracks executed run dates. Returns the list of execution dates that were processed.
493	Sets unfinished DAG runs to failed state by updating their state based on task instances and marking them as failed if not already finished.
494	Initializes and executes a backfill job for a DAG over a specified date range, handling task execution, error collection, and cleanup.
495	This method serves as a callback to monitor and validate the execution state of a task. It checks if the task is still running on the same host and process as recorded in the database. If the task state has been externally changed to something other than RUNNING, or if the hostname/pid don't match, it raises exceptions or terminates the task runner to prevent inconsistent execution states. The method also handles graceful termination when the system is already terminating.
496	Returns a Cloud Spanner API client for the specified project, creating it if it doesn't already exist.
497	Gets information about a particular Cloud Spanner instance. Returns the instance object if it exists, None otherwise. Takes optional project_id parameter (defaults to connection's project if None) and required instance_id parameter.
498	Applies a specified function to a Cloud Spanner instance by first retrieving or creating the instance with given parameters, then executing the function on it and handling any Google API call errors.
499	Creates a new Cloud Spanner instance with the specified parameters by applying the configuration to the instance.
500	Updates an existing Cloud Spanner instance with the specified configuration, node count, and display name.
501	Deletes an existing Cloud Spanner instance with the specified instance ID. If project ID is not provided, uses the default project from the GCP connection. Handles Google API call errors by logging the error and re-raising the exception. Returns None upon successful deletion.
502	Retrieves a Cloud Spanner database by instance and database ID, returning the database object or None if it doesn't exist. Raises AirflowException if the specified instance doesn't exist in the project.
503	Creates a new database in Cloud Spanner with the specified parameters, including instance ID, database ID, and DDL statements. Raises an exception if the instance doesn't exist or if an error occurs during database creation. Logs the operation result upon successful creation.
504	Updates the DDL (Data Definition Language) of a Cloud Spanner database with the provided statements. Validates that the specified instance exists, then attempts to update the database's schema. Handles idempotency via an optional operation ID and manages exceptions such as already existing operations or API call errors, logging appropriate messages throughout the process. Returns None upon successful completion or if the operation is a replayed idempotent operation.
505	Deletes a database in Cloud Spanner by first verifying the existence of both the instance and database, then dropping the database and handling any potential Google API call errors during the process.
506	Pokes for a mail attachment on the mail server and returns True if the attachment is present, False otherwise.
507	Creates additional_properties parameter by merging language_hints and web_detection_params into existing additional_properties, with language_hints and web_detection_params taking precedence. Returns the merged dictionary with image_context containing the hints and parameters.
508	Returns a Cassandra Session object, creating a new one if the current session is shutdown or doesn't exist.
509	Checks if a table exists in Cassandra by verifying the keyspace and table names against the cluster metadata. Returns True if the table exists, False otherwise. Supports dot notation to specify keyspace.table format.
510	Checks if a record exists in Cassandra by executing a SELECT query with the specified keys and values. Returns True if the record exists, False otherwise.
511	Constructs and returns a command to poll the driver status by building a connection command with spark binary path, master URL, and driver ID, raising an exception if no driver ID is available.
512	Method: submit
Summary: Executes a spark-submit job remotely using subprocess.Popen. Builds the spark submit command, sets up environment variables, and runs the command with specified arguments. Tracks the driver status and raises exceptions if the job fails or exits with an error code. Returns the result of the spark-submit execution.
513	Processes Spark submit log output to extract driver identification information based on deployment mode. For YARN cluster mode, extracts application ID; for Kubernetes cluster mode, extracts driver pod name and exit code; for standalone mode with driver tracking enabled, extracts driver ID. Logs all lines at INFO level and debug logs at DEBUG level.
514	Parses Spark driver status logs from a subprocess iterator, extracting and storing the driver state while logging each line.
515	Returns the appropriate task runner instance based on the configured _TASK_RUNNER variable. Supports "StandardTaskRunner" and "CgroupTaskRunner" types, raising AirflowException for unknown types.
516	Wait for AWS Batch job execution to complete by using either the built-in waiter with exponential backoff as a fallback, with timeout managed by Airflow and retry logic based on job status.
517	Queries MySQL database using MySqlHook, executes the stored SQL query, and returns a cursor to the results.
518	Configures a CSV writer with the specified file handle and writes the schema as headers to the new file.
519	Writes BigQuery schema in .json format from cursor results to a local temporary file and returns a dictionary containing the filename, file handle, and MIME type for upload.
520	Return a dictionary mapping column names to column types based on the schema, handling different schema input types (string, list) and providing default behavior for invalid schemas.
521	Helper function that maps MySQL data types to BigQuery data types, returning 'STRING' for unmapped types.
522	Execute a Sqoop job based on the command type ('import' or 'export') by initializing a SqoopHook and calling the appropriate import/export method with specified parameters.
523	Saves lineage information to XCom and optionally sends it to a backend service. The decorator captures inlets and outlets from the operator, pushes them to XCom for later use, and sends them to a configured backend if one is available.
524	Returns the extra property by deserializing JSON, logging any parsing errors.
525	Generate a list of dates based on a start date, end date, and a time delta which can be either a timedelta object or a cron expression. The function supports specifying either an end date or a number of dates to generate. It handles timezone-aware and timezone-naive datetime objects, processes cron expressions using the croniter library, and returns dates in sorted order.
526	Convert an array of time durations in seconds to the specified time unit (minutes, hours, or days).
527	Returns a datetime object representing `n` days ago, with the time set to the specified hour/minute/second/microsecond (defaulting to midnight if not specified).
528	Initialize a role with specified permissions and view-menus, adding the role if it doesn't exist and setting up permissions only if the role has no existing permissions.
529	Delete a role from the ab_role table by name, raising an exception if the role doesn't exist.
530	Get all roles associated with a user. If no user is specified, uses the current user from the global context. For anonymous users, returns the public role if configured, otherwise returns an empty list. For authenticated users, returns their associated roles.
531	Returns a set of tuples containing permission names and view menu names for all user roles.
532	Checks if the user has any of the specified roles. Returns True if the user has at least one role from the provided role name or list of role names.
533	Checks if the user has a specific permission for a view menu, rebuilding permissions if necessary.
534	Method `clean_perms` cleans up faulty permissions in the database by:
1. Querying PermissionView records that have null permission or view_menu values
2. Deleting all matching records
3. Committing the transaction
4. Logging the number of deleted records if any were found

The method handles "faulty permissions" that FAB (Fabric) leaves behind, ensuring data integrity by removing orphaned or incomplete permission entries.
535	Merge permission with view menu by adding permission-view menu relationship if it doesn't exist, and create entries in meta tables if needed.
536	Updates the admin role's permissions by adding any missing permission-view combinations from the database, ensuring the admin has all available permissions.
537	Syncs DAG view permissions by setting access control policies for a given DAG, creating missing permissions and roles, and revoking stale permissions for non-Admin roles. Raises exceptions for invalid roles or permissions.
538	Create permission-VM pairs for all DAGs in the FAB security model by iterating through each DAG VM and permission combination.
539	Deferred load of Fernet key that returns a Fernet object, initializing it with a key from configuration or NullFernet if not available. Raises AirflowException if Fernet object creation fails.
540	Checks for the existence of a partition in the AWS Glue Catalog table by splitting the table name if it contains a dot, logging the poke operation with database name, table name, and expression, then returning the result of checking for the partition using the hook's check_for_partition method with the specified database name, table name, and expression.
541	Gets the AwsGlueCatalogHook, creating it if it doesn't already exist.
542	Check for messages on a subscribed SQS queue and write the message to XCom with key 'messages'. Returns True if message is available, False otherwise.
543	Returns a snakebite HDFSClient object configured based on connections and configuration settings, supporting single namenode, HA, or auto-configured clients.
544	Method `get_conn` establishes a connection to HDFS using either insecure or kerberos client based on configuration. It tries multiple namenodes specified in connections, attempts a read operation on each, and returns the first successful connection. If all connections fail, it raises an AirflowWebHDFSHookException listing all failed hosts. Returns either hdfs.InsecureClient or hdfs.ext.kerberos.KerberosClient object.
545	Check if a given HDFS path exists by querying its FileStatus. Returns True if the path exists, False otherwise.
546	Uploads a file or folder to HDFS with optional parallelization and overwrite support.
547	```python
def get_conn(self):
    """
    Establish a connection to pinot broker through pinot dbqpi.
    """
    conn = self.get_connection(self.pinot_broker_conn_id)
    pinot_broker_conn = connect(
        host=conn.host,
        port=conn.port,
        path=conn.extra_dejson.get('endpoint', '/pql'),
        scheme=conn.extra_dejson.get('schema', 'http')
    )
    self.log.info('Get the connection to pinot '
                  'broker on {host}'.format(host=conn.host))
    return pinot_broker_conn
```

Summary:
Method that establishes a connection to a Pinot broker by retrieving connection details from Airflow's connection manager and using them to create a Pinot DBAPI connection with specified host, port, endpoint path, and schema. Returns the established connection object.
548	Get the connection URI for Pinot broker in the format http://host:port/endpoint.
549	Converts a Python datetime.date object to a dictionary format with day, month, and year keys supported by the API.
550	Convert a Python datetime.time object to a dictionary format with hours, minutes, and seconds for API compatibility.
551	Returns a Redis connection by initializing and returning a Redis object using connection details from the specified connection ID.
552	Executes a SQL query and returns the results as a pandas DataFrame.

Parameters:
- sql (str or list): The SQL statement(s) to execute
- parameters (mapping or iterable): Parameters to render the SQL query with

Returns:
- pandas.DataFrame: The query results

Note: This method automatically handles connection closing using a context manager.
553	Runs SQL commands sequentially using a database connection. Accepts either a single SQL string or a list of SQL statements to execute. Supports optional autocommit setting and parameterized queries. Executes commands within a transaction context and commits changes when autocommit is disabled.
554	Sets the autocommit flag on the connection, logging a warning if autocommit is enabled but not supported by the connection.
555	Inserts rows into a database table with support for transactions and optional replacement. Takes table name, rows to insert, target fields, commit frequency, and replace flag as parameters. Returns nothing.
556	Serializes a cell value to its SQL literal string representation. Handles None, datetime, and other objects by converting them to appropriate string formats for database insertion.
557	This method checks the health status of an Airflow instance by verifying the metadatabase and scheduler components. It queries the latest heartbeat from the scheduler job to determine if it's running within the configured health check threshold. The method returns a JSON response containing the health status of both the metadatabase and scheduler, along with the latest scheduler heartbeat timestamp. If any errors occur during the database query, the metadatabase is marked as unhealthy.
558	A RESTful endpoint that retrieves external links for a given Operator by querying the operator for links associated with a specific link name. It accepts parameters including dag_id, task_id, execution_date, and link_name, and returns either a JSON response with the URL and no error (status 200) or a JSON response indicating no URL was found along with an error message (status 404). The method validates the existence of the DAG and task, parses the execution date, and calls the task's get_extra_links method to retrieve the URL.
559	Opens a connection to the cloudant service and returns an authorized cloudant session context manager object. Validates the connection using the cloudant connection ID and credentials (username/api key, password, and account/host). Returns a cloudant session that can be used as a context manager for automatic connection closing.
560	Execute a Slack webhook call using the provided parameters and context.
561	Returns the Google API Credentials object by loading credentials from a key file path, key file data, or default application credentials, with optional scope specification and subject delegation support.
562	Returns an authorized HTTP object for Google cloud service hook connection using credentials and httplib2.
563	A decorator function that catches various HTTP and API exceptions, logging detailed error messages and re-raising them as AirflowException for better error handling in Airflow workflows.
564	Decorator that provides fallback for Google Cloud Platform project id. If the project is None, it will be replaced with the project_id from the service account the Hook is authenticated with. Project id can be specified either via project_id kwarg or via first parameter in positional args. Raises AirflowException if project_id is not provided.
565	A list of states indicating that a task either has not completed a run or has not even started.
566	Constructs and returns a complete spark-sql command by combining default parameters with optional configuration settings and a provided command. Enables verbose output by default and logs the final command.
567	Convert a PIL Image or numpy.ndarray to a tensor. Handles different image modes and data types, converting to CHW format with appropriate scaling. Raises TypeError for invalid input types.
568	Normalize a tensor image with given mean and standard deviation. Supports in-place operation. Raises TypeError if input is not a tensor image. Returns the normalized tensor.
569	Resizes a PIL Image to a given size while maintaining aspect ratio. If size is an integer, the smaller edge is matched to this value while preserving the original aspect ratio. If size is a tuple/list of two values (h, w), the image is resized to exactly match those dimensions. Uses the specified interpolation method (default: BILINEAR) for the resizing operation. Validates that the input is a PIL Image and size argument is valid.
570	Pad the given PIL Image on all sides with specified padding mode and fill value. Supports padding with constant values, edge padding, reflect padding, and symmetric padding. Handles different padding configurations (int, tuple of 2, or tuple of 4 values) and works with both color and grayscale images, preserving image mode and palette when necessary.
571	Crop the given PIL Image at the specified coordinates with given height and width.

Args:
    img (PIL Image): Image to be cropped
    i (int): y-coordinate of the upper left corner
    j (int): x-coordinate of the upper left corner  
    h (int): Height of the cropped image
    w (int): Width of the cropped image

Returns:
    PIL Image: Cropped image

Raises:
    TypeError: If img is not a PIL Image
572	Crop the given PIL Image at the specified location and resize it to the desired size.

Args:
    img (PIL Image): Image to be cropped and resized
    i (int): Upper left corner row index
    j (int): Upper left corner column index  
    h (int): Height of the cropped image
    w (int): Width of the cropped image
    size (sequence or int): Desired output size
    interpolation (int, optional): Desired interpolation method. Default is PIL.Image.BILINEAR

Returns:
    PIL Image: Cropped and resized image
573	Horizontally flip the given PIL Image.

Args:
    img (PIL Image): Image to be flipped.

Returns:
    PIL Image: Horizontally flipped image.
574	Perform perspective transform on a PIL Image using given start and end points.

Args:
    img (PIL Image): Image to be transformed
    startpoints: Starting points for perspective transformation
    endpoints: Ending points for perspective transformation
    interpolation: Interpolation method (default: Image.BICUBIC)

Returns:
    PIL Image: Perspective transformed image

Raises:
    TypeError: If img is not a PIL Image

The function calculates perspective coefficients from start and end points, then applies the perspective transform using PIL's transform method with Image.PERSPECTIVE mode.
575	Vertically flip a PIL Image by transposing it with FLIP_TOP_BOTTOM mode. Raises TypeError if input is not a PIL Image.
576	Crop the given PIL Image into four corners and the central crop.

Args:
   size (sequence or int): Desired output size of the crop. If size is an
       int instead of sequence like (h, w), a square crop (size, size) is
       made.

Returns:
   tuple: tuple (tl, tr, bl, br, center)
            Corresponding top left, top right, bottom left, bottom right and center crop.
577	Adjusts the brightness of a PIL Image by a specified factor using ImageEnhance.Brightness. Accepts a non-negative brightness_factor where 0 produces a black image, 1 preserves the original, and values > 1 increase brightness. Raises TypeError if input is not a PIL Image.
578	Adjusts the contrast of a PIL Image by a specified factor using ImageEnhance.Contrast.
579	Adjusts the color saturation of a PIL Image by a specified factor, where 0 produces black and white, 1 maintains original saturation, and values > 1 enhance saturation.
580	Adjusts the hue of a PIL image by converting to HSV color space, shifting the hue channel by the specified factor, and converting back to the original color mode. The hue factor must be between -0.5 and 0.5, where 0 means no change and values at the extremes produce complementary colors. Raises TypeError if input is not a PIL Image and ValueError if hue_factor is outside the valid range. Returns the hue-adjusted PIL Image.
581	Perform gamma correction on a PIL Image by adjusting pixel intensities according to the power law transform equation I_out = 255  gain  (I_in/255)^gamma, where gamma controls shadow brightness (gamma > 1 darkens shadows, gamma < 1 lightens them) and gain is a constant multiplier. The function validates input image type and gamma value, converts the image to RGB mode for processing, applies the gamma transformation using PIL's point function for efficiency, then restores the original image mode.
582	Rotates a PIL image by the specified angle in degrees counter clockwise. Supports optional resampling filter, image expansion to fit entire rotated image, and custom rotation center. Raises TypeError if input is not a PIL Image.
583	Apply affine transformation on the image keeping image center invariant. The function rotates, translates, scales, and shears a PIL Image using an affine transformation matrix. It supports rotation angle, translation offsets, scaling factor, and shear angle. The transformation is applied while maintaining the image center position. The function includes input validation for image type, translation parameters, and scale value, and returns the transformed image with optional resampling and fill color parameters.
584	Converts a PIL image to grayscale format with specified output channels.

Args:
    img (PIL Image): Input image to be converted
    num_output_channels (int): Number of output channels (1 or 3)

Returns:
    PIL Image: Grayscale image with either single channel (if num_output_channels=1) or three channels (if num_output_channels=3 where all channels are identical)

Raises:
    TypeError: If input is not a PIL Image
    ValueError: If num_output_channels is not 1 or 3

The function converts PIL images to grayscale by:
- For single channel output: Uses PIL's built-in 'L' mode conversion
- For triple channel output: First converts to grayscale, then duplicates the single channel to create RGB channels
- Maintains original image dimensions and data type throughout conversion
585	Save a tensor image to a file by converting it to a grid layout and applying optional normalization and scaling.
586	Finds class folders in a dataset by scanning the directory. Returns a tuple of (classes, class_to_idx) where classes are sorted and class_to_idx maps class names to indices. Ensures no class is a subdirectory of another.
587	Return a Tensor containing the first n patches extracted from image files in the specified directory. The patches are 64x64 numpy arrays converted from PIL images, extracted by cropping 1024x1024 images into 16x16 patches. The function processes all image files with the specified extension in the data directory and returns the patches in a ByteTensor.
588	Reads a label file and returns a LongTensor containing the labels (first column of each line).
589	Read matches file and return a Tensor containing ground truth matches where each entry consists of [3D point ID, match ID, 1 if match else 0].
590	Computes the accuracy over the k top predictions for specified values of k. Takes model output and target labels, returns a list of accuracies for each k value in topk.
591	This function disables printing when not in the master process by overriding the built-in print function to only allow printing from the master process unless the 'force' parameter is True.
592	Download a file from a URL and place it in the specified root directory. If a filename is not provided, use the basename of the URL. Optionally verify the file's integrity using MD5 checksum. If the file already exists and is verified, use it instead of downloading. Handle HTTPS to HTTP fallback in case of download failure.
593	List all directories at a given root path, optionally prepending the root path to each result.
594	List all files ending with a specified suffix in a given directory path. If prefix=True, returns full paths; otherwise returns just the filenames.
595	Download a file from Google Drive and place it in the specified root directory. Uses the file ID to identify the Google Drive file, and optionally verifies the download using MD5 checksum. If a filename is not provided, the file ID is used as the filename. Creates the root directory if it doesn't exist and checks if a file with the same name already exists and is valid before downloading.
596	Get random crop parameters for a PIL Image.

This function calculates random crop coordinates (i, j, h, w) for a given image and desired output size. It takes a PIL Image and target output size as input, then returns the top-left coordinates (i, j) and crop dimensions (h, w) for a random crop.

Args:
    img (PIL Image): Image to be cropped
    output_size (tuple): Expected output size of the crop (height, width)

Returns:
    tuple: params (i, j, h, w) to be passed to crop for random crop
    - i: top coordinate of crop
    - j: left coordinate of crop  
    - h: height of crop
    - w: width of crop

If the image dimensions match the output size exactly, returns (0, 0, h, w) for no crop.
597	Get parameters for perspective transformation by generating random distortion coordinates for all four corners of an image, returning both original and transformed corner points.
598	Get parameters for 'crop' for a random sized crop, including handling fallback to central crop.
599	Get a randomized transform to adjust brightness, contrast, saturation, and hue in random order.
600	Get parameters for affine transformation including rotation angle, translations, scale, and shear values within specified ranges.
601	Download and extract a tarball file, then download individual photos from URLs listed in a dataset file.
602	Download MNIST data if not already present, create directories if needed, download files from URLs, extract gzip archives, process data into torch files, and save training and test datasets.
603	Download EMNIST data if not already present, extract zip and gzip files, convert to torch files, and save in processed folder.
604	Returns the current theme name by checking override parameter, then URL arguments, then user preferences, falling back to default theme if needed.
605	Return autocompleter results for a search query, handling disabled engines, parsing queries, processing !bang commands, and formatting results based on request parameters.
606	Render the preferences page and save user preferences. If the request method is POST, it parses the form data, validates it, and saves the preferences. Otherwise, it gathers statistics for each search engine, retrieves user preferences, and renders the preferences page with all necessary data and settings.
607	Returns a list of available themes by listing directories in the templates path, excluding the '__common__' directory if present.
608	The `searx_bang` function processes a search query to identify and generate autocomplete suggestions for special syntax patterns known as "bangs" in the Searx search engine. It handles two types of bangs: those starting with `!` or `?`, used for specifying search engines or categories, and those starting with `:`, used for setting language preferences. 

The function checks if the query is empty and returns an empty list if so. For queries starting with `!` or `?`, it suggests common engine names or categories that match the input. For queries starting with `:`, it provides language codes and names based on the input. The function removes duplicate suggestions and filters out any results already present in the original query, returning a final list of unique, relevant autocomplete suggestions.
609	Function `response(resp)` processes an HTTP response to extract currency conversion information. It parses the response text to isolate JSON data, extracts the conversion rate, and formats a descriptive answer string showing both the converted amount and the conversion rate. The function returns a list containing a dictionary with the formatted answer and a related URL. If parsing fails, it returns an empty list.
610	Embeds a custom gradient into a tensor using stop_gradient to override the gradient computation. The function ensures that the forward pass equals the original function output while the backward pass uses the specified gradient. It supports both scalar and tensor inputs, with optional manual gradient stopping for partial gradient control. The implementation uses the mathematical identity h(x) = stop(f(x)) + stop(g(x)) * (x - stop(x)) to achieve the custom gradient behavior, where the gradient is explicitly controlled to be stop(g(x)) while maintaining f(x) in the forward pass.
611	Creates a MultivariateNormalDiag distribution using Independent Normal distributions for efficient construction.
612	Computes the joint log-probability for the eight schools model given treatment effects, treatment standard deviations, average effect, average standard deviation, and school effects standard values.
613	Runs Hamiltonian Monte Carlo (HMC) on the eight-schools unnormalized posterior with specified sampling parameters and returns benchmark results including iteration count, acceptance rate, and wall time.
614	Decorator to programmatically expand the docstring.

Args:
  **kwargs: Keyword arguments to set. For each key-value pair `k` and `v`,
    the key is found as `${k}` in the docstring and replaced with `v`.

Returns:
  Decorated function.
615	**Summary:**

The `_simple_name` function extracts the original user-visible name from a TensorFlow probability distribution instance by reversing name-scope transformations. It handles cases where distributions are created within name scopes (resulting in names ending with '/') and cases where duplicate names are automatically suffixed with numbers (like 'x_3'). The function returns the clean, original name that was passed to the distribution constructor.

**Example:** 
- Input: `tfd.Normal(0., 1., name='x')` creates a distribution with name `'x/'`  `_simple_name` returns `'x'`
- Input: Duplicate `tfd.Normal(0., 1., name='x')` creates a distribution with name `'x_2/'`  `_simple_name` returns `'x'`
616	Helper function that creates a RandomVariable with a dummy name argument, allowing program transformations to override RV values by name while preserving the distribution's inherited name.
617	Wrap an existing distribution as a traceable random variable for use in Edward models. Enables custom distributions to be intercepted and overridden, though they may not support program transformations that require overriding distribution parameters. Returns a RandomVariable wrapping the provided distribution.
618	Factory function to create a random variable given a distribution class, with interceptable decorator, docstring expansion, and proper handling of sample_shape and value arguments.
619	Computes one-step-ahead predictive distributions for a structural time series model given posterior parameter samples. Returns a mixture distribution representing forecast uncertainty at each time step based on past observations and sampled parameters.
620	Constructs a predictive distribution over future observations using posterior samples from a structural time series model.

This function takes a fitted structural time series model, observed time series data, posterior parameter samples, and the number of forecast steps to predict. It returns a mixture distribution representing the forecast uncertainty over the future time steps.

The function performs filtering on the observed data to get the final state posterior, which serves as the prior for the forecast. It then constructs a state-space model for the forecast period and combines it with the posterior samples into a MixtureSameFamily distribution. The result represents the predictive distribution over future observations, enabling forecast means, scales, and samples to be computed for uncertainty quantification.

Args:
  model: A StructuralTimeSeries model instance
  observed_time_series: Observed time series data tensor
  parameter_samples: Posterior samples of model parameters
  num_steps_forecast: Number of time steps to forecast

Returns:
  A MixtureSameFamily distribution with forecast predictive distributions
621	Returns the maximum value along specified axis, substituting a mask value for non-finite results.
622	Asserts all elements of `x` are finite, raising `InvalidArgumentError` if any element is infinite or NaN. Returns the input tensor if all elements are finite, otherwise raises an error with optional message and data for debugging.
623	Asserts that tensor `x` has rank less than or equal to the specified `rank`. Returns an operation that raises `InvalidArgumentError` if the condition is violated, or `no_op` if static checks confirm the rank is correct. Supports optional data printing, summarization, and messaging for error cases.
624	Computes the total number of elements in a tensor with the given event shape, returning either a numpy integer or a scalar tensor depending on whether the shape is static.
625	Summary: Helper function that computes probabilities, CDF, etc. for OneHotCategorical distributions over their support by evaluating the given function `fn` on the identity matrix reshaped to match the distribution's batch shape, then transposing the result to align dimensions correctly.
626	Return a convert-to-tensor function based on the given identifier, which can be None, a string, a dictionary, or a callable. Raises ValueError if the identifier cannot be interpreted.
627	Computes the total number of parameters needed to create a MixtureSameFamily distribution by calculating num_components + num_components * component_params_size.
628	Returns the top-most interceptor from the thread-local interceptor stack, allowing for nested interception of operations. Uses a context manager pattern to temporarily remove and then restore the interceptor on the stack, enabling interception in nested order.
629	Decorator that wraps a function so its execution is intercepted by a chain of interceptors. The wrapper passes the function to the next available interceptor for the current thread, or calls the function directly if no interceptors are available. Returns the decorated function.
630	A context manager for recording interceptable executions onto a tape, similar to `tf.GradientTape` but designed for Edward2 probabilistic programming. It captures operations executed within its context that are registered as `ed.interceptable`, storing their named outputs in an OrderedDict. The tape records operations based on their `name` keyword argument, allowing inspection of probabilistic computations after execution.
631	Generates synthetic data for binary classification by sampling random weights and bias, creating uniformly distributed design matrix points, and computing binary labels based on a logistic model with noise. Returns the sampled weights, bias, design matrix, and binary labels.
632	Visualizes decision boundaries in R^2 by plotting data points and candidate decision rules.

Plots scatter points with colors based on labels, draws decision boundaries from candidate weights/biases in blue with transparency, and overlays the true decision boundary in green. Saves the resulting plot as a PNG file.
633	Build a Dataset iterator for supervised classification by creating a tf.data.Dataset from input arrays, repeating the dataset, batching the data, and returning the next batch of features and labels.
634	Validates that `map_values` is a non-empty vector with strictly increasing elements when `validate_args` is True, raising ValueError for rank and size issues, and adding assertions for strict monotonicity.
635	A `TransitionOperator` that executes a given function repeatedly for a specified number of steps and records (traces) its outputs at each step. It applies the function to an initial state, runs it for `num_steps` times, and accumulates the outputs of a provided tracing function into a stacked tensor structure. The function returns the final state and the stacked traces of the specified outputs.
636	Calls a transition operator with arguments, unpacking the arguments if they form a sequence (but not a namedtuple-like structure). Returns the result of the function call.
637	Calls a transition operator function and computes gradients of its first output with respect to the input arguments.

Args:
  fn: A TransitionOperator function
  args: Input arguments to the function

Returns:
  ret: First output of the function
  extra: Second output of the function  
  grads: Gradients of ret with respect to args

The function uses TensorFlow's GradientTape to automatically compute gradients while executing the forward pass.
638	Broadcasts a singleton structure to match the shape of another structure by repeating the singleton element. If the first structure contains only one element, that element is tiled to match the number of elements in the second structure. The original elements are not copied during this tiling process. Returns a new structure with the same layout as the target structure.
639	Transforms a log-probability function using bijector(s) to operate on transformed space, optionally returning the inverse-transformed initial state.
640	Leapfrog step implementation for Hamiltonian Monte Carlo sampling. Takes a state, momentum, and step size to perform a single leapfrog integration step, updating both position and momentum variables while computing gradients of target log probability and kinetic energy. Returns the updated state and additional information including target log probability and kinetic energy values.
641	Metropolis-Hastings step that probabilistically chooses between current and proposed states based on energy change to preserve detailed balance. Returns the chosen state, acceptance indicator, and random uniform value used for selection.
642	Hamiltonian Monte Carlo (HMC) is a Markov Chain Monte Carlo (MCMC) method that uses Hamiltonian dynamics to efficiently sample from a target distribution. This implementation performs HMC by:

1. Initializing momentum from a normal distribution (or uses provided momentum)
2. Computing the initial energy (negative log probability + kinetic energy)
3. Performing `num_leapfrog_steps` of leapfrog integration to propose a new state
4. Computing the proposed energy and accepting/rejecting the new state using Metropolis-Hastings
5. Returning the updated state and sampling statistics

Key features:
- Supports custom kinetic energy functions and momentum sampling
- Allows tracing of leapfrog integrator steps
- Handles bijector transformations for complex target distributions
- Returns acceptance statistics and detailed sampling information
- Uses TensorFlow for automatic differentiation and vectorized operations

The function is designed to work within TensorFlow's computational graph and supports reproducible sampling through seed parameters.
643	A function to perform sign-based control adaptation that adjusts a control variable based on the relationship between output and set point values.
644	Creates a layer instance from its configuration dictionary by deserializing function objects and passing the remaining configuration to the layer constructor.
645	Converts input to Tensor type or returns None if input is None.
646	Constructs a scale operator from multiple components including identity multiplier, diagonal matrix, lower triangular matrix, and optional low-rank updates. Returns either a scalar tensor for constant scaling or a LinearOperator for more complex scaling operations. Supports validation of arguments and handles special cases like pure identity scaling. Raises ValueError if no scaling components are provided.
647	Returns a callable that adds random normal perturbations to input state parts for random walk Metropolis-Hastings algorithms. The function accepts state parts and a random seed, then returns perturbed state parts by sampling from zero-mean normal distributions with specified scales. The scales can be broadcast with state parts, and the returned callable maintains the same tensor shapes and types as the inputs.
648	Returns a callable that adds a random uniform perturbation to the input state parts. The perturbation is sampled from a uniform distribution within the bounds defined by the scale parameter. The function accepts state parts and a random seed, and returns perturbed state parts with the same shapes and types as the inputs. Raises ValueError if scale does not broadcast with state parts.
649	Expands the rank of input tensor `x` by adding dimensions for broadcasting up to the static event rank. Returns the expanded tensor with additional dimensions inserted at the end.
650	Returns a lower bound on the entropy of the mixture model using the concavity property of the entropy function. The bound is calculated as the weighted sum of entropies of individual components, where weights are the categorical probabilities. This lower bound can be used in ELBO calculations when the mixture serves as a variational distribution.
651	Get a list of num_components batchwise probabilities by applying softmax or log_softmax to categorical logits.
652	Validates that `outcomes`, `logits`, and `probs` have compatible shapes and valid properties. Checks that the last dimension of `outcomes` matches `logits` and `probs`, that `outcomes` has rank 1, that `outcomes` is not empty, and that `outcomes` is strictly increasing. Returns a list of assertions for runtime validation when `validate_args` is True.
653	This function attempts to import TensorFlow and checks that the installed version meets the minimum required version (1.13). If TensorFlow cannot be imported, it provides a helpful error message with installation instructions. If the version is too old, it raises an ImportError with version mismatch information.
654	Bayesian logistic regression model that computes binary labels from input features using Bayesian inference with multivariate normal prior on coefficients.
655	Builds the Covertype dataset by fetching the data, normalizing features, adding an intercept column, and binarizing labels to focus on the most frequent category.
656	Computes the Cholesky factor of the covariance matrix from vector-variate random samples. Given input data where the rightmost dimension represents events (random variables), this function calculates the sample covariance matrix and returns its Cholesky decomposition. The result is a lower triangular matrix that can be used to generate random samples with the same covariance structure or to define a multivariate normal distribution. The function supports specifying which axes contain samples and whether to preserve dimensions.
657	Estimates the standard deviation of samples along specified axes.

This function computes the standard deviation of input tensor `x` along the given `sample_axis`, using the formula Stddev[X] = Sqrt[Var[X]], where Var[X] is the variance calculated as the average of squared deviations from the mean. It handles multiple sample axes and supports dimension reduction via `keepdims`. The result has the same data type as `x` but reduced rank based on the sample axes.

Args:
  x: A numeric Tensor containing samples
  sample_axis: Scalar or vector Tensor designating axes holding samples (default: 0)
  keepdims: Boolean indicating whether to preserve reduced dimensions
  name: Optional string prefix for operation names

Returns:
  Tensor of same dtype as x with standard deviation estimates, rank reduced by number of sample axes
658	Estimates the variance of samples along specified axes using the formula Var[X] = N^(-1) * sum(X_n - Xbar) * Conj(X_n - Xbar), where Xbar is the sample mean. Divides by N (numpy default) to avoid NaN when N=1, but introduces slight bias. Returns a tensor of variances with dimensions reduced according to sample_axis.
659	Converts negative axis values to positive equivalents given the number of dimensions. Handles both static (list) and dynamic (tensor) cases, returning a list or tensor of positive axis values.
660	A TensorFlow function that squeezes dimensions from a tensor along specified axes, handling both static and dynamic axis parameters by using tensor operations to dynamically determine which dimensions to keep.
661	Standardizes input `x` to a unit normal by subtracting the location parameter and dividing by the scale parameter within a standardize name scope.
662	Reconstructs input `x` from its normalized version `z` using the inverse transformation: `x = z * scale + loc`.
663	Builds a transition matrix for a semi-local linear trend model with shape [..., 2, 2] where the bottom-right entry is filled with the autoregressive coefficient, supporting batched inputs.
664	Builds the transition noise model for a semi-local linear trend model by defining the stochasticity of level and slope components and incorporating a bias term to implement nonzero slope mean, returning a multivariate normal distribution with diagonal covariance.
665	Returns a sample from the `dim` dimensional Halton sequence, which generates low-discrepancy quasi-random numbers in the unit hypercube. The function supports both randomized and non-randomized sequences, with optional control over the number of results or specific sequence indices. It is primarily used for quasi-Monte Carlo integration where deterministic sequences with low discrepancy are preferred over pseudo-random numbers. The resulting samples should be transformed appropriately if integrating over domains other than the unit cube.
666	Generates uniform iid samples from the space of permutations by drawing `num_results` samples from permutation groups specified by `dims` tensor, returning a tensor of shape `[num_results, sum(dims)]` where each row contains permutations of the specified degrees.
667	Generates starting points for the Halton sequence procedure by creating indices from either a count or provided sequence indices, converting to the specified dtype, shifting to 1-based indexing, and reshaping to `[n, 1, 1]` format for later use in Halton sequence generation.
668	Computes the number of terms in the place value expansion of a number in specified bases.

This function calculates how many digits (terms) are needed to represent a number in different bases by using logarithms. For each base, it returns the floor of log_base(num) + 1, which corresponds to the number of terms in the place value expansion.

Args:
  num: Scalar tensor of dtype float32 or float64 - the number to analyze
  bases: Tensor of same dtype as num - the bases to compute expansion sizes for

Returns:
  Tensor of same dtype and shape as bases containing the number of terms needed to represent num in each base
669	Returns sorted array of primes such that `2 <= prime < n` using a sieve of Eratosthenes algorithm optimized for odd numbers only.
670	Returns the machine epsilon for the specified data type using numpy's finfo function.
671	Performs an inexact line search using the Hager-Zhang algorithm, which is designed to satisfy approximate Wolfe conditions for optimization purposes. It takes a univariate function and its gradient, and returns a step size that satisfies the Wolfe conditions or an approximate version thereof, depending on proximity to the minimum. The function handles batched inputs and includes parameters for controlling the search behavior, such as shrinkage, expansion, and curvature parameters.
672	Shrinks the input step size until the value and gradient become finite by iteratively halving the step size up to a maximum number of iterations determined by the machine epsilon of the input dtype.
673	Brackets the minimum of a univariate function using an initial interval and performs a line search to find a point satisfying Wolfe or approximate Wolfe conditions. It handles both single and batched evaluations, returning convergence status, iteration counts, and updated bracketing interval endpoints. The algorithm uses expansion and shrinkage parameters to adjust the search interval and ensure convergence within a specified number of iterations.
674	Performs the main loop of line search after the minimum has been bracketed, using the Hager-Zhang method with secant updates and optional interval shrinkage checks.
675	Performs bisection line search by evaluating the function at the midpoint and updating the search interval based on the results, handling both valid and invalid function evaluations while tracking convergence and evaluation counts.
676	Prepares arguments for line search initialization by evaluating the objective function at specified points and computing necessary values for optimization algorithms. Returns function values at initial points, a threshold for approximate Wolfe conditions, and evaluation count.
677	Wrapper for tf.Print which supports lists and namedtuples for printing.
678	Uses Gauss-Hermite quadrature to approximate the softmax-normal distribution on a simplex, returning grid points and probabilities for numerical integration.
679	Uses SoftmaxNormal quantiles to generate quadrature points on a simplex for numerical integration.
680	Helper function that validates quadrature parameters (loc/scale) for mixture models, checking that they are vectors with shape[-1] = 1, raising errors for invalid ranks or non-bimixture cases, and returning validated parameters or assertions for dependency handling.
681	Helper function to infer batch_shape and event_shape from grid and endpoint_affine parameters by broadcasting shapes across affine transformations.
682	Helper function that interpolates between two locations on a quadrature grid. Takes a grid and location pair, performs linear interpolation using grid weights, and returns interpolated values for each degree of freedom. Supports handling of None values in the location pair. Raises NotImplementedError for non-bimixture cases and ValueError when grid point count is unknown.
683	Helper function that interpolates between two scales by linearly combining operators derived from a quadrature grid and scale coefficients. Raises NotImplementedError for non-bimixture cases and ValueError if grid point count is unknown. Returns a list of interpolated operators for each quadrature point.
684	Creates a weighted LinearOperator by scaling an existing LinearOperator with a weight factor w, handling special cases for Identity, ScaledIdentity, Diag, and LowerTriangular operators while preserving their mathematical properties.
685	Concatenates input vectors, statically if possible. If all vectors have static values, returns a flattened list of all values; otherwise, returns a tensor concatenation along axis 0.
686	Multiply tensor of vectors by matrices assuming values are stored as logs, using log-sum-exp trick for numerical stability.
687	Multiply tensor of matrices by vectors assuming values are stored as logs, using log-sum-exp trick for numerical stability.
688	Multiply tensor of vectors by matrices using tensor contraction.
689	Extract log probabilities from a batch of distributions by creating states tensor and moving dimensions.
690	Computes marginal probability distribution for each hidden state across all time steps by performing forward message passing through the HMM. Returns tensor of shape [num_steps, batch_shape, num_states] containing exponential of forward log probabilities.
691	Computes marginal posterior distributions for each state in a hidden Markov model given a sequence of observations. Uses the forward-backward algorithm to calculate the probability of being in each hidden state at each time step, given all observations. Returns a categorical distribution representing these marginal probabilities for each time step.
692	Compute the maximum likelihood sequence of hidden states using the Viterbi algorithm given a sequence of observations.
693	Chooses random directions in the event space by generating normal random variables for each component, computing the sum of squares across all components, and normalizing the directions using the square root of the sum of squares. Returns the normalized random direction parts.
694	Applies a single iteration of slice sampling update using hit and run style sampling. Chooses a random direction on the unit sphere and performs 1D slice sampling along that direction to propose a new state. Returns the proposed state, target log probability, bounds satisfaction status, sampling direction, and slice bounds.
695	Helper function that computes `fn_result` by calling `fn` with `fn_arg_list` if `fn_result` is None, then validates that the result has a floating point dtype.
696	Pads the input tensor `x` with trailing dimensions of size 1 to achieve the specified `final_rank`. If `x` has shape [1, 5, 7, 2] and `final_rank` is 7, the result will have shape [1, 5, 7, 2, 1, 1, 1]. The function handles both dynamic and static shape cases, returning a tensor of the desired rank by expanding dimensions on the right side.
697	Runs one iteration of the Slice Sampler algorithm, advancing the Markov chain by one step. Takes the current state and previous kernel results as input, and returns the next state along with updated kernel results containing information about the sampling process such as bounds satisfaction and direction. The method handles both single and multiple chain cases, and includes validation for step sizes and data types.
698	Builds a transformed-normal variational distribution over a parameter's support with trainable location and scale parameters.
699	Builds a variational inference loss function for Structural Time Series models using KL divergence minimization. Returns the negative ELBO loss and variational distributions for model parameters.
700	Minimizes a loss function using an optimizer within the TensorFlow graph for a specified number of steps.
701	Computes mean and variance of a masked time series by excluding masked entries. Takes a time series tensor and corresponding boolean mask, returns batched mean and variance tensors of the same shape as the batch dimensions.
702	Get the first unmasked entry of each time series in the batch by computing indices of first unmasked elements and extracting corresponding values using batch_gather operation.
703	Get broadcast batch shape from distributions, statically if possible, falling back to dynamic computation if static shape is not fully defined.
704	Combines multiple multivariate normal distributions into a single factored joint distribution by concatenating their means and creating a block-diagonal covariance matrix from their scales.
705	Summary: The `sum_mvns` function computes the sum of multiple MultivariateNormalDiag distributions by adding their means and variances. It takes an iterable of `tfd.MultivariateNormalDiag` objects with compatible shapes and returns a new `tfd.MultivariateNormalDiag` instance representing their sum. The function currently only supports summing MultivariateNormalDiag distributions and raises NotImplementedError for other distribution types.
706	Compute empirical statistics (mean, standard deviation, and centered initial value) of a time series or batch of time series, handling both observed and masked data cases.
707	Summary: Expands the trailing dimension of `observed_time_series_tensor` to ensure it has shape `[..., 1]`, handling both tensor inputs with and without the extra dimension.
708	Canonicalizes an observed time series tensor into a standard shape `[..., num_timesteps, 1]` and returns a `MaskedTimeSeries` namedtuple containing the canonicalized observed time series and an optional boolean mask indicating missing values. If the input is already a `MaskedTimeSeries`, extracts and processes the underlying time series and missing value mask. If the input has a trailing dimension of size 1, it is preserved; otherwise, a trailing dimension is added. The returned object ensures consistent tensor shapes for further processing in time series models.
709	Constructs a predictive normal distribution by mixing over posterior draws. Takes means and variances tensors, reshapes them to mix over the posterior draws dimension, and returns a MixtureSameFamily distribution representing a uniform mixture over the posterior samples.
710	Returns the difference between high and low values (high - low) within the specified name scope.
711	Creates a factory function that generates summary statistic methods (like mean, mode, stddev) for a class. The returned function computes the specified attribute across all distributions, but raises a ValueError if any distributions are dependent. The result is unflattened before returning.
712	Creates a wrapped distribution function that calls the original function with all previous nodes in the correct order, along with the argument names. Returns the wrapped function and argument names, or None if input is not callable.
713	Resolves distribution names from argument names, filling in missing names with a leaf name prefix. Takes distribution function arguments, distribution names list, and a leaf name, returns a tuple of resolved distribution names.
714	Returns the distribution's required arguments by analyzing the function signature using tf_inspect, removing the 'self' argument for classes, and excluding arguments with default values to ensure only required arguments are returned as a tuple.
715	Calculate the KL divergence between two `JointDistributionSequential`s by summing the KL divergences of their elemental distributions, ensuring both distributions have the same number of components and all distributions are independent.
716	Creates `dist_fn`, `dist_fn_wrapped`, and `dist_fn_args` by validating that the model is list-like and then applying `_unify_call_signature` to each element in the model.
717	Creates a dependency graph representation of a JointDistribution model as a tuple of (name, dependencies) pairs. The function resolves distribution names and validates uniqueness and one-to-one correspondence with model elements. Returns a tuple where each element contains a distribution name and its dependency names, with None values treated as empty tuples. Handles experimental edge cases and includes validation checks for distribution name uniqueness and proper alignment with model components.
718	Computes the Shannon entropy in nats for independent distributions, raising a ValueError if distributions are not independent. Returns the sum of entropies from wrapped distribution functions with validation.
719	Decorator function for argument bounds checking that validates if the first argument is within the distribution's support before executing the decorated method.
720	Visualizes image sequences as TensorBoard summaries by clipping values to [0,1], unstacking sequences, concatenating frames horizontally and vertically, and creating a single image summary with optional frame limit.
721	Visualizes input-reconstruction pairs in TensorBoard by concatenating the first `num` examples of both tensors and creating an image summary with the specified name.
722	This function performs qualitative analysis visualization for a DisentangledSequentialVAE model by generating and displaying reconstruction and generation results. It shows reconstructions from different sampling modes (standard, static prior, dynamic prior, swapped static/dynamic) and generated sequences with fixed static/dynamic components. The function uses tensor operations to compute averages across samples and organizes visualizations under appropriate scopes for clear analysis.
723	Summarize the parameters of a distribution by creating histogram summaries of its mean and standard deviation.

Args:
  dist: A Distribution object with mean and standard deviation parameters
  name: The name of the distribution
  name_scope: The name scope of this summary

Creates histogram summaries for distribution mean and standard deviation under the specified name scope.
724	Summarizes the mean of a tensor in both nats and bits per unit using TensorFlow summary operations within specified name scopes.
725	Runs the model to generate multivariate normal distribution.

Args:
  inputs: Unused.

Returns:
  A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions].
726	Returns an initial state for the LSTM cell with zero-filled tensors for previous output and cell state, shaped according to the specified sample batch shape and dimensions.
727	Runs the model to generate a distribution for a single timestep, returning a MultivariateNormalDiag distribution and the recurrent cell state. Takes sampled z values from previous timestep and current hidden/cell states as input, outputs distribution parameters using LSTM and output layer, with softplus activation to ensure positive diagonal scale.
728	Method summary:
Runs the model to generate an intermediate representation of input image sequences by applying a series of convolutional layers.

Args:
- inputs: A batch of image sequences `x_{1:T}` with shape `[sample_shape, batch_size, timesteps, height, width, channels]`

Returns:
- A batch of intermediate representations with shape `[sample_shape, batch_size, timesteps, hidden_size]`

The method reshapes input sequences, applies four convolutional layers (conv1-conv4), then reshapes the output back to the original structure.
729	Generate new sequences by sampling from latent priors and passing through decoder.

Args:
  batch_size: Number of sequences to generate
  length: Number of timesteps to generate for each sequence  
  samples: Number of samples to draw from latent distributions
  fix_static: Whether to share static latent variable samples across examples
  fix_dynamic: Whether to share dynamic latent variable samples across examples

Returns:
  Batched Independent distribution over generated sequences with shape [samples, batch_size, timesteps, height, width, channels]
730	Reconstruct input sequences by sampling from latent distributions and decoding. Supports various sampling and swapping modes for static and dynamic latents. Returns a batched distribution over reconstructed pixels.
731	Sample the static latent prior by drawing samples from a MultivariateNormalDiag distribution. Returns a tuple containing the sample tensor and the distribution object. When fixed=True, the same random sample is shared across all sequences; otherwise, independent samples are drawn for each sequence.
732	Sample the dynamic latent prior by generating sequences from a time-varying distribution.

Args:
  samples: Number of samples to draw from the latent distribution
  batch_size: Number of sequences to sample  
  length: Number of timesteps to sample for each sequence
  fixed: Boolean flag to share same random sample across all sequences

Returns:
  Tuple of (sample_tensor, MultivariateNormalDiag_distribution) where:
  - sample_tensor has shape [samples, batch_size, length, latent_size]
  - distribution has event shape [latent_size] and batch shape [samples, 1, length] (if fixed) or [samples, batch_size, length] (otherwise)
733	Returns the static batch shape of models represented by this component, which is the broadcast batch shape of all model parameters' prior batch shapes.
734	Returns the runtime batch shape of models represented by this component as an int Tensor, which matches the batch shape of derived state space models.
735	Creates a LinearGaussianStateSpaceModel distribution over a specified number of timesteps using the model's parameters.

Args:
  num_timesteps: Python int number of timesteps to model
  param_vals: List of tensor parameter values or dict mapping parameter names to values
  initial_state_prior: Optional Distribution instance overriding default initial state prior
  initial_step: Optional int specifying initial timestep (for time-varying components)

Returns:
  LinearGaussianStateSpaceModel Distribution object
736	Samples from the joint prior over model parameters and trajectories.

Args:
  num_timesteps: Scalar `int` `Tensor` number of timesteps to model.
  initial_step: Optional scalar `int` `Tensor` specifying the starting timestep. Default value: 0.
  params_sample_shape: Number of possible worlds to sample iid from the parameter prior. Default value: [].
  trajectories_sample_shape: For each sampled set of parameters, number of trajectories to sample. Default value: [].
  seed: Python `int` random seed.

Returns:
  trajectories: `float` `Tensor` of shape `trajectories_sample_shape + params_sample_shape + [num_timesteps, 1]` containing all sampled trajectories.
  param_samples: list of sampled parameter value `Tensor`s, in order corresponding to `self.parameters`, each of shape `params_sample_shape + prior.batch_shape + prior.event_shape`.
737	Computes the minimum event dimensions associated with a chain of bijectors by tracking how rank-changing bijectors affect the dimensions requiring computation. For each bijector in the list, it adjusts the minimum event dimensions based on whether the computation is forward or inverse, accounting for synthetic rank growth or decrease caused by rank-changing bijectors. The result represents the total number of rightmost dimensions that require computation in the bijector chain.
738	Converts a vector size to the corresponding square matrix dimension by solving the triangular number formula. For scalar inputs, validates that the vector length is a triangular number and returns the matrix dimension. For tensor inputs, performs the same validation within a TensorFlow graph with optional runtime validation.
739	Returns the indices that would sort an array along the given axis, with support for both ascending and descending order.
740	Sorts an array in ascending or descending order along a specified axis using numpy implementation, with optional stability guarantee.
741	Normal distribution function that computes the area under the Gaussian probability density function from negative infinity to x, returning 0.5 * (1 + erf(x / sqrt(2))) or 0.5 * erfc(x / sqrt(2)). Accepts float32/float64 tensors, raises TypeError for other dtypes.
742	Computes the standard normal cumulative distribution function (CDF) using error function transformations for numerical stability.
743	Returns the inverse of the CDF of the Normal distribution function, computing x such that the area under the pdf from minus infinity to x equals p. Uses piece-wise rational approximation. Supports float32 and float64 dtypes.
744	Computes the log of the Normal distribution function (log_ndtr) using different approximations based on the input value range. For large positive x, uses the approximation `-ndtr(-x)`; for intermediate values, takes the log of ndtr; for small x, uses an asymptotic series approximation of erf. Supports float32 and float64 dtypes with configurable series order for the asymptotic expansion. Raises TypeError for unsupported dtypes or invalid series_order values.
745	Calculates the asymptotic series used in log_ndtr by computing an alternating sum of terms involving double factorials and powers of x, returning 1 plus the computed sum.
746	Computes the inverse error function (erfinv) of a tensor.

This function calculates the inverse of the error function (erf) for input tensor `x`. It accepts float32 or float64 tensors and returns a tensor of the same dtype. The computation uses the relationship between the error function and the inverse normal cumulative distribution function (ndtri).

Args:
  x: `Tensor` of type `float32`, `float64`
  name: Python string. A name for the operation (default="erfinv")

Returns:
  `Tensor` with `dtype=x.dtype`

Raises:
  TypeError: if `x` is not floating-type

The implementation uses the mathematical relationship: erfinv(x) = sqrt(2) * ndtri((x + 1) / 2)
747	Log Laplace distribution function that computes log of cumulative distribution function with numerical stability. For x <= 0, it uses exact formula log(0.5) + x. For x > 0, it uses log(1 - 0.5 * exp(-x)) with safe exponential computation to avoid numerical issues. Supports float32 and float64 dtypes.
748	Computes the joint log probability for a piecewise Poisson rate model with two lambda parameters and a change point tau. Returns the sum of log probabilities from exponential priors on lambda_1 and lambda_2, uniform prior on tau, and Poisson likelihood of count_data given the piecewise lambda rates.
749	Runs Hamiltonian Monte Carlo (HMC) on a text-messages unnormalized posterior, measuring acceptance rate and wall time for sampling.
750	Returns True if the given index_points would yield a univariate marginal distribution. A marginal is considered univariate if the number of index points is exactly 1. If the number of index points cannot be determined statically (dynamic shape), it defaults to False (multivariate) and warns that some methods like `cdf` will be unavailable.
751	Computes the marginal distribution of the Gaussian Process at specified index points. Returns either a Normal distribution (for single index point) or MultivariateNormalLinearOperator (for multiple index points), leveraging cached computations and numerical stability via Cholesky decomposition with jitter.
752	Return `index_points` if not None, else `self._index_points`. Raises ValueError if both are None.
753	Creates a stacked IAF (Invertible Affine Flow) bijector for vector-valued events with alternating masked autoregressive flows and permutations. The bijector consists of multiple IAF layers with specified hidden layers and alternating permutation layers, operating on events of given size.
754	Runs one iteration of NeuTra by updating the number of leapfrog steps based on the current step size and then executing one step of the underlying kernel, returning the new state and kernel results with the original state structure restored.
755	Trains a bijector using variational inference and creates initial kernel results for a Markov chain. Uses Adam optimization to minimize the difference between variational distribution and target log probability over sampled batches. The function performs gradient-based optimization for a specified number of training steps, applies gradient clipping, and returns bootstrapped results from an underlying kernel using samples from the variational distribution.
756	Returns the outer product of the squared difference between x and y, equivalent to tf.squared_difference but computed as z[..., tf.newaxis, :] * z[..., tf.newaxis] where z = x - y.
757	Enables uniform interface to value and batch jacobian calculation that works in both eager and graph modes. Takes a scalar function f and value x, returns tuple of (f(x), J(x)) where J(x) is the batch jacobian. Uses GradientTape for eager mode and gradients.batch_jacobian for graph mode.
758	Disables computation of second derivatives for a tensor by returning the tensor unchanged along with a gradient function that raises LookupError when second derivatives are attempted to be computed.
759	Performs distributional transform on mixture samples by applying conditional CDFs to convert them into samples from a product of Uniform[0, 1] distributions. It assumes factorized components and computes posterior mixture weights to calculate the transformed result.
760	Split a covariance matrix into block-diagonal marginals of given sizes.
761	Decomposes a joint posterior distribution into marginal distributions for each component of an additive structural time series model. Takes posterior means, covariances, and parameter samples, and returns a dictionary mapping each model component to its corresponding predictive distribution over time.
762	Decomposes an observed time series into contributions from each component of a structural time series model by computing posterior marginals and mapping them back through the observation models. Returns a dictionary of distributions representing the posterior marginal distributions for each model component.
763	Decompose a forecast distribution into contributions from each component of a structural time series model.

This function takes a forecast distribution generated by `tfp.sts.forecast()` and decomposes it into marginal forecast distributions for each individual component of the model. It extracts the latent mean and covariance from the forecast distribution, reorganizes the dimensions appropriately, and then uses internal helper functions to compute the component-wise forecasts based on the model structure and parameter samples.

Args:
  model: A `tfp.sts.Sum` instance representing the structural time series model.
  forecast_dist: A `Distribution` instance from `tfp.sts.forecast()`, specifically a `tfd.MixtureSameFamily` over `tfd.LinearGaussianStateSpaceModel`.
  parameter_samples: Posterior samples of model parameters, either as a list or dict of tensors.

Returns:
  An `OrderedDict` mapping each component in `model.components` to its corresponding forecast distribution with matching batch and event shapes.

The function is designed to work with forecast distributions created by `tfp.sts.forecast()` and requires the forecast distribution to be a mixture of linear Gaussian state space models. The returned component forecasts can be used to analyze individual component contributions to the overall forecast and visualize their uncertainties separately.

Example usage involves first fitting a structural time series model and generating a forecast, then calling this function to decompose the forecast into individual component forecasts for further analysis and visualization.
764	Converts a dense Tensor to a SparseTensor by dropping cells with a specified ignore value, preserving the original shape while only storing non-ignored elements.
765	Defers an operator overload to the specified attribute by creating a wrapper function that applies the operator to the 'value' attribute of the first argument.
766	Returns a human-readable representation of a tensor's numpy value as a string, with special handling for multi-line outputs and non-numpy-compatible dtypes.
767	Sample the shape of a random variable and return it as a `TensorShape` object. If the sample shape is already a tensor, it extracts the static value to create the TensorShape. Otherwise, it directly converts the sample shape to a TensorShape.
768	Samples the shape of a random variable as a 1-D Tensor, returning either the existing sample shape tensor or converting the sample shape to a tensor with int32 dtype.
769	Get tensor that the random variable corresponds to. Samples from the distribution if no value has been set yet, raising NotImplementedError if sampling is not implemented for the distribution.
770	Evaluates and returns the value of this random variable in a TensorFlow session. Requires an active session where the graph has been launched. If no session is provided, uses the default session. Accepts an optional feed dictionary for tensor values. Returns the computed value of the random variable.
771	Returns the value as a NumPy array, but only works when the value is an EagerTensor in TF Eager mode. Raises NotImplementedError if the value is not an EagerTensor.
772	Computes the posterior Normal distribution with conjugate prior on the mean for known scale observations.

This function calculates the posterior distribution of an unknown mean `loc` given:
- A prior Normal distribution with parameters (loc0, scale0)
- Known variance scale
- Sum s of n observations

The result is a new Normal distribution with updated parameters:
- Location: ' = (/ + s/)  '
- Scale: ' = 1/(1/ + n/)

The function performs type checking and broadcasting to handle multidimensional inputs, returning a Normal distribution object representing the posterior belief about the unknown mean.
773	Builds a scale-and-shift function using a multi-layer neural network for Real NVP bijector, returning shift and log_scale terms. Supports optional conditioning through a conditioned template, and can be configured for shift-only (NICE) behavior. Raises NotImplementedError for unknown input dimensions or conditioning.
774	Returns a batch of points chosen uniformly from the unit hypersphere by generating random Gaussian samples and normalizing them to unit norm.
775	Returns the unnormalized log density of an LKJ distribution for correlation matrices.

This function computes the log density of correlation matrices with respect to an LKJ distribution using the formula `det(matrix) ** (concentration - 1)`. It handles numerical stability issues by using `slogdet` instead of `logdet` when the input is not in Cholesky form, which avoids errors with nearly singular matrices.

Args:
  x: `float` or `double` `Tensor` of correlation matrices with shape `B + [D, D]`
  name: Python `str` name prefixed to Ops (optional)

Returns:
  A Tensor of unnormalized log densities for each matrix element
776	Returns the log normalization of an LKJ distribution using a formula from D. Lewandowski et al [1], p. 1999. Computes log normalizers using log-gamma functions and pi constants, with operations performed in a name-scope for the given name.
777	Returns the explicit dtype from `args_list` if it exists, otherwise returns the preferred_dtype. If multiple dtypes are found in args_list, raises a TypeError for incompatible dtypes. If neither args_list nor preferred_dtype provide a dtype, returns None. The result is converted to numpy dtype format.
778	Creates a factory function that generates summary statistic implementations (like mean, stddev, mode) for distributions. The returned function computes the statistic along with appropriate reshaping and broadcasting to maintain proper tensor dimensions according to batch shape, sample shape, and event shape.
779	Helper function that broadcasts a tensor to match the shape of target tensors by adding zero tensors of the same shape.
780	Pdf evaluated at the peak, normalized between low and high bounds.
781	Estimates a lower bound on the effective sample size (ESS) for each independent Markov chain in the input states. ESS represents the size of an independent and identically distributed sample that would have the same variance as the input states. The function computes ESS by estimating the auto-correlation sequence and applying optional filters to truncate noisy tail terms. It supports both single tensors and lists of tensors as input, and returns ESS values with the same structure as the input states (excluding the first dimension which indexes the samples).
782	Computes the effective sample size (ESS) for a single tensor of states, accounting for autocorrelation and optional filtering. It calculates ESS based on the formula involving the sum of weighted autocorrelations, with handling for truncation and threshold filtering of autocorrelation values.
783	Computes the potential scale reduction (R-hat) statistic for one state tensor, measuring convergence of MCMC chains by comparing between-chain and within-chain variances. Returns the R-hat value that should approach 1.0 for well-converged chains.
784	Get the number of elements of tensor `x` along a specific `axis`, returning the count with the same dtype as `x`. If `axis` is None, returns the total number of elements in `x`.
785	Broadcasts a secondary argument to match the length of states, either by validating a list argument or replicating a scalar value.
786	Uses Gauss-Hermite quadrature to construct quadrature points and weights for log-normal distributions, mapping grid points to log-rate parameters of Poisson distributions.
787	Creates a quadrature scheme using LogNormal quantiles for integration on positive reals. Returns grid points and probabilities for quadrature approximation.
788	Returns new _Mapping with args merged with self.

Args:
  x: `Tensor` or None. Input to forward; output of inverse.
  y: `Tensor` or None. Input to inverse; output of forward.
  ildj: `Tensor`. This is the (un-reduce_sum'ed) inverse log det jacobian.
  kwargs: Python dictionary. Extra args supplied to forward/inverse/etc
    functions.
  mapping: Instance of _Mapping to merge. Can only be specified if no other
    arg is specified.

Returns:
  mapping: New instance of `_Mapping` which has inputs merged with self.

Raises:
  ValueError: if mapping and any other arg is not `None`.
789	Summary: Removes a specified field from the cache by setting it to None while preserving other fields and metadata.
790	Helper method to merge two values, returning the first non-None value or raising a ValueError if values are incompatible when use_equals is False (checks identity) or True (checks equality).
791	Converts nested tuple, list, or dict to nested tuple by recursively traversing and converting all nested collections to tuples, with dict items sorted by keys.
792	Computes the doubling increments for the left endpoint in a doubling procedure used to find a supersets of true slices. Returns the relative position of the left endpoint and interval widths after each doubling iteration.
793	Finds the index of the optimal set of bounds for each chain by determining the earliest point where bounds lie outside the slice, or the widest bounds if no such point exists. Uses tensor operations to compute weighted sums of bounds indicators and returns the argmax index.
794	Returns the bounds of the slice at each stage of the doubling procedure used in slice sampling.

This function implements the "doubling" algorithm from Neal (2003) to efficiently find appropriate slice bounds for slice sampling. It precomputes all possible doubling values for each chain and uses them to determine the optimal interval that lies outside the slice.

Args:
  x_initial: Initial points for slice sampling with shape and real dtype
  target_log_prob: Function returning log probability of target distribution
  log_slice_heights: Log of slice heights for each chain
  max_doublings: Maximum number of doublings to consider
  step_size: Initial interval size
  seed: Random seed for reproducibility
  name: Name prefix for operations

Returns:
  upper_bounds: Slice upper bounds for each chain
  lower_bounds: Slice lower bounds for each chain  
  both_ok: Boolean tensor indicating if both bounds lie outside slice

The function uses parallel computation of all possible doubling steps for efficiency and selects the best interval using a greedy approach based on the doubling procedure.
795	Samples from a slice using shrinkage for rejected points, implementing Neal's 2003 one-dimensional slice sampling algorithm with doubling and shrinkage steps.
796	Performs one-dimensional slice sampling for Markov chain Monte Carlo. Samples a new point from the target distribution using Neal's slice sampling algorithm, which adaptively finds valid sampling bounds and generates a new sample within those bounds. Returns the new sample, its target log probability, and the sampling bounds information.
797	Creates a value-setting interceptor for Edward2 random variables, allowing users to set specific values for variables in a model. It's useful for conditioning on observed data, sampling from posterior predictive distributions, and building inference primitives. The returned function intercepts operations and assigns specified values to matching random variables by name, leaving others unchanged. This enables flexible model manipulation such as computing log joint probabilities or generating posterior samples.
798	**Summary:**

`make_log_joint_fn` is a function that takes an Edward probabilistic program (a Python callable) and returns a log-joint probability function. This function computes the logarithm of the joint probability distribution over all random variables in the model, conditioned on the model's inputs and their corresponding values. It internally uses an interceptor to track random variable values and accumulate their log probabilities, returning the sum as the total log joint probability. The returned function accepts both positional and keyword arguments corresponding to the inputs and values of random variables in the model.
799	Filters keyword arguments to be compatible with a function's signature, returning only those arguments that exist in the function's parameter list.
800	VGG convolutional block that applies two 2D flipout convolutions with batch normalization and ReLU activation, followed by max pooling.
801	Builds a tree for Hamiltonian Monte Carlo by recursively performing leapfrog integration steps, combining results from subtrees, and determining valid candidates based on slice sampling and U-turn detection.
802	Wraps a value and gradients function to check for None gradients and raise a ValueError if any are found.
803	Returns True if the dot product of state differences and momentum is positive, indicating no U-turn pattern exists between the states.
804	Runs one step of leapfrog integration for Hamiltonian Monte Carlo, updating state and momentum using gradient information and step size.
805	Computes the log-joint probability by summing the target log-probability and the negative half sum of squared momentum values.
806	Returns samples from a Bernoulli distribution by generating random uniform values and comparing them with the given probabilities.
807	Creates a closure that generates `loc` and `scale` parameters using `tf.get_variable`. The closure accepts dtype, shape, name, trainable flag, and variable creation function to produce location and scale parameters for distributions, with optional singular mode where scale is None.
808	Creates a function that builds Normal distributions with trainable parameters. The returned function generates either a Normal distribution or a Deterministic distribution (when scale approaches 0) using trainable loc and scale parameters initialized according to specified initializers. The distributions are wrapped in an Independent distribution with reinterpreted batch dimensions.
809	Creates a multivariate standard Normal distribution with specified parameters and shape, ignoring name, trainable, and add_variable_fn arguments. Returns an Independent distribution with batch dimensions reinterpreted.
810	Deserializes Keras-serialized functions by handling both named functions and lambda expressions. For 'function' type, it uses TensorFlow's deserialization utility for safer lookup in custom objects. For 'lambda' type, it loads functions from bytecode using `generic_utils.func_load`, which is unsafe. Raises TypeError for unknown function types. The function assumes required modules are imported within the function itself since Keras deserialized functions don't perform lexical scoping. This mimics TensorFlow's Lambda layer implementation.
811	Serializes a Python function for Keras by returning either its bytecode (for anonymous functions) or name (for named functions) along with its type, mimicking tf.keras.layers.Lambda implementation.
812	Broadcasts `from_structure` to match the structure of `to_structure`. If `from_structure` contains a single element, it is replicated to match the shape of `to_structure` without copying elements. Returns a new structure matching `to_structure`'s shape.
813	Converts a structure to tensors recursively, trying whole structure conversion first then individual elements if that fails.
814	Converts arguments to Tensors with optional dtype constraints. When dtype is None, converts elements recursively while preserving structure, treating lists/tuples as containers. When dtype is specified, it acts as both structural and numeric type constraint, ensuring the output matches the dtype structure. Returns converted arguments maintaining their original structure.
815	Calls a function with provided arguments, automatically expanding them based on argument type: unpacks lists/tuples (except namedtuples) as positional arguments, unpacks dictionaries as keyword arguments, or passes arguments directly otherwise.
816	Returns `Tensor` attributes related to shape and Python builtins, including overloadable operators and whitelisted members/properties for distribution semantics.
817	Creates a mixture of Gaussians prior distribution for latent representations. For a single component, returns a diagonal multivariate normal distribution with unit variance. For multiple components, returns a mixture model with learnable means, diagonal covariance matrices, and mixing weights, using softplus activation for positive scales.
818	Helper utility to arrange images in a grid pattern by reshaping and transposing image tensors into a rectangular field of specified dimensions.
819	Downloads a file from a URL to a local directory path, creating the directory if it doesn't exist. Returns the local file path.
820	Builds fake MNIST-style data for unit testing by creating random samples and returning train/eval input functions that generate tf.data.Dataset iterators with the fake data.
821	Helper to validate block sizes. Raises ValueError if block_sizes shape is incompatible with bijectors length, or returns block_sizes unchanged.
822	Verifies that tensor shapes in flat_xs don't broadcast, raising a ValueError with a specific message if they do. Returns the input tensors if validation is disabled or if all shapes are fully defined and equal. If shapes are not fully defined, it creates assertions to check shape equality at runtime.
823	Creates a trainable MultivariateNormalTriL distribution by parameterizing location and scale through neural network transformations. The function takes an input tensor and applies affine transformations to produce mean and lower-triangular scale matrix parameters for the MVN, with the scale matrix constrained to have positive diagonal elements via a softplus activation and shift.
824	Constructs a trainable Bernoulli distribution parameterized by logits using a dense layer transformation. Takes input tensor `x` and applies a layer function (default tf.layers.dense) to produce logits, then returns a `tfd.Bernoulli` distribution. Used for logistic regression and maximum likelihood estimation.
825	Creates a trainable `tfd.Normal` distribution with loc and scale parameters derived from input tensor `x` through configurable transformations. The function uses a layer function (defaulting to `tf.layers.dense`) to map input `x` to distribution parameters, allowing for flexible parameterization such as linear regression. The `loc_fn` and `scale_fn` arguments control how the location and scale parameters are computed from the layer outputs, with `scale_fn` supporting either callable transformations or fixed tensor values. Returns a `tfd.Normal` distribution instance.
826	Creates a trainable Poisson distribution parameterized by log rate using a neural network layer. The function applies a transformation to input tensor x through a configurable layer function and applies a log rate transformation before constructing the Poisson distribution. This is commonly used for Poisson regression tasks where the log rate parameter is learned from data through backpropagation.
827	Applies one step of the Euler-Maruyama method for Markov chain Monte Carlo sampling. Generates a proposal state by adding drift, volatility-weighted random noise, and step-size scaled perturbations to the current state. Returns the proposed state(s) with the same shape as the input state(s).
828	Computes the diffusion drift for MALA (Metropolis-Adjusted Langevin Algorithm) using the Euler-Maruyama method. The drift is calculated as 0.5 * step_size * volatility * gradient of target log probability + step_size * gradient of volatility, where volatility is squared and gradients are computed with respect to the current state. Returns drift components for each state part.
829	Helper function that computes the log acceptance-correction for a Metropolis-Hastings step with normal proposal densities. Given current and proposed states, volatilities, drifts, and step sizes, it calculates the correction term needed for the acceptance probability in MCMC sampling. The correction accounts for the asymmetric proposal densities where q(current_state | proposed_state) and q(proposed_state | current_state) are normal distributions with means shifted by drift terms and variances scaled by step size and volatility. Returns a tensor representing the log acceptance correction.
830	Helper function that computes volatility function results and their gradients when needed, handling both scalar and list-like inputs, broadcasting volatility values to match state dimensions, and calculating gradients of volatility squared.
831	Helper function that broadcasts volatility parts to match the shape of state parts by adding zeros with the same dtype as state parts.
832	Builds a transition matrix for an autoregressive StateSpaceModel. The matrix computes expected new values from previous states using autoregressive coefficients and shifts previous values down while "forgetting" the oldest value. The resulting matrix has shape [order, order] where the first row contains coefficients and subsequent rows form a shifted identity matrix.
833	Computes the graph and static `sample_shape` by analyzing the dimensions of input tensor `x` relative to batch and event dimensions, returning both dynamic and static shape components.
834	Reshapes input tensor according to sample and batch shapes, applies function, then reshapes output back to correct dimensions with shape validation.
835	Calls the provided function `fn` with optional extra arguments, reshapes its output according to batch and event shapes, and sets the static shape when possible. The function handles both dynamic and static shape information, ensuring the result has the correct tensor shape based on batch shape and event shape lists. Uses control dependencies for runtime assertions.
836	The `_bdtr` function computes the binomial cumulative distribution function, which calculates the sum of probabilities from 0 to k in a binomial distribution. It takes three floating-point tensors (k, n, p) representing the upper limit, number of trials, and success probability respectively. The function uses the incomplete beta function (`betainc`) for computation while handling edge cases where k equals n to ensure numerical stability and proper gradient computation. The result represents P(X  k) for a binomial distribution with parameters n and p.
837	Method `_flat_sample_distributions` executes a model generator to create both sampled values and their corresponding probability distributions. It iterates through the model's coroutine, handling each distribution by either using a provided value or sampling from the distribution. The method returns two lists: one containing the distributions and another containing the generated values. The sampling process uses a seed stream for reproducibility, and handles both root distributions (which may have sample shapes) and child distributions (which use empty sample shapes). The method gracefully handles the end of the generator with a StopIteration exception.
838	Latent Dirichlet Allocation generative model that samples documents as bags of words, parameterized by a Dirichlet prior over topics and topic-word probability distributions.
839	Creates a variational distribution for LDA by building a neural network encoder that maps bag-of-words input to topic distributions, using specified activation functions and layer sizes, and returns a function that generates a Dirichlet distribution over topics.
840	Returns a summary of learned topics as strings, showing top words for topics with highest prior weights.
841	Creates a tf.data.Dataset from the 20 newsgroups dataset by loading data from a directory, converting it to a sparse matrix representation, and returning a dataset that yields dense TensorFlow tensors for each document. Supports shuffling and repeating for training data.
842	Builds fake data for unit testing with train and eval input functions and vocabulary.
843	Builds input functions for training and evaluation data using bag-of-words representation.

Arguments:
  data_dir: Folder in which to store the data.
  batch_size: Batch size for both train and evaluation.

Returns:
  train_input_fn: A function that returns an iterator over the training data.
  eval_input_fn: A function that returns an iterator over the evaluation data.
  vocabulary: A mapping of word's integer index to the corresponding string.
844	Minimizes a regularized loss function using Hessian-informed proximal gradient descent. Solves the optimization problem argmin{ Loss(x) + l1_regularizer * ||x||_1 + l2_regularizer * ||x||_2**2 : x in R^n } where Loss is a convex C^2 function. Uses gradient and Hessian information to efficiently find the minimum, with support for L1 and L2 regularization. The algorithm iteratively applies proximal gradient steps until convergence or maximum iterations reached. Returns the optimized x values, convergence status, and number of iterations performed.
845	Adds control dependencies to commitment loss to update the codebook using exponential moving averages of assignments and means.
846	Helper method to save a grid of images to a PNG file.
Args:
  x: A numpy array of shape [n_images, height, width].
  fname: The filename to write to (including extension).
Returns:
  None (saves file to disk)
847	Helper method to save images visualizing model reconstructions by saving input images, their reconstructions, and optional prior samples to the specified directory with given prefix.
848	Loads Hugo Larochelle's binary static MNIST dataset as a tf.data.Dataset, where each image is represented as a 28x28x1 boolean tensor cast to float32, and returns it with dummy labels set to 0.
849	Returns the numpy dtype corresponding to this dtype. If the dtype has an as_numpy_dtype attribute, it returns that, otherwise it returns the dtype itself.
850	Returns the base dtype by removing reference types, if present. If the input dtype has a base_dtype attribute (such as reference dtypes), it returns that base dtype; otherwise, it returns the original dtype unchanged.
851	Returns whether the given data type is a boolean data type. Uses TensorFlow's dtype handling with fallback to NumPy dtype checking via the 'kind' attribute to properly identify boolean types while avoiding incorrect subdtype matches.
852	Returns whether the given dtype represents a complex floating point type by checking both TensorFlow's is_complex attribute and NumPy's complex subtype compatibility.
853	Returns the maximum representable value in the given data type. For floating-point and complex types, it uses `np.finfo(dtype).max`, and for integer types, it uses `np.iinfo(dtype).max`. If the dtype has a `max` attribute, it returns that directly.
854	Returns the string name for a given dtype by checking for 'name' attribute, '__name__' attribute, or converting to string.
855	Returns the number of bytes to represent a given dtype.
856	Asserts all items are of the same base type, raising ValueError if types don't match. Returns the validated type or None if no items provided.
857	Validate and return float type based on `tensors` and `dtype` for operations requiring consistent floating point types. Checks that all tensors are the same type, validates against supplied dtype if provided, and ensures the type is a floating point type. Returns the validated type or defaults to `dtypes.float32` if neither tensors nor dtype is supplied. Raises ValueError if requirements are not met.
858	Minimizes a scalar-valued function using the Nelder-Mead simplex algorithm. Supports batch evaluation of the objective function and allows customization of algorithm parameters. Returns optimization results including convergence status, position, objective value, and evaluation counts.
859	Performs a single iteration of the Nelder-Mead optimization algorithm, updating the simplex and objective values based on reflection, expansion, contraction, or shrinkage operations. Returns the updated simplex, objective values, and evaluation count.
860	Creates a condition function pair that accepts a reflection by replacing the worst simplex point with the reflected point. Returns a function that performs the replacement and returns the updated simplex and objective values.
861	Creates a condition function pair for performing the expansion step in a simplex optimization algorithm. The function expands the worst point of the simplex away from the face centroid and accepts either the expanded point or the original reflected point based on which has a better objective value. Returns a tuple containing the next simplex, next objective values, and a step count of 1.
862	Creates a function that performs outside contraction in Nelder-Mead optimization, evaluating whether the contracted point should replace the worst point in the simplex based on objective function values.
863	Shrinks the simplex around the best vertex by moving all vertices towards the best vertex using the specified shrinkage factor, then evaluates the objective function at the new simplex positions. Returns a tuple containing a boolean flag (False indicating no successful contraction), the shrunk simplex, objective values at the shrunk simplex, and evaluation metadata.
864	Replaces an element at the specified index in a tensor with a replacement value, returning a new tensor with the element swapped at that position.
865	Returns True if the simplex has converged based on either function value variation or position tolerance criteria.
866	Summary: Prepares initial simplex and objective function values for optimization. Either an initial simplex or initial vertex (with step sizes) must be provided. Validates inputs and returns structured arguments including simplex vertices, objective values, and evaluation counts. Supports both batch and individual evaluation modes. Raises ValueError for invalid input combinations.
867	Prepares and validates simplex arguments for optimization by converting the initial simplex to a tensor, determining the problem dimension, evaluating the objective function at simplex vertices if needed, and returning all necessary components including dimension, number of vertices, simplex coordinates, objective values, and evaluation count.
868	Constructs a standard axes-aligned simplex for optimization algorithms by creating a set of vertices around an initial vertex, evaluates the objective function at these vertices, and returns the simplex along with function evaluations.
869	Evaluates an objective function on a batch of points, either in batch mode or element-wise. Returns function values and evaluation count.
870	Save a PNG plot with histograms of weight means and stddevs.

Args:
  names: A Python `iterable` of `str` variable names.
  qm_vals: A Python `iterable`, the same length as `names`,
    whose elements are Numpy `array`s, of any shape, containing
    posterior means of weight varibles.
  qs_vals: A Python `iterable`, the same length as `names`,
    whose elements are Numpy `array`s, of any shape, containing
    posterior standard deviations of weight varibles.
  fname: Python `str` filename to save the plot to.
871	Save a PNG plot visualizing posterior uncertainty on heldout data. The plot shows input images alongside posterior samples and predictive probabilities for the first `n` datapoints. Each row displays: (1) the input image, (2) bar plots of Monte Carlo samples of class probabilities (with transparency), and (3) bar plot of mean predicted probabilities across all samples. The plot is saved to the specified filename with an optional title.
872	Build fake MNIST-style data for unit testing with specified number of examples, containing random images and labels for both training and validation sets.
873	Returns initializer configuration as a JSON-serializable dict containing serialized initializers, sizes, and validate_args.
874	Creates an initializer instance from a configuration dictionary by deserializing nested initializers and extracting relevant parameters.
875	Numpy matmul wrapper that supports optional matrix transposition and adjoint operations, but does not support sparse matrix multiplication.
876	Helper function to compute standard deviation, covariance, and variance with proper handling of degrees of freedom and edge cases.
877	Computes the log of the exponentially weighted moving mean of the exponential of a new observation, updating a variable in a numerically stable and lock-free manner.
878	Ensures non-scalar input has at least one column by reshaping 1D tensors to 2D tensors with shape (n, 1) while preserving multi-dimensional tensors and scalar inputs unchanged.
879	Generates a Tensor of -1 or +1 values chosen uniformly at random, following the Rademacher distribution. Uses random uniform generation and transforms it to produce the desired output values.
880	Generates a tensor of positive real numbers drawn from a Rayleigh distribution with specified shape and scale parameter. The function uses the inverse transform sampling method, where uniform random variables are transformed using the inverse cumulative distribution function of the Rayleigh distribution. The scale parameter controls the distribution's spread, with default value of 1.0. Supports broadcasting between shape and scale tensors, and allows optional seeding for reproducible results.
881	Convenience function that selects between two scalar values based on a predicate, using tf.where for dynamic cases and direct return for static cases.
882	Finish computation of log_prob on one element of the inverse image by rotating dimensions, computing base distribution log probability, applying event dimension reduction if needed, adding inverse log determinant of Jacobian, and setting the appropriate output shape.
883	Finish computation of probability for one element of the inverse image by rotating dimensions, computing distribution probability, applying log-determinant of Jacobian adjustment, and handling event dimension overrides with shape broadcasting.
884	Helper function that rotates tensor dimensions by rolling event dimensions left or right, with rotation only applied when needed based on internal flag.
885	Inverse of tf.nn.batch_normalization.

Args:
  x: Input `Tensor` of arbitrary dimensionality.
  mean: A mean `Tensor`.
  variance: A variance `Tensor`.
  offset: An offset `Tensor`, often denoted `beta` in equations, or
    None. If present, will be added to the normalized tensor.
  scale: A scale `Tensor`, often denoted `gamma` in equations, or
    `None`. If present, the scale is applied to the normalized tensor.
  variance_epsilon: A small `float` added to the minibatch `variance` to
    prevent dividing by zero.
  name: A name for this operation (optional).

Returns:
  batch_unnormalized: The de-normalized, de-scaled, de-offset `Tensor`.
886	Validates that a given layer is a proper BatchNormalization layer without unsupported features.

Checks that:
- Layer is an instance of tf.keras.layers.BatchNormalization or tf.compat.v1.layers.BatchNormalization
- Layer does not use renormalization (renorm=True)
- Layer does not use virtual batch sizes (virtual_batch_size specified)

Raises ValueError with descriptive messages if any validation fails.
887	Slices a single parameter of a distribution according to the given slices, handling broadcasting and alignment between parameter and distribution batch dimensions.
888	Computes a dictionary of batch-sliced parameter overrides for a distribution.

This function takes a distribution, its parameter event dimensions, and slicing information, then creates a dictionary mapping parameter names to their sliced tensor values. It validates that required parameters exist, handles None values for optional parameters, determines appropriate dtypes, converts parameters to tensors, and applies slicing operations to generate the override dictionary used for batch slicing operations.

Args:
  dist: The tfd.Distribution being batch-sliced
  params_event_ndims: Per-event parameter ranks as a `str->int` dictionary
  slices: Slices as received by __getitem__

Returns:
  overrides: `str->Tensor` dictionary of batch-sliced parameter overrides
889	Applies a single slicing step to a distribution by creating a new instance with updated parameters based on slices and overrides.
890	Applies a sequence of slice or copy-with-overrides operations to a distribution by iteratively processing each slice/override pair and updating the distribution accordingly.
891	Slices a distribution along its batch dimensions using the provided slices and parameter overrides, maintaining provenance tracking for gradient computation back to original distribution arguments. Returns a new batch-sliced distribution instance.
892	Runs multiple Fisher scoring steps to fit a generalized linear model by iteratively optimizing model coefficients until convergence or maximum iterations are reached.
893	Returns a callback function that checks if the fitting procedure has converged based on the relative change in model coefficients. Convergence is determined when the maximum relative Euclidean norm between successive coefficient vectors is less than the specified tolerance. The function computes the relative norm as ||w0 - w1|| / (1 + ||w0||) and returns True if this value is below the tolerance threshold across all coefficients, and the iteration count is greater than zero.
894	Helper function to sanitize and prepare input arguments for model fitting, ensuring consistent dtypes and handling default values for model coefficients and predicted linear responses.
895	Returns the number of columns in a given Tensor by checking the last dimension value or falling back to using tf.shape.
896	Wraps a function to prefer calling a static version when all inputs are static, raising an error if argument specs don't match.
897	Wraps new_fn with the docstring of original_fn after validating that both functions have matching argument specifications. Raises ValueError if argument specs don't match. Returns a decorated version of original_fn that executes new_fn with the same arguments.
898	Helper function for statically evaluating predicates in `cond`. Accepts boolean values, 1/0, or tensors and returns their static evaluation. Raises TypeError for invalid input types.
899	Computes the rank of a tensor given its shape, handling both tensor shapes and shape tensors with appropriate fallbacks and lambda functions for dynamic size calculation.
900	A function that executes conditional logic similar to tf.case but with static predicate evaluation. It processes predicate-function pairs, executing the first function whose predicate evaluates to True, or the default function if none match. Predicates that are constants or boolean values are evaluated statically for optimization. Returns tensors from the executed function or default.
901	Helper function to standardize operation scope by creating a nested name scope with the object's name as the outer scope and an optional custom scope as the inner scope.
902	Computes the standard deviation of a mixture distribution given component weights, means, and standard deviations. Uses batched matrix operations to calculate the weighted averages of means, variances, and squared means, then applies the variance formula to derive the final standard deviation.
903	Creates a LinearOperator representing a lower triangular matrix from given scale parameters. Supports construction from lower triangular matrix, diagonal matrix, or scaled identity matrix, with optional validation and positive definiteness checks. Returns a LinearOperatorLowerTriangular instance when a lower triangular component is provided, otherwise falls back to diagonal scaling.
904	Creates a LinearOperator representing a diagonal matrix with optional scaling. Returns a LinearOperatorDiag, LinearOperatorIdentity, or LinearOperatorScaledIdentity based on input parameters. Supports validation and assertion checking for positive definiteness. Raises ValueError if shape cannot be inferred when only scale_identity_multiplier is provided.
905	Infers distribution batch and event shapes by broadcasting location and scale parameters. Returns statically determinable shapes when possible, otherwise returns tensors. Validates that the last dimension of loc is either size 1 or matches scale's range dimension. Handles both scalar and tensor inputs for loc and scale, with special handling for scalar loc values.
906	Returns `True` if `scale` is a `LinearOperator` that is known to be diagonal, including instances of `LinearOperatorIdentity`, `LinearOperatorScaledIdentity`, or `LinearOperatorDiag`. Raises `TypeError` if `scale` is not a `LinearOperator`.
907	Helper function to validate a scalar distribution initialization argument. Checks that the distribution has scalar batch and event shapes, is fully reparameterized, and has the expected dtype. Optionally adds tf.Assert ops to enforce these checks at graph execution time. Returns a list of assertion ops to run if validate_args is True. Raises ValueError if distribution is not fully reparameterized or not scalar, and TypeError if dtypes don't match.
908	Pad dimensions of event tensors for mixture distributions to enable broadcasting with categorical distributions.
909	Convenience function that chooses one of two values based on a scalar boolean predicate, equivalent to a static version of `tf.where` that returns the result immediately if the predicate can be evaluated statically, or uses `tf.where` otherwise.
910	Move a tensor dimension from a source index to a destination index within its shape, returning a tensor with the same rank but with the specified dimension moved to the new position. Handles negative indexing and includes special cases for when the source and destination indices are equal or when moving left versus right within the dimension order.
911	Asserts that tensor x is non-negative and (optionally) contains only integers. Returns the input tensor if assertions pass, otherwise raises an exception.
912	Returns whether two tensors have the same dynamic shape by comparing their shape tensors element-wise using conditional logic that handles cases where shapes may not be fully defined at graph construction time.
913	Helper function that attempts to extract a static value from a tensor, optionally casting to a specific dtype. Returns the static value if possible, otherwise returns None.
914	Helper function that returns True if the given dtype is known to be unsigned, specifically for bool, uint8, and uint16 types. Returns False for all other dtypes.
915	Helper function that returns True if a dtype is known to be signed, checking against a predefined set of signed dtypes including float types and signed integer types.
916	Helper function that returns the largest integer exactly representable by a given dtype. For floating-point types, it calculates based on the number of mantissa bits. For integer types, it uses the maximum value from numpy's integer info. For boolean types, it returns 1. Raises TypeError for unrecognized dtypes.
917	Helper function that returns the smallest integer exactly representable by a given dtype. For unsigned dtypes, returns 0. For signed dtypes, returns the negative of the largest representable integer. Raises TypeError for unrecognized dtypes.
918	Helper function that returns True if a dtype is integer-like (either an integer type or boolean type), otherwise raises TypeError for unrecognized dtypes.
919	Checks that categorical distribution parameters don't have too many classes, ensuring the number of classes doesn't exceed the precision limits of the dtype and int32 indexing constraints. Raises TypeError for unknown dtypes and ValueError for statically identified oversized parameters.
920	Computes the multinomial coefficient n! / (n_i!) where n is the total number of outcomes and counts represents the distribution across k classes. Uses log-gamma functions for numerical stability.
921	Rotates the dimensions of a tensor circularly left or right by a specified number of positions. When `shift` is negative, dimensions are moved left; when positive, they are moved right. The operation is equivalent to transposing the tensor using a rolled permutation of dimension indices. Supports both static and dynamic tensor shapes, with optimizations for static cases. The function handles edge cases like shifts greater than the number of dimensions by using modulo arithmetic.
922	Picks elements from two tensors based on a boolean condition. If the condition is a constant, returns the corresponding tensor immediately. Otherwise, concatenates the tensors and slices based on the condition to return either the true_vector or false_vector. Raises TypeError if dtypes don't match or if condition is not boolean.
923	**Summary:**

`prefer_static_broadcast_shape` is a convenience function that computes the broadcast shape of two tensor shapes, preferring static computation when possible. It takes two 1-D integer tensors representing shapes and returns the broadcast shape as either a `TensorShape` (when static computation is possible) or a `Tensor` (when dynamic computation is required). The function first attempts to statically broadcast the shapes using `tf.broadcast_static_shape`, and falls back to dynamic broadcasting with `tf.broadcast_dynamic_shape` if static computation cannot be performed. The function handles both tensor shapes and tensor values, converting them appropriately for broadcasting.
924	Generate a new seed from the given seed and salt by combining them, hashing with MD5, taking the first 8 characters of the hexadecimal digest, converting to an integer, and applying a mask to ensure it's a positive 32-bit integer. Returns None if seed is None.
925	Creates a tridiagonal matrix from below, diagonal, and above diagonals. The function takes three optional tensor arguments representing the below-diagonal, main diagonal, and above-diagonal elements respectively, and returns a tensor representing the tridiagonal matrix. If any diagonal is not provided, it is treated as zeros. The operation is intended for convenience rather than efficiency.
926	Returns the size of a specific dimension of tensor `x` along the given `axis`. First attempts to get the static shape value, and falls back to dynamic shape computation if the static value is not available.
927	Validates or computes quadrature grid and probabilities for numerical integration. Returns a tuple of tensors representing sample points and weights, ensuring they have matching dimensions and are properly normalized. When input is None, uses Hermite-Gauss quadrature with degree 8. Includes optional validation of input arguments.
928	Returns parent frame arguments as a dictionary containing the caller's positional and keyword arguments, excluding variable arguments (*varargs). When called inside a function, it captures the caller's function arguments and returns them. When called at global scope, it returns an empty dictionary. WARNING: Argument names overloaded before calling this method will reflect the overloaded values, so it's recommended to call at the beginning of the function.
929	Transform a 0-D or 1-D `Tensor` to be 1-D. Converts scalar inputs to single-element vectors while preserving existing 1-D tensors. Handles both static and dynamic shapes with optional validation.
930	Produces an output tensor only after specified dependencies have been executed, using control dependencies to ensure execution order in TensorFlow graphs. Returns the original tensor with embedded dependencies that must complete before the output is evaluated.
931	Checks that `rightmost_transposed_ndims` is a valid scalar integer type with non-negative value, raising errors or returning assertions for validation based on `validate_args` parameter.
932	Checks that `perm` is a valid permutation vector, raising errors for invalid types, shapes, or values. Returns assertions for validation when `validate_args` is True.
933	Helper function for _forward and _inverse_event_shape that computes the event shape by applying permutation and handling None dimensions. It validates input shape dimensions, handles static permutation cases, and returns the transformed shape with appropriate None values preserved.
934	Returns the concatenation of dimensions from two shape objects. Combines the dimensions of `x` and `other` (both convertible to `tf.TensorShape`) into a new shape object of the same type as `x`. If either input is completely unknown, information about the other shape is discarded. For example, concatenating shape [2, 3] with [4, 5] results in [2, 3, 4, 5].
935	Returns a list of dimension sizes from a shape object, or `None` if rank is unknown. Converts input to `tf.TensorShape` and returns dimension sizes as `tf.Dimension` objects if input is already a `tf.TensorShape`, otherwise returns `int` values.
936	Returns a shape combining the information in `x` and `other` by merging their dimensions elementwise using `tf.TensorShape.merge_with()`. The result has the same type as `x` and contains combined shape information. Raises ValueError if the shapes are incompatible.
937	Returns a shape based on `x` with at least the given `rank`.

For more details, see `help(tf.TensorShape.with_rank_at_least)`.

Args:
  x: object representing a shape; convertible to `tf.TensorShape`.
  rank: An `int` representing the minimum rank of `x` or else an assertion is
    raised.

Returns:
  shape: a shape having `type(x)` but guaranteed to have at least the given
    rank (or else an assertion was raised).

Raises:
  ValueError: If `x` does not represent a shape with at least the given
    `rank`.
938	Check that source and target shapes match, performing static validation when possible and dynamic validation when necessary. Returns None if shapes match statically, otherwise returns an assertion op for dynamic shape checking. Raises ValueError if static shapes don't match or if target shape cannot be inferred.
939	Augments a sample shape to broadcast batch dimensions by computing an augmented sample shape that allows a distribution with a partial batch shape to be broadcast to a full sample and batch shape. The function ensures that the batch dimensions of the distribution align with the target shape, raising errors for incompatible shapes or unsupported broadcasting scenarios. Returns the augmented sample shape that, when used to sample from the distribution, produces the desired combined sample and batch shape.
940	Builds a callable that performs one step of backward smoothing in a Kalman smoother, updating the backward pass state from timestep t to t-1 using transition matrices and filtering parameters.
941	Computes the backward update for a Kalman smoother, returning the smoothed mean and covariance at time t given filtered and predicted values, and the next posterior estimates. Uses the backward Kalman gain to combine the filtered state with the next time step's posterior information to produce the smoothed state estimate.
942	Builds a callable that performs one step of Kalman filtering given functions to retrieve transition and observation matrices and noise distributions.
943	Performs a conjugate update for a linear Gaussian model, computing the posterior distribution over a latent variable given linear Gaussian observations. Returns the posterior mean, posterior covariance, and the prior predictive distribution.
944	Propagates a filtered distribution through a transition model using Kalman filter principles, returning the predicted mean and covariance.
945	Builds a callable that performs one step of Kalman mean recursion, computing latent state and observation means at time t given the latent mean at time t-1.
946	Builds a callable for one step of Kalman covariance recursion, computing latent state and observation covariance at time t given latent covariance at time t-1.
947	Builds a callable for one step of Kalman sampling recursion, which samples latent states and observations at a given timestep based on previous latent state and transition/observation models.
948	Propagates a mean value through a linear Gaussian transformation by applying the linear operator to the mean and adding the mean of the distribution, with the distribution mean broadcast to add to the last dimension.
949	Propagates covariance through a linear Gaussian transformation by computing A P A' + dist.cov() where A is the linear operator and P is the input covariance matrix.
950	Run the backward pass in Kalman smoother using Rauch, Tung and Striebel smoother to compute smoothed marginal distributions p(z_t | x_{1:T}) from filtered and predicted distributions.
951	Draws a joint sample from the prior over latents and observations for a Linear Gaussian State Space Model. Samples the initial timestep from the prior, then uses a Kalman filter-style scan to sample remaining timesteps, combining and reordering dimensions to return samples of shape `[num_samples, batch_shape, num_timesteps, size]`.
952	Runs a Kalman smoother to compute posterior mean and covariance of latent states given an observed time series. Returns smoothed means and covariances where means depend on the observed data and covariances depend only on the model. The function performs backward smoothing pass using outputs from the forward filter pass.
953	Compute prior means for all variables via dynamic programming.

Returns:
  latent_means: Prior means of latent states `z_t`, as a `Tensor`
    of shape `batch_shape + [num_timesteps, latent_size]`
  observation_means: Prior covariance matrices of observations
    `x_t`, as a `Tensor` of shape `batch_shape + [num_timesteps,
    observation_size]`
954	Compute prior covariances for all variables via dynamic programming.

Returns:
  latent_covs: Prior covariance matrices of latent states `z_t`, as
    a `Tensor` of shape `batch_shape + [num_timesteps,
    latent_size, latent_size]`
  observation_covs: Prior covariance matrices of observations
    `x_t`, as a `Tensor` of shape `batch_shape + [num_timesteps,
    observation_size, observation_size]`
955	Push latent means and covariances forward through the observation model to compute observation means and covariances.
956	Computes the log-normalizer of the von Mises-Fisher distribution by calculating the log-partition function using Bessel functions and surface area calculations, with proper handling of edge cases where concentration parameter is non-positive.
957	The `_mode` method returns the mode of the von Mises-Fisher distribution, which is equal to the mean direction shifted by zero-padding the concentration parameter's last dimension.
958	Rotates input samples using a Householder reflection matrix defined by the mean direction, effectively reflecting samples across a hyperplane perpendicular to the rotation axis.
959	A specialized 3D inversion sampler for von Mises-Fisher distribution that generates samples using the inversion method. The function handles edge cases where concentration or random variables approach zero by using safe operations and provides numerical stability checks. It returns samples with an additional dimension added for compatibility.
960	Creates a deep copy of a function by reconstructing it using its code object and metadata, raising TypeError if the input is not callable.
961	Removes dictionary keys that have a specified value, returning a new dictionary with those key-value pairs filtered out.
962	Recursively replaces dictionaries with `_PrettyDict` objects while preserving other data structures. For dictionaries, it creates `_PrettyDict` instances with recursively processed values. For sequences (excluding strings), it processes elements recursively and reconstructs the sequence. For mappings, it creates new mapping instances with recursively processed values. Other types are returned unchanged.
963	Returns samples from a distribution based on either specifying a number of samples 'n' or providing pre-existing samples 'z'. Raises an error if neither or both arguments are provided. Uses TensorFlow's name scope for proper naming and handles seed for reproducible results.
964	Helper function that checks if an input is namedtuple-like by verifying it has `_fields` attribute and can access all fields via `getattr`. Returns `True` if the input is namedtuple-like, `False` otherwise.
965	Helper function that expands `is_accepted` to match input shapes and applies tf.where to select between accepted and rejected values, with support for nested structures.
966	Helper function that expands dimensions of `is_accepted` and applies tf.where, handling both base cases and namedtuple-like objects by recursively applying the choice operation to each field.
967	Elementwise adds list members, replacing non-finite results with alt_value.

Typically the `alt_value` is chosen so the `MetropolisHastings`
`TransitionKernel` always rejects the proposal.

Args:
  x: Python `list` of `Tensors` to elementwise add.
  alt_value: Python scalar used to replace any elementwise sums which would
    otherwise be non-finite.
  name: Python `str` name prefixed to Ops created by this function.
    Default value: `None` (i.e., "safe_sum").

Returns:
  safe_sum: `Tensor` representing the elementwise sum of list of `Tensor`s
    `x` or `alt_value` where sums are non-finite.

Raises:
  TypeError: if `x` is not list-like.
  ValueError: if `x` is empty.
968	Helper function that computes function values and gradients, supporting both eager and graph execution modes with proper tensor conversion and optional block diagonal Jacobian computation.
969	Calls a function and computes its gradients with respect to arguments, with validation checks for tensor dtypes, argument-gradient correspondence, and non-None gradients.
970	Constructs a for loop that uses a Python loop when the number of iterations is statically known, otherwise uses tf.while_loop. Takes the number of iterations, a body function, and initial variables as inputs, and returns the result of applying the body function iteratively.
971	A simplified version of `tf.scan` with configurable tracing that repeatedly applies a function to an initial state and elements, while tracking intermediate results through a trace function. It uses `tf.while_loop` for iteration and `TensorArray` for efficient tensor handling, returning both the final state and stacked trace results.
972	Wraps a setter function to apply it to the innermost results in a nested kernel results structure. The wrapper recursively traverses through `inner_results` attributes until reaching the innermost level, applies the original setter to those results, then reconstructs the nested structure by replacing `inner_results` attributes with the modified results in reverse order. Returns a new setter that operates on the innermost kernel results while preserving the outer structure.
973	Wraps a getter function to extract values from the innermost level of kernel results, automatically unwrapping nested results until reaching the innermost results without an `inner_results` attribute.
974	Enables the `store_parameters_in_results` parameter in a chain of kernels by recursively updating all kernels in the chain to have this parameter set to `True`. Returns the updated kernel chain.
975	Replaces the rightmost dimensions of a shape tensor with a new event shape, validating the operation if specified. Returns the modified shape tensor and its static shape representation.
976	Replaces the event shape dimensions of a `TensorShape` with a new event shape, validating compatibility between the input event shape and the specified replacement. Returns the modified `TensorShape` and a boolean indicating whether static validation occurred. Raises `ValueError` if static validation detects incompatible shapes.
977	Check that a shape Tensor is int-type and otherwise sane, including validating rank, at most one -1 element, and non-negative values.
978	Returns True if any batch member has converged OR all batch members have failed, otherwise False.
979	Returns a dictionary containing the initial state for a search procedure, including convergence status, objective function evaluation count, and initial position, objective value, and gradient values. Performs initial convergence check and evaluates objective function at initial position.
980	Performs a line search step in the BFGS optimization procedure using the Hager-Zhang method to determine an appropriate step size along a given search direction. Updates the optimization state with the new position, objective value, and gradient if the line search is successful, and handles convergence and failure conditions based on specified tolerances. Returns an updated copy of the input state with adjusted fields including position, objective value, gradient, iteration count, and evaluation count, while checking for convergence or failure using a provided stopping condition.
981	Restricts an n-dimensional function to a given direction and computes the gradient of the restricted function. Given a function f: R^n -> R, a point x0, and a direction p0, it creates a 1D function g(t) = f(x0 + t * p0) and returns the function value, derivative (df/dt), and full gradient at each point along the direction. The returned function accepts a parameter t along the direction and returns a namedtuple containing the parameter value, function value, derivative, and full gradient.
982	Updates the optimization state by advancing the position with a given delta, checking for convergence and failure conditions, and returning the updated state with new position, objective value, and gradient information.
983	Checks if the algorithm satisfies convergence criteria based on gradient, position, and objective function changes. Returns True if any convergence condition is met.
984	Broadcast a value to match the batching dimensions of a target tensor by converting it to a tensor and broadcasting to the target's batch dimensions.
985	Compute the harmonic number from its analytic continuation using the digamma function. Returns the analytic continuation of the harmonic number for the input x.
986	Returns a function that generates exchange proposals for replica exchange Monte Carlo. The returned function creates combinations of adjacent replicas for exchange with a given probability, or returns an empty tensor if no exchange is proposed. The exchange combinations are structured as an [n, 2] integer tensor where each row represents a pair of replicas to exchange.
987	Returns a specified field from kernel_results or its accepted_results attribute, raising TypeError if the field cannot be found in either location.
988	Get list of TensorArrays holding exchanged states after applying proposed exchanges, using temperature-adjusted log probabilities and acceptance ratios based on log-uniform random variables.
989	Helper method that computes a shared scale term for variance and covariance calculations by expanding dimensions and applying a square root transformation to the ratio of concentration and total count terms.
990	Creates a function that computes the sum of log determinant Jacobians from a list of bijectors applied to transformed state parts.
991	Creates a function that applies forward transformations from a list of bijectors to transformed state parts.
992	Creates a function that applies inverse transformations from a list of bijectors to state parts.
993	Runs one iteration of the Transformed Kernel by applying the inner kernel's step to the transformed state and then transforming the result back to the original space.
994	Returns conditional elements from two namedtuples or tensors, similar to tf.where but works with namedtuples.
995	Performs the secant square procedure of Hager-Zhang for bracketed root finding. Given an interval that brackets a root, it updates both endpoints using two intermediate points generated via secant interpolation. The procedure is based on steps S1-S4 from Hager and Zhang (2006) and returns updated interval endpoints along with convergence and failure indicators. The function handles batched operations and checks Wolfe conditions for convergence, returning a namedtuple with the updated search interval, convergence status, and evaluation counts.
996	A helper function for the secant square algorithm that updates bracketing intervals, determines new candidate points, and manages function evaluations. It handles active and failed branches, applies updates to maintain valid brackets, checks if new points need evaluation, and recursively continues the optimization process until convergence or exhaustion of active branches.
997	Helper function for secant-square step that updates bracketing intervals and checks Wolfe conditions for convergence.
998	Updates a bracketing interval containing a minimum by squeezing it based on a trial point, using the opposite slope conditions. The function checks if the trial point lies within the interval and satisfies conditions on function value and derivative to determine a new smaller interval. If the trial point is outside the interval or doesn't satisfy the conditions, the original interval is returned. The update may also trigger bisection to further narrow the interval. Returns a namedtuple with updated interval bounds and algorithm statistics.
999	Brackets the minimum of a function using the Hager-Zhang algorithm given an initial starting point, expanding the search interval until a bracket is found or maximum iterations are reached. Returns the updated interval with function values and derivatives at the new endpoints, along with iteration counts and status flags indicating convergence, failure, or completion.
1000	Bisects an interval to find a bracketing interval satisfying opposite slope conditions, used in line search algorithms like Hager-Zhang. Takes a function that returns function values and derivatives, along with initial interval endpoints and a function value threshold. Returns updated interval endpoints, iteration count, and termination status.
1001	Implementation of bisection method to find a minimum within an interval by iteratively narrowing down the search space based on function values and gradients, stopping when opposite slope conditions are met or failure criteria are reached.
1002	Checks if the supplied values are finite by verifying that function values and derivatives in the namedtuple instances are all finite. Returns a scalar boolean Tensor indicating whether all values are finite.
1003	Checks whether the Wolfe or approximate Wolfe conditions are satisfied for line search algorithms, using function values and gradients evaluated at two points along a search direction. Returns a boolean tensor indicating if either condition set is met.
1004	Returns the secant interpolation for the minimum by applying the secant method to the derivative of a function. Given two points with function values and derivatives, it computes a weighted average that approximates where the derivative equals zero, ensuring the result stays within the bounding interval [a,b] under the assumption of opposite slope conditions.
1005	Creates a step-size update policy for adaptive MCMC sampling based on a target acceptance rate, adjusting the step size according to the average of log acceptance ratios.
1006	Applies one step of the leapfrog integrator for Hamiltonian Monte Carlo sampling. Updates momentum and state variables using the given step sizes and target log probability function gradients. Supports per-variable step sizes and optional gradient stopping for optimization purposes. Returns the updated momentum, state, target log probability, and its gradients.
1007	Computes the log acceptance correction for the UncalibratedHMC kernel by calculating the difference in kinetic energy between current and proposed momentum states, using log-sum-exp operations for numerical stability.
1008	Runs one iteration of Hamiltonian Monte Carlo by advancing the Markov chain state by one step, updating step size if necessary, and returning the new state along with kernel results containing internal calculations used for the chain advancement.
1009	Creates initial `previous_kernel_results` using a supplied `state`, and optionally updates step size if `step_size_update_fn` is provided, returning updated kernel results with step size assignment stored in `extra` field.
1010	Constructs a Bayesian ResNet18 model with variational inference layers. The model uses Flipout estimation for Bayesian layers and allows customization of kernel posterior distributions through scale parameters. It accepts input tensors of specified shape and outputs class probabilities for the given number of classes. The function returns a tf.keras.Model object representing the constructed network.
1011	Creates a ResNet network block with batch normalization, ReLU activation, optional projection shortcut, and stochastic convolutional layers using Flipout estimator for variational inference.
1012	Creates an encoder function that maps bag-of-words input to a Dirichlet distribution over topics using a neural network with specified architecture and activation functions.
1013	Creates a decoder function that maps topic distributions to word probability distributions. Returns a callable that takes topic encodings and outputs a OneHotCategorical distribution over words, along with the learned topic-word probabilities.
1014	Create a prior distribution for topic modeling.

Args:
  num_topics: Number of topics.
  initial_value: The starting value for the prior parameters.

Returns:
  prior: A callable that returns a tf.distribution.Distribution instance, the prior distribution.
  prior_variables: A list of Variable objects, the trainable parameters of the prior.
1015	Samples from a Markov chain using the provided transition kernel. Supports multiple chains, burn-in steps, thinning, and tracing of kernel results. Returns sampled states and optionally traced values or final kernel results.
1016	A multi-layered topic model over a documents-by-terms matrix with three layers of latent variables and gamma-distributed parameters.
1017	Creates a learnable deterministic distribution over positive real numbers using a softplus activation to ensure positivity, with an optional minimum lower bound.
1018	Creates a learnable Gamma distribution using unconstrained concentration and scale parameters with softplus transformations to ensure positivity, and returns an Edward Gamma random variable.
1019	Loads the NIPS 2011 conference papers dataset from a CSV file, downloading it if necessary. Returns a bag-of-words matrix and corresponding word list, filtered to include only papers from 2011 and words appearing in at least 2 documents with a total count of at least 10.
1020	Initializes and validates `amplitude` and `length_scale` parameters for a kernel. Converts inputs to tensors with common dtype and applies positive-assertion validation if requested. Returns the common dtype of the parameters.
1021	Returns the KL divergence function registered for given classes a and b by traversing their method resolution order hierarchies and finding the closest matching registered divergence function.
1022	Returns an image tensor by reading an image file from the specified filepath, decoding it with the specified number of channels, and converting its data type to float32.
1023	Downloads sprite data from a URL, extracts it to the specified data directory, and returns the filepath. Creates the data directory if it doesn't exist, and removes the downloaded zip file after extraction.
1024	Creates a character sprite by compositing multiple attribute sprites (skin, hair, top, pants) using alpha masks for proper layering and transparency handling.
1025	Creates a sequence tensor by extracting frames from a character sprite based on action metadata and direction, with optional length and start offset. The function handles frame rolling and tiling to ensure the desired sequence length, and returns the frames as a float32 tensor with specified shape.
1026	Creates a random sequence by generating a random starting position and calling create_seq with that position.
1027	Creates a tf.data pipeline for a sprites dataset, yielding image sequences and corresponding attribute labels (skin, hair, top, pants, action) from character sprites, with options for shuffling, specifying sequence length, and generating synthetic data.
1028	Validates that a list of distributions satisfies assumptions including matching dtypes, vector variate events, and identical batch shapes, with optional argument validation.
1029	Flattens a list of kernels by expanding any `_SumKernel` instances into their constituent kernels, returning a single-level list of all kernel instances.
1030	Flattens a list of kernels by replacing any `_ProductKernel` instances with their constituent kernels, returning a flattened list of `PositiveSemidefiniteKernel` instances.
1031	Build fake CIFAR10-style data for unit testing with 10 examples each for training and testing sets, where training data has randomly generated images and shuffled labels, and testing data has randomly generated images and shuffled labels.
1032	Counts the number of occurrences of each value in an integer array, with optional weighting and axis reduction. Works like `tf.math.bincount` but supports reducing over specific dimensions specified by the `axis` parameter. Returns a tensor of bin counts with shape `[K] + arr.shape[~axis]`, where `K` is determined by the maximum value in `arr` or by `minlength`/`maxlength` if provided. If `weights` are given, each bin is incremented by the corresponding weight value instead of 1. Supports optional dtype specification and name scoping.
1033	Bins values into discrete intervals based on provided edges, returning the corresponding bin indices for each value in the input tensor. The function handles both 1-D and multi-dimensional inputs, with options to extend the lower and upper intervals. It supports different output dtypes and manages edge cases like NaN values and out-of-bounds inputs. The binning logic uses searchsorted to efficiently determine which interval each value falls into, then adjusts the indices to match the specified interval definitions.
1034	Count how often values in `x` fall into intervals defined by `edges`. Supports optional extension of lower and upper intervals, axis-based grouping, and custom output dtype. Returns histogram counts for each interval.
1035	Compute quantiles of a tensor along specified axes using various interpolation methods. Returns cut points that divide the data range into equal-probability intervals. Supports multiple interpolation types including 'nearest', 'linear', 'lower', 'higher', and 'midpoint'. Can operate on specific axes or treat all dimensions as sample dimensions.
1036	Get static number of dimensions of a tensor and assert expectations.

This function returns the number of dimensions 'ndims' of tensor x as a Python int, and optionally checks that the ndims meet specified expectations.

Args:
  x: A Tensor
  expect_static: Expect `x` to have statically defined `ndims`
  expect_ndims: Optional Python integer - assert x has exactly this many dimensions
  expect_ndims_no_more_than: Optional Python integer - assert x has no more than this many dimensions
  expect_ndims_at_least: Optional Python integer - assert x has at least this many dimensions

Returns:
  ndims: A Python integer representing the number of dimensions

Raises:
  ValueError: If any expectations are violated or if expect_static is True but ndims is not statically defined
1037	Insert singleton dimensions at specified axes in a tensor, preserving all original values while adding new dimensions of size 1 at the given axis positions.
1038	Converts a possibly negatively indexed axis to a list of non-negative integers.

This function takes an axis tensor and the number of dimensions, converts the axis to non-negative values, validates that the axis is statically defined, and returns it as a list of Python integers.

Args:
  axis: Integer Tensor representing axis index (can be negative)
  ndims: Number of dimensions the axis indexes into

Returns:
  List of non-negative Python integers

Raises:
  ValueError: If axis is not statically defined
1039	Move specified dimensions of a tensor to the end and flatten them into a single dimension.

This function takes a tensor and moves the dimensions specified by `axis` to either the right or left end of the tensor's shape, then flattens those moved dimensions into a single dimension. The function handles both cases where the tensor has fully defined shapes and where it has dynamic shapes.

Args:
  x: Input tensor with shape `[B0,B1,...,Bb]`
  axis: List of dimension indices to move
  x_ndims: Number of dimensions in the input tensor
  right_end: If True, move dimensions to the right end; if False, move to the left end

Returns:
  Tensor with the specified dimensions moved to the end and flattened into a single dimension
1040	Sorts a tensor along its last dimension using top_k and preserves the original shape.
1041	Build an ordered list of Distribution instances for component models by canonicalizing parameter values and creating LinearGaussianStateSpaceModel objects for each component in canonical order.
1042	The `amari_alpha` function computes the Amari-alpha Csiszar function in log-space, which is a member of convex functions used in information theory for measuring divergence between probability distributions. The function takes parameters including `logu` (logarithm of u), `alpha` (a scalar that defines the family of divergences), and `self_normalized` (a boolean indicating whether the function should be self-normalized). When `self_normalized` is True, the function adjusts its calculation to ensure the derivative at u=1 equals zero, which maintains non-negativity of the implied divergence even with unnormalized measures. The method supports three cases based on the value of alpha: 0, 1, and other values, each handled differently to compute the appropriate form of the Csiszar-function. It also includes error checking to ensure that `alpha` and `self_normalized` are not tensors or None, and raises appropriate TypeErrors if they are. The output is a tensor of the evaluated Csiszar-function at u = exp(logu).
1043	The `kl_reverse` function computes the reverse Kullback-Leibler Csiszar function in log-space. It takes a tensor representing log(u) and returns the Csiszar-function value at u = exp(logu). When `self_normalized=True`, it uses the function f(u) = -log(u) + (u - 1), otherwise it omits the (u - 1) term. The function is equivalent to the reverse KL divergence D_f[p, q] = KL[q, p] and is useful in maximum likelihood contexts. It raises a TypeError if `self_normalized` is None or a Tensor. The function delegates to `amari_alpha` with alpha=0.
1044	Computes the Jensen-Shannon Csiszar-function in log-space.

This function implements the Jensen-Shannon divergence as a Csiszar-function, which induces a symmetric f-Divergence. When `self_normalized=True`, it uses the self-normalized form: f(u) = u log(u) - (1 + u) log(1 + u) + (u + 1) log(2). When `self_normalized=False`, the constant term is omitted. The function is numerically unstable for large absolute values of logu and returns the Csiszar-function evaluated at u = exp(logu).

Args:
  logu: Float-like Tensor representing log(u)
  self_normalized: Boolean indicating whether to include the self-normalized term
  name: Name prefix for operations

Returns:
  Float-like Tensor of the Csiszar-function evaluated at u = exp(logu)
1045	The `pearson` function computes the Pearson Csiszar-function in log-space, defined as f(u) = (u - 1) where u = exp(logu). It takes a tensor of log-space values and returns the Csiszar-function evaluation. The function uses tf.math.expm1 for numerical stability in the computation but warns that non-log-space calculations may cause numerical instability for large absolute values of logu.
1046	The `squared_hellinger` function computes the Squared-Hellinger Csiszar-function in log-space, defined as f(u) = (sqrt(u) - 1) where u = exp(logu). It uses the Pearson Csiszar-function with a scaled input (0.5 * logu) to evaluate the function. The function is symmetric and induces a symmetric f-Divergence. Warning: non-log-space calculations may cause numerical instability for large absolute values of logu.
1047	The `triangular` function computes the Triangular Csiszar-function in log-space, defined as f(u) = (u - 1) / (1 + u) where u = exp(logu). It returns the Csiszar-function evaluated at u, but note that it performs non-log-space calculations which may cause numerical instability for large values of logu. The function is symmetric, meaning it induces a symmetric f-Divergence.
1048	The `t_power` function computes the T-Power Csiszar-function in log-space, which is a convex function used in information theory. It takes the logarithm of u (`logu`) and a parameter `t`, and optionally applies self-normalization. When `self_normalized=True`, it uses the formula `f(u) = s * [u^t - 1 - t(u-1)]` where `s = -1` if `0 < t < 1` and `s = 1` otherwise. When `self_normalized=False`, the term `-t(u-1)` is omitted. The function returns the Csiszar-function evaluated at `u = exp(logu)`.
1049	Returns the log1p-abs Csiszar-function evaluated at u = exp(logu). This function computes f(u) = u**(sign(u-1)) - 1 where u is exponentiated from logu, using the relationship log(1 + f(u)) = g(log(u)) for a convex function g. The implementation uses tf.math.expm1(tf.abs(logu)) for numerical efficiency. Warning: non-log-space calculations may cause numerical instability for large |logu| values.
1050	The `jeffreys` function computes the Jeffreys Csiszar-function in log-space, which is defined as f(u) = 0.5 * (u * log(u) - log(u)). It takes a tensor of log-space values and returns the Csiszar-function evaluated at u = exp(logu). This function represents a symmetric f-Divergence and is useful in information theory and statistics. Note that it performs non-log-space calculations which may cause numerical instability for large absolute values of logu.
1051	The `modified_gan` function computes the Modified-GAN Csiszar-function in log-space, which is used in generative adversarial networks. It takes a tensor of log-values (`logu`) and returns the Csiszar-function evaluation at `u = exp(logu)`. When `self_normalized=True`, it includes an additional term `0.5 * (u - 1)` to ensure the function satisfies `f'(u=1)=0`, making the implied f-Divergence remain non-negative even for unnormalized measures. The function uses `tf.nn.softplus` for numerical stability and includes a warning about potential numerical instability for large `|logu|` values. The output is a tensor of the same dtype as `logu`.
1052	Calculates the dual Csiszar-function in log-space using the formula f^*(u) = u * f(1/u), where f is a given Csiszar-function. Takes log-space input logu and applies the dual transformation by first exponentiating logu to get u, then evaluating the csiszar_function at -logu (which represents log(1/u)) and multiplying by u. Warning: may be numerically unstable for large |logu| values.
1053	Symmetrizes a Csiszar-function in log-space by applying the transformation f_g(u) = 0.5*g(u) + 0.5*u*g(1/u), where g is the provided Csiszar-function. Returns the symmetrized result evaluated at u = exp(logu).
1054	Monte-Carlo approximation of the Csiszar f-Divergence between two distributions p and q, using either reparameterization or score-gradient tricks for gradient estimation.
1055	Helper function for CSISZAR-VIMCO that computes log-average and leave-one-out log-average of importance weights. Given log importance weights logu, it returns:
1. log_avg_u: log of average importance weight
2. log_sooavg_u: log of swap-one-out averages where each term is replaced by its leave-one-out geometric average

The function handles numerical stability by using log-sum-exp tricks and properly manages edge cases where the standard computation would fail due to numerical issues. Both outputs have gradients that sum to 1, which is crucial for the VIMCO estimator's correctness.
1056	Asserts that tensor x has the expected number of dimensions, raising ValueError if expectations are not met.
1057	Summary: This function performs a batch gather operation with broadcasting support. It takes parameters and indices tensors, broadcasts their leading dimensions to match, and then applies batch_gather to select elements along a specified axis. The function allows for broadcasting of dimensions to the left of the specified axis, making it more flexible than standard batch_gather by handling cases where the batch dimensions don't exactly match but can be broadcast together.
1058	Broadcasts event or distribution parameters by ensuring proper dtype casting and shape alignment. If event has floating dtype, it's cast to int32. When shapes are incompatible, broadcasting is performed using tf.ones_like to match dimensions, with shape validation and assignment when rank information is available. Returns the broadcasted event and params with compatible shapes.
1059	Importance sampling estimator in log-space for computing log(E_p[f(Z)]), where f(z) = exp(log_f(z)) and p(z) = exp(log_p(z)). Uses samples from a proposal distribution q to estimate the logarithm of the expectation of f(Z) p(Z) / q(Z), with numerical stability via log-space computation and max-subtraction. Returns the log-space estimate of the expectation.
1060	Broadcasts event or samples to match the shape of samples, adding appropriate dimensions and ensuring compatible shapes for further operations.
1061	Minimizes a differentiable function using the BFGS algorithm. Takes a function and its gradient, initial position, and various tolerance parameters to find the minimum. Returns optimization results including convergence status, position, objective value, and inverse Hessian estimate.
1062	Computes control inputs to validate that a provided inverse Hessian is positive definite and symmetric by using Cholesky decomposition for positive definiteness check and symmetry check via norm comparison, returning tf.Assert operations for use with tf.control_dependencies.
1063	Updates the BFGS inverse Hessian estimate using the BFGS update formula, only when the optimization step is valid (not converged or failed) and the update is non-singular. Returns the updated BFGS state with the new inverse Hessian estimate where updates were applied, otherwise returns the original state unchanged.
1064	Applies the BFGS update to the inverse Hessian estimate using matrix-vector operations to compute the next inverse Hessian approximation. The function takes gradient and position deltas, a normalization factor, and the current inverse Hessian estimate, then returns the updated inverse Hessian estimate along with a validity indicator. The update is computed using an expanded formulation that avoids explicit matrix multiplications, instead using vector outer products and scalar operations. The result maintains the symmetry and positive definiteness properties of the inverse Hessian estimate.
1065	Computes the matrix-vector product where the vector is multiplied on the right side of the matrix. Supports dynamic shapes and batched computation. Takes a matrix tensor of shape `[..., n, m]` and a vector tensor of shape `[..., m]`, returning a tensor of shape `[..., n]`. Uses `tf.matmul` with appropriate reshaping to perform the computation efficiently.
1066	Computes the outer product of two possibly batched vectors using matrix multiplication.

Args:
  t1: A `tf.Tensor` of shape `[..., n]`.
  t2: A `tf.Tensor` of shape `[..., m]`.

Returns:
  A tensor of shape `[..., n, m]` where each element is computed as `t1[..., i] * t2[..., j]`.

The function works by:
1. Expanding dimensions of t1 to shape `[..., n, 1]`
2. Expanding dimensions of t2 to shape `[..., 1, m]`
3. Performing matrix multiplication to get shape `[..., n, m]`
1067	Transpose a possibly batched matrix by rearranging the last two dimensions while preserving batch dimensions.
1068	Add `ndims` ones to the right side of tensor `x`'s shape by padding and reshaping. If `ndims` is zero, return `x` unchanged. Raises `ValueError` if `ndims` is negative or not an integer. Returns a tensor with the same static shape information as `x` but with `ndims` additional dimensions of size 1 appended to the right.
1069	Returns a Tensor with the right-most `ndims` dimensions summed.

Args:
  x: the Tensor whose right-most `ndims` dimensions to sum
  ndims: number of right-most dimensions to sum.

Returns:
  A Tensor resulting from calling `reduce_sum` on the `ndims` right-most
  dimensions. If the shape of `x` is statically known, the result will also
  have statically known shape. Otherwise, the resulting shape will only be
  known at runtime.
1070	A square root function with finite gradients that avoids NaN values when computing gradients at zero. The function overrides the gradient at zero to be a large finite value instead of infinity, preventing numerical instability in kernel computations. It returns both the square root of the input tensor and a custom gradient function that handles the special case at zero by using the square root of the maximum floating point value for the gradient, thus avoiding overflow issues. This is particularly useful in kernel functions where identical inputs would otherwise produce NaN gradients due to the mathematical properties of the square root derivative at zero.
1071	Returns the common dtype of items in arg_list, or None if the list is empty or all items are None. Uses dtype_util.common_dtype with tf.float32 as default.
1072	Minimizes a differentiable function using the L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm. This optimization method is designed for unconstrained minimization problems and is particularly effective for large-scale optimization tasks. It approximates the inverse Hessian matrix using a limited number of past iterations to guide the search direction. The function returns a namedtuple containing the optimization results including whether the algorithm converged, the final position, objective value, and gradient information. It supports various stopping criteria based on gradient tolerance, relative function change, and position change, and allows for custom stopping conditions. The implementation handles batching dimensions and provides detailed diagnostics about the optimization process.
1073	Creates LBfgsOptimizerResults with initial state of search procedure by initializing state arguments and empty queues for position and gradient deltas.
1074	Computes the search direction for the L-BFGS optimization algorithm using the two-loop recursion method. Given the current state with correction pairs, it implements the L-BFGS update to approximate the inverse Hessian and returns the search direction for line search. Returns the negative of the computed direction as the final search direction.
1075	Creates a zero-filled TensorFlow tensor suitable to hold k element-shaped tensors. The returned tensor has shape (k,) + element.shape and the same dtype as the input element.
1076	Conditionally updates a batch of first-in-first-out queues by pushing new vectors into them. For each batch member, if the corresponding `should_update` flag is True, the new vector replaces the first element in the queue (pushing out the oldest element), otherwise the queue remains unchanged. The operation preserves the queue structure where each queue has `k` n-D vectors, and the update is performed along the first dimension of the queue tensor. Returns a new tensor with updated queues.
1077	Computes whether each square matrix in the input tensor is positive semi-definite (PSD) by checking if all eigenvalues are non-negative. Returns a mask tensor where each element is 1 if the corresponding matrix is PSD, otherwise 0. Uses eigenvalue decomposition instead of Cholesky decomposition due to TensorFlow's exception handling limitations.
1078	Returns a mask indicating which matrices in x have determinants above the given bounds. The mask is a tensor of the same dtype as x, with 1.0 where the determinant condition is met and 0.0 otherwise.
1079	Returns a tensor of uniformly random "correlation-like" matrices, which are symmetric square matrices with entries between -1 and 1 inclusive and 1s on the main diagonal. The output tensor has the specified batch shape and matrix dimensions, where each matrix is symmetric and has unit diagonal entries.
1080	Returns rejection samples from a uniform distribution over correlation-like matrices, filtering for positive semi-definite matrices with determinant above specified bounds. Returns weights for accepted samples and the volume of the proposal space.
1081	Computes the Clopper-Pearson confidence interval for the mean of a Bernoulli distribution using the binomial distribution's CDF. Validates that samples are Bernoulli-distributed and uses root-finding to determine the interval bounds. Raises ValueError for non-1D samples or non-Bernoulli data. Returns a tuple of (lower_bound, upper_bound) for the confidence interval.
1082	Computes confidence intervals for correlation matrix volumes using the Clopper-Pearson method. Takes determinant bounds, matrix dimension, and sampling parameters to estimate volumes with specified statistical significance. Returns a dictionary mapping each determinant bound to its confidence interval bounds.
1083	Computes the von Mises cumulative distribution function (CDF) and its derivative using series expansion. Implements a while loop to calculate the series terms, then clips the CDF values to [0, 1] and handles derivative computation for the clipped values. Returns both the clipped CDF and its derivative with respect to the concentration parameter.
1084	Computes the von Mises CDF and its derivative using Normal approximation with correction terms. Uses a helper function that transforms the von Mises distribution into an approximately normal distribution through a series of mathematical corrections involving Bessel functions and polynomial approximations, then evaluates the standard normal CDF on the transformed variable. Returns both the CDF value and its gradient with respect to the concentration parameter.
1085	Performs one step of the differential evolution optimization algorithm. Takes a population of candidate solutions and evolves them using mutation, crossover, and selection operations to find better solutions. Returns the updated population and their objective function values.
1086	Minimizes a function using the Differential Evolution algorithm. Supports both single initial position and initial population configurations, with options for population size, standard deviation, maximum iterations, and convergence tolerances. Returns optimization results including the best position found, objective value, and convergence status.
1087	Processes initial arguments for evolutionary optimization algorithm, including handling iterable inputs, generating initial population, converting parameters to tensors, and evaluating objective function on initial population. Returns processed arguments including population data, function values, and algorithm parameters.
1088	Finds the population member with the lowest value by determining the minimum value in the values tensor and returning the corresponding population member along with its value.
1089	Checks whether convergence criteria have been met for a population based on function value tolerance and position tolerance. Returns True if either the function value range is within tolerance OR all population members are within half the position tolerance of the first member.
1090	Constructs the initial population for evolutionary algorithms. If an initial population is provided, it converts it to tensors. Otherwise, it generates a population by adding random normal noise to an initial position, ensuring the initial position is included as the first member. The population size and standard deviation control the generation process, with a random seed for reproducibility.
1091	Performs binary crossover recombination on a population using mutation vectors. For each component of population members, with probability `crossover_prob` it takes the corresponding component from the mutant vector, otherwise keeps the original. Ensures at least one crossover per individual by randomly forcing one component to come from the mutant. Returns the recombined population with the same structure as the input.
1092	Computes mutated vectors for each population member using differential evolution mutation strategy.

This function implements the mutation step of the differential evolution algorithm. For each individual in the population, it creates a mutant vector by combining three randomly selected individuals (from the mixing indices) with specific weights. The mutation strength is controlled by the differential weight parameter.

Args:
  population: List of tensors representing current population vectors
  population_size: Scalar tensor indicating population size
  mixing_indices: Tensor of shape [n, 3] containing valid indices for selecting donor vectors
  differential_weight: Scalar tensor controlling mutation strength (0 < weight < 2.0)

Returns:
  List of tensors containing the mutated vectors, same shape and dtype as input population
1093	Generates an array of indices suitable for differential evolution mutation operations, creating a tensor of shape [size, 3] where each row contains three distinct indices that are different from the row index and from each other, with all indices in the range [0, size-1].
1094	Converts the input argument to a list if it is not already a list or tuple. Returns a tuple containing the list of tensors and a boolean indicating whether the original input was already a list/tuple.
1095	Gets a Tensor of type `dtype`, 0 if `tol` is None, with optional validation.
1096	Soft Thresholding operator that applies the soft threshold function to each element of the input tensor. The operator is defined as: SoftThreshold(x, gamma)[i] = sign(x[i]) * max(|x[i]| - gamma, 0), where gamma is the threshold parameter. This function is commonly used in proximal gradient methods for L1 regularization, as it computes the proximity operator of the L1 norm. The implementation handles tensor inputs and applies the soft threshold operation element-wise, returning a tensor of the same shape and dtype as the input.
1097	Clips tensor values to a specified min and max while preserving the gradient. Returns a tensor of the same type and shape as input `t` with values clamped between `clip_value_min` and `clip_value_max`, but the gradient remains unaltered (identical to the input tensor). Uses `tf.stop_gradient` to prevent gradient flow through the clipping operation.
1098	Build an input pipeline that creates a tensorflow dataset from training images, shuffles the dataset, repeats it indefinitely, batches the data, and returns an iterator over the batches.
1099	Save synthetic images as a PNG file.

This function takes a collection of generated images and saves them as a single PNG figure. It creates a 4x4 grid of subplots, displays each image with axes turned off, and saves the entire layout to the specified filename. The images are shown in grayscale using the 'Greys_r' colormap, and there is minimal spacing between subplots for a clean presentation.
1100	Converts a sequence of productions into a string of terminal symbols by iteratively expanding nonterminal symbols according to production rules, starting with the start symbol. Raises ValueError if the first production rule doesn't begin with the start symbol.
1101	Runs the model forward to generate a sequence of productions by sampling from a latent code and using an LSTM to generate grammatical productions until the stack is empty, returning a tensor of one-hot vectors representing the productions.
1102	Runs the model forward to return a stochastic encoding by processing input productions through an encoder network and returning a variational distribution sample.
1103	Computes the integral of the hat function h(x) = x^(-power) for sampling purposes. Returns H(x) = _x^ t^(-power) dt as tf.exp((-power+1) * log1p(x) - log(power-1)).
1104	Returns the inverse of the hat integral function, computing the original value from the transformed input using the power parameter.
1105	Compute the matrix rank by counting the number of non-zero SVD singular values.

This function calculates the rank of matrix(ies) by computing their singular value decomposition and counting how many singular values are greater than a specified tolerance threshold. The tolerance defaults to machine epsilon multiplied by the maximum dimension and maximum singular value when not provided.

Args:
  a: (Batch of) float-like matrix-shaped Tensor(s) to compute rank for
  tol: Threshold below which singular values are considered zero (default: None)
  validate_args: Whether to add graph assertions for input validation (default: False)
  name: Python string prefixed to ops created by this function (default: "matrix_rank")

Returns:
  (Batch of) int32 scalars representing the number of non-zero singular values (matrix rank)

The function uses SVD (Singular Value Decomposition) to compute singular values and applies the specified tolerance to determine which values are effectively zero. It handles both batched and non-batched matrix inputs and supports automatic validation when requested.
1106	Compute the Moore-Penrose pseudo-inverse of a matrix using its singular-value decomposition (SVD). The pseudo-inverse solves the least-squares problem Ax = b and can be computed as A_pinv = V @ inv(Sigma) @ U^T, where A = U @ Sigma @ V^T is the SVD of A. The function uses a default condition number cutoff of 10 * max(num_rows, num_cols) * machine_epsilon if not specified. It returns a tensor with the same shape as the input except the rightmost two dimensions are transposed.
1107	Solves systems of linear equations `A X = RHS` using LU factorization.

This function takes the LU decomposition of a matrix (as returned by `tf.linalg.lu`) and solves for the unknown matrix `X`. It handles both scalar and batched cases, applying permutations to the right-hand side vector(s) before solving the system using forward and backward substitution.

Args:
  lower_upper: `lu` as returned by `tf.linalg.lu`, where `matmul(P, matmul(L, U)) = X` and `lower_upper = L + U - eye`
  perm: `p` as returned by `tf.linalg.lu`, where `matmul(P, matmul(L, U)) = X` and `perm = argmax(P)`
  rhs: Matrix-shaped float Tensor representing targets for which to solve; `A X = RHS`
  validate_args: Python bool indicating whether arguments should be checked for correctness
  name: Python str name given to ops managed by this object

Returns:
  x: The `X` in `A @ X = RHS`

Example:
```python
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp

x = [[[1., 2],
      [3, 4]],
     [[7, 8],
      [3, 4]]]
inv_x = tfp.math.lu_solve(*tf.linalg.lu(x), rhs=tf.eye(2))
tf.assert_near(tf.matrix_inverse(x), inv_x)
# ==> True
```
1108	Computes the inverse of a matrix given its LU decomposition.

This function takes the LU decomposition of a matrix (as returned by `tf.linalg.lu`) and computes the matrix inverse without explicitly reconstructing the original matrix. It uses the LU factors and permutation vector to solve the system `AX = I` where `I` is the identity matrix, effectively computing `A^{-1}`.

Args:
  lower_upper: `lu` as returned by `tf.linalg.lu`, i.e., `L + U - eye` where `P * L * U = X`
  perm: `p` as returned by `tf.linalg.lu`, i.e., permutation indices
  validate_args: Python `bool` indicating whether arguments should be checked for correctness
  name: Python `str` name given to ops managed by this object

Returns:
  inv_x: The matrix inverse of the original matrix reconstructed from the LU decomposition

The function is useful for computing matrix inverses when the LU decomposition is already available, as it avoids the computational overhead of explicitly reconstructing the original matrix before inversion. Note that no invertibility checks are performed even when `validate_args=True`.
1109	Returns list of assertions checking that `lu_reconstruct` inputs satisfy their assumptions, including:
- `lower_upper` must have at least 2 dimensions
- `rank(lower_upper)` must equal `rank(perm) + 1`  
- `lower_upper` must be square (last two dimensions equal)
1110	Returns list of assertions related to `lu_solve` assumptions, including checks for minimum rank of `rhs` and matching dimensions between `lower_upper` and `rhs`.
1111	Returns a block diagonal rank 2 SparseTensor from a batch of SparseTensors by transforming indices to create a block-diagonal structure while preserving non-zero entries.
1112	Checks that input is a float matrix, returning validation assertions. Raises TypeError for non-floating dtype and ValueError for insufficient dimensions. When validate_args is True, adds rank assertion for runtime validation.
1113	Computes the negative log-likelihood gradient and Fisher information for a Generalized Linear Model (GLM). The function calculates the gradient of the negative log-likelihood with respect to model coefficients and the Fisher Information Matrix (FIM) using the model matrix, linear response, response values, and a GLM model specification. It handles invalid values by masking them and uses matrix operations to compute the FIM in a computationally efficient manner. The FIM is returned in a form that allows reconstruction as `Transpose(model_matrix) @ diag(fim_middle) @ model_matrix`.
1114	Fits a GLM using coordinate-wise FIM-informed proximal gradient descent with L1 and L2 regularization. Uses negative Fisher information as a second-order approximation to the Hessian for optimization. Handles sparse model matrices via SparseTensor input. Returns learned model coefficients, convergence status, and number of iterations.
1115	Generates slices for building an autoregressive mask by dividing input and output dimensions into blocks and creating row/column slices for each block based on the mask type.
1116	Generate a mask for building an autoregressive dense layer by creating a zero matrix and setting specific slices to 1 based on the mask type and block configuration.
1117	A masked dense layer implementation analogous to `tf.layers.dense` that applies autoregressive masking, similar to MADE (Masked Autoencoder for Distribution Estimation). It supports optional blocking structure, diagonal exclusion for the first layer, customizable initialization, and integrates with TensorFlow's layer infrastructure. The mask ensures that each output depends only on previous inputs, making it suitable for modeling sequential data distributions.
1118	Creates a degree vector for input based on specified order pattern. Returns array of integers from 1 to input_size following left-to-right, right-to-left, or random ordering, or validates custom input_order array. Raises ValueError for invalid input_order.
1119	Returns a list of degree vectors for input and hidden layers in an autoregressive model, where each unit's degree determines which units can feed into it. The degrees ensure autoregressive constraints are maintained, with output units having the same degree as their corresponding input units. Supports different input order options ('left-to-right', 'right-to-left', 'random') and hidden unit degree assignment methods ('equal', 'random'). Raises ValueError for invalid input order or hidden degrees.
1120	Returns a list of binary mask matrices enforcing autoregressivity by creating masks between input-hidden, hidden-hidden, and hidden-output layers based on degree relationships.
1121	Returns a masked version of the given initializer that applies a mask to the initialized values.
1122	Builds the layer by inferring event shape from input shape, creating masks for autoregressive dependencies, and constructing a Keras Sequential network with masked dense layers.
1123	This method applies an autoregressive transformation to input tensor `x` by:
1. Converting input to tensor with specified dtype
2. Handling 1D inputs by adding batch dimension
3. Passing through internal network `_network`
4. Reshaping output to include parameter dimensions
5. Using name scope for better graph visualization

The method supports dynamic shapes and returns reshaped tensor with extended parameter dimensions.
1124	Samples from a multinomial distribution by drawing categorical samples and summing them appropriately.

This function generates multinomial samples given logit probabilities, number of classes, and trial counts. It handles batching by broadcasting the trial counts with the logits, then uses tf.map_fn to process each batch member individually since tf.random.categorical requires uniform trial counts across the batch. For each batch member, it draws categorical samples, converts them to one-hot encoding, sums across trials, and casts to the specified output dtype. The final result has shape [num_samples] + batch_shape + [num_classes].
1125	Build a zero-dimensional MultivariateNormalDiag object with custom covariance method.
1126	Returns an observation noise function that creates a MultivariateNormalDiag distribution centered on the given timeseries slice at time t, with zero scale diagonal.
1127	Build regression weights from model parameters by transforming global and local scale parameters and combining them with weights noncentered.
1128	Computes the depth (number of edges on longest path from node to root) for each node in a graph using recursive exploration with memoization. Returns an annotated graph where each node has its depth computed.
1129	Creates a tuple of string tuple-string pairs representing resolved and sorted DAG by recursively exploring nodes in topological order based on their depths.
1130	Creates lists of callables suitable for JDSeq by processing named distribution makers through a chain rule flattening process.
1131	Creates `dist_fn`, `dist_fn_wrapped`, `dist_fn_args`, and `dist_fn_name` by flattening the model using `_prob_chain_rule_flatten`. Raises TypeError if model cannot be converted to dict.
1132	Computes the negative variational lower bound loss for a Variational Gaussian Process (VGP), as described in Hensman et al. (2013). The loss is composed of three components: a likelihood term, a trace term from the posterior predictive covariance, and a KL divergence term between the variational posterior and the prior. The method supports optional observation index points and allows scaling of the KL divergence component. The result is a scalar tensor suitable for optimization.
1133	Computes optimal variational parameters for a Sparse Variational Gaussian Process (SVGP) model based on Titsias' 2009 method. Given training data and inducing points, it calculates the optimal variational posterior location and scale. Returns a tuple of (location, scale) tensors representing the variational distribution parameters. Uses kernel matrix computations, Cholesky decomposition, and matrix operations to derive the optimal variational parameters. Supports customizable mean functions, observation noise variance, and numerical stability jitter.
1134	Builds a utility function to determine if a given step represents the last day of a season, based on predefined seasonal durations.
1135	Builds change-of-basis matrices that transform seasonal effects into residuals (differences from mean effect) and projects them onto the subspace where mean effect is zero. Returns two matrices: one for transforming effects to residuals, and another as its pseudo-inverse for transforming residuals back to effects.
1136	Builds a function that computes transition matrices for a seasonal effect model, with optional basis change transformation to enforce zero-sum constraints. The transition matrix either permutes latent states when seasons change or returns an identity matrix otherwise.
1137	Builds a seasonal transition noise model for a SeasonalStateSpaceModel that increases variance of the just-ended seasonal effect by drift_scale, otherwise returns zero noise.
1138	Builds the transition noise distribution for a ConstrainedSeasonalSSM, returning a function that generates MultivariateNormalTriL distributions based on whether it's the last day of a season.
1139	Returns `True` if the given observation data is empty, which means either both `observation_index_points` and `observations` are `None`, or the number of observations (determined by the shape of `observation_index_points`) is zero.
1140	Validates that observation data and locations have consistent shapes by checking that their batch shapes are broadcastable. Raises ValueError if shapes are not broadcastable.
1141	Add a learning rate scheduler to the contained schedules.

Parameters:
- scheduler: learning rate scheduler to be added
- max_iteration: iteration numbers this scheduler will run

Returns:
- Result of the BigDL function call to add the scheduler
1142	Configures checkpoint settings by setting the interval for writing snapshots, specifying the checkpoint path, and determining whether to overwrite existing snapshots. Creates the checkpoint directory if it doesn't exist.
1143	Configures constant gradient clipping by setting minimum and maximum clipping values.
1144	Optimizes the model by calling the Java optimization function and returns a Layer object containing the optimized model.
1145	Set the training summary for the optimizer, which contains information about log recording frequency, storage location, and retrieval method. Returns the current object for chaining operations.
1146	Sets the validation summary for the optimizer, which contains information about log recording frequency, storage location, and retrieval methods. Returns the current object for chaining.
1147	Creates an optimizer for neural network model training, returning either a local or distributed optimizer based on the training set type. Supports both RDD/DataSet for distributed training and tuple data for local training.
1148	Sets a new training dataset for optimizer reuse with specified batch size.
1149	Set the interval of recording for each indicator by configuring a trigger for a specific tag name. The supported tags include "LearningRate", "Loss", "Throughput", and "Parameters" (which encompasses weights, biases, gradients, and batch normalization running status). If no triggers are set, Loss and Throughput are recorded every iteration by default, while LearningRate and Parameters are excluded due to potential performance overhead. Returns the result of calling the BigDL function with the specified parameters.
1150	Read MNIST data from directory, download if necessary, and return features and labels as numpy arrays. Features are 4D uint8 arrays representing pixel values (0-255) and labels are 1D uint8 arrays representing digits (0-9).
1151	Parse or download news20 dataset from specified directory and return list of (tokens, label) tuples.
1152	Loads pre-trained GloVe word2vec embeddings from a local directory or downloads them if needed, returning a dictionary mapping words to their vector representations.
1153	Configures the learning process for the model by setting up the optimizer, loss function, and metrics. Must be called before calling fit or evaluate. Accepts string representations of optimizer, loss, and metrics which are converted to their corresponding objects if needed. Calls the backend compile function with the specified parameters.
1154	Train a model for a fixed number of epochs on a dataset, supporting both distributed and local training modes with optional validation data.
1155	Evaluate a model on a given dataset in distributed mode.

**Arguments:**
- x: Input data. A Numpy array or RDD of Sample.
- y: Labels. A Numpy array. Default is None if x is already RDD of Sample.
- batch_size: Number of samples per gradient update.

**Returns:**
Result of the model evaluation.
1156	Use a model to do prediction on input data, supporting both distributed and local modes with appropriate input validation.
1157	Get MNIST dataset and parallelize into RDDs. Downloads data automatically if not present at specified location. Returns RDD of (features: ndarray, label: ndarray) pairs with labels shifted by 1 for BigDL compatibility.
1158	Preprocess MNIST dataset by normalizing training and test data using respective means and standard deviations, then transform into Sample objects from RDDs. Returns tuple of (train_data, test_data) RDDs of Sample objects.
1159	Returns an end trigger for optimization based on options - either MaxEpoch or MaxIteration depending on endTriggerType.
1160	Sets validation and checkpoint for distributed optimizer with specified batch size, validation data, and checkpoint path.
1161	Return the broadcasted value, loading it from path if not already loaded.
1162	Calls a BigDL API function by name, iterating through JavaInvoker instances to find and execute the matching method, raising an exception if the function cannot be found.
1163	Summary: The `callJavaFunc` function serves as a bridge to invoke Java functions from Python code. It takes a Java function and its arguments, converts the Python arguments to Java-compatible objects using `_py2java`, calls the Java function with these converted arguments, and then converts the Java result back to a Python object using `_java2py` before returning it. The function relies on a gateway object obtained from `_get_gateway()` to facilitate communication between Python and Java environments.
1164	Converts a Python RDD to a JavaRDD of Object by unpickling each Python object into Java object using Pyrolite serialization, preserving batch serialization format.
1165	Convert Python object into Java by handling different types: RDD, DataFrame, SparkContext, list, tuple, dict, JavaValue, JavaObject, basic types, and serializing other objects through BigDLSerDe.
1166	Converts an activation name string to a BigDL activation layer object. Supports tanh, sigmoid, hard_sigmoid, relu, softmax, softplus, softsign, and linear activations. Raises exception for unsupported activation types.
1167	Convert a numpy ndarray to a DenseTensor for use in the Java side. Takes a numpy array as input and returns a JTensor object with the same data and shape. Handles the conversion between Python numpy arrays and Java-side tensor objects. Includes validation to ensure the input is a numpy array and properly handles edge cases like empty arrays. The resulting tensor can be converted back to numpy format using the to_ndarray() method.
1168	```python
def get_label(self):
    """
    Extract label as ndarray from ImageFeature
    Returns label tensor converted to numpy ndarray format
    """
    label = callBigDlFunc(self.bigdl_type, "imageFeatureToLabelTensor", self.value)
    return label.to_ndarray()
```
1169	Read parquet file as DistributedImageFrame.
1170	Writes an ImageFrame as a parquet file to the specified path with given partitioning and data type configuration.
1171	```python
def get_image(self, float_key="floats", to_chw=True):
    """
    get image from ImageFrame
    """
    return self.image_frame.get_image(float_key, to_chw)
```

Summary: Returns an image from the ImageFrame instance using the specified float key and optional HWC/CHW format conversion.
1172	Returns a list of images from an ImageFrame by converting tensors to numpy arrays. Takes optional parameters for specifying the float key and whether to convert to CHW format.
1173	Returns the label RDD from an ImageFrame by converting it to a tensor RDD and mapping each tensor to its numpy array representation.
1174	Returns prediction RDD from ImageFrame by calling distributedImageFrameToPredict and mapping predictions to convert second element to ndarray.
1175	Generates output predictions for input samples, processing them in batches. Supports both local (numpy array) and distributed (RDD) modes. In distributed mode, converts numpy arrays to RDD format before prediction. Returns numpy array for local mode or RDD[Sample] for distributed mode. Raises exception for unsupported input types or when batch_size/verbose parameters are specified.
1176	Summary: The `fit` method optimizes a model using specified training parameters, supporting both local and distributed modes. It accepts input data `x` and optional labels `y`, along with various training configurations like batch size, epochs, and validation settings. The method validates the input and raises exceptions for unsupported parameters such as callbacks, class weights, sample weights, and others. It creates an optimizer based on the provided parameters and executes the optimization process. The method is designed to work with either local ndarray inputs or distributed RDD[Sample] inputs depending on the `is_distributed` flag.
1177	Apply the transformer to images in "inputCol" and store results in "outputCols".
1178	Save a Keras model definition to a JSON file at the specified path.
1179	Builds a CNN model using Keras 1.2.2 with sequential architecture consisting of convolutional layers with ReLU activation, max pooling, dropout regularization, and dense layers with softmax output for 10-class classification.
1180	Method: predict_class_distributed
Parameters: self, data_rdd
Returns: An RDD representing the predict label
Description: Performs distributed prediction on the input data RDD and returns the predicted class labels as an RDD. Uses the model's predict class functionality through BigDL's callBigDlFunc interface.
1181	Sets the weights for this layer using the provided numpy arrays representing weights and biases. The method validates that the number of input weight/bias arrays matches the layer's expected configuration. For layers without weights (like ReLU), it raises an IllegalArgumentException. For layers with mismatched weight counts (like Add), it also raises an IllegalArgumentException. Returns nothing on successful execution.

Example usage:
- For a Linear layer: `linear.set_weights([weight_matrix, bias_vector])`
- For a CAdd layer: `cAdd.set_weights(weight_matrix)`
- For layers without weights: raises IllegalArgumentException with message "this layer does not have weight/bias"
- For mismatched dimensions: raises IllegalArgumentException with dimension mismatch details
1182	Get weights for this layer

:return: list of numpy arrays which represent weight and bias
1183	Save a model to protobuf files for tensorflow inference by adding placeholders to the tf model with specified input information, byte order, and data format.
1184	Set the layer to training mode if is_training=True, otherwise set to evaluation mode. Returns the layer instance.
1185	Loads a pre-trained Torch model from the specified path and returns it as a Layer object.
1186	Load a pre-trained Keras model from JSON and/or HDF5 files, returning a BigDL model. Supports loading model architecture from JSON, weights from HDF5, or both together with optional name-based weight loading.
1187	Create a python Criterion by a java criterion object

**Parameters:**
- jcriterion: A java criterion object which created by Py4j
- bigdl_type: The data type, default is "float"

**Returns:**
- A criterion object wrapping the java criterion
1188	Loads model weights from JSON and HDF5 files, returning the loaded model. Supports various file systems and optional name-based weight loading.
1189	Load IMDB dataset and transform it into padded sequences. Returns training and test data as padded numpy arrays.
1190	Builds a recurrent convolutional neural network model using Keras 1.2.2 with embedding, convolutional, max pooling, and LSTM layers for binary classification.
1191	Return the input shape(s) of the model. If there are multiple inputs, returns a list of shape tuples; otherwise returns a single shape tuple.
1192	Return the output shape of the layer. If there are multiple outputs, returns a list of shape tuples; otherwise returns a single shape tuple.
1193	Get MNIST dataset with features and label as ndarray. Data would be downloaded automatically if it doesn't present at the specific location.

:param data_type: "train" for training data and "test" for testing data.
:param location: Location to store mnist dataset.
:return: (features: ndarray, label: ndarray)
1194	Parse or download MovieLens 1M data if train_dir is empty.

:param data_dir: The directory storing the MovieLens data
:return: a 2D numpy array with user index and item index in each row
1195	Get and return the jar path for bigdl if exists.
1196	Check if Spark version is below 2.2 by comparing the major and minor version numbers, returning True if below 2.2 and False otherwise.
1197	Export variable tensors from TensorFlow checkpoint files into a dictionary mapping variable names to numpy arrays.
1198	Save a dictionary of tensors to a Java object file for BigDL compatibility. Converts tensor values to numpy arrays if needed, then uses BigDL's saveTensorDictionary function to persist the data.
1199	Expand and tile tensor along given axis by reshaping and tiling operations.
1200	The function `precompute_future_symbols` precomputes all possible symbol continuations of length up to `n` for each node in a trie data structure. It populates the `trie.data` attribute with sets of symbols that can follow each node at different depths (from 0 to n-1). The function handles optional space characters and ensures that precomputation is only performed once by checking `trie.precompute_symbols`. For each depth level from 1 to n-1, it aggregates symbols from child nodes and, if allowed, includes symbols from the root node for transitions back to the start state. The function marks the trie as terminated after completion.
1201	Computes simple attention mechanism by applying dropout to memory, generating attention weights through two-layer dense networks, masking invalid positions, and returning weighted sum of memory elements.
1202	Computes weighted sum of inputs conditioned on state using attention mechanism with masking.

**Parameters:**
- inputs: Input tensor 
- state: State tensor for conditioning
- att_size: Size of attention layer
- mask: Mask tensor for attention weights
- scope: Variable scope name

**Returns:**
- res: Weighted sum of inputs
- logits: Attention logits before softmax
1203	Computes the BLEU score for machine translation evaluation by comparing translations against reference texts. Returns tuple of BLEU score, n-gram precisions, brevity penalty, length ratio, and actual lengths.
1204	Returns an opened file object for writing dialog logs by creating a log directory, generating a timestamped log file path, and opening the file in append mode with UTF-8 encoding.
1205	Logs a single dialog utterance to the current dialog log file, handling different utterance types and managing log file rotation based on size limits.
1206	Summary of `summary_gradient_updates`:

This function creates summary operations to track the magnitude of gradient updates during training. It takes gradient information, an optimizer, and learning rate as input, then computes the normalized update magnitude for each trainable variable. The function handles both dense and sparse gradients, applies AdaGrad scaling when available, and returns a list of summary tensors that normalize the update norm by the parameter norm for monitoring training dynamics.
1207	Dump trained model weights from TensorFlow checkpoint to HDF5 file, converting variable names to a specific format while excluding softmax variables.
1208	Reads data using a dataset reader configured according to the provided config dictionary, supporting only classification dataset type. Raises exceptions for unsupported dataset types or missing configuration.
1209	Trains and evaluates a model based on the provided configuration. Supports recursive training, downloading dependencies, and custom data iterators. Returns evaluation metrics from specified targets.
1210	Function `interact_alice` handles communication between an agent and Yandex.Dialogs service by processing incoming JSON requests, extracting message details, and formatting responses. It takes an Agent object as input, processes the request data to extract command/text and payload information, creates a DialogID from user and session IDs, and then queries the agent for a response. The function returns a JSON response containing the agent's output, with special handling for RichMessage objects that contain multiple text segments. The response includes session metadata and is sent back with HTTP status 200.
1211	Convert labels to one-hot vectors for multi-class multi-label classification by mapping each sample's classes to binary indicators in a 2D array where rows represent samples and columns represent classes.
1212	Convert probability vectors to one-hot representations using a confident threshold by first converting probabilities to class labels and then to one-hot encoding.
1213	Configure and return a TensorFlow session with GPU options set to allow memory growth and use visible device list '0'.
1214	Loads a model from a file if the model file exists, logging the loading process with the file path.
1215	Extracts momentum variable values from optimizer, returns either `rho` or `beta_1` attribute, or None if neither exists.
1216	Update graph variables setting given learning_rate and momentum values.
1217	Calculates the F1 macro measure by rounding predicted values and computing the F1 score with macro averaging. Handles both rounded and unrounded predictions, returning the macro-averaged F1 score.
1218	Function `process_word` converts a word into a tuple of symbols with optional lowercase conversion and capitalization labeling. It handles special cases like all uppercase words (<ALL_UPPER>), first letter uppercase (<FIRST_UPPER>), digits (<DIGIT>), and URLs (<HTTP>). The function returns a tuple of the processed word components, with case information optionally prepended or appended based on the `append_case` parameter.
1219	Stacks multiple convolutional layers on top of each other with optional batch normalization and dilation.

Args:
    units: Input tensor with shape [None, n_tokens, n_features]
    n_hidden_list: List specifying number of hidden units for each layer
    filter_width: Width of convolutional kernel (default: 3)
    use_batch_norm: Whether to apply batch normalization between layers (default: False)
    use_dilation: Whether to use increasing dilation rates [1, 2, 4, 8, ...] (default: False)
    training_ph: Training phase placeholder for batch norm (required if use_batch_norm=True)
    add_l2_losses: Whether to add L2 regularization losses (default: False)

Returns:
    Output tensor from the last convolutional layer with shape [None, n_tokens, n_hidden_list[-1]]
    
The function applies a series of 1D convolutional layers with ReLU activation, optionally including batch normalization and dilated convolutions. Each layer uses 'same' padding and the specified filter width.
1220	Creates a bidirectional recurrent neural network with GRU or LSTM cells. Takes input tensor of shape [batch_size, n_tokens, n_features] and processes it through bidirectional RNN layers. Supports configurable hidden units, sequence lengths, trainable initial states, and peephole connections for LSTM. Returns the output tensors from both forward and backward passes along with their final hidden states. Includes L2 regularization on kernel weights.
1221	Stacked bidirectional recurrent neural networks (GRU or LSTM) that process input tensors through multiple recurrent layers. Takes input tensor with shape [None, n_tokens, n_features] and applies bidirectional RNNs with specified cell types. Returns the output tensor from the last layer and the last hidden states (or cell states for LSTM). Supports variable sequence lengths and peephole connections for LSTM cells.
1222	Stacked highway convolutional network with skip connections and gating mechanism. Takes input tensor and applies a series of 1D convolutional layers with optional batch normalization, dilation, and highway connections that use sigmoid gates to control information flow. Returns output tensor with specified hidden dimensions.
1223	Creates a token embedding layer that generates embeddings for tokens. Can initialize with pre-trained embedding matrices or randomly initialize embeddings. Returns embedded tokens tensor with shape [B, T, E] where B is batch size, T is number of tokens, and E is embedding dimension. Supports both trainable and non-trainable embeddings.
1224	Summary: CuDNN GRU layer implementation that processes sequence data efficiently using TensorFlow's CudnnGRU. Takes input tensor with shape [B x T x F], where B is batch size, T is sequence length, and F is feature dimension. Returns all hidden states [B x T x F] and last hidden state [B x H]. Supports configurable number of layers, trainable initial states, and sequence length masking. Uses CuDNN for optimized performance on GPU.
1225	CuDNN Compatible GRU implementation for loading models saved with CudnnGRUCell to run on CPU. Takes input tensor of shape [B x T x F], processes through multi-layer GRU with specified hidden dimension, supports trainable initial states and sequence lengths. Returns all hidden states [B x T x F] and last hidden state [B x H].
1226	Creates a fast CuDNN LSTM implementation that processes input sequences and returns hidden states and final states. Supports configurable layers, trainable initial states, and optional sequence length masking for extracting last states.
1227	CuDNN Compatible LSTM implementation for loading and running models saved with CudnnLSTMCell on CPU. Takes input tensor of shape [B x T x F] and returns hidden states and last hidden/cell states. Supports configurable layers, trainable initial states, and sequence length masking. Uses CudnnCompatibleLSTMCell internally and handles multi-layer RNN construction.
1228	Creates a fast CuDNN Bidirectional GRU implementation that processes input sequences using both forward and backward GRU layers, returning all hidden states and last hidden states for both directions.
1229	Creates a fast CuDNN Bi-LSTM implementation that processes input sequences using forward and backward LSTM layers. Returns hidden states and last hidden/cell states for both directions.
1230	Fast CuDNN Stacked Bi-GRU implementation that applies multiple bidirectional GRU layers to input sequences. Takes input tensor of shape [B x T x F] and processes it through n_stacks of bidirectional GRUs, each with n_hidden units. Supports optional sequence lengths, dropout between layers, and trainable initial states. Returns hidden states with concatenated outputs from all layers if concat_stacked_outputs is True, otherwise returns the last layer's output with shape [B x T x ((n_hidden * 2) * n_stacks)].
1231	Variational dropout function that applies the same dropout mask across specified dimensions to maintain consistency in temporal or feature dimensions while randomizing dropout elsewhere.
1232	Builds a Keras network with word CNN layers, optional additional word embeddings, and basic LSTM network components, then compiles it with categorical crossentropy loss and nadam optimizer.
1233	Builds a word-level CNN network with configurable convolutional layers, highway layers, and dropout mechanisms for text processing.
1234	Creates basic network architecture that transforms word embeddings to intermediate outputs using dropout, bidirectional LSTM layers, and a softmax activation dense layer.
1235	Trains the model on a single batch of data and labels using the internal `_transform_batch` method to preprocess the data, then calls `train_on_batch` on the model with the transformed inputs.
1236	Makes predictions on a single batch of word sequences using the model's predict_on_batch method, returning either tag indexes or formatted tags based on the return_indexes parameter.
1237	Transforms a sentence into a 3D numpy array for neural network input, where each element represents the indices of characters in words with begin/end markers and padding.
1238	Transforms a sentence of tags into a 2D numpy array where each element represents the index of the corresponding tag in the input sentence. The method uses a vocabulary map (tags.tok2idx) to convert tags to their respective indices. If no bucket length is specified, it defaults to the length of the input tags. Returns a 1D numpy array of integer indices representing the tag sequence.
1239	Calculate BLEU score with advanced options including smoothing function, auto re-weighting, and brevity penalty.

Parameters:
- y_true: list of reference tokens
- y_predicted: list of query tokens
- weights: n-gram weights (default: (1,))
- smoothing_function: SmoothingFunction (default: SMOOTH.method1)
- auto_reweigh: Option to re-normalize the weights uniformly (default: False)
- penalty: Either enable brevity penalty or not (default: True)

Returns:
- BLEU score as float

The function computes sentence-level BLEU score with optional brevity penalty adjustment based on the reference and hypothesis lengths.
1240	Verify that a signature certificate URL meets Amazon Alexa requirements by checking:
- URL uses HTTPS scheme
- Domain is s3.amazonaws.com
- Path starts with '/echo.api/'
- Port is 443 or None

Returns True if all conditions are met, False otherwise.
1241	Extracts pycrypto X509 objects from SSL certificates chain string.

Args:
    certs_txt: SSL certificates chain string.

Returns:
    List of pycrypto X509 objects.
1242	Verifies if a chain of trust exists between Amazon certificate and root CA using intermediate certificates and system CA certificates. Returns True if verification succeeds, False otherwise.
1243	Verifies an Alexa request signature using RSA signature verification with SHA-1 hashing. Takes an Amazon certificate, base64-decoded signature, and request body as inputs, returning True if the signature is valid and matches the request body, False otherwise.
1244	```python
def verify_cert(signature_chain_url: str) -> Optional[crypto.X509]:
    """Conducts series of Alexa SSL certificate verifications against Amazon Alexa requirements.

    Args:
        signature_chain_url: Signature certificate URL from SignatureCertChainUrl HTTP header.
    Returns:
        result: Amazon certificate if verification was successful, None if not.
    """
    try:
        certs_chain_get = requests.get(signature_chain_url)
    except requests.exceptions.ConnectionError as e:
        log.error(f'Amazon signature chain get error: {e}')
        return None

    certs_chain_txt = certs_chain_get.text
    certs_chain = extract_certs(certs_chain_txt)

    amazon_cert: crypto.X509 = certs_chain.pop(0)

    # verify signature chain url
    sc_url_verification = verify_sc_url(signature_chain_url)
    if not sc_url_verification:
        log.error(f'Amazon signature url {signature_chain_url} was not verified')

    # verify not expired
    expired_verification = not amazon_cert.has_expired()
    if not expired_verification:
        log.error(f'Amazon certificate ({signature_chain_url}) expired')

    # verify subject alternative names
    sans_verification = verify_sans(amazon_cert)
    if not sans_verification:
        log.error(f'Subject alternative names verification for ({signature_chain_url}) certificate failed')

    # verify certs chain
    chain_verification = verify_certs_chain(certs_chain, amazon_cert)
    if not chain_verification:
        log.error(f'Certificates chain verification for ({signature_chain_url}) certificate failed')

    result = (sc_url_verification and expired_verification and sans_verification and chain_verification)

    return amazon_cert if result else None
```
1245	Returns a list of JSON-compatible representations of the RichMessage instance's nested controls by calling the json() method on each control.
1246	Returns a list of MS Bot Framework compatible states for the RichMessage instance's nested controls by calling the ms_bot_framework() method on each control.
1247	Returns a list of Telegram-compatible representations of the RichMessage instance's nested controls by calling the telegram() method on each control.
1248	Returns a list of Amazon Alexa compatible states of the RichMessage instance nested controls by calling the alexa() method on each control.
1249	This function is a DeepPavlov console utility that manages configuration settings. It parses command line arguments to determine whether to populate settings with default files or display the current settings path. When the --default flag is used, it forces creation of default settings files in the configured path, providing feedback on success or if the directory already contains defaults. Without the flag, it simply reports the current settings path location.
1250	Wraps a function to execute it within a specified graph context, ensuring the function runs with the graph as the default context.
1251	Wraps a function to execute it within a specific Keras backend session and graph context, ensuring proper tensor computation environment.
1252	Calculate accuracy as the proportion of correctly predicted samples.

Args:
    y_true: array of true values
    y_predicted: array of predicted values

Returns:
    float: proportion of absolutely coincidental samples (accuracy score)
1253	Rounds predictions and calculates accuracy in terms of absolute coincidence.

Args:
    y_true: list of true values
    y_predicted: list of predicted values

Returns:
    portion of absolutely coincidental samples
1254	Initializes variables with pretrained weights from HDF5 files, handling special padding indices and mapping variable names between the graph and checkpoint files.
1255	Reads a file from the specified path and returns data as a dictionary mapping data types ('train', 'valid', 'test') to lists of input-output tuples. Raises NotImplementedError in the base class.
1256	Builds a hello-bot agent using PatternMatchingSkill and HighestConfidenceSelector that can handle simple greetings like "hello", "hi", "bye", etc.
1257	Converts an array of integers into one-hot encoded vectors using a k-dimensional unit matrix.
1258	Prettifies a list of metric tuples into an ordered dictionary with rounded values. Takes a list of (key, value) tuples and returns an OrderedDict where each value is rounded to the specified precision (default 4 decimal places).
1259	Populate settings directory with default settings files, optionally replacing existing ones. Returns True if any files were copied, False otherwise.
1260	Load model parameters from self.load_path, excluding optimizer variables by default.
1261	Save model parameters to the specified save path using TensorFlow's Saver, excluding variables in specified scopes.
1262	Get train operation for given loss with optional gradient clipping and variable scoping.
1263	Finds all dictionary words within a d-window distance from the input word using trie-based search, with options to allow spaces and return edit costs.
1264	Sets default operation costs to 1.0 for all replacements, insertions, deletions, and transpositions. For each alphabet character, defines costs for replacing with other characters (0.0 for same character), inserting/deleting characters, and allows optional space handling. Includes transposition costs for all character pairs and space-related operations when enabled.
1265	Initiates a self-destruct timer that will call the self_destruct_callback after the configured conversation lifetime duration.
1266	Handles Alexa requests by routing them to appropriate handlers based on request type, logs the request, and returns a response conforming to Alexa response specification. Unsupported request types are handled by a default handler.
1267	Infers DeepPavlov agent with raw user input extracted from Alexa request.

Args:
    utterance: Raw user input extracted from Alexa request.
Returns:
    response: DeepPavlov agent response.
1268	Populates generated response with additional data conforming Alexa response specification by merging a response template with the raw response, ensuring session attributes are properly set and missing keys from the template are added to the response.
1269	Handles an IntentRequest Alexa request by validating the intent name and slot, extracting the utterance from the slot, processing it through the agent, and generating a response conforming to Alexa specification. Returns error responses for invalid intents, missing slots, or processing failures, otherwise returns the generated Alexa response.
1270	Handles LaunchRequest Alexa request by creating a response with start message, generating the final response, and returning it.
1271	Handles unsupported Alexa requests by generating a standard response with an error message and card, then returns the formatted response.
1272	Method that defines pretty printing rules for Struct objects in IPython, handling both normal and cyclical printing scenarios by using IPython's representation printer to format the struct data.
1273	Calculates perplexity from a list of model losses by taking the exponential of the average loss.
1274	Build and return a model based on the provided configuration, with options for loading trained components, downloading dependencies, and using serialized data.
1275	Start interaction with a model using the specified configuration, taking user input for model inputs, generating predictions, and displaying results until an exit command is received.
1276	Make predictions on streaming data using a model specified in a configuration file, processing input from stdin or a file in batches and outputting JSON formatted results.
1277	Reads a file in CONLL-U format and returns a list of sentences, where each sentence is represented as a tuple of word sequence and tag sequence. Supports options to specify which columns to read, limit the number of sentences, and read only words.
1278	Returns a function object from a string name in the format "module:function_name" by importing the module and getting the function attribute. Raises ConfigError if the string is not in the expected format.
1279	Decorator for metric registration that registers a function under a specified metric name in a global registry, warning if the metric name already exists.
1280	Returns a metric callable by its registered name, raising ConfigError if not found.
1281	Convert a decay type string label to its corresponding special index by normalizing the label and looking up in class members, raising NotImplementedError if not found.
1282	Find the best value from a list of values based on corresponding losses, considering maximum loss divergence and minimum value divergence thresholds. Returns the best value divided by min_val_div.
1283	Encodes text tokens into embeddings, returning either individual token embeddings or their mean embedding based on the mean parameter. Handles missing tokens by attempting to retrieve word vectors or defaulting to zero vectors, and caches embeddings in tok2emb.
1284	Parses requirements from requirements.txt file, separating package names and links, returning a dictionary with 'install_requires' and 'dependency_links' keys.
1285	Calculates log loss by calling the log_loss function with true and predicted values as parameters.
1286	Exports a TensorFlow model to TF-Hub format by creating a module specification from weight file and options, then saving it to the specified directory.
1287	Format catalog item output

Parameters:
    item_data: item's attributes values

Returns:
    [rich_message]: list of formatted rich message
1288	Creates and returns an EcommerceAgent instance with a TFIDF retrieval skill by loading configuration and building the model.
1289	Parse command line arguments and start the Microsoft Bot Framework server using the specified bot agent, app ID, and app secret with stateful communication enabled.
1290	Download a file from a URL to one or several target locations, with optional caching and force download settings.
1291	Extracts files from a tar archive to a specified folder.
1292	Download and extract .tar.gz, .gz, or .zip files from a URL to specified paths, with optional caching. The function handles multiple extraction targets and cleans up the downloaded archive after successful extraction.
1293	Updates a dictionary recursively with values from another dictionary, handling nested dictionaries by recursively updating nested mappings while directly assigning non-mapping values.
1294	Given a file URL, return the URL of the corresponding MD5 checksum file by appending '.md5' to the original file path.
1295	Sets or replaces a query parameter in a URL and returns the modified URL. Takes a URL, parameter name, and parameter value as input, updates the query string with the new parameter, and returns the updated URL.
1296	Returns Amazon Alexa compatible state of the PlainText instance with populated "outputSpeech" and "card" sections.
1297	Returns a JSON-compatible dictionary representation of the Button instance, containing the button's name, callback function, and control JSON structure.
1298	Returns MS Bot Framework compatible state of the Button instance as a CardAction dictionary with postBack type, including the button title and callback value.
1299	Returns a JSON-compatible dictionary representation of the ButtonsFrame instance, including its text content (if exists) and all nested controls. The method constructs a dictionary with 'text' key (if text exists) and 'controls' key containing JSON representations of all child controls, then updates and returns the instance's control_json attribute.
1300	Returns MS Bot Framework compatible state of the ButtonsFrame instance as a dictionary with message type and thumbnail card attachment containing formatted buttons and title.
1301	Calculates the F-1 score between true and predicted answers for SQuAD-v2.0 evaluation. For each prediction, it finds the best matching true answer and computes the F-1 score using precision and recall. Returns the average F-1 score across all predictions as a percentage.
1302	Calculates recall at k ranking metric by evaluating whether the true candidate (represented by index 0) appears in the top-k predictions for each sample. The function takes true labels (unused), predicted ranking scores, and a k value, then returns the proportion of samples where the true candidate is within the top-k ranked predictions.
1303	Return True if at least one GPU is available, using TensorFlow to check local devices and caching the result.
1304	Recursively replaces variables in configuration properties with their corresponding values, handling strings, lists, and dictionaries while leaving other types unchanged.
1305	Parse configuration by reading variables from JSON file or dict, applying environment variable overrides, and processing all properties with formatted variables.
1306	Converts relative paths to absolute paths by resolving the user directory (~) and normalizing the path.
1307	Builds and returns a Component from a dictionary of parameters, handling component references, configuration paths, and recursive parameter initialization.
1308	Thread run method that continuously processes requests from input queue, handles them, and places responses in output queue.
1309	Deletes a conversation instance from the conversations dictionary using the provided conversation key, and logs the deletion operation.
1310	Refreshes valid certificates by cleaning up expired ones and reschedules itself to run periodically.
1311	This method performs Alexa request verification by checking the signature certificate chain URL against valid certificates, validating the certificate if necessary, and then verifying the request signature. It returns True if all verifications pass, False otherwise. The method caches validated certificates for performance and logs validation results.
1312	Processes Alexa requests by verifying signatures and timestamps, managing conversation sessions, and handling request responses through conversation agents.
1313	Returns a class object from a string name in 'module:ClassName' format by importing the module and retrieving the class.
1314	A decorator function that registers classes for JSON configuration initialization, mapping class names to registry names (converted to snake-case by default) and tracking them in a global registry.
1315	Returns a registered class object with the name given in the string. If the name is not registered and doesn't contain a colon, raises a ConfigError. Otherwise, returns the class from string representation.
1316	Extracts the full regularization path from a GLM model's lambda search, returning lambdas, explained deviance metrics, and coefficients organized by regularization parameter.
1317	Create a custom GLM model using provided coefficients by making an API call to H2O's MakeGLMModel endpoint, then resolve and return the resulting model with the specified threshold for binomial classification.
1318	Creates an H2OCluster object from key-value pairs, setting valid properties while raising AttributeError for invalid attributes.
1319	Shuts down the H2O server by making a REST API call to the "/3/Shutdown" endpoint, but only if the cluster is running. Optionally prompts the user for confirmation before shutting down, and closes the connection after shutdown.
1320	Check if the H2O cluster is running by attempting to connect to the server and making an API request. Returns True if the cluster is up and accessible, False otherwise.
1321	Prints the current status information of the H2O cluster. If the info is stale, it refreshes it first. It displays basic cluster details like uptime, version, memory, and node status. If `detailed` is True, it also shows detailed information about each node such as CPU, memory, and system load.
1322	Lists all jobs performed by the cluster, returning a table with job types, destinations, descriptions, and statuses.
1323	Return the list of all known timezones as an H2OFrame.
1324	Update this object's information from another H2OCluster instance by copying properties and timestamp, then clearing the source object's data.
1325	Returns the metalearner algorithm parameters as a dictionary. If the parameters contain single-element lists, those elements are extracted. Returns None if no parameters are set.
1326	Method `stabilize` repeatedly tests a given function until it returns True or a timeout occurs. It takes a test function, an error handler (either a string template or callable), timeout duration, and retry delay as parameters. The method executes the test function with retry count and timeout information. If the test function doesn't return True within the timeout period, it raises an exception with either a formatted error message or a custom error message generated by the error handler. The method also periodically checks for sandbox errors every 50 retries.
1327	Return the summary for a single column for a single Frame in the h2o cluster.
1328	Delete a frame from the H2O cluster using its key. Returns the result of the delete operation. If ignoreMissingKey is False and the frame is not found, raises a ValueError.
1329	Return a model builder or all model builders known to the H2O cluster, with optional algorithm filtering and timeout support.
1330	Validates model parameters for a given algorithm against the H2O cluster by checking parameter existence and values, validating training frame if provided, and returning validation results from the ModelBuilders REST API.
1331	Score a model on the h2o cluster using the specified frame and return only the model metrics.
1332	Method: `model_metrics`

Summary: Retrieves a list of model metrics from the H2O cluster API endpoint `/3/ModelMetrics.json` using a GET command. The method includes error checking against the sandbox environment and returns the JSON response containing the model metrics data. The operation has a configurable timeout (default 60 seconds) and accepts additional keyword arguments for request customization.
1333	Delete a model from the H2O cluster using the specified key. Returns the deletion result. If ignoreMissingKey is False and the model key is not found, raises a ValueError. Includes timeout parameter for the request.
1334	Returns a pretty-formatted tabulated string of cached data with optional rollup statistics. If no valid data exists, it fills the cache first. For each column, it processes data based on type (enum, time, or numeric) and optionally includes summary statistics (mins, mean, maxs, sigma, zeros, missing) when rollups=True. The output uses the tabulate library with the specified table format.
1335	Creates a new reservation for a specified number of EC2 instances with given configuration and waits for them to become running state. Optionally waits for SSH access and applies tags to instances. Returns the reservation object or raises an exception if creation fails.
1336	Terminate all EC2 instances with the given IDs in the specified region, then log the termination process.
1337	Stop all the EC2 instances given by their IDs in the specified region.
1338	Start all the EC2 instances given their IDs in the specified region.
1339	Reboot all the EC2 instances specified by their IDs in the given region, with logging of the reboot process.
1340	Wait for SSH service to appear on given hosts by checking if SSH is live on each IP address with optional skipping of already alive hosts and required success count threshold.
1341	Return fully qualified function name by attempting to find the "full name" of a function object, which is either "<class name>.<method name>" for class methods or "<module name>.<func name>" for regular functions. This is a back-port of func.__qualname__ for Python 2.
1342	This function searches through a frame's local and global variables to find a function object that matches the given compiled code. It traverses the frame's scope looking for objects with a `__code__` attribute that matches the provided code object, handling various data structures (classes, modules, lists, tuples, sets, dictionaries) recursively up to a depth limit of 3 to avoid infinite loops. The function returns the matching function object if found, or None otherwise.
1343	Return a function's declared arguments as a string, with optional highlighting of a specific argument name. For example, for a function with arguments "func, highlight=None", it returns that string representation. The output typically matches the function's declaration inside the parentheses.
1344	Wrap text around if needed, with specified line length and indentation.
1345	Wait for job completion, clean up resources, and resolve the model.
1346	Train the H2O model with specified training data and parameters.

**Parameters:**
- `x`: List of predictor column names/indices
- `y`: Response column name/index
- `training_frame`: H2OFrame containing training data
- `offset_column`: Column name/index for offsets
- `fold_column`: Column name/index for fold assignments
- `weights_column`: Column name/index for row weights
- `validation_frame`: H2OFrame for validation scoring
- `max_runtime_secs`: Maximum training time in seconds (0 to disable)
- `ignored_columns`: Columns to ignore during training
- `model_id`: Custom model ID
- `verbose`: Whether to print scoring history

**Returns:** None (modifies model in-place)
1347	Fit an H2O model as part of a scikit-learn pipeline or grid search, issuing a warning if called outside of sklearn context. Returns the current instance for method chaining.
1348	Get parameters for this estimator, including nested estimators when deep=True, used for sklearn pipelines and grid search operations.
1349	Helper function to handle caught signals by terminating cloud resources gracefully when a signal is received.
1350	Clears the output directory by removing it if it exists, handling potential OS errors during the removal process.
1351	Removes sandbox directories named "Rsandbox" from a specified parent directory, using platform-appropriate deletion methods (cygwin rm on Windows, shutil.rmtree on Unix-like systems) with error handling.
1352	Method `scrape_port_from_stdout` parses the stdout log to extract the port number chosen by the JVM. It uses a regular expression to search for a specific pattern indicating the H2O Flow URL, and if found, stores the port number in `self.port` and returns. If the port cannot be found after 30 retries (with 1-second delays between retries), the program terminates with an error message. The method is blocking and will wait for the server to start up, checking the output file for the port information.
1353	Method: `scrape_cloudsize_from_stdout`

Summary: This method monitors a stdout log file to detect when a cluster of a specified size is formed. It repeatedly reads through the log file looking for a pattern indicating "Cloud of size X formed" where X matches the expected `nodes_per_cloud` parameter. The method blocks until either the correct cloud size is detected or it exhausts 60 retries. If the cloud size matches the expected size, the method returns successfully. If the maximum retries are exceeded, it prints an error message and exits the program. The method includes checks for termination flags and handles file I/O operations safely.
1354	```python
def stop(self):
    """
    Normal node shutdown that terminates the JVM process.
    
    Attempts to terminate the child JVM process gracefully using terminate() and wait().
    If the process doesn't exist or other OS errors occur, they are ignored.
    Sets the pid to -1 after shutdown attempt.
    
    :return: None
    """
    if self.pid > 0:
        print("Killing JVM with PID {}".format(self.pid))
        try:
            self.child.terminate()
            self.child.wait()
        except OSError:
            pass
        self.pid = -1
```
1355	Stops all nodes and client nodes in the cluster gracefully.
1356	Return an IP address to communicate with this cluster by selecting the first available client node, or falling back to the first regular node if no client nodes exist.
1357	Return a port to use for communicating with the cluster by getting the port from the first available client node, or falling back to the first regular node if no client nodes exist.
1358	Returns the ROC curve coordinates (false positive rates, true positive rates) for specified data sets. Can return training, validation, or cross-validation data as tuples, or a dictionary if multiple are requested.
1359	Determines the vector size for a pre-trained model by verifying the first column is of string type and ensuring only one string column exists in the model, then sets self.vec_size to the number of columns minus one.
1360	Computes the mean absolute error between actual and predicted values for H2O models, with optional sample weights. Returns the average absolute difference between predicted and actual responses, where lower values indicate better model performance.
1361	Mean squared error regression loss calculation between actual and predicted values.
1362	Median absolute error regression loss function that calculates the median of absolute differences between actual and predicted values. Returns the median absolute error where lower values indicate better model performance.
1363	Explained variance regression score function that calculates the ratio of variance explained by the model. Returns a score between 0 and 1, where 1 indicates perfect prediction. Handles edge cases where denominator is zero.
1364	**Summary:**

The `assert_is_type` function validates that a given variable matches one or more expected types. It raises an `H2OTypeError` if the type check fails, providing customizable error messages and frame skipping for debugging. The function accepts a variable, expected types, and optional keyword arguments for error message customization and frame skipping.
1365	Asserts that a string variable matches a given regular expression, raising an H2OValueError with a descriptive message if it doesn't match. Returns the match object if successful.
1366	Asserts that a variable satisfies a given condition, raising an H2OValueError with a descriptive message if the condition is not met.
1367	Retrieves argument names from assert statements by parsing the source code using tokenization. It walks up the stack trace to find the calling frame outside of the current file, reads the source line, and extracts the arguments passed to the assertion function. The function handles parentheses matching and tokenizes the source code to identify the actual argument expressions. If it fails to read the file, it returns a default argument name "arg".
1368	Check if a variable is of the specified type, handling various type cases including None, primitive types, string, integer, numeric, MagicType, class names, lists, sets, tuples, dictionaries, and functions.
1369	Return the name of the provided type, handling various type cases including built-in types, custom types, collections, and functions.
1370	This function attempts to extract the source code of a lambda function from a given string by:
1. Tokenizing the source string to identify lambda expressions
2. Parsing tokens to find complete lambda syntax (lambda parameters: body)
3. Testing each found lambda against the target function's bytecode
4. Returning the lambda body when a match is found, or "<lambda>" if no match

The function uses Python's tokenize module to properly parse the source code and compare bytecode to ensure it finds the correct lambda expression.
1371	Return True if the variable does not match any of the types, and False otherwise.
1372	Method `check` verifies if a given value is a valid enum constant by first checking if the value is of string type, then validating if the mangled version of the string exists in the enum's constants dictionary. Returns `True` if valid, `False` otherwise.
1373	Retrieve the config as a dictionary of key-value pairs. If the config hasn't been loaded yet, read it first. Returns the loaded configuration.
1374	Reads and parses a configuration file, storing valid configuration keys and their values in `self._config`. Returns early when the first existing config file is found and parsed. Logs information about reading the file and errors for invalid keys or syntax errors.
1375	Return possible locations for the .h2oconfig file by searching in the current directory and all parent directories, then check the user's directory.
1376	Executes a progress bar by continuously polling a progress function until completion. It handles both regular functions and generators, manages progress rendering, and supports interruption via Ctrl+C or StopIteration exceptions. The method initializes progress tracking parameters, updates progress based on the provided function, renders the widget at appropriate intervals, and finalizes the display before raising exceptions if needed.
1377	Store model progress data and update next poll time based on progress level and delay calculations.
1378	Recalculates model parameters (t0, x0, v0, ve) based on current progress and estimated completion time, adjusting for edge cases where progress may have overshoot or speed constraints are violated.
1379	Estimates when the underlying process is expected to complete based on progress data and constraints. Returns a future timestamp ensuring the process doesn't finish before the next poll time when progress is below 100%. Uses recent progress data to calculate an estimated completion time, with fallbacks for no progress cases. The result is clamped between the current time and current time plus a finish delay, and adjusted to respect polling constraints.
1380	Determine the next poll interval for progress status based on elapsed time and real progress. Returns the minimum of 20% of elapsed time or 0.5 plus the square root of (1 - real_progress).
1381	Calculate the modelled progress state for the given time moment.

Returns tuple (x, v) of the progress level and progress speed.
1382	Returns the projected time when a target progress level will be reached using Newton method for nonlinear progress modeling. Uses iterative linear approximation to converge on solution within 20 iterations, returning overflow time if convergence fails.
1383	Method `_draw` prints the rendered string to stdout. If not in file mode, it starts writing from the beginning of the line using carriage return. It writes the text and adds a newline at the end if it's the final render and the widget is not hidden. In non-final renders, it flushes the output to ensure immediate display.
1384	Computes the optimal width allocation for all widgets in a progress bar, handling both fixed and flexible widgets while ensuring minimum width requirements and managing rendering in constrained spaces.
1385	Get the width of the terminal stdout in characters, falling back to various methods if direct terminal detection fails.
1386	Sets the encoding for the widget's character stream and configures bar symbols accordingly. If the specified encoding supports Unicode block characters, it updates the bar symbols and ends to use those characters for progress visualization. If the encoding is invalid or unsupported, it prints a warning and falls back to default symbols.
1387	Returns encoding map as an object that maps 'column_name' -> 'frame_with_encoding_map_for_this_column_name'

:param frame frame: An H2OFrame object with which to create the target encoding map
1388	Retrieves an existing H2OFrame from the H2O cluster using the frame's ID with specified preview and fetch parameters. Returns the H2OFrame object if successful, or None if the frame doesn't exist. Supports options for row/column limits, offsets, and light frame retrieval.
1389	Reload frame information from the backend H2O server by flushing the cache and re-fetching the frame with cache filled.
1390	Returns the type of a specified column in the frame, which can be accessed by either name or index. The type is one of: ``str``, ``int``, ``real``, ``enum``, ``time``, ``bool``. Raises H2OValueError if the column does not exist.
1391	Extract columns of the specified type from the frame and return their indices. The coltype parameter specifies which column type to filter by, including "numeric", "categorical", "string", "time", "uuid", and "bad". The method validates the input parameters and returns a list of column indices matching the requested type.
1392	Displays summary information about the frame including min/mean/max/sigma and other rollup data. If return_data is True, returns a dictionary of the summary output; otherwise prints the summary. Returns empty frame data if frame is empty or uninitialized.
1393	Generate an in-depth description of the H2OFrame by printing its dimensions, column information, summary statistics, and first 10 rows. Optionally includes chunk and distribution summaries when chunk_summary=True.
1394	Return the first `rows` and `cols` of the frame as a new H2OFrame, with dimensions at most `rows` x `cols`.
1395	Multiply this frame by another matrix and return the result as a new H2OFrame.
1396	Get the factor levels as a list of lists, one list per column, of levels.
1397	Get the number of factor levels for each categorical column.

Returns a list of the number of levels per column.
1398	Sets all column values to a specified level and returns an H2OFrame with the entries set to the desired level.
1399	Replace the levels of a categorical column with new levels, maintaining alignment with the old domain. Returns a single-column H2OFrame with the updated levels.
1400	Rename columns in the frame by applying dictionary transformations to column names, supporting both integer indices and string names for column identification.
1401	Change names of all columns in the frame.

:param List[str] names: The list of new names for every column in the frame.
:returns: Self instance for chaining operations.
1402	Set a new name for a specified column in the frame. Raises errors if the column index/name is invalid or if the new name already exists. Updates the frame's column names and types accordingly.
1403	Test whether elements of an H2OFrame are contained in the given items.

Parameters:
    item: An item or a list of items to compare the H2OFrame against.

Returns:
    An H2OFrame of 0s and 1s showing whether each element in the original H2OFrame is contained in item.
1404	Build a fold assignments column for cross-validation using modulo operation. Rows are assigned to folds based on their row number modulo the specified number of folds. Returns a single-column H2OFrame containing the fold assignments.
1405	Creates a stratified k-fold column that ensures each fold maintains the same class distribution as the original dataset. Returns an H2OFrame with fold assignments for cross-validation.
1406	Display the internal structure of an H2OFrame with dimensions, variable names, and data types, showing factor levels or numeric values for each column.
1407	Converts the H2OFrame dataset into a python-local object, either as a pandas DataFrame (when pandas is available) or as a nested list with optional header row. Returns a pandas DataFrame if pandas is available and use_pandas=True, otherwise returns a list of lists containing the frame data.
1408	Pop a column from the H2OFrame at index i and return it as a new H2OFrame while removing it from the current frame. The method accepts either an integer index or string column name, modifies the current frame in-place by removing the specified column, and returns the popped column as a separate H2OFrame object.
1409	Compute quantiles for the H2OFrame with optional probabilities, combine method, and weights column. Returns a new H2OFrame containing quantiles and probabilities.
1410	Concatenates multiple H2OFrames to this frame either column-wise (default) or row-wise based on the specified axis parameter. Returns the combined H2OFrame.
1411	Append data to this frame column-wise, returning a new H2OFrame with all frames appended column-wise. Raises an error if the number of rows doesn't match. Handles both H2OFrame and numeric data inputs.
1412	Append data to this frame row-wise, ensuring column names, types, and counts match across all frames being combined.
1413	Split a frame into distinct subsets based on given ratios using probabilistic splitting method. Returns a list of H2OFrames where each frame corresponds to a subset defined by the ratios. The splitting is approximate and more accurate on larger datasets. The number of subsets equals the number of ratios plus one. Each subset is defined by boundary values calculated from the provided ratios.
1414	Returns a new GroupBy object using this frame and the specified grouping columns, with groups sorted by natural group-by column sort.
1415	Fill NA values in a frame along a given axis and direction with a maximum fill length, returning a new H2OFrame.
1416	Impute missing values into the frame in-place using specified method and return the imputation values or group-by results. Supports mean, median, and mode imputation with various combine methods for median. Can impute specific columns or entire frame, with optional grouping and predefined impute values.
1417	Merge two datasets based on common column names with support for different merge methods (auto, radix, hash). The method handles cases with duplicate rows and string columns, with radix being the default and preferred method. Returns a new H2OFrame with the merged result.
1418	Reorders the levels of an H2O factor column such that the specified reference level becomes level 0, with other levels adjusted accordingly. Returns a new reordered factor column.
1419	Inserts missing values into the H2OFrame by replacing a specified fraction of entries with missing values, modifying the frame in-place. Returns the modified H2OFrame.
1420	Compute the variance-covariance matrix of one or two H2OFrames, with options for handling missing values and returning scalar variance in special cases.
1421	Compute the correlation matrix of one or two H2OFrames, with options to handle missing values and specify the correlation method. Returns an H2OFrame or scalar depending on the input dimensions.
1422	Computes pairwise distance measures between all rows of two numeric H2OFrames. Supports L1 (absolute), L2 (Euclidean), cosine, and squared cosine distance metrics. Returns an H2OFrame containing the pairwise distance/similarity matrix between the two input frames.
1423	Convert columns in the current frame to categoricals.

**Returns:** new H2OFrame with columns of the "enum" type.

**Raises:** H2OValueError if column types are not 'int' or 'string', H2OTypeError if types are not available in result.
1424	Split the strings in the target column on the given regular expression pattern.

**Parameters:**
- `pattern` (str): The split pattern.

**Returns:**
- H2OFrame containing columns of the split strings.
1425	Counts occurrences of a pattern substring in each string element of a frame, returning a numeric frame with the same shape containing the match counts. The pattern can be a single string or list of strings to search for. All columns in the frame must be string or categorical type.
1426	Returns a new H2OFrame containing substrings of the original strings, starting from start_index and ending at end_index (exclusive). If end_index is omitted, the substring extends to the end of each string. Returns empty strings for invalid indices, and coerces negative start_index values to 0.
1427	Return a copy of the column with leading characters removed, similar to Python's str.lstrip() method. The set argument specifies the set of characters to be removed, defaulting to whitespace if omitted. Returns a new H2OFrame with the same shape as the original frame having all values trimmed from the left.
1428	Computes Shannon entropy for each string in the frame, returning an H2OFrame of entropy values with cached dimensions.
1429	Returns an H2OFrame containing the count of valid substrings (2+ characters) found in each string, where validity is determined by checking against a word list stored in a line-separated text file.
1430	Compute counts of values in a column or co-occurrence counts between two columns, returning an H2OFrame with the results.
1431	Compute a histogram for a numeric column with specified breaks and optional plotting. Returns histogram data or displays a plot based on the plot parameter.
1432	Compute the iSAX index for numeric time series data by converting time series into symbolic representations using specified number of words and cardinality, returning an H2OFrame with time series names, iSAX word strings, and binary representations.
1433	Substitutes the first occurrence of a pattern in an H2OFrame with a replacement string, optionally ignoring case sensitivity. Returns a new H2OFrame with the replacement applied.
1434	Converts all strings in a column to uppercase case and returns a new H2OFrame with the converted values.
1435	Searches for regex pattern matches within string column elements, returning either matching indices or logical vector.
1436	Remove rows with NAs from the H2OFrame.

Returns: new H2OFrame with all rows from the original frame containing any NAs removed.
1437	Conducts a diff-1 transform on a numeric frame column, returning an H2OFrame where each element equals the corresponding element minus the previous-row element. Raises H2OValueError for multi-column frames or non-numeric columns.
1438	Returns an H2OFrame of 1s and 0s indicating which elements are NA values.
1439	Extract the "minute" part from a date column and return it as a single-column H2OFrame.
1440	Generate a column of random numbers from a uniform distribution [0,1) with specified seed, returning a single-column H2OFrame.
1441	Creates a stratified random split column for train/test division with specified test fraction and random seed, returning an H2OFrame with "train" and "test" categories.
1442	Cut a numeric vector into categorical "buckets" based on specified break points, returning a single-column H2OFrame of categorical data with optional labeling and interval configuration.
1443	Get the index of the maximum value in each column or row of the frame.

Parameters:
- skipna (bool): If True (default), ignores NAs during search. If False, returns NA if any NAs are present.
- axis (int): Direction to search for maximum index. If 0 (default), searches column-wise. If 1, searches row-wise.

Returns:
- H2OFrame containing the indices of maximum values, either per column (axis=0) or per row (axis=1)
1444	Apply a lambda expression to an H2OFrame along specified axis (0 for columns, 1 for rows) and return a new H2OFrame with results.
1445	Parse code from a string of text by splitting into lines and tokenizing each line using a generator-based readline function.
1446	Parse the provided file and return a Code object by tokenizing its content.
1447	Moves the token by the specified number of rows and columns by updating both start and end coordinates.
1448	Convert the parsed representation back into source code using an Untokenizer.
1449	Returns cluster sizes for specified data splits (train, validation, cross-validation). If only one split is requested, returns a list of sizes; if multiple splits are requested, returns a dictionary with split names as keys and their respective cluster size lists as values. If no splits are specified, returns training data cluster sizes by default.
1450	Returns the cluster centers from the KMeans model output, extracting center coordinates from the model's cell values.
1451	Returns the standardized centers for the kmeans model by extracting and processing center values from the model output.
1452	Connect to an existing H2O server (local or remote) using specified connection parameters. Supports connecting via server instance, URL, or IP/port combination with optional HTTPS, authentication, proxy, and SSL verification settings. Returns an H2OConnection object.
1453	Perform a REST API request to a connected H2O server, forwarding parameters to the underlying H2OConnection.request method.
1454	Function `version_check()` verifies compatibility between the h2o-python module and the H2O server by comparing their version numbers. It raises `H2OConnectionError` with specific messages if versions don't match, handling different cases like unknown builds or developer builds. It also prints a warning if the H2O cluster version is too old.
1455	Import a single file or collection of files from a given path with optional pattern matching. Returns either a single H2OFrame or a list of H2OFrames.
1456	Uploads a local dataset file to the H2O cluster and returns it as an H2OFrame. Supports specifying column names, types, separators, missing value strings, and skipped columns. Uses single-threaded push operation.
1457	Import a dataset from a specified path on the cluster into an H2OFrame. Supports both single files and directories with optional pattern matching. Provides various parsing options such as header detection, column types, missing value handling, and skipped columns. If parse is True (default), the file is parsed into a frame; otherwise, it returns the file path(s). Requires valid cluster-wide paths and supports distributed multi-threaded import.
1458	Import a Hive table into an H2OFrame object. Requires H2O to be started with Hive on classpath and hive-site.xml available. Supports importing specific partitions and handling tables with different storage formats. Returns an H2OFrame containing the Hive table data.
1459	Import a SQL table into an H2OFrame in memory using JDBC connection. Supports parallel ingestion and distributed/single-node import modes. Requires h2o.jar and JDBC driver in classpath. Returns an H2OFrame with the table data.
1460	Imports data from a SQL database query into an H2OFrame by creating a temporary table and using parallel ingestion. Supports distributed or single-node import modes. Requires JDBC driver in classpath.
1461	Parse dataset using the parse setup structure.

:param setup: Result of ``h2o.parse_setup()``
:param id: an id for the frame
:param first_line_is_header: -1, 0, 1 if the first line is to be used as the header

:returns: an :class:`H2OFrame` object
1462	Create a deep clone of an H2OFrame with a specified ID, returning a new H2OFrame that is independent of the original frame.
1463	Load a model from the server based on the model ID and return the corresponding model object. The function determines the model type from the algorithm name in the model JSON and instantiates the appropriate estimator class, then resolves the model using the model ID and JSON data.
1464	Return the specified grid by ID, retrieving grid search results and resolving model parameters to construct an H2OGridSearch instance with hyperparameter information.
1465	Get an H2OFrame handle by frame ID.

Parameters:
    frame_id (str): The ID of the frame to retrieve
    **kwargs: Additional keyword arguments to pass to the underlying frame retrieval

Returns:
    H2OFrame: An H2OFrame object corresponding to the specified frame ID

Example:
    >>> frame = get_frame("frame_123")
    >>> print(frame)
    H2OFrame: frame_123
1466	Downloads the POJO (Plain Old Java Object) code for a given model to a specified directory or prints to screen. Returns the location of the downloaded POJO file. Optionally also downloads the h2o-genmodel.jar file to the same directory. Raises an error if POJO export is not supported for the model.
1467	Downloads an H2OFrame object to a CSV file on the local disk by making a URL request to the H2O server and writing the response data to the specified file.
1468	Download H2O log files to disk as a zip file.

This function downloads all H2O log files from the current session and saves them to a specified directory as a compressed zip file. If no filename is provided, it attempts to extract the filename from the response headers. The function creates the target directory if it doesn't exist and returns the full path to the saved zip file.

Parameters:
- dirname (str): Directory path where the log file will be saved (default: current directory)
- filename (str, optional): Name of the output zip file (must include .zip extension)

Returns:
- str: Path to the saved zip file containing the logs

Example:
```python
h2o.download_all_logs(dirname='./logs/', filename='h2o_logs.zip')
```
1469	Exports an H2OFrame to a specified path on disk, with options for multiple part files and force overwrite.
1470	Convert an H2O data object into a Python-specific object (list-of-lists or pandas DataFrame) with optional header support.
1471	Summary: The `demo` function is an H2O built-in demonstration facility that allows users to execute predefined demo functions. It takes a function name as a string and optional parameters to control interactivity, command echoing, and testing behavior. The function retrieves and executes the specified demo function from the h2o.demos module, or prints an error message if the demo is not available. The function includes input validation and supports both interactive and non-interactive demonstration modes.
1472	Loads a dataset file from within the 'h2o_data' folder by searching for it in multiple possible locations, and uploads it if found. Raises an error if the file cannot be located.
1473	Create model metrics from predicted and actual values in H2O by making an API call to compute metrics based on the provided frames and optional parameters.
1474	Uploads a local file to DKV (Deep Learning KV) under a specified key name. Takes a file path and optional destination key/overwrite parameters, uploads the file via API POST request, and returns the destination key name. If no destination key is provided, uses an empty string. The overwrite parameter determines whether to overwrite existing keys with the same name.
1475	Uploads a custom metric function to the H2O cluster. The function can be provided as a class or a string representation of a class, and it must implement `map`, `reduce`, and `metric` methods. The metric is saved under a specified key and returned as a reference. Supports optional parameters for file naming, class name, and source code provider.
1476	Check that the provided frame id is valid in Rapids language, ensuring it's not None or empty, doesn't contain illegal characters, and doesn't start with a number.
1477	Converts a byte size into a human-readable string representation with appropriate units (PB, TB, GB, MB, KB, bytes).
1478	Normalize a slice object by converting negative indices to positive equivalents and handling None values for start, stop, and step attributes, ensuring all values are within the valid range [0, total).
1479	Return True if slice `s` is in "normalized" form, meaning all of start, stop, and step are not None and start is less than or equal to stop.
1480	MOJO scoring function that takes a Pandas dataframe and uses a MOJO model (provided as a zip file) to generate predictions. The function converts the input dataframe to CSV, scores it using the MOJO model, and returns the predictions as a Pandas dataframe. It handles temporary file management and includes optional parameters for customizing the Java environment and classpath.
1481	MOJO scoring function that takes a CSV file and uses a MOJO model (zip file) to generate predictions. It requires an input CSV path and MOJO zip path, with optional parameters for output CSV path, genmodel JAR path, classpath, Java options, and verbosity. The function validates file paths, sets up Java execution with appropriate options, invokes the MOJO predictor, and returns the predictions as a list of dictionaries. If no output CSV path is specified, it defaults to 'prediction.csv' in the same directory as the MOJO zip.
1482	A decorator that marks functions as deprecated by printing a warning message with the file location and source code line where the deprecated function is called, along with the provided deprecation message.
1483	Wait until grid finishes computing by polling the job and cleaning up the future and job references.
1484	Returns a dictionary of hidden layer details for each model in the ensemble, obtained by extracting features from the specified layer of each model using the provided test data.
1485	Print a detailed summary of the explored models in a formatted table display.
1486	Print models sorted by metric, showing either grid search combinations or sorted metrics table.
1487	Get the hyperparameters of a model explored by grid search.

**Parameters:**
- `id` (str): The model id of the model with hyperparameters of interest.
- `display` (bool): Flag to indicate whether to display the hyperparameter names.

**Returns:**
- A list of the hyperparameters for the specified model.
1488	Returns a dictionary of model parameters derived from hyperparameters used to train a specific grid search model. Retrieves the model by ID, handles cross-validation cases, extracts actual parameter values, and optionally displays hyperparameter names.
1489	Retrieve an H2OGridSearch instance, optionally sorted by a specified metric in ascending or descending order. If no sorting parameters are provided, returns the original grid. The sorted grid displays appropriate metrics based on cross-validation, validation frame, or training data usage.
1490	Returns a dictionary of model keys to F1 values for specified data splits (train, validation, cross-validation) or training metrics by default.
1491	Return the importance of components associated with a PCA model. If the model has importance data, it returns the values, optionally as a pandas DataFrame if requested and pandas is available. If no importance data exists, it prints a warning message.
1492	Projects model archetypes back into the original feature space of training data.

**Parameters:**
- `test_data` (H2OFrame): Dataset used for model training
- `reverse_transform` (bool): Whether to reverse the training data transformation

**Returns:**
- H2OFrame: Archetypes projected into original feature space

**Raises:**
- ValueError: If test_data is None or empty
1493	Produces a scree plot showing variances of components. Supports both barplot and lines plot types using matplotlib. Requires matplotlib library. Plots components on x-axis and variances on y-axis with title 'Scree Plot'.
1494	Convert names with underscores into camelcase, handling leading/trailing underscores and capitalizing words after the first segment.
1495	Dedents the input text to remove common indentation and then adds the specified amount of indentation to every line. If the requested indentation level is 0, it only removes the common indentation. Otherwise, it adds the specified number of spaces to the beginning of each line in the dedented text.
1496	Extracts operation times for GLRM model building iterations from a Java log file, organizing results into a dictionary with individual operation times and total runtime.
1497	Main program that takes a Java log file as input, parses it, and extracts runtime information into a structured format while storing results in a JSON file.
1498	Close an existing connection by sending a DELETE request to the server and clearing session data. If the server is unresponsive, it uses a timeout of 1 second. Any exceptions during the process are caught and ignored. The method also resets the session ID and stage indicators to their default values, making the connection unusable afterwards. Though automatic cleanup mechanisms exist, this method is publicly available for explicit connection termination.
1499	Return the session id of the current connection, generating it via API request if necessary.
1500	Start logging all API requests to the specified destination file or handle. If no destination is provided, creates a temporary file for logging. Returns a handle to the open file if logging to a file.
1501	Prepares data for server transmission by converting it into key/value pairs, handling None values, lists, dictionaries, and other data types appropriately.
1502	Prepare a file for upload by creating a requests-compatible data structure. Raises H2OValueError if file doesn't exist. Returns None for invalid filenames.
1503	Logs the beginning of an API request with request details including endpoint, parameters, body data, JSON payload, and files.
1504	Log the end of an API transaction with response details and timing information.
1505	Log the message `msg` to the destination `self._logging_dest`, writing to a file if `self._logging_dest` is a file path or writing to a file handle if `self._logging_dest` is an open file object.
1506	Process HTTP response by handling file downloads, content-type detection, JSON parsing, and error status conversion to appropriate exceptions.
1507	Helper function to print connection status messages when in verbose mode.
1508	Retrieve information about an AutoML instance including project name, leader model, and leaderboard data.
1509	Download the POJO for the leader model in AutoML to the specified directory. If path is empty, output to screen. Optionally download the h2o-genmodel.jar file. Returns the name of the POJO file written.
1510	Downloads the leader model from AutoML in MOJO format.

**Parameters:**
- `path` (str): Path where MOJO file should be saved (default: ".")
- `get_genmodel_jar` (bool): If True, also downloads h2o-genmodel.jar (default: False)
- `genmodel_name` (str): Custom name for the genmodel jar file (default: "")

**Returns:**
- str: Name of the MOJO file that was written

**Notes:**
This method delegates to `ModelBase.download_mojo()` using the AutoML leader model as the source.
1511	Fit this object by computing the means and standard deviations used by the transform method.

:param X: An H2OFrame; may contain NAs and/or categoricals.
:param y: None (Ignored)
:param params: Ignored
:returns: This H2OScaler instance
1512	Scale an H2OFrame with the fitted means and standard deviations.
1513	Undoes the scale transformation by applying inverse scaling formula: X[i] = mean[i] + std[i] * X[i] to each column in the H2OFrame.
1514	Extracts and returns the portion of a string that comes after the '[0m' delimiter, removing any preceding characters. If the delimiter is not found, returns the original string. Used to clean Jenkins console output by removing UTF-8 encoding artifacts introduced by ASCII redirection.
1515	Find the slave machine where a Jenkins job was executed on by searching for a node name in the console output, extract the node name from the line, store it in the global dictionary, and remove the function from the processing list. Returns True to continue text mining.
1516	Find git hash and branch information from Jenkins console output line, store it in global dictionary, and remove the function from processing list. Returns True to continue text mining.
1517	Find if a Jenkins job has exceeded its timeout limit and was terminated. Returns False to stop text mining when timeout is detected, True to continue mining.
1518	Function to detect Jenkins build failures by checking if failure messages exist in console output, records the failure in global dictionary, removes itself from processing list, and returns False to stop further text mining.
1519	Finds the Jenkins build ID from a console line, stores it in the global dictionary, removes the function from temp_func_list, and updates the Jenkins URL. Returns True to continue text mining.
1520	Extracts Jenkins job information from a URL string, storing the job name in `g_failed_test_info_dict`, and the Jenkins URL and view name in `g_jenkins_url` and `g_view_name` respectively. Validates that the URL has sufficient path components and exits if the URL is malformed.
1521	The `grab_java_message()` function scans through Java output text to extract and record error messages that occur during unit test execution. It filters out messages that are listed in `g_ok_java_messages` and associates the remaining messages with the current test name. The function handles multi-line messages by tracking continuation states and categorizes messages based on their types (e.g., WARN, ERRR, FATAL). It updates global lists of Java messages and their types, linking them to the appropriate unit test. The function also manages test name transitions and ensures proper message accumulation and classification.
1522	Save log scraping results into designated log files and a pickle file, including failed and passed test information with build ID formatting.
1523	This function concatenates daily log files into a summary text file for user delivery at the end of log scraping. It appends content from failed and passed test output files to a global summary file using a temporary file handle. The function takes no parameters and returns nothing.
1524	Write content from a log file into a summary text file, including a header with the log file name.
1525	Writes Java messages to a log file, including message types and content, but only for messages not associated with unit tests. The function takes a key string and a list of lists containing Java message data, then writes formatted output to the specified text file.
1526	Loads Java messages to ignore from a pickle file into a global dictionary. If the pickle file doesn't exist, initializes a "general" key with an empty list.
1527	Normalize an enum constant string to canonical snake-case format by converting uppercase letters to lowercase and inserting underscores before uppercase letters that follow lowercase letters.
1528	Find synonyms for a given word using a word2vec model and return them sorted by similarity score in descending order.
1529	Wait until the job finishes by continuously querying the server status and displaying progress bar. Raises exceptions if job is cancelled or failed. Returns self.
1530	Convert munging operations on H2OFrame to a POJO (Plain Old Java Object) by generating Java code and optionally downloading the required h2o-genmodel.jar file. The method saves the POJO Java file to a specified path and returns None.
1531	Method `fit` performs munging operations on an H2OFrame according to specified steps. It takes an H2OFrame as input, applies the munging operations defined in `self.steps`, and returns the transformed H2OFrame. The method constructs a steps string representation, sends it to the H2O assembly API for processing, and retrieves the result frame using the returned frame name. The assembly identifier is stored in `self.id` for potential later use.
1532	This function calculates the percentile of a sorted list of values using various interpolation methods. It takes a sorted list N, a percentile value (0.0 to 1.0), an optional key function for computation, and an interpolation method. The function supports five interpolation approaches: 'floor', 'ceil', 'funky', 'linear', and 'mean'. It handles both integer and fractional positions in the sorted list, returning the appropriate percentile value based on the chosen interpolation method. The function also prints debug information showing surrounding values and the interpolation method used.
1533	Returns a dictionary of default parameters for the model, where keys are parameter names and values are their default values.
1534	Returns a dictionary of actual parameters for the model by mapping parameter names to their actual values, handling special cases for model_id, response_column, training_frame, and validation_frame parameters.
1535	Returns hidden layer details for deep learning model by creating a feature space from test data at specified layer index or layer name.
1536	Retrieves the model's score history and returns it as an H2OTwoDimTable or Pandas DataFrame. Prints a message if no score history is available for the model.
1537	Prints the internal details of a model, including model information, training metrics, validation metrics, cross-validation metrics, and variable importances. Handles cases where no model has been trained or the estimator has been removed.
1538	Returns variable importances for a model, either as a list or pandas DataFrame. For GLM models, computes standardized coefficients with relative, scaled, and percentage importance metrics. For other models, uses built-in variable importances. Returns None and prints warning if model has no variable importances.
1539	Return the residual degrees of freedom for the specified model metrics (training or validation set), or None if not present. Raises an error if cross-validation is requested. If neither train nor valid is specified, defaults to training set. If both train and valid are True, defaults to training set.
1540	Return the coefficients for non-standardized data as a dictionary mapping parameter names to their coefficients. Returns None if no coefficients are available. Note that coefficients are returned assuming standardize=True by default, unless the model was fit with standardize=False in which case they represent the directly fitted coefficients.
1541	Downloads the POJO (Plain Old Java Object) representation of this model to the specified directory. If path is empty, outputs to screen. Optionally downloads the h2o-genmodel.jar file as well. Returns the name of the POJO file that was written.
1542	Download the model in MOJO format.

:param path: the path where MOJO file should be saved.
:param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.
:param genmodel_name Custom name of genmodel jar
:returns: name of the MOJO file written.
1543	Save H2O model details in JSON format to disk.

Parameters:
- path (str): Path to save the model details at (hdfs, s3, local). If empty, uses current working directory.
- force (bool): If True, overwrite destination directory if it exists. If False, throw exception if directory exists.

Returns:
- str: Path of the saved model details

The method saves the model details as a JSON file named after the model ID with .json extension.
1544	Checks that y_actual and y_predicted have the same length, raises ValueError if they don't.
1545	Get a list of cross-validation models from the model output, returning H2OModel objects or None if not available.
1546	GBM model demo that showcases H2O's Gradient Boosting estimator. The demo initializes H2O, loads the prostate dataset, splits it into training and test sets, converts the response column to a factor for binary classification, builds a GBM model with specified parameters, displays the model, makes predictions on the test set, examines tree structure, and shows default performance metrics.
1547	Deep Learning model demo that demonstrates H2O's Deep Learning capabilities. The demo uploads the prostate dataset, splits it into training and test sets, converts the response column to a factor for binary classification, builds a Deep Learning model with Tanh activation and 10-10-10 hidden layers, trains the model for 10,000 epochs, and evaluates performance on the test set. It displays model details, predictions, and default performance metrics.
1548	GLM model demo that showcases H2O's Generalized Linear Estimator by uploading the prostate dataset, splitting it into training and test sets, building a binary classification GLM model, making predictions, and displaying performance metrics.
1549	Wait for a key press on the console and return the pressed key. Handles both Windows (using msvcrt) and Unix-like systems (using termios) platforms. Returns the pressed key character or None if no key was pressed.
1550	Convert the object to a pandas DataFrame if pandas is available, otherwise return the object itself. When pandas is available, it creates a DataFrame using the cell values and column headers, with max column width set to 70 characters.
1551	Print the contents of this table with optional header and truncated view for large tables.
1552	Start a new H2O server on the local machine with specified configuration options.
1553	Finds the location of an h2o.jar executable by checking a specified path or searching through default paths. Raises H2OStartupError if h2o.jar cannot be found in any searched location.
1554	Generator function that yields potential paths for an h2o.jar executable file, checking environment variable, source directory, backend bin folder, and various installation locations in order of preference.
1555	Retrieves hit ratio metrics for training, validation, and/or cross-validation data. Returns either a single hit ratio value (if one data type specified) or a dictionary mapping data types to their respective hit ratio tables (if multiple data types specified). Defaults to returning training data hit ratio when no parameters are True.
1556	Creates a CSV DictWriter object that handles unicode delimiters properly on Python 2 by converting them to strings.
1557	Convert URI to absolute filepath. Returns None if no valid path exists, otherwise returns the absolute file system path for the given URI. Handles both module files (with .py extension) and package directories (with __init__.py). For the package name itself, returns the path to __init__.py. For nested modules, constructs the path by replacing dots with directory separators and appending .py or __init__.py as appropriate.
1558	Convert directory path to URI format by replacing root path with package name and converting path separators to dots.
1559	Parse lines of text to extract public function and class names, returning them sorted in separate lists.
1560	Generates reStructuredText documentation for a Python module, including inheritance diagrams, class and function listings with their respective docstring documentation. Returns a string containing the auto-generated API documentation.
1561	Return module sequence discovered from ``self.package_name`` by walking through the root path and collecting package and module names that survive exclusion filters.
1562	Generate API reST files for discovered modules into specified output directory, creating directory if it doesn't exist and setting self.written_modules to list of written modules.
1563	Creates a reST API index file from written modules.

Parameters:
- outdir: Directory to write the generated index file to
- froot: Root filename without extension (defaults to 'gen')
- relative_to: Path to make filenames relative to (optional)

Writes an auto-generated reST index file containing links to all written modules, with paths adjusted relative to the specified root path if provided. Raises ValueError if no modules have been written.
1564	Convert this confusion matrix into a 2x2 plain list of values.
1565	Loads Java messages from a pickle file into a global dictionary structure, creating an empty list for "general" key if the file doesn't exist.
1566	Add new Java messages to ignore by reading from user text file and updating the global ignored messages dictionary.
1567	Updates the global `g_ok_java_messages` dictionary by either adding or removing Java ignored messages based on the specified action. If action is 1, adds new messages to existing keys or creates new keys. If action is 2, removes specified messages from existing keys. New keys can only be added, not removed.
1568	Extracts Java messages to be ignored from a text file and returns them as a dictionary with test names as keys and lists of Java message strings as values.
1569	Save the global ignored Java message dictionary to a pickle file if it has been modified.
1570	Writes Java ignored messages from g_ok_java_messages dictionary to a text file and prints them to console, sorted by key names.
1571	Parse command line arguments to set global variables for managing Java message files, including input/output file specifications and print options.
1572	Function `usage()` prints a help message showing all valid command-line flags and their descriptions, then exits the program. It displays options for input files, pickle files for loading/saving Java messages, and printing ignored Java messages. The function uses a global variable `g_script_name` to display the script name in the usage text.
1573	Function `locate_files` finds all Python files in a given directory and its subdirectories. It takes a root directory path as input, walks through all subfolders using `os.walk`, and collects files ending with ".py" extension into a list. The function returns the list of all found Python files with their full paths.

Example usage:
```python
python_files = locate_files("/path/to/directory")
# Returns list of all .py files in directory and subdirectories
```
1574	Searches a file for magic incantations in comments and returns the spell and any extra words, or None if no magic is found.
1575	This function processes all files found in the root directory by reading them, tokenizing their content, normalizing the tokens, and then converting them back to text. It verifies that the original text matches the normalized text through an assertion check, ensuring the tokenization and normalization process preserves the original content.
1576	Transforms an H2OFrame using a MOJO Pipeline and returns a new H2OFrame with the transformed data.
1577	Function `summarizeFailedRuns()` scans the local directory for files with specific start names and size requirements, loads JSON data from these files, and aggregates test results into a global summary dictionary by processing failed tests through the `addFailedTests()` function. Returns None.
1578	This function extracts and prints intermittent test failures from collected data, then saves the results to both a JSON file and a CSV file. It identifies tests that have failed above a specified threshold, formats the failure information including timestamps and test categories, and displays the intermittent test details on screen. The function returns None.
1579	Produces an ROC curve plot with AUC annotation using matplotlib, with optional server-side generation.
1580	Returns the confusion matrix for specified metric(s) and threshold(s). Takes optional parameters for metrics (defaulting to 'f1') and thresholds, and returns either a single ConfusionMatrix object or a list of ConfusionMatrix objects based on input. Validates inputs and computes confusion matrices using threshold-specific metrics from model results.
1581	Returns True if a deep water model can be built, or False if no backend is found. Checks the visibility status of the deepwater model builder and prints a message if it's experimental.
1582	Method: `trim_data_back_to(monthToKeep)`

Summary: Removes test data from both summary text files and dictionary files that occurred before a specified number of months. The method calculates the oldest timestamp allowed based on the input month threshold and then calls cleanup functions to remove outdated test information from both data storage locations.
1583	Return endpoints grouped by the class which handles them.
1584	Update or create a site object with the specified domain and name using the sites framework.
1585	Adds default_data to the provided data dictionary and dumps it to JSON format. If no data is provided, uses an empty dictionary.
1586	Comments on the most recent media posts of a specified user, with an optional limit on the number of comments. Returns False if the user is invalid or has no public media, otherwise returns the result of commenting on the media items.
1587	Returns login and password from secret.txt, handling account selection and management when multiple accounts exist.
1588	Likes the most recent medias from a specified user's feed, with optional filtering and limit controls.
1589	Likes the most recent medias associated with a given hashtag.
1590	Filter bot from real users by checking user ID against whitelist/blacklist, verifying user info, and applying bot detection rules.
1591	Reads a list from a file where each line represents an item. Returns the list of non-empty lines after stripping whitespace. If the file doesn't exist or an error occurs, returns an empty list.
1592	Schedule a message to be enqueued at a specific time by adding the scheduled time as an annotation to the message properties.
1593	Defers a message by modifying it to remain in the queue but be received specifically by its sequence number. Raises exceptions if the message is already settled, has expired locks, or if the settle operation fails.
1594	Downloads VPN site configurations for a VirtualWAN as a SAS URL. Returns an LROPoller for tracking the long-running operation.
1595	Function `guess_service_info_from_path` takes a spec path and extracts service information by:
1. Converting path to lowercase
2. Slicing path to start from "specification" 
3. Splitting path by "/"
4. Extracting resource provider name (second element) and checking if it's ARM (third element equals "resource-manager")
5. Returning dictionary with "rp_name" and "is_arm" keys

Example input: "specification/compute/resource-manager/readme.md"
Example output: {"rp_name": "compute", "is_arm": True}
1596	Updates a running PowerShell command with more data.
1597	Deletes the managed application definition with the specified ID and returns a long-running operation poller.
1598	Creates or updates a managed application definition with the specified ID and parameters, returning a poller object for tracking the long-running operation.
1599	Return the target URI for the request by constructing it from the protocol, host, port, and path.
1600	Creates a connection for the request using the specified protocol and optional proxy settings, including authentication if provided.
1601	Sends an HTTP request to a cloud service server and returns the response, handling redirects and errors appropriately.
1602	Executes script actions on the specified HDInsight cluster with optional persistence and polling support. Returns an AzureOperationPoller instance for tracking the long-running operation.
1603	Check the availability of a Front Door resource name with the specified type.
1604	Permanently deletes a soft-deleted Azure key vault by purging it. This operation removes the vault from the system completely and cannot be undone. The method returns an LROPoller object that can be used to track the long-running operation status. The purge operation requires the vault name and location as parameters, and supports custom headers and polling configuration. Returns None upon successful completion or a ClientRawResponse if raw=True is specified.
1605	Returns the URI for the authorization server if present, otherwise returns an empty string. Checks for 'authorization_uri' and 'authorization' keys in that order.
1606	Validates a request URI by checking that it's not empty, is an absolute URI with a valid HTTP or HTTPS scheme, and returns the host authority component. Raises ValueError for invalid URIs.
1607	Return a CLI profile class by loading Azure CLI credentials from the local configuration file.

This function:
- Imports required classes from azure-cli-core package (Profile, ACCOUNT, get_config_dir)
- Raises ImportError if azure-cli-core package is not available
- Loads CLI credentials from the default Azure config directory
- Returns a Profile instance initialized with the loaded ACCOUNT storage

The function is useful for accessing Azure CLI authentication information programmatically.
1608	Returns Azure CLI credentials and subscription ID from the current profile, with optional tenant ID.
1609	Gets predictions for a given utterance using LUIS, returning intents and entities. Supports various configuration options like timezone offset, verbose results, staging endpoint, spell checking, and custom headers. Returns either a LuisResult object or a raw response based on the raw parameter.
1610	Check Name Availability for global uniqueness in a specified location and returns whether the given name is available for the specified resource type.
1611	Opens an HTTP request with the specified method and URL using the WinHttpRequest object.

**Parameters:**
- method (str): HTTP request verb ('GET', 'POST', etc.)
- url (str): The URL to connect to

**Returns:**
- None (modifies the WinHttpRequest object in-place)

**Notes:**
- Uses VARIANT.create_bool_false() for the async flag
- Converts method and url strings to BSTR objects before passing to _WinHttpRequest._Open()
1612	Sets up the timeout for the request by converting seconds to milliseconds and configuring all timeout values using the WinHttpRequest object.
1613	Sets a request header with the specified name and value using the Windows HTTP request object.
1614	Gets all response headers from the WinHttpRequest object and returns them as a string.
1615	Sends the request body using WinHttpRequest. If no request is provided (GET/HEAD requests), sends VT_EMPTY. Otherwise, converts the request string to a SAFEArray and sends it.
1616	Gets the status of the response by calling the Windows HTTP request status API and returns it as an integer value.
1617	Gets the status text of a response by calling the WinHttpRequest _StatusText method, extracts the Unicode string value, frees the allocated string memory using _SysFreeString, and returns the status text string.
1618	Gets response body as a SAFEARRAY and converts it to string, returning empty string if conversion fails.
1619	Sets the client certificate for the request by converting the certificate to a BSTR and calling the underlying _SetClientCertificate method.
1620	Connects to host and sends HTTP request with specified method and URI, setting up SSL certificate if configured.
1621	Sends HTTP request headers by setting the specified name-value pair using the internal HTTP request object. Handles Unicode decoding for Python 2.x versions.
1622	Sends an HTTP request with optional request body. If no request body is provided, sends a basic request. Otherwise, sends the request with the specified body.
1623	Gets the HTTP response and creates a _Response object with status, status text, headers, length, and body.
1624	Returns a simplified, more readable version of an ID by extracting the name portion after the namespace prefix.
1625	Converts a Python name into a serializable name by applying specific transformation rules, including handling known serialization forms, converting 'x_ms_' prefixes to hyphens, replacing '_id' suffixes with 'ID', handling special prefixes like 'content_', 'last_modified', 'if_', and 'cache_control', and capitalizing words separated by underscores.
1626	Verifies whether a face belongs to a specific person by comparing a face ID with a person ID. Supports both regular and large person groups. Returns verification result or raw response based on parameters.
1627	Adds a job to the specified Batch account using the provided job parameters and options. Supports two approaches for job execution control: Job Manager task or direct task management via Task APIs. Includes optional timeout, client request ID, and other metadata via job_add_options. Returns None or raw response based on the raw parameter. Raises BatchErrorException on service errors.
1628	Returns a dictionary of properties extracted from an XML entry node, including etag, updated timestamp, author name, and optional ID/name fields based on the specified parameters.
1629	Returns the list of children at the deepest level of a node hierarchy by following a given path. Only returns direct children sharing a common parent, not cousins. Traverses the hierarchy step by step using the provided path components, which can be either string names or namespace tuples. Returns an empty list if the path cannot be fully traversed.
1630	Recursively searches from parent to child nodes, gathering all XML namespaces along the path. Returns True if child is found, False otherwise. Collects namespace declarations (xmlns and xmlns:*) from ancestor nodes and stores them in the provided namespaces dictionary.
1631	Converts an XML response string into a ServiceBusNamespace object by parsing relevant fields and applying optional conversion functions to the values.
1632	Converts XML response to service bus region object by parsing the XML string and extracting Code and FullName values from the RegionCodeDescription element.
1633	Converts XML response to service bus namespace availability by parsing the XML string and extracting the availability result boolean value.
1634	Converts XML response to Service Bus metrics objects by parsing XML content and mapping it to the specified object type, handling both metric properties and metric values with proper data type conversion.
1635	Replace the runbook draft content with the specified content. Returns an AzureOperationPoller object for tracking the long-running operation.
1636	Get domain name recommendations based on keywords, returning an iterator of NameIdentifier objects with optional custom headers and raw response support.
1637	Asynchronous operation to modify a knowledgebase with the specified ID using the provided update configuration. Returns an Operation object or ClientRawResponse if raw is true. Raises ErrorResponseException if the response status code is not 202.
1638	Gets a collection of group object IDs that the specified user is a member of, with an option to filter by security-enabled groups only. Returns an iterator-like object containing the group IDs.
1639	Builds a package from a given PR number by cloning the PR branch and executing the build script for each package found in the PR files. Optionally creates a comment on the PR with installation and download instructions. Returns the built package files in the specified output folder.
1640	Import data into Redis cache. Returns an AzureOperationPoller instance that handles the long-running operation. The method supports custom headers, raw response mode, and different polling strategies. The files parameter specifies the files to import, and optional format parameter can specify the file format. The operation returns None upon completion or ClientRawResponse<None> if raw=True is specified.
1641	Publishes a runbook draft in Azure Automation. Takes resource group name, automation account name, and runbook name as parameters. Returns an LROPoller object for tracking the long-running operation. Supports custom headers, raw response mode, and custom polling strategies. Raises ErrorResponseException on failure.
1642	Renew the message lock to maintain ownership and prevent reprocessing. Raises TypeError for session messages, MessageLockExpired if lock expired, SessionLockExpired if session lock expired, or MessageAlreadySettled if message already settled. Only available for non-sessionful messages.
1643	Replace alterations data by sending word alterations to the QnA Maker service.
1644	Adds a new version of a specified secret resource by creating a secret value with the given name and value. The method constructs and sends an HTTP PUT request to the Service Fabric cluster, using the provided secret resource name and secret value resource name to determine the endpoint. It handles request construction including URL formatting, query parameters, headers, and body content. The method supports custom headers, raw response returns, and operation configuration. It returns a SecretValueResourceDescription object on successful creation (status codes 200 or 201) or raises a FabricErrorException on failure, with status codes other than 200, 201, or 202 indicating an error condition. The secret value cannot be modified once created.
1645	Returns system properties for the specified storage account.
1646	Returns the primary and secondary access keys for the specified storage account.
1647	Regenerates the primary or secondary access key for a specified storage account by sending a POST request to the storage service API with the key type parameter.
1648	Creates a new storage account in Windows Azure with the specified parameters including service name, description, label, and storage account type, while validating required fields and ensuring either location or affinity group is specified.
1649	Updates the label, description, and geo-replication status of a storage account in Windows Azure. The method allows modifying storage account properties including description, label, and account type (Standard_LRS, Standard_ZRS, Standard_GRS, Standard_RAGRS). The geo_replication_enabled parameter is deprecated and replaced by account_type. Returns the result of the update operation.
1650	Deletes the specified storage account from Windows Azure by performing a delete operation on the storage service path, with validation to ensure the service name is not none. Returns an asynchronous operation result.
1651	Checks if a specified storage account name is available or already taken. Returns an AvailabilityResponse indicating the name's availability status.
1652	Retrieves system properties for a specified hosted service, including service name, type, affinity group or location, and optionally deployment information. Takes service name and an embed_detail flag as parameters, returns HostedService object with the requested properties.
1653	Creates a new hosted service in Windows Azure with the specified parameters including service name, label, description, location, affinity group, and extended properties. Validates that either location or affinity_group is specified but not both. Returns the result of performing a POST request with serialized hosted service data.
1654	Deletes a hosted service from Windows Azure. If complete=True, also deletes all OS/data disks and source blobs from storage. Returns the result of the delete operation.
1655	Creates a new deployment for a hosted service in either staging or production slot by uploading a service package and optionally starting it immediately.
1656	Deletes the specified deployment from a hosted service, with optional VHD deletion support.
1657	Swaps the virtual IP between staging and production deployment environments for a specified service. Takes the service name and deployment names as parameters, validates they are not None, and initiates the swap operation asynchronously. Returns the result of the async operation.
1658	Changes the configuration of a deployment by initiating a configuration update operation. Takes service name, deployment name, and base-64 encoded configuration as required parameters, plus optional parameters for treating warnings as errors, upgrade mode (Auto/Manual), and extended properties. Returns an asynchronous operation response.
1659	Updates the status of a deployment by sending a POST request to the deployment's status endpoint with the specified status value (Running or Suspended).
1660	Initiates an upgrade of a deployment in a hosted service with specified parameters including mode, package URL, configuration, and label. Supports both Manual and Auto upgrade modes, with options for forced rollback and role-specific upgrades. Returns an asynchronous operation response.
1661	Walks the specified upgrade domain during manual in-place upgrade or configuration change for a given service deployment.
1662	Requests a reboot of a specified role instance in a deployment by performing a POST request to the deployment's role instances endpoint with a reboot operation parameter.
1663	Deletes specified role instances from a deployment, reinstalling the operating system and initializing storage resources. Returns an async operation.
1664	Checks if a specified hosted service name is available or already taken by making a GET request to the Azure management API and returning an AvailabilityResponse object.
1665	Lists all service certificates associated with the specified hosted service by making a GET request to the certificates endpoint for the given service name.
1666	Returns the public data for the specified X.509 certificate associated with a hosted service using the provided service name, thumbprint algorithm, and thumbprint.
1667	Adds a certificate to a hosted service with the specified parameters.
1668	Deletes a service certificate from the certificate store of a hosted service using the specified service name, thumbprint algorithm, and thumbprint.
1669	Retrieves information about a management certificate with the specified thumbprint, which authenticates clients connecting to Windows Azure subscription resources.
1670	Adds a management certificate to the list of certificates for authenticating clients connecting to Windows Azure subscription resources. The certificate is specified by its public key, thumbprint, and raw data in base-64 encoded .cer format.
1671	Deletes a management certificate from the list of certificates associated with the subscription, using the specified thumbprint for identification.
1672	Returns the system properties associated with the specified affinity group by performing a GET request to the affinity group's endpoint.
1673	Creates a new affinity group for the specified subscription with the given name, label, location, and optional description.
1674	Deletes an affinity group with the specified name in the current subscription.
1675	List subscription operations with optional filters and time range parameters.
1676	Reserves an IPv4 address for the specified subscription with the given name, optional label, and required location. Returns an asynchronous operation result.
1677	Deletes a reserved IP address from the specified subscription.

**Parameters:**
- `name` (str): Required. Name of the reserved IP address.

**Returns:**
- Result of the delete operation as an async task.

**Raises:**
- `ValueError`: If the name parameter is None or empty.
1678	Associates an existing reserved IP address with a deployment in a hosted service. Takes the reserved IP name, service name, and deployment name as required parameters, with an optional virtual IP name for multi-VIP tenants. Returns an asynchronous operation result.
1679	Disassociates an existing reserved IP address from a specified deployment by sending a POST request with association XML data, validating all required parameters including name, service_name, and deployment_name, and optionally specifying a virtual IP name for multi-VIP tenants.
1680	Retrieves information about a specified reserved IP address by performing a GET request to the reserved IP endpoint, validating that the name parameter is not null.
1681	Retrieves a specified virtual machine role by service name, deployment name, and role name. Validates that all parameters are provided and returns the role information as a PersistentVMRole object.
1682	Creates a virtual machine deployment in Azure with the specified configuration, including system settings, network configuration, and optional extensions. Returns an async operation response.
1683	Adds a virtual machine to an existing deployment with specified configuration parameters.
1684	Updates the specified virtual machine with the given configuration parameters including OS disk, network settings, availability set, data disks, role size, and extensions. Returns an asynchronous operation handle.
1685	Deletes the specified virtual machine role from a deployment. If complete=True, also deletes OS/data disks and source blobs from storage. Returns an asynchronous operation response.
1686	Captures a virtual machine image from a role in a deployment and stores it in the image gallery, creating a customized virtual machine image that can be used for additional deployments. Validates all required parameters and performs a POST operation to capture the role with specified settings including post-capture action, target image name, and label.
1687	Starts the specified virtual machine role instance.

Parameters:
- service_name (str): The name of the service
- deployment_name (str): The name of the deployment  
- role_name (str): The name of the role

Returns:
- Response from the start operation

The method validates that all required parameters are provided, then performs a POST request to the role instance operations endpoint using the start role operation XML payload. The operation is performed asynchronously.
1688	Starts the specified virtual machines in a deployment.

**Parameters:**
- `service_name` (str): The name of the service
- `deployment_name` (str): The name of the deployment  
- `role_names` (iterable): The names of the roles to start

**Returns:**
- Async operation result for starting the roles

**Validation:**
- All parameters are validated to ensure they are not None

**Implementation:**
- Constructs the roles operations path using service and deployment names
- Serializes the role names into XML format for the start operation
- Performs a POST request to start the specified roles asynchronously
1689	Restarts the specified virtual machine role within a deployment. Takes service name, deployment name, and role name as parameters, validates they are not none, and performs a POST operation to restart the role using the role instance operations path with restart XML serialization. Returns an async operation response.
1690	Shuts down a specified virtual machine role with optional post-shutdown action. The method performs validation on all parameters and sends a POST request to the Azure management API to execute the shutdown operation. The post_shutdown_action parameter controls whether the VM is stopped (retaining resources/billing) or stopped deallocated (releasing resources/no billing). Returns an async operation response.
1691	Shutdown specified virtual machines in a deployment with optional post-shutdown action.
1692	Adds a DNS server definition to an existing deployment by validating all parameters and performing a POST request with DNS server XML data.
1693	Updates the IP address of a specified DNS server within a service deployment and returns an asynchronous operation result.
1694	Deletes a DNS server from a specified deployment within a service. Validates that all required parameters (service name, deployment name, and DNS server name) are provided, then performs an asynchronous delete operation using the DNS server's path.
1695	Lists the available versions of a resource extension that can be added to a Virtual Machine for the specified publisher and extension name.
1696	Replicates a VM image to multiple target regions for publishers. The operation replaces existing replications with the specified regions, taking parameters for vm_image_name, regions list, offer, sku, and version, and returns an asynchronous operation result.
1697	Unreplicates a VM image from all regions. This operation is only available to image publishers and requires registration with Microsoft Azure. Takes a VM image name as parameter and returns an async result.
1698	Shares a replicated OS image with specified permissions (public, msdn, or private) for a given virtual machine image name, requiring image publisher registration with Windows Azure.
1699	Creates a VM Image in the image repository associated with the specified subscription using the provided virtual hard disks configuration.
1700	Deletes a VM image from the image repository. If delete_vhd is True, also deletes the underlying VHD blob in Azure storage. Returns an async operation.
1701	Retrieves a list of VM Images from the image repository for the specified subscription, filtered by optional location, publisher, and category parameters.
1702	Updates a VM Image in the image repository associated with the specified subscription. Takes the name of the image to update and an instance of VMImage class with configuration details for the operating system disk, data disks, and optional metadata such as description, language, and URIs for icons and EULA. Returns an async operation response.
1703	Adds an OS image from blob storage to the image repository with validation and async processing.
1704	Updates an OS image in the repository with the specified parameters, validating all required fields and performing a PUT operation to the image path.
1705	Updates metadata elements for a specified OS image reference by sending a PUT request with the image data serialized to XML format.
1706	Deletes the specified OS image from the image repository. If delete_vhd is True, also deletes the underlying VHD blob in Azure storage. Returns the result of the delete operation.
1707	Retrieves the specified data disk from a virtual machine given service name, deployment name, role name, and LUN. Validates all parameters are not none and performs a GET request to retrieve the data virtual hard disk.
1708	Adds a data disk to a virtual machine with specified configuration parameters including caching, labels, and disk size.
1709	Updates the specified data disk attached to a virtual machine by modifying its properties such as host caching, media link, disk label, disk name, and logical size. The operation targets a specific disk using its service name, deployment name, role name, and LUN identifier, and returns an asynchronous response.
1710	Removes the specified data disk from a virtual machine. Optionally deletes the underlying VHD blob in Azure storage.
1711	Adds a disk to the user image repository. The disk can be an OS disk or a data disk. Parameters include label (disk description), media_link (blob location in Windows Azure blob store), name (disk identifier), and os (OS type). Returns the result of a POST operation with serialized disk data.
1712	Updates an existing disk in the image repository with the specified disk name and label, while ignoring deprecated parameters. Returns the result of the update operation.
1713	Deletes the specified disk from the image repository, with optional deletion of the underlying VHD blob in Azure storage.
1714	Summarizes policy states for resources under a specified management group, with optional query parameters for filtering and time ranges. Returns summary results or raw response based on parameters.
1715	Builds a receiver handler for the AMQP connection with specified settings and opens it, applying temporary patch for uAMQP compatibility.
1716	Receive a batch of messages at once, prioritizing quick return over meeting a specified batch size. The actual number of messages returned depends on the prefetch size and incoming stream rate. Returns an empty list if no messages arrive within the specified timeout period.
1717	Renew the session lock to maintain ownership of the session for continued message processing. This operation must be performed periodically to prevent the lock from expiring, which would close the connection. The method sends a management request to renew the session lock and updates the internal `locked_until` timestamp with the new expiration time. Can be used as a background task when registered with `AutoLockRenew`.
1718	Creates or updates a virtual machine scale set with the specified parameters, returning a long-running operation poller that yields either a VirtualMachineScaleSet object or a raw response depending on the raw parameter setting.
1719	Converts the SinglePlacementGroup property to false for an existing virtual machine scale set, allowing it to use multiple placement groups instead of a single one. This operation updates the scale set's configuration to support larger deployments across multiple placement groups. The method accepts optional parameters to specify which placement group should be used for future VM instances. It returns None or a raw response based on the raw parameter, and raises CloudError in case of failures.
1720	Screen text content for profanity and match against custom and shared blacklists. Supports multiple languages, autocorrection, PII detection, and classification.
1721	Creates a new key in Azure Key Vault with specified parameters, storing it and returning key parameters and attributes. If the key already exists, a new version is created. Requires keys/create permission. Supports various key types and attributes like size, operations, tags, and curve. Returns a KeyBundle or raw response based on the raw parameter.
1722	Imports an externally created key into Azure Key Vault, storing it and returning the key parameters and attributes. Requires keys/import permission. Supports both HSM and software keys with optional attributes and tags.
1723	Updates specified attributes of a stored key in Azure Key Vault. This operation modifies key properties such as operations, attributes, and tags, but cannot change the cryptographic material itself. Requires keys/update permission. The key must already exist in the vault. Returns the updated KeyBundle or ClientRawResponse if raw=true.
1724	Sets a secret in a specified key vault. If the named secret already exists, Azure Key Vault creates a new version of that secret. This operation requires the secrets/set permission.
1725	Sets the specified certificate issuer in the key vault with the given parameters including provider, credentials, organization details, and attributes. Requires certificates/setissuers permission. Returns an IssuerBundle or ClientRawResponse depending on the raw parameter.
1726	Create a Service Bus client from a connection string by parsing the connection string components and initializing the client with the appropriate parameters.
1727	Get an async client for a subscription entity.

:param topic_name: The name of the topic.
:type topic_name: str
:param subscription_name: The name of the subscription.
:type subscription_name: str
:rtype: ~azure.servicebus.aio.async_client.SubscriptionClient
:raises: ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found.
:raises: ~azure.servicebus.common.errors.ServiceBusResourceNotFound if the subscription is not found.
1728	Get an async client for all subscription entities in the topic.

**Parameters:**
- `topic_name` (str): The topic to list subscriptions for.

**Returns:**
- list[~azure.servicebus.aio.async_client.SubscriptionClient]: List of subscription clients.

**Raises:**
- ~azure.servicebus.common.errors.ServiceBusConnectionError: If the namespace is not found.
- ~azure.servicebus.common.errors.ServiceBusResourceNotFound: If the topic is not found.
1729	Send one or more messages to the current entity using a single-use connection. Opens a connection, sends the messages, and closes the connection. If the entity requires sessions, a session ID must be provided either in the call or on each message. Returns a list of send results, where each result is a tuple indicating success/failure and any error. Supports both single messages and iterables of messages.
1730	Get a Sender for the Service Bus endpoint.

A Sender represents a single open connection within which multiple send operations can be made.

:param message_timeout: The period in seconds during which messages sent with
 this Sender must be sent. If the send is not completed in this time it will fail.
:type message_timeout: int
:param session: An optional session ID. If supplied this session ID will be
 applied to every outgoing message sent with this Sender.
 If an individual message already has a session ID, that will be
 used instead. If no session ID is supplied here, nor set on an outgoing
 message, a ValueError will be raised if the entity is sessionful.
:type session: str or ~uuid.Guid
:returns: A Sender instance with an unopened connection.
:rtype: ~azure.servicebus.aio.async_send_handler.Sender
1731	Get a Receiver for the Service Bus endpoint. A Receiver represents a single open connection with which multiple receive operations can be made. The method validates session requirements, prefetch limits, and returns either a SessionReceiver or regular Receiver based on whether a session is specified. The receiver can be configured with prefetch settings, settle mode, and idle timeout.
1732	Get a Receiver for the deadletter endpoint of the entity, supporting both standard and transfer deadletter queues with configurable prefetch, settle mode, and idle timeout settings.
1733	Extracts request ID from response headers and returns an AsynchronousOperationResult object with the request ID, or None if response is None.
1734	Performs a GET request to the specified path with optional version header and returns the response.
1735	Performs a PUT request to the specified path with the given body and returns the response, optionally using a custom x-ms-version header.
1736	Waits for an asynchronous operation to reach a specified status. Calls get_operation_status in a loop until the desired status is achieved or timeout occurs. Supports callbacks for progress, success, and failure notifications. Returns the operation result upon completion or timeout.
1737	Returns the status of a specified asynchronous operation using the provided request ID, allowing you to determine if the operation succeeded, failed, or is still in progress.
1738	Add additional headers for management requests including Content-Length for write operations, x-ms-version, and Content-Type for non-GET/HEAD requests.
1739	Function `travis_build_package()` prepares a package for deployment on Travis CI by:

1. Checking if `TRAVIS_TAG` environment variable exists
2. Parsing the tag to extract package name and version
3. Validating that the version follows PEP440 standards
4. Ensuring the package isn't in the omitted release list
5. Creating the package in the dist directory
6. Verifying the created package matches the expected version
7. Printing the package location and upload server information

Returns exit status string or None, prints output to stdout for Travis CI integration.
1740	**Summary:**

The `get_certificates` method retrieves a list of certificates from a specified Azure Key Vault. It supports optional parameters such as `maxresults` to limit the number of returned certificates, `include_pending` to include partially provisioned certificates, and custom headers. The method returns an iterator-like object of `CertificateItem` objects, allowing pagination through the results. It requires the `certificates/list` permission to execute successfully. The method handles both raw and deserialized responses based on the `raw` parameter.
1741	Get list of available service bus regions by performing a GET request to the service bus regions endpoint and converting the XML response to region objects using the service bus management XML serializer.
1742	List the service bus namespaces defined on the account.
1743	Get details about a specific service bus namespace by performing a GET request and converting the XML response to a namespace object.
1744	Create a new service bus namespace with the specified name and region. Validates that the name is not None, then performs a PUT request to create the namespace using the provided region information.
1745	Delete a service bus namespace with the specified name.
1746	Checks if a specified service bus namespace is available or already taken. Returns availability status information.
1747	Retrieves the topics in the service namespace by performing a GET request to the list topics endpoint and converting the XML response to Azure object feeds.
1748	Retrieves the notification hubs in the service namespace by performing a GET request to the notification hubs path and converting the XML response to Azure object feeds.
1749	Retrieves the relays in the service namespace by performing a GET request to the relays list path and converting the XML response to Azure RelayDescription objects.
1750	This operation retrieves rollup data for Service Bus queue metrics, including telemetry aggregation time granularity and retention settings for each time granularity.
1751	This operation retrieves rollup data for Service Bus metrics from a specified topic within a namespace. The rollup data contains time granularity settings for telemetry aggregation and retention policies for each time granularity level. The method takes three parameters: the service bus namespace name, the topic name, and the metric name, then returns structured metric rollup information using XML serialization.
1752	This operation retrieves rollup data for Service Bus metrics from a notification hub, including telemetry aggregation time granularity and retention settings for each time granularity.

**Parameters:**
- `name` (string): Name of the service bus namespace
- `hub_name` (string): Name of the service bus notification hub in the namespace
- `metric` (string): Name of a supported metric

**Returns:**
- MetricRollups object containing the rollup data and metadata

**Side effects:**
- Makes HTTP GET request to retrieve metrics data
- Converts XML response to Python objects using serialization
- Uses internal helper methods for path construction and XML parsing
1753	This operation retrieves rollup data for Service Bus metrics relay, including telemetry aggregation time granularity and retention settings for each time granularity. It takes the service bus namespace name, relay name, and metric name as parameters, performs a GET request to fetch the data, and converts the XML response into MetricRollups objects.
1754	Creates a virtual environment in the specified directory with the given configuration options and returns the builder context.
1755	Creates a temporary virtual environment, installs specified packages, and yields the environment. Takes an iterable of pip version specifications, creates a venv with pip installed, upgrades pip, installs the specified packages, and returns the environment for use.
1756	Creates a new Azure SQL Database server with the specified administrator credentials and location, then returns the server creation response.
1757	Reset the administrator password for a specified server by performing a POST request with the new password XML data.
1758	Gets quotas for an Azure SQL Database Server by performing a GET request to the quotas endpoint and parsing the response into ServerQuota objects.
1759	Gets event logs for an Azure SQL Database Server with specified parameters including server name, start date, interval size, and event types.
1760	Creates an Azure SQL Database server firewall rule with the specified parameters.
1761	Update a firewall rule for an Azure SQL Database server with the specified IP address range.
1762	Deletes an Azure SQL Database server firewall rule with the specified name from the given server.
1763	Retrieves the set of firewall rules for an Azure SQL Database Server by performing a GET request to the firewall rules endpoint and parsing the response into FirewallRule objects.
1764	Gets the service level objectives for an Azure SQL Database server by performing a GET request to the service objectives endpoint and parsing the response into ServiceObjective objects.
1765	Creates a new Azure SQL Database with the specified parameters including server name, database name, and service objective ID, with optional parameters for edition, collation, and maximum size.
1766	Updates existing database details on an Azure SQL Database server with optional changes to database name, service level, edition, or size.
1767	Deletes an Azure SQL Database from the specified server.
1768	List the SQL databases defined on the specified server name by performing a GET request to the list databases endpoint and parsing the response into Database objects.
1769	Gets all legal agreements that user needs to accept before purchasing a domain. Returns an iterator of TldLegalAgreement objects.
1770	Close the handler connection asynchronously. If already closed, do nothing. Optionally record an error exception. Not thread-safe. Called automatically when used in a context manager.
1771	Close the receiver connection if it's open, setting internal flags and calling the parent close method. Does nothing if already closed. Not thread-safe. Recommended to use with context manager rather than calling directly.
1772	Get the session state.

Returns None if no state has been set.

:rtype: str

Example:
    .. literalinclude:: ../examples/async_examples/test_examples_async.py
        :start-after: [START set_session_state]
        :end-before: [END set_session_state]
        :language: python
        :dedent: 4
        :caption: Getting and setting the state of a session.
1773	Set the session state by encoding the state value if it's a string and sending a management request with the session ID and session state.
1774	Receive deferred messages by sequence numbers from the current session using specified settle mode. Validates input sequence numbers, performs management request response operation, and returns list of DeferredMessage objects with receiver reference set. Raises ValueError if no sequence numbers provided.
1775	Merges two reservations into a new reservation, given a reservation order ID and source reservation IDs. Supports custom headers, raw response return, and polling configuration. Returns an LROPoller object for tracking the long-running operation.
1776	Validates that the challenge is a Bearer challenge and extracts the key=value pairs from it. Raises ValueError if challenge is empty or not a Bearer challenge. Returns the challenge data after removing the 'Bearer ' prefix.
1777	Purges data in a Log Analytics workspace from a specified table based on user-defined filters. Returns an LROPoller object for tracking the long-running operation.
1778	Handle connection and service errors by parsing error conditions to determine retry actions. Returns appropriate ErrorAction based on error type - with specific handling for server busy, timeout, operation cancelled, and container close errors, plus no-retry errors and default retry behavior.
1779	Creates a new queue with the specified name. Returns True if successful, False if the queue already exists and fail_on_exist is False. Throws an exception if the queue exists and fail_on_exist is True. Queue resource manifest is immutable once created.
1780	Deletes an existing queue and all its associated state including messages. Returns True if successful, False if the queue doesn't exist and fail_not_exist is False. Throws an exception if the queue doesn't exist and fail_not_exist is True.
1781	Retrieves an existing queue by name from the service bus.

Parameters:
- queue_name (str): Name of the queue to retrieve

Returns:
- Queue object: The retrieved queue information

The method validates the queue name is not null, constructs an HTTP GET request to the service bus endpoint with the queue name in the path, adds the necessary headers, performs the request, and converts the response to a queue object.
1782	Creates a new topic with the specified name. Returns True if successful, False if the topic already exists and fail_on_exist is False. Throws an exception if the topic exists and fail_on_exist is True. The topic resource manifest becomes immutable after creation.
1783	Retrieves the description for the specified topic by sending an HTTP GET request to the service bus endpoint and converting the response to a topic object.
1784	Creates a new rule for a topic subscription with immutable resource manifest. Returns True on success, False if rule exists and fail_on_exist is False, raises exception if rule exists and fail_on_exist is True.
1785	Retrieves the description for a specified rule from a service bus topic subscription. Validates that topic name, subscription name, and rule name are not None, constructs an HTTP GET request to the service bus API with the provided parameters, performs the request, and converts the response to a rule object. The method builds the request path using the format: /topic_name/subscriptions/subscription_name/rules/rule_name.
1786	Retrieves the rules that exist under the specified subscription by making a GET request to the service bus endpoint and converting the response to rule objects.
1787	Creates a new subscription for a topic. The subscription resource manifest is immutable once created. Returns True if successful, False if subscription already exists and fail_on_exist is False. Throws exception if subscription exists and fail_on_exist is True.
1788	Gets an existing subscription for a given topic name and subscription name by making a GET request to the service bus endpoint and converting the response to a subscription object.
1789	Retrieves the subscriptions in the specified topic by sending a GET request to the service bus endpoint and converting the response to subscription objects.
1790	Sends a message to a specified topic by enqueuing it with validation checks and HTTP request handling.
1791	Unlock a message for processing by other receivers on a given subscription by deleting the lock object. Requires the topic name, subscription name, sequence number, and lock token as parameters.
1792	Sends a batch of messages to a specified queue, validating inputs and handling HTTP request formatting, including JSON body serialization and service bus header updates.
1793	Unlocks a message in a queue for processing by other receivers by deleting the lock object using the specified queue name, sequence number, and lock token.
1794	Receive a message from a queue for processing, with options to peek-lock or read-delete the message based on the peek_lock parameter.
1795	Receive a message from a subscription for processing, with options for locking or deleting the message.
1796	Creates a new Event Hub with the specified name and properties. Returns True if successful, False if it already exists and fail_on_exist is False. Supports optional Event Hub properties like message retention, status, metadata, and partition count. Handles existing hub scenarios based on the fail_on_exist parameter.
1797	Updates an Event Hub with the specified name and properties, returning the updated Event Hub object.
1798	Retrieves an existing event hub by name, validates the hub name is not None, constructs an HTTP GET request with the appropriate headers and URI, performs the request, and converts the response to an event hub object.
1799	Sends a message event to an Event Hub with optional device ID and broker properties.
1800	Updates Service Bus request headers by adding Content-Length for write operations, setting Content-Type for non-GET/HEAD requests, and adding authorization header. Returns the updated headers.
1801	Returns a signed authorization string with token for the given request and HTTP client.
1802	Check if a token is expired by comparing its expiration time with current time, allowing a 30-second grace period.
1803	Returns an authentication token for Service Bus requests by either using a cached token or obtaining a new one from the access control server. The token is cached based on host, path, issuer, and account key to avoid repeated requests.
1804	Method `_update_request_uri_query` processes the request URI to extract query parameters from the path and move them to the request's query object. It handles existing query parameters by appending URI parameters after them. The method also URL-encodes the path and query parameters, then reconstructs the request path with encoded query string parameters. Returns the updated request path and query parameters.
1805	Reset the service principal profile of a managed cluster by updating its client ID and optional secret password. This is a long-running operation that returns a poller object for tracking the operation status. The method accepts parameters for the resource group name, managed cluster name, client ID, and optional secret, along with custom headers and polling configuration. The operation can return either a raw response or a deserialized response based on the 'raw' parameter.
1806	Deletes a message from either a queue or topic subscription using its lock token and sequence number, raising an error if the message wasn't peek-locked.
1807	Unlocks a message by releasing its lock on either a queue or topic subscription using the service bus service. Raises an error if the message is not peek-locked.
1808	Renews the lock on a Service Bus message by calling the appropriate renew lock method based on whether the message is from a queue or subscription. If the message is from a queue, it calls `renew_lock_queue_message` with the queue name and message properties. If the message is from a subscription, it calls `renew_lock_subscription_message` with the topic name, subscription name, and message properties. Raises an error if the message is not peek-locked.
1809	Adds additional headers to a request including custom properties, content-type, and broker properties, then returns the updated headers.
1810	Returns the current message formatted as a batch body dictionary with Body, UserProperties, and BrokerProperties sections for JSON serialization.
1811	Gets the health of a Service Fabric cluster with optional filtering for nodes, applications, and events based on health state, and options to exclude health statistics or include system application health statistics.
1812	Gets the health of a Service Fabric cluster using the specified policy, with filters for nodes, applications, and events health states, and optional health statistics inclusion.
1813	Unprovisions (unregisters) a Service Fabric application type from the cluster. This operation removes the application type definition, preventing new instances from being created for that type. It can only be performed if all application instances of the type have been deleted. The operation supports asynchronous execution and includes timeout and custom header options. Returns None or a raw response object depending on the raw parameter. Raises FabricErrorException on failure.
1814	Gets a list of repair tasks matching the specified filters including task ID, state, and executor filters. Supports API version 6.0 and returns RepairTask objects or raw response based on parameters.
1815	Submits a batch of property operations to Service Fabric. Either all operations are committed or none are, depending on the success of the batch. The method takes a name identifier, optional timeout, list of operations, and other configuration parameters. Returns either a successful or failed property batch info based on the operation result.
1816	Simple error handler for Azure that constructs a detailed error message including the HTTP error details and response body, then raises an AzureHttpError with the combined information.
1817	Starts capturing network packets for a web app by initiating a long-running operation that traces network traffic for a specified duration and stores the capture in a blob storage location identified by a SAS URL. Returns a poller object to track the operation's progress and retrieve the network trace results.
1818	Get the difference in configuration settings between two web app slots.
1819	Swaps two deployment slots of an app, using the specified source and target slot names. Optionally preserves Virtual Network during the swap operation. Returns an AzureOperationPoller object for tracking the long-running operation.
1820	Execute an OData query for events in Application Insights with specified filters and parameters.
1821	Add a face to a large face list from an image stream, returning a persistedFaceId. Supports optional user data, target face rectangle specification, custom headers, and raw response options. Raises APIErrorException on failure.
1822	Resets the authentication attempt flag when a redirect occurs.
1823	Creates a migration configuration and starts the migration process from a Standard namespace to a Premium namespace, returning a long-running operation poller for tracking the migration status.
1824	Publishes a batch of events to an Azure Event Grid topic.

:param topic_hostname: The host name of the topic, e.g. topic1.westus2-1.eventgrid.azure.net
:type topic_hostname: str
:param events: An array of events to be published to Event Grid.
:type events: list[~azure.eventgrid.models.EventGridEvent]
:param dict custom_headers: headers that will be added to the request
:param bool raw: returns the direct response alongside the deserialized response
:param operation_config: Operation configuration overrides.
:return: None or ClientRawResponse if raw=true
:rtype: None or ~msrest.pipeline.ClientRawResponse
:raises: HttpOperationError
1825	Moves resources from one resource group to another resource group. The source and target resource groups may be in different subscriptions. Both groups are locked during the move operation. Returns an AzureOperationPoller object.
1826	Defines a new default profile by setting the profile attribute to a valid ProfileDefinition or KnownProfiles instance. Raises ValueError if the provided profile is not of the correct type.
1827	Queries policy tracked resources under a specified management group, returning an iterator of PolicyTrackedResource objects. Supports optional query parameters like top and filter, and can return raw responses. Raises QueryFailureException on query failures.
1828	Creates a Service Bus queue with the specified configuration parameters, including lock duration, size limits, duplicate detection, session requirements, and message expiration settings. Returns the created queue entity or raises exceptions for connection errors or existing queue conflicts.
1829	Delete a queue entity.

:param queue_name: The name of the queue to delete.
:type queue_name: str
:param fail_not_exist: Whether to raise an exception if the named queue is not found. If set to True, a ServiceBusResourceNotFound will be raised. Default value is False.
:type fail_not_exist: bool
:raises: ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found.
:raises: ~azure.servicebus.common.errors.ServiceBusResourceNotFound if the queue is not found and `fail_not_exist` is set to True.
1830	Create a topic entity with the specified properties.

**Parameters:**
- `topic_name` (str): The name of the new topic
- `default_message_time_to_live` (timedelta, optional): The default time-to-live for messages
- `max_size_in_megabytes` (int, optional): The maximum size of the topic in megabytes
- `requires_duplicate_detection` (bool, optional): Whether duplicate detection is required
- `duplicate_detection_history_time_window` (timedelta, optional): The time window for duplicate detection
- `enable_batched_operations` (bool, optional): Whether batched operations are enabled

**Returns:**
- Topic entity created in the Service Bus namespace

**Raises:**
- `ServiceBusConnectionError`: If the namespace is not found
- `AzureConflictHttpError`: If a topic with the same name already exists
1831	Delete a topic entity.

:param topic_name: The name of the topic to delete.
:type topic_name: str
:param fail_not_exist: Whether to raise an exception if the named topic is not found. If set to True, a ServiceBusResourceNotFound will be raised. Default value is False.
:type fail_not_exist: bool
:raises: ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found.
:raises: ~azure.servicebus.common.errors.ServiceBusResourceNotFound if the topic is not found and `fail_not_exist` is set to True.
1832	Creates a subscription entity under a specified topic with various configuration options including lock duration, session requirements, message time-to-live, dead lettering settings, and batched operations support. Returns the created subscription object or raises connection errors if namespace is not found or conflict errors if subscription already exists.
1833	Create a Client from a Service Bus connection string by parsing the connection string to extract address, policy, key, and entity information, then constructing the full URI and returning a new client instance with the extracted credentials and properties.
1834	Method `get_properties` retrieves and updates the properties of an entity by fetching the entity data and converting it to a dictionary. It also handles session requirements and raises specific exceptions for resource not found, connection errors, and HTTP authentication issues. Returns the entity properties as a dictionary.
1835	Whether the receivers lock on a particular session has expired. Returns True if locked_until is set and less than or equal to current time, False otherwise.
1836	Creates a session for a specified node with optional authentication and retention settings, returning a long-running operation poller for the session resource.
1837	Creates an Azure subscription with the specified billing account and invoice section, using the provided creation parameters. Returns a long-running operation poller that eventually returns the subscription creation result.
1838	Exports API request rate logs by interval for throttling activity analysis within a specified time window and location.
1839	Scans output for exceptions and collects results from a queue of attempted add_collection operations.

**Parameters:**
- results_queue: Queue containing results of attempted add_collection's

**Returns:**
- List of TaskAddResults

**Side effects:**
- Consumes all items from results_queue by popping them
- Modifies results_queue by removing all its items
1840	Adds a chunk of tasks to the job, handling retries for server errors and request size limits. Splits large chunks in half if the request body is too large, and retries tasks that fail due to server errors. Tasks that fail due to client errors (unless already existing) are recorded as failures, while successful tasks are added to the results queue.
1841	Main worker method that processes tasks from a collection queue. Pops chunks of tasks (up to maximum allowed per request) from the pending tasks queue and submits them in bulk for processing. Uses a lock to ensure thread-safe access to the shared task collection. Continues processing until either all tasks are added or an error occurs. The processed tasks are then added to the provided results queue.
1842	Builds the actual configuration for Jinja2 based on SDK config, managing classifier status, namespace packages, ARM support, and pre-computing Jinja variables for template usage.
1843	Resets the user password on an environment. This operation can take a while to complete. Returns an AzureOperationPoller instance that returns None or ClientRawResponse<None> if raw==True.
1844	Starts an environment by starting all resources inside the environment. This operation can take a while to complete. Returns an AzureOperationPoller instance.
1845	Creates a message object from a Service Bus response by parsing headers and body content, handling various property types and broker properties.
1846	Converts an XML etree element to a rule object by parsing the rule description, including filter and action expressions, and extracting entry properties.
1847	Converts an XML etree element to a Queue object by parsing the queue description elements and setting the corresponding attributes on the Queue instance. Raises AzureServiceBusResourceNotFound if the queue element is invalid. Extracts additional properties from the entry element and sets them on the queue object.
1848	Converts an XML entry element to a Topic object by parsing the TopicDescription element and its properties, then sets additional entry properties on the topic. Raises AzureServiceBusResourceNotFound if the topic is invalid.
1849	Converts an XML entry element to a Subscription object by parsing subscription description elements and properties from the XML structure.
1850	Creates a new certificate inside the specified Batch account with the given parameters, supporting conditional requests via ETag headers and returning an AzureOperationPoller for long-running operations.
1851	Deletes the specified certificate from a Batch account. Returns an AzureOperationPoller instance that handles the asynchronous deletion operation, which can return None upon completion or a ClientRawResponse if raw=True is specified. The method requires the resource group name, Batch account name, and certificate identifier (formatted as algorithm-thumbprint) to perform the deletion. It supports custom headers and operation configuration options, and raises CloudError in case of failures.
1852	Return a SDK client initialized with current CLI credentials, CLI default subscription and CLI default cloud. Parameters provided in kwargs will override CLI parameters and be passed directly to the client.
1853	Return a SDK client initialized with a JSON auth dict, handling credential acquisition and parameter setup automatically while allowing override of parameters via kwargs.
1854	Return a SDK client initialized with authentication file. The auth file can be specified directly or through the AZURE_AUTH_LOCATION environment variable. The method reads the JSON authentication file and uses its contents to initialize the client with credentials, subscription_id, and base_url. Additional parameters provided in kwargs will override the default values. Raises KeyError if no auth path is provided, FileNotFoundError if the file doesn't exist, json.JSONDecodeError if the file isn't valid JSON, and UnicodeDecodeError if the file isn't UTF-8 compliant.
1855	Parses an XML response into a structured object containing enumerated results. Takes an XML response, parses it using ElementTree, extracts items of a specified type from the response, and populates a return object with the parsed data. Returns an object of the specified return_type with the items list populated and other data members filled from the XML.
1856	Extracts properties from an XML element tree, including etag, updated timestamp, author name, and optional ID/name fields based on specified parameters.
1857	Delete the specified certificate associated with the Provisioning Service.
1858	Get a client for a queue entity.

:param queue_name: The name of the queue.
:type queue_name: str
:rtype: ~azure.servicebus.servicebus_client.QueueClient
:raises: ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found.
:raises: ~azure.servicebus.common.errors.ServiceBusResourceNotFound if the queue is not found.
1859	Get clients for all queue entities in the namespace.

Returns:
    list[~azure.servicebus.servicebus_client.QueueClient]

Raises:
    ~azure.servicebus.common.errors.ServiceBusConnectionError: If the namespace is not found.
1860	Get a client for a topic entity.

:param topic_name: The name of the topic.
:type topic_name: str
:rtype: ~azure.servicebus.servicebus_client.TopicClient
:raises: ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found.
:raises: ~azure.servicebus.common.errors.ServiceBusResourceNotFound if the topic is not found.
1861	Get a client for all topic entities in the namespace.

**Returns:** list[~azure.servicebus.servicebus_client.TopicClient]

**Raises:** ~azure.servicebus.common.errors.ServiceBusConnectionError if the namespace is not found

**Example:**
```python
topic_clients = client.list_topics()
```
This method retrieves all topics from the Service Bus namespace and returns a list of TopicClient objects for each topic. It handles connection errors by raising a ServiceBusConnectionError when the namespace cannot be found.
1862	Receive messages by sequence number that have been previously deferred from a Service Bus entity. Validates that all sequence numbers belong to the same partition, checks for session requirements, and supports both PeekLock and ReceiveAndDelete settle modes. Returns a list of Message objects corresponding to the deferred messages.
1863	Settle deferred messages with specified settlement action. Validates settlement type and message list, then sends management request to update message disposition status. Raises ValueError for invalid settlement types, empty message lists, or sessionful messages outside locked sessions. Supports 'completed', 'suspended', and 'abandoned' settlement options.
1864	Get site details for a specific website within a webspace by performing a GET request to the sites details endpoint and returning a Site object.
1865	Creates a website with the specified parameters including webspace name, website name, geographical region, and host names. Supports different plans (VirtualDedicatedPlan), compute modes (Shared/Dedicated), and site modes (Limited/Basic), with required parameters for Standard mode such as server farm name. Returns a Site object.
1866	Delete a website with optional parameters to also delete the empty server farm and metrics.
1867	Update a website's state in Azure, accepting 'Running' or 'Stopped' as valid states.
1868	Restarts a website by sending a POST request to the restart endpoint for the specified webspace and website name. Returns an asynchronous operation result.
1869	Get historical usage metrics for a website in a webspace with optional filtering by metrics, time range, and time grain.
1870	Get metric definitions for a website by performing a GET request to the metric definitions endpoint, returning a MetricDefinitions object containing available metrics for the specified webspace and website.
1871	Get a website's publish profile as an XML string by retrieving it from the specified webspace.
1872	Get a website's publish profile as a PublishData object by performing a GET request to the publish XML endpoint for the specified webspace and website.
1873	Updates the policies (quarantine and trust) for a specified container registry in a resource group. Returns an LROPoller object for tracking the long-running operation result.
1874	Creates a new cloud service with the specified parameters, grouping job collections together in a given region. Validates all inputs and returns an asynchronous operation result.
1875	Checks if a new job collection with the specified name can be created in a cloud service. Returns a Boolean indicating availability.
1876	Gets the details of a job collection by performing a GET request to the specified path, validating that both cloud_service_id and job_collection_id are not None. Returns a Resource object containing the job collection details.
1877	Completes a restore operation on a managed database by initializing the restore process and returning a long-running operation poller. The method takes parameters for location, operation ID, and last backup name, and supports custom headers, raw response handling, and custom polling strategies. It returns an AzureOperationPoller instance that handles the asynchronous restoration process.
1878	Cancel one or more messages that have previously been scheduled and are still pending.

**Parameters:**
- `sequence_numbers` (int): The sequence numbers of the scheduled messages.

**Example:**
```python
# Schedule messages
await client.cancel_scheduled_messages(123, 456)
```

**Note:** If the client is not running, it will be opened automatically before processing the request. The method sends a management request to cancel the specified scheduled messages and returns the response from the management handler.
1879	Wait until all pending messages have been sent and return their send results. Each result is a tuple indicating success/failure and any error message. If the sender is not running, it will be opened first. Raises MessageSendFailed if there's an exception during the send process.
1880	Reconnects the handler by attempting to re-establish connection and re-queue any pending messages, handling exceptions that may occur during the process.
1881	Extracts management certificate from Azure publish settings file and writes it to specified path, returning the subscription ID. Reads certificate data from XML publish settings, decodes base64 certificate, converts from PKCS12 to PEM format, and saves to target location. Validates subscription ID if provided, otherwise uses first subscription in file. Requires pyopenssl library for certificate operations.
1882	Load stored cookies from cache that haven't expired and restore them to the session, returning the names of restored cookies.
1883	Returns the display width of a string by summing the width of each character. Handles bytes input by decoding to UTF-8, then calculates total width using character width mapping.
1884	Returns a prefix of the input value that fits within the specified maximum length, measuring length by unicode characters rather than bytes. If the input is bytes, it's decoded to UTF-8, then the function finds the longest suffix that fits within the limit and returns it, preserving the original data type.
1885	Clears the previous line and prints a new message in place on the terminal.
1886	Formats a file size into human-readable format with appropriate units (bytes, KB, MB, GB, TB) and correct decimal precision.
1887	Formats elapsed seconds into a human readable format showing hours, minutes, and seconds.
1888	Creates a status line with appropriate size by formatting parameters according to available progress formats and ensuring it fits within terminal width.
1889	Progress an iterator and updates a pretty status line to the terminal showing amount of data read, time elapsed, and average speed.
1890	Generates segment numbers and their availability times for media playlists. For static streams, segment numbers are sequential starting from startNumber up to the total duration. For dynamic streams, segment numbers are calculated based on time relative to availability start time, accounting for presentation time offset, suggested presentation delay, and minimum buffer time. Returns an iterator of (segment_number, available_time) tuples.
1891	This method yields segments based on available segment information. It first retrieves segmentBase, segmentLists, and segmentTemplate from the current object or parent objects. If segmentTemplate exists, it generates segments using the template with provided kwargs and yields them. If segmentLists exist, it iterates through them and yields individual segments. If neither exists, it yields a default Segment object with base_url, duration 0, and both init and media flags set to True. The method handles both dynamic content (with time-based segments) and static content (all segments available).
1892	Pauses the thread for a specified time and returns False if interrupted by another thread, True if time runs out normally.
1893	Adds a segment to the download pool and write queue by submitting a fetch task to the executor and queuing the future result.
1894	Puts a value into a queue with timeout handling, retrying until successful or thread is closed.
1895	Returns Akamai HD player verification parameters including token and HDNTL cookie data.
1896	Extracts a nonce from an HTTP response's redirect URL history for use in future authenticated requests. The method parses the redirect URL, extracts the 'goto' parameter, decodes the JSON 'state' parameter, and returns the 'nonce' value found within it.
1897	Find the Video Packet ID in the HTML for the provided URL by searching for a mediator regex pattern and parsing the JSON response.
1898	Parses JSON data with error handling and optional schema validation. Wraps parsing errors in a custom exception containing a data snippet, and validates against an optional schema if provided.
1899	Parses XML data with additional features including handling incorrect encoding, namespace stripping, and custom error handling with data snippets.
1900	Parses a query string into a dictionary, with duplicate keys removed, and optionally validates the result against a schema.
1901	Search for a key in a nested dictionary or list of nested dictionaries and yield all matching values.
1902	Spawn a process with optional parameters and arguments, handling timeouts and error cases. Convert parameters to command-line options using specified prefixes, redirect stderr, and optionally wait for process completion or timeout. Return the spawned process object.
1903	A brute force regex-based HTML tag parser that finds HTML tags without requiring standards compliance. Returns a generator yielding Tag objects for matching tags, including those in comments or script sections. Takes HTML content and a tag name as input, and yields tags with their attributes and inner content.
1904	Parses a DASH manifest file from a URL or XML string and returns a dictionary of DASH stream instances grouped by quality and audio language. Handles DRM-protected content by raising an error, filters video and audio representations, supports multiple audio languages with locale-based preference, and creates stream names indicating video quality (height/ bandwidth) and audio bandwidth.
1905	Determine the Unicode encoding of a JSON text sample by analyzing NULL byte patterns in the first 4 octets. Returns "UTF-32BE", "UTF-16BE", "UTF-32LE", "UTF-16LE", or "UTF-8" based on the NULL byte positions.
1906	Parses JSON from a response by first determining the appropriate encoding if not already set, then parsing the response text.
1907	Parses XML from a response object's text content using the parse_xml function.
1908	Parses a semi-colon delimited list of cookies and sets each cookie using the provided kwargs.
1909	Parses a semi-colon delimited list of headers and stores them in the headers dictionary.
1910	Parses semi-colon delimited query parameters from cookies and stores them in self.params dictionary.
1911	Return the message for this LogRecord after merging any user-supplied arguments with the message.
1912	Factory method that creates specialized LogRecords based on the logger name, with support for additional extra attributes while preventing key overwrites.
1913	Attempt login to LiveEdu.tv using email and password credentials, handling CSRF token retrieval and POST request with proper error handling.
1914	Loads a plugin from the same directory as the calling plugin by extracting the caller's path from the stack trace and using a workaround for frozen executables.
1915	Update or remove keys from a query string in a URL. Parse the URL, update specified keys with new values, remove specified keys, and return the updated URL. If remove is "*", all keys are removed. Updated keys are never removed even if they appear in the remove list.
1916	This method reads FLV tags from a file descriptor or buffer, processes them with adjusted timestamps, and yields serialized FLV data. It handles FLV header writing, tag verification, timestamp adjustment, duration checking, and manages timestamps for different tag types. The method can skip headers and supports flattening or preserving timestamp adjustments.
1917	Find all the arguments required by name, yielding each required argument and detecting cycles in the dependency graph.
1918	Checks if a file already exists and prompts the user whether it should be overwritten, unless the force flag is set. Returns a FileOutput object.
1919	Creates an output handler based on command line arguments, returning one of several output types:
- stdout pipe
- subprocess stdin pipe  
- named pipe for subprocess reading
- regular file

The function handles various combinations of output options and validates that conflicting options aren't used together. When no explicit output is specified, it creates a player output that can use either a named pipe or HTTP server for streaming media to a specified media player.
1920	Creates a HTTP server listening on the specified host and port, defaulting to all interfaces and a random high port if not specified. Returns the server instance or exits with an error if creation fails.
1921	Iterates over HTTP requests by repeatedly accepting connections on a server while a player is running or indefinitely if serving externally. Yields server connections with a 2.5 second timeout, continuing on OSError exceptions.
1922	Function `output_stream_http` continuously outputs a media stream over HTTP using either an external server or a local player. It handles stream fetching, HTTP request processing, and stream data transfer. The function supports both internal player playback and external server access, with appropriate error handling and logging throughout the process.
1923	This function prepares a filename from a stream URL to be passed to a media player for playback. It creates a title using the provided plugin, formats the stream URL as a quoted filename, and initializes a PlayerOutput object with the specified player, arguments, and title. The function then attempts to start the player and returns True on success or False if it fails to start.
1924	Opens a stream, reads 8192 bytes for validation, and returns the stream handle and prebuffered data. Raises StreamError if opening or reading fails, or if no data is returned.
1925	Open a stream, create an output, and write the stream to the output with retry logic and error handling.
1926	Reads data from a stream in chunks and writes it to an output, with support for player outputs, HTTP servers, and fifos. Handles player process checking on Windows, progress reporting, and proper error handling with graceful exits. Closes the stream when finished.
1927	Handles stream processing based on command-line arguments, supporting command-line output, JSON representation, URL conversion, and stream output to file or HTTP.
1928	Fetches streams using the specified stream types and sorting excludes parameters from args, returning the results from the plugin's streams method.
1929	Attempts to fetch streams repeatedly until some are returned or retry limit is hit. Returns the fetched streams or None if limit exceeded.
1930	Returns the actual stream name for a given stream name, resolving synonyms by finding the original stream name that matches the given stream's object reference, or returns the original name if no synonym resolution is needed.
1931	Formats and filters a dictionary of streams by removing synonyms and displaying them alongside their corresponding streams, sorted by quality weight. Returns a comma-separated string of the formatted stream names.
1932	Handles a URL by resolving it to a plugin, fetching available streams, and either playing a specified stream or displaying the list of available streams. Supports retry logic for stream fetching and provides JSON output options. Exits with error messages if no plugin handles the URL, no streams are found, or specified streams are not available.
1933	Outputs a list of all loaded Streamlink plugins, formatted as a comma-separated string. If console.json is True, outputs the list as JSON; otherwise, prints it as a formatted message.
1934	Opens a web browser to authenticate Streamlink with Twitch OAuth by redirecting to Twitch's authorization URL with required scopes and handles browser opening errors.
1935	Loads plugins from a list of directories by expanding user paths and checking if each directory exists before loading them.
1936	Sets up and parses command line arguments using argparse, with support for config files and case-insensitive stream handling. Loads arguments from specified config files, parses known arguments, handles unrecognized arguments based on ignore_unknown flag, converts stream names to lowercase, and sets URL from url_param if URL is not specified.
1937	**Summary:** The `setup_console` function initializes the console output system by creating a `ConsoleOutput` object with the specified output and streamlink parameters. It sets the JSON mode based on command-line arguments and configures signal handling to treat SIGTERM the same as SIGINT.
1938	Sets global HTTP session options including proxy settings, cookies, headers, query parameters, and SSL configuration based on command line arguments.
1939	Loads additional plugins from the default plugins directory and an optional extra plugin directory.
1940	Sets various Streamlink options based on command-line arguments, configuring HLS, HDS, HTTP, RTMP, stream segment, and FFmpeg related settings, as well as subprocess error logging and locale preferences.
1941	Show current installed versions including OS, Python, Streamlink, and dependency versions when debug logging is enabled.
1942	Extracts and returns the stream_id from text using regex pattern matching.
1943	Returns stream objects from iframe URL found in text using regex pattern matching.
1944	Sets a general option used by plugins and streams originating from this session object. Options include settings for HDS and HLS streaming, HTTP requests, RTMP streams, and more, with various data types such as floats, integers, strings, and booleans. The method handles backwards compatibility for deprecated option names and updates corresponding internal attributes or options accordingly.
1945	Returns the current value of a specified option, handling backwards compatibility for deprecated option keys and retrieving various HTTP-related settings from self.http when appropriate.
1946	Sets a plugin-specific option by storing the given key-value pair in the plugin's option storage.

**Parameters:**
- `plugin` (str): Name of the plugin
- `key` (str): Option key to set
- `value`: Value to set the option to

**Behavior:**
- Checks if the specified plugin exists in `self.plugins`
- If plugin exists, retrieves the plugin instance and calls its `set_option` method with the provided key and value
- No return value

**Note:** This method assumes the plugin has a `set_option` method that accepts a key-value pair for storage.
1947	Returns the current value of a plugin-specific option by looking up the plugin by name and retrieving the specified option key from it.
1948	Attempts to find a plugin that can handle the given URL by checking against loaded plugins and sorting by priority. If no plugin is found, it tries to follow redirects and recursively resolves the redirect URL. Raises NoPluginError if no suitable plugin is found after following redirects.
1949	Load plugins from a specified directory path by iterating through modules and attempting to load each one, with error handling that prints exceptions to stderr if loading fails.
1950	Converts a timestamp string to total seconds, supporting formats like hh:mm:ss, minutes:seconds, and 11h22m33s style notation. Returns seconds as integer.
1951	Checks if a string value starts with another string, raising a ValueError if the condition is not met.
1952	Checks if a string value ends with another string, raising a ValueError if the condition is not met.
1953	Checks if a string contains another string, raising ValueError if the substring is not found.
1954	Returns a transform function that gets a named attribute from an object, returning a default value if the attribute doesn't exist.
1955	Filters out unwanted items using the specified function, supporting both dictionaries and sequences. For dictionaries, key/value pairs are expanded when applied. Returns a transformed result maintaining the original data structure type.
1956	Apply a function to each value in a sequence or dictionary, handling both cases appropriately with special handling for Python 2 string types.
1957	Function that creates a URL validator with specified attributes, parses URLs, validates their components, and raises ValueError for invalid URLs or attributes.
1958	Find a XML element via xpath and validate the result.
1959	Returns a transformer function that finds all XML elements matching the given xpath from an XML element.
1960	Finds and constructs a player URL from an HTTP response by extracting embedded URL patterns and appending hash parameters when needed, returning the complete URL prefixed with the Czech Television base domain.
1961	Loads and parses M3U8 playlist data using the specified parser, with optional base URI for resolving relative URIs.
1962	Check if the current player supports adding a title by testing the command against supported players list. Returns the player name if supported, None otherwise.
1963	Logs in to Steam with the provided credentials, handling captcha, email authentication, and two-factor authentication if required. Returns True if login is successful, False otherwise.
1964	Returns the stream_id extracted from HTML using a regex pattern, logging an error if extraction fails.
1965	Returns a nested list of stream options containing stream_url and stream_quality_name for each stream found in the HTML. Converts empty quality names to "source" and logs an error if no stream info is extracted.
1966	Method `_login(self, username, password)` handles the login process by:
1. Fetching the login page to extract hidden input fields
2. Creating a data dictionary with extracted input values and provided credentials
3. Submitting a POST request to the login URL with the login data
4. Saving session cookies to cached attributes
5. Returning True if login was successful (checking for required session cookies) or False if it failed

The method uses regex patterns to parse input fields from the login page and handles potential parsing errors gracefully. It also sets an expiration time for the cached session data upon successful login.
1967	Creates a key-function mapping by appending a key-function pair to self._map, where the function is wrapped with partial to handle extra arguments.
1968	Makes an API call to the specified entrypoint with given parameters and optional schema validation, handling session management and error processing.
1969	Starts a session against Crunchyroll's server and returns the session ID.
1970	Returns data for a specific media item by calling the API with the given media ID and optional fields/schema parameters.
1971	Creates a CrunchyrollAPI object, initiates its session, and authenticates using saved credentials or user-provided username and password. Handles credential purging, locale setting, and logging of authentication status.
1972	Compresses a byte string using the Brotli compression algorithm with specified parameters.

**Args:**
- `string` (bytes): The input data to compress
- `mode` (int, optional): Compression mode (MODE_GENERIC, MODE_TEXT, or MODE_FONT). Defaults to MODE_GENERIC
- `quality` (int, optional): Compression speed vs density tradeoff (0-11). Defaults to 11
- `lgwin` (int, optional): Base 2 logarithm of sliding window size (10-24). Defaults to 22
- `lgblock` (int, optional): Base 2 logarithm of maximum input block size (16-24). Defaults to 0

**Returns:**
- Compressed byte string

**Raises:**
- `brotli.error`: If arguments are invalid or compression fails
1973	Function that formats characters for readable output, displaying printable ASCII characters normally, special characters (\n, \r, space) with escape sequences, and other characters in hexadecimal format.
1974	Function that formats a string by replacing spaces with actual space characters and applying character formatting, with a maximum length of 200 characters (showing first and last 100 characters with ellipsis if exceeded).
1975	Read n bytes from the stream on a byte boundary. Raises ValueError if not on a byte boundary. Returns the bytes read and advances position by 8*n bits.
1976	Returns the value used for processing, which can be a tuple with optional extra bits. Raises ValueError if extra value doesn't fit in extraBits or if extra bits are provided when not supported.
1977	Returns a long explanation of the value from the numeric value with optional extra bits, used by Layout.verboseRead when printing the value. If the code has extra bits, it calls the callback with both self and extra; otherwise, it calls the callback with just self.
1978	Store decodeTable and compute lengthTable, minLength, maxLength from encodings by iteratively splitting symbols using bit masks until all symbols are uniquely identified.
1979	Sets up decoding tables based on bit pattern lengths for symbols, computing forward codes and reversing them for proper decoding, while tracking minimum and maximum code lengths.
1980	Show all words of the code in a formatted table with binary patterns and mnemonics arranged in columns.
1981	Reads a symbol from stream and returns the symbol along with its length.
1982	Method `explanation` that returns an expanded explanation string for a given index, optionally incorporating extra bits. The format varies based on whether `extra` is provided and whether `extraTable` exists. When `extra` is None, it uses a basic format. When `extra` is provided and `extraTable` exists, it uses a more complex format that includes extra bits, bit pattern, span range, and calculated value. The method handles three different formatting scenarios depending on the presence of extra bits and the existence of an extra table, returning a formatted string with descriptive information about the code at the specified index.
1983	Override this method if you don't define value0 and extraTable. Calculates a value based on span bounds and extra offset, raising ValueError if extra exceeds upper bound.
1984	Returns the range of possible values at a given index in a tuple, useful for mnemonics and explanations. Calculates lower bound as value0 plus sum of powers of 2 up to index, and upper bound as lower plus 2 raised to the power of the extraTable value at index. Returns tuple of (lower, upper-1).
1985	Return count and value based on index and extra parameters. For index=0, return (1, 0). For index<=RLEMAX, return ((1<<index)+extra, 0). For index>RLEMAX, return (1, index-RLEMAX).
1986	Create a mnemonic representation for a given index by splitting it into components and formatting them with appropriate syntax highlighting and extra bit indicators.
1987	Returns mnemonic representation of meaning for a given index. For indices 0-15, returns predefined string values. For indices 16 onwards, constructs formatted strings like "1xx01-15" where 'x' represents compressed sequences and the format depends on the index and internal parameters. The verbose parameter controls string compression for long sequences of 'x' characters.
1988	Builds an action table from text by parsing lines, extracting actions based on column positions, processing action strings to add quotes around strings, replacing space symbols, expanding shortcuts like ".U" to ".upper()", and storing actions in a list at their corresponding indices.
1989	Perform the specified action by evaluating it in the local environment with the UpperCaseFirst set as U.
1990	Produce hex dump of data bits from specified position to current stream position.
1991	Process a brotli stream by reading and decoding stream headers, metablock headers, block type descriptors, distance code parameters, context maps, and prefix code lists, while handling last block indicators and uncompressed data blocks.
1992	Method `metablockLength` reads MNIBBLES and meta block length from the stream. If the block is not empty (MLEN has a value), it returns `False`. If the block is empty, it skips the reserved bytes, reads the skip length, reads fillers, advances the stream position by the skip length multiplied by 8, prints the new position, and returns `True`.
1993	Method `uncompressed` checks if data is uncompressed by reading a boolean flag. If uncompressed data is detected, it skips filler bytes, reads a specified number of bytes (MLEN), and outputs the uncompressed data. Returns True if data was uncompressed, False otherwise.
1994	Reads block type switch descriptor for a given block type kind, including block type codes, block count codes, and current block counts.
1995	In-place inverse move-to-front transform that reconstructs the original sequence from transformed values by maintaining a dynamic move-to-front list and inserting accessed elements at the front.
1996	Read prefix code array for specified kind and number of trees, populate alphabet objects with prefix codes, and store results in prefixCodes dictionary.
1997	Converts an intensity array to a monochrome image by scaling values to a specified color. Takes an input array I and maps its values from vmin-vmax range to 0-1, then multiplies by the given color tuple to produce an RGB image. Values outside the range are clipped to 0-1. Uses nanmin/nanmax for automatic range detection when vmin/vmax are None. Returns array with shape (height, width, 3) where 3 represents RGB channels.
1998	Function that converts multi-dimensional image data into RGB color image using specified colors and normalization.

The function takes multi-dimensional image data and maps it to RGB colors based on the specified color palette. It normalizes the input data to [0,1] range using either provided min/max values or computes them from the data, then uses dot product with color vectors to generate the final RGB image.

Parameters:
- I: ndarray of any shape (typically 3D input results in 2D image output)
- colors: sequence of [(r,g,b), ...] color values to use for mapping
- vmin: normalization minimum for I (defaults to nanmin when None)
- vmax: normalization maximum for I (defaults to nanmax when None)
- axis: axis to sum over for normalization (defaults to last axis)

Returns:
- RGB image as ndarray with shape (..., 3) where ... represents input dimensions except the axis being summed over

Example usage:
```python
I = np.arange(32.).reshape(4,4,2)
colors = [(0, 0, 1), (0, 1, 0)]  # blue and green
rgb = vx.image.polychrome(I, colors)  # returns shape (4,4,3)
```
1999	Creates an Arrow table from a Vaex dataframe by converting columns to Arrow arrays and combining them into a pyarrow Table.
2000	Adds method f to the Dataset class by storing it in the class's hidden dictionary with the method name as key.
2001	Adds virtual columns for radial velocity and proper motions converted from cartesian velocities. Calculates vr (radial velocity), pm_long (proper motion in longitude direction), and pm_lat (proper motion in latitude direction) using cartesian coordinates (x,y,z) and velocities (vx,vy,vz). Uses distance as optional parameter or defaults to sqrt(x+y+z). Includes proper motion conversion factor k=4.74057.
2002	Convert proper motion components to perpendicular velocity components using the formula v = k * pm * distance, where k = 4.74057. Creates virtual columns for velocity components (vl, vb) based on proper motion (pm_long, pm_lat) and distance. Optionally propagates uncertainties if requested.
2003	Returns a graphviz.Digraph object representing the expression as a graph, where nodes are expression components and edges represent dependencies between them.
2004	Computes counts of unique values in a column, returning a Pandas Series with the counts and corresponding values as the index. Supports options to drop NA/null values, control sorting order, and display progress. Handles both categorical and non-categorical data, with special handling for string types. Uses a multi-threaded map-reduce approach for efficient computation.
2005	Map values of an expression or in-memory column according to a dictionary or callable function, handling NaN and null mappings.
2006	Creates a vaex application window using QApplication. Requires proper Qt API level setup in Jupyter notebooks with `%gui qt` magic command. Returns a VaexApp instance for GUI operations within Jupyter environments.
2007	Open a list of filenames, and return a DataFrame with all DataFrames concatenated.

Parameters:
    filenames (list[str]): list of filenames/paths

Returns:
    DataFrame: concatenated DataFrame from all valid files

The function iterates through filenames, strips whitespace, skips empty lines and comments (starting with #), opens valid files, and concatenates all DataFrames into a single DataFrame using vaex.dataframe.DataFrameConcatenated.
2008	Connects to a SAMP Hub to receive a single table load event, downloads the table, and returns it as a DataFrame. Useful for transferring tables from applications like TOPCAT to vaex.
2009	Create a vaex DataFrame from an Astropy Table by wrapping it in a DatasetAstropyTable object.
2010	Create an in-memory DataFrame from numpy arrays passed as keyword arguments. Supports both individual arrays and dictionaries of arrays. Returns a DataFrame object with the specified arrays as columns.
2011	Creates a DataFrame from scalar values, equivalent to from_arrays but for single values. Takes keyword arguments where keys become column names and values become the single row of data. Returns a DataFrame with one row.
2012	Creates an in-memory Vaex DataFrame from a pandas DataFrame by converting each column and optionally copying the index. Returns a DataFrame object with the same data as the input pandas DataFrame.

```python
def from_pandas(df, name="pandas", copy_index=True, index_name="index"):
    """Create an in memory DataFrame from a pandas DataFrame.

    :param: pandas.DataFrame df: Pandas DataFrame
    :param: name: unique for the DataFrame

    >>> import vaex, pandas as pd
    >>> df_pandas = pd.from_csv('test.csv')
    >>> df = vaex.from_pandas(df_pandas)

    :rtype: DataFrame
    """
    import six
    vaex_df = vaex.dataframe.DataFrameArrays(name)

    def add(name, column):
        values = column.values
        try:
            vaex_df.add_column(name, values)
        except Exception as e:
            print("could not convert column %s, error: %r, will try to convert it to string" % (name, e))
            try:
                values = values.astype("S")
                vaex_df.add_column(name, values)
            except Exception as e:
                print("Giving up column %s, error: %r" % (name, e))
    for name in df.columns:
        add(name, df[name])
    if copy_index:
        add(index_name, df.index)
    return vaex_df
```
2013	Reads a CSV file using pandas and converts it to a DataFrame.

This function serves as a shortcut for reading CSV files with pandas and converting the result to a DataFrame format. It leverages pandas' `read_csv` functionality while providing additional control over index handling through the `copy_index` parameter. The function accepts all standard pandas `read_csv` parameters via `**kwargs`, allowing for flexible CSV parsing options while maintaining compatibility with existing DataFrame workflows.

Parameters:
- filename_or_buffer: str or file-like object, path to the CSV file or buffer to read from
- copy_index: bool, whether to copy the index from the pandas DataFrame (default: True)
- **kwargs: additional arguments passed to pandas.read_csv()

Returns:
- DataFrame: parsed data converted from the CSV file
2014	Connect to a hostname supporting the vaex web API and return a ServerRest object. The function parses the URL to extract scheme, port, base path, and hostname, then creates and returns a ServerRest instance with the appropriate connection parameters. The connection is not established until actually needed.
2015	Creates a Zeldovich DataFrame with specified dimensions, grid size, power spectrum index, time, and scale parameters by utilizing vaex's Zeldovich implementation.
2016	Concatenate a list of DataFrames into a single DataFrame using the concat method.
2017	Creates a virtual column equivalent to numpy.arange that uses zero memory, returning a ColumnVirtualRange object with the specified start, stop, step, and data type parameters.
2018	Opens a dataset from a given path, adds it to the UI, and returns the dataset object. Handles both local files and remote URLs/WS connections, with logging and recent files tracking.
2019	Evaluates an expression on the server side with optional parameters. Takes an expression and additional arguments (i1, i2, out, selection, delay) and returns the result from the server. The 'out' parameter is currently ignored.
2020	Decorator that enables transparent acceptance of delayed computations by converting function arguments and keyword arguments into promises, executing the function once all promises are resolved, and handling errors through promise callbacks.
2021	Find all columns that this selection depends on for dataframe ds by collecting variables from all expressions and recursively checking previous selection dependencies.
2022	Helper function that handles task execution with optional progress bar support. When delay is enabled, it schedules the task for later execution and returns a promise. When delay is disabled, it immediately executes the task with optional progress bar visualization, connects to progress signals, and returns the actual result while properly managing progress bar lifecycle and signal connections.
2023	Sorts the table by a specified column number in either ascending or descending order, updating the indices accordingly. For column 0, sorts by pair names; for column 1, sorts by ranking if available. Emits layout change signals before and after sorting.
2024	Function `getinfo` reads header data from a Gadget data file to determine file type and calculate data offsets. It returns the total particle count, position offset, velocity offset, and header information. The function handles both Gadget file types (1 and 2) by detecting the file structure and adjusting offsets accordingly. The header contains particle numbers, mass array, time, redshift, flags, and other simulation parameters. The position and velocity data offsets are calculated based on the file type and particle count.
2025	Clears the cursor by hiding vertical and horizontal lines along with an ellipse, and saves the background if blitting is enabled.
2026	Waits for all plots to complete processing by monitoring plot events and processing Qt events until the last plot finishes.
2027	Open a document using the operating system's default application handler. On macOS, uses the 'open' command; on Linux, uses 'xdg-open'; on Windows, uses 'start'. Can open files, URLs, or any document type associated with a default application.
2028	A flexible writing function that accepts either a file object or filename, automatically handling file opening/closing operations. If a file object is provided, it yields the object directly. If a filename is provided, it opens the file in the specified mode, yields the file object, and then closes it. The function is designed to be used as a context manager for seamless file I/O operations.
2029	Combines masks from a list of arrays into a single logical OR mask and returns the data arrays with their masks removed.
2030	Evaluates an expression and discards the result, useful for benchmarking lazy evaluations in vaex.
2031	Return the first element of a binned expression, where values in each bin are sorted by an order expression. Supports binning by multiple columns, limits, shape specification, and various options like selection, delay, and progress tracking. The result is a numpy array containing the first elements from each bin.
2032	Calculate the mean for a given expression, optionally on a grid defined by binby. Supports various parameters for filtering, shaping, and selection, and can handle delayed computation. Returns a scalar or array depending on the input and parameters.
2033	```python
def sum(self, expression, binby=[], limits=None, shape=default_shape, selection=False, delay=False, progress=None, edges=False):
    """Calculate the sum for the given expression, possible on a grid defined by binby

    Example:

    >>> df.sum("L")
    304054882.49378014
    >>> df.sum("L", binby="E", shape=4)
    array([  8.83517994e+06,   5.92217598e+07,   9.55218726e+07,
                     140008776e+08])

    :param expression: {expression}
    :param binby: {binby}
    :param limits: {limits}
    :param shape: {shape}
    :param selection: {selection}
    :param delay: {delay}
    :param progress: {progress}
    :return: {return_stat_scalar}
    """
    return self._compute_agg('sum', expression, binby, limits, shape, selection, delay, edges, progress)
```
2034	Calculate the standard deviation for the given expression, possibly on a grid defined by binby. Returns scalar or array depending on whether binby is specified.
2035	Calculate the covariance matrix for given expressions, optionally binned by specified columns. Supports single or multiple expressions, with options for binning, limits, shape, selection, and delayed computation. Returns a covariance matrix array.
2036	Calculate the minimum and maximum for expressions, possibly on a grid defined by binby. Returns an array with shape (2) containing the min and max values. Supports single or multiple expressions, binning, limits, and progress tracking.
2037	Calculate the minimum value(s) for given expressions, optionally on a grid defined by binby parameters. Supports single values, arrays, and binned calculations with specified limits and shape. Returns scalar or array results depending on input.

**Parameters:**
- expression: {expression}
- binby: {binby} 
- limits: {limits}
- shape: {shape}
- selection: {selection}
- delay: {delay}
- progress: {progress}

**Returns:** {return_stat_scalar}, the last dimension is of shape (2)
2038	Calculate the median approximation by computing the cumulative distribution on a grid, equivalent to calling percentile_approx with the 50th percentile.
2039	Creates a 1D, 2D, or 3D visualization widget for Jupyter notebooks using specified backend (bqplot, ipyleaflet, ipyvolume, matplotlib). Supports various plot types and customization options including color schemes, normalization, and selection filters. Returns the plot object for further manipulation or display.
2040	Count non-missing values for an expression on healpix data, grouping by healpix pixels at a specified level and optionally binning by additional dimensions.
2041	Plots data on a 2D map using Healpix coordinates, supporting transformations between equatorial, galactic, and ecliptic systems. It allows customization of the plot via various parameters such as colormap, smoothing, rotation, and figure size, with options for interactive visualization. The method can apply functions to the data before plotting and handles data aggregation based on Healpix expressions.
2042	Creates a 3D plot using ipyvolume visualization. Takes 3D coordinates (x, y, z) and optional velocity components (vx, vy, vz), with various rendering options including smoothing, normalization, color mapping, and lighting effects. Returns the plot object and optionally displays it. Requires ipyvolume to be installed.
2043	Return the numpy dtype for the given expression. If the expression is a column, use the column's dtype. If not a column, evaluate the expression to determine dtype. For internal use, return the actual dtype; for external use, convert string-like dtypes to str_type.
2044	Returns the path to a directory where files are stored for metadata etc. for each DataFrame. Creates the directory if it doesn't exist and the create parameter is True.
2045	Return the internal state of the DataFrame in a dictionary, including virtual columns, variables, functions, selections, units, UCDs, descriptions, and active range.
2046	Sets the internal state of the DataFrame using a provided state dictionary, including virtual columns, functions, selections, units, and variables. It allows optional use of an active range for filtering data.
2047	Removes the virtual_meta.yaml file from the private directory if it exists, and removes the directory itself if it becomes empty after the removal. Handles potential exceptions during the file and directory removal operations.
2048	Writes virtual columns and variables metadata (UCDs, descriptions, and units) to a YAML file in the DataFrame's private directory. The metadata includes information about virtual columns and variables along with their associated UCDs, units, and descriptions. This file is used to persist virtual metadata between DataFrame sessions and is updated when virtual columns/variables are added or removed.
2049	Writes metadata information (description, ucds, units, and descriptions) to a meta.yaml file in the DataFrame's private directory using JSON or YAML format.
2050	Generate a Subspaces object with specified expressions or all possible combinations up to given dimensions, optionally excluding certain combinations based on criteria.
2051	Sets a variable to an expression or value. The variable can be retrieved using `get_variable()` and evaluated using `evaluate_variable()`. If `write=True`, the variable is written to the meta file.
2052	Evaluates a variable by name, handling both string expressions and direct values. If the variable is a string, it evaluates the expression using a global namespace and current variables. Otherwise, it returns the variable's value directly.
2053	Evaluates a selection mask within a specified range using BlockScopeSelection. Takes optional parameters for name, start index (i1), end index (i2), selection criteria, and caching. Returns the evaluation result from the scope.
2054	Return a dictionary containing the ndarray corresponding to the evaluated data, using the specified column names and selection criteria.
2055	Return a copy of the DataFrame with specified column names and selection options, optionally copying virtual columns and selection histories while maintaining metadata.
2056	Converts the ndarray data to a pandas DataFrame with optional column selection, indexing, and filtering.

**Parameters:**
- `column_names` (list, optional): List of column names to export. If None, uses all columns.
- `selection` (str, optional): Selection expression to filter data.
- `strings` (bool): Whether to include string columns when column_names is None.
- `virtual` (bool): Whether to include virtual columns when column_names is None.
- `index_name` (str, optional): Column name to use as DataFrame index.

**Returns:**
- `pandas.DataFrame`: DataFrame containing the evaluated data with optional index.

**Example:**
```python
df_pandas = df.to_pandas_df(["x", "y", "z"])
df_copy = vaex.from_pandas(df_pandas)
```
2057	Returns a pyarrow.Table object containing the arrays corresponding to the evaluated data, with options to specify column names, selection criteria, and data type handling.
2058	Returns an astropy table object containing the evaluated data from the DataFrame. Converts data types appropriately for astropy compatibility, handles masked arrays, and includes metadata such as units, descriptions, and UCDs. Supports optional column selection and filtering.
2059	Add an in-memory array as a column to the DataFrame, validating length compatibility and handling both numpy arrays and Column objects. Raises ValueError for invalid arrays or length mismatches.
2060	Renames a column in the dataset by updating its in-memory name while preserving the underlying data. The method handles both regular and virtual columns, updates associated metadata (UCDs, units, descriptions), and optionally tracks the rename operation in the state. The rename only affects the in-memory representation and does not modify the disk storage. Returns the new column name.
2061	Convert cartesian coordinates to polar coordinates by adding virtual columns for radius and azimuth angle, with optional uncertainty propagation and unit conversion.
2062	Converts Cartesian velocity components (vx, vy, vz) to spherical coordinates (vr, vlong, vlat) using vector calculus transformations based on the input spatial coordinates (x, y, z). The method creates three new virtual columns representing the radial velocity (vr), longitude velocity (vlong), and latitude velocity (vlat) components in the spherical coordinate system. The transformation accounts for the relationship between Cartesian and spherical coordinate systems, including proper normalization by distance and angular components. The distance calculation can be customized or defaults to the standard Euclidean distance formula. The implementation follows the mathematical relationships derived from the conversion between cartesian and spherical coordinate systems.
2063	Convert cartesian velocities to polar velocities using the transformation equations: vr = (x*vx + y*vy)/radius, vphi = (x*vy - y*vx)/radius, where radius = sqrt(x + y). Optionally propagates uncertainties through the transformation.
2064	Convert cylindrical polar velocities to Cartesian coordinates by computing vx and vy components from radial and azimuthal velocity components using trigonometric transformations.
2065	Adds virtual columns representing 2D rotated coordinates. Takes x and y column names/expressions, applies rotation by specified angle (in degrees), and creates new virtual columns for transformed coordinates. Optional uncertainty propagation supported.
2066	Convert spherical coordinates (alpha, delta, distance) to cartesian coordinates (x, y, z) with optional uncertainty propagation and center offset.
2067	Convert cartesian coordinates (x, y, z) to spherical coordinates (alpha, delta, distance) with optional centering. The transformation computes distance as sqrt(x + y + z), alpha as arctan2(y, x), and delta as -arccos(z/distance) + /2. Supports radians output and optional center offset adjustment.
2068	Add a virtual column to the DataFrame with the specified name and expression, handling name conflicts by making the name unique if requested. The method supports expressions that can reference existing columns and emits a signal when the column is added.
2069	Deletes a virtual column from a DataFrame and emits a signal indicating the column deletion.
2070	Add a variable to a DataFrame with the given name and expression, returning the valid variable name if unique is True.
2071	Deletes a variable from the DataFrame and emits a signal indicating the variable has been deleted.
2072	Return a shallow copy of a DataFrame with the last n rows.
2073	Display the first and last n elements of a DataFrame using HTML table formatting.
2074	Generate a descriptive statistics overview of the DataFrame, including data types, counts, missing values, mean, standard deviation, minimum, and maximum values for numeric columns, and data types and counts for string columns. Supports optional filtering via selection and options to include string and virtual columns. Returns a Pandas DataFrame with the statistics.
2075	Display a portion of the DataFrame as a table from row i1 to i2, supporting multiple output formats including HTML, plain text, and LaTeX. For HTML format, it displays directly in Jupyter notebooks, while other formats are printed to the console.
2076	Sets the current row to the specified value and emits the signal_pick signal. Raises an IndexError if the index is out of range [0, len(self)).
2077	Return a list of column names filtered by virtual, hidden, string, and regex parameters.
2078	Return a DataFrame with all columns trimmed by the active range, setting the active range to cover the entire original length. If inplace=True, modify the current DataFrame; otherwise, return a copy. The trimming operation adjusts the _index_start and _index_end attributes to reflect the full original range, and updates related length and fraction attributes accordingly.
2079	Returns a DataFrame containing only rows indexed by indices.

Example:

>>> import vaex, numpy as np
>>> df = vaex.from_arrays(s=np.array(['a', 'b', 'c', 'd']), x=np.arange(1,5))
>>> df.take([0,2])
 #  s      x
 0  a      1
 1  c      3

:param indices: sequence (list or numpy array) with row numbers
:return: DataFrame which is a shallow copy of the original data.
:rtype: DataFrame
2080	Return a DataFrame containing only the filtered rows.

The resulting DataFrame may be more efficient to work with when the original DataFrame is heavily filtered (contains just a small number of rows).

If no filtering is applied, it returns a trimmed view.
For the returned df, len(df) == df.length_original() == df.length_unfiltered()

:rtype: DataFrame
2081	Returns a DataFrame with a random subset of rows based on specified sampling parameters.

This method allows for random sampling of rows from a DataFrame with various options:
- Sample by count (n) or fraction (frac)
- With or without replacement
- With optional weighted probabilities
- With reproducible results using random_state

The method supports both integer seeds and RandomState objects for controlling randomness. When weights are provided, they're normalized and used to influence sampling probabilities. The result is a shallow copy of the original DataFrame containing only the sampled rows.

Parameters:
- n: Number of samples to take (default 1 if frac is None)
- frac: Fractional number of samples to take
- replace: If True, rows may be selected multiple times
- weights: Unnormalized probability weights for sampling
- random_state: Seed or RandomState for reproducible results

Returns:
- DataFrame with randomly sampled rows (shallow copy)

Example usage:
- `df.sample(n=2)` - Take 2 random rows
- `df.sample(frac=0.5)` - Take 50% of rows randomly
- `df.sample(frac=1, replace=True)` - Shuffle with possible duplicates (bootstrap)
2082	Returns a list containing random portions of the DataFrame by shuffling indices and splitting based on specified fractions.

**Parameters:**
- `frac`: int or list - If int, splits into two portions with first having size specified; if list, creates portions for each fraction
- `random_state`: int or None - Random number seed for reproducibility

**Returns:**
- list - A list of DataFrames containing the split portions

**Example:**
```python
import vaex, numpy as np
np.random.seed(111)
df = vaex.from_arrays(x=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
for dfs in df.split_random(frac=0.3, random_state=42):
    print(dfs.x.values)  # [8 1 5] then [0 7 2 9 4 3 6]
```
2083	Splits a DataFrame into ordered subsets based on specified fractions. Returns a generator yielding DataFrames where each DataFrame contains a portion of the original data according to the given fraction(s). If a single fraction is provided, splits into two parts; if a list of fractions is provided, splits into multiple parts corresponding to each fraction. The fractions are normalized if provided as a list, and each portion is assigned based on cumulative distribution of the fractions.
2084	Sorts the DataFrame by the specified expression and returns a new sorted DataFrame.

Parameters:
- by (str or expression): Expression to sort by
- ascending (bool): Sort in ascending order (default: True) or descending (False)
- kind (str): Sorting algorithm to use (passed to numpy.argsort, default: 'quicksort')

Returns:
- A new DataFrame sorted by the specified expression

The method first evaluates the sorting expression, then uses numpy.argsort to get the indices that would sort the values, and finally returns a new DataFrame with rows reordered according to these indices. When ascending=False, the indices are reversed to achieve descending order. The method operates on unfiltered data and returns a copy of the original DataFrame with sorted rows.
2085	Returns a new DataFrame where the specified virtual column is converted into an in-memory numpy array. The virtual column is evaluated, removed from the DataFrame, and replaced with a real column containing the computed numpy array values. Raises KeyError if the virtual column doesn't exist. If inplace=True, modifies the DataFrame in place.

Example:
```python
>>> x = np.arange(1,4)
>>> y = np.arange(2,5)
>>> df = vaex.from_arrays(x=x, y=y)
>>> df['r'] = (df.x**2 + df.y**2)**0.5  # 'r' is virtual
>>> df = df.materialize('r')  # 'r' becomes real column
```
2086	Undoes a selection for the specified name by reverting to the previous state in the selection history, updating the history index, and emitting a selection changed signal.
2087	Redo a selection operation for the specified name by moving forward in the selection history, updating the index, emitting a selection changed signal, and logging the operation.
2088	Can the specified selection name be redone? Returns True if there are more entries in the selection history after the current index, False otherwise.
2089	Perform a selection based on a boolean expression, combining it with previous selection using specified mode. Selections are tracked in a history tree by name for undo/redo functionality. Returns nothing.
2090	Creates a selection that filters rows to keep only those with non-missing values for specified columns, using either NaN or masked value dropping criteria, and stores the selection with the given name.
2091	Create a shallow copy of a DataFrame with filtering to drop rows containing missing values. The method allows specifying whether to drop rows with NaN values, masked values, or both, and can target specific columns. Returns the filtered DataFrame copy.
2092	Select a 2D rectangular region in the space defined by x and y coordinates, bounded by the specified limits. The method takes x and y expressions, a limits parameter defining the rectangular bounds as [(x1, x2), (y1, y2)], and optional parameters for selection mode and name. It delegates to the underlying select_box method with the provided parameters.
2093	Select a n-dimensional rectangular box bounded by limits using boolean conditions.
2094	Select a circular region centered on (xc, yc) with radius r using the specified x and y expressions. The selection can be inclusive or exclusive of the circle boundary and supports different modes and naming conventions.
2095	Select an elliptical region in a dataset with specified center, dimensions, and orientation. The method allows for inclusive or exclusive selection based on whether points fall within or strictly within the ellipse bounds. It supports rotation of the ellipse and accepts both degree and radian angle inputs. The selected points can be added to or replace existing selections in the dataset.
2096	Selects points using a lasso tool with specified coordinates and boolean mode operations.
2097	Invert the current selection by creating a SelectionInvert object and applying it through the _selection method with the specified name and executor.
2098	Sets a selection object into a specified slot, with an optional executor. Creates a selection using the provided selection object and stores it in the internal selection storage. The selection is executed fully during storage. Returns nothing.
2099	Selects a lasso or rectangle region with the given name, updating the selection history and emitting a selection changed signal. The method handles both local and non-local execution contexts, manages selection history by appending new selections and clipping redo history, and returns a fulfilled promise. The selection is created using the provided create_selection function and can optionally be executed fully.
2100	Finds a non-colliding name by optionally postfixing the initial name with available suffixes, avoiding conflicts with existing column names including hidden ones.
2101	Returns a list of virtual column names that are not used in any other virtual column expression. These are the root nodes in the virtual column dependency graph, representing the top-level virtual columns that serve as starting points for computation.
2102	Return a graphviz.Digraph object with a graph of all virtual columns.
2103	Method `categorize` marks a specified column as categorical with given labels, assuming zero-based indexing. It takes a column parameter (which can be an expression), optional labels list, and a check flag. When check is True, it validates that the column's minimum and maximum values don't exceed the number of provided labels. If no labels are given, it automatically generates string labels from 0 to the maximum value. The method stores the categorical information (labels and count) in the object's `_categories` dictionary under the given column name.
2104	Encode a column as ordinal values and mark it as categorical, replacing the original column with numerical values between [0, len(values)-1].
2105	Returns direct access to the data as numpy arrays, allowing tab-completion in IPython. Provides access to real (non-virtual) columns by name as numpy.ndarray attributes. Use DataFrame.evaluate() for virtual columns. Example: `r = np.sqrt(df.data.x**2 + df.data.y**2)`
2106	Get the length of the DataFrame. If selection is True and a mask exists, returns the sum of selected rows; otherwise returns the total length of the DataFrame.
2107	Stacks columns from another DataFrame horizontally to this DataFrame, ensuring matching lengths and optionally prefixing column names.
2108	Concatenates two DataFrames by combining their rows into a new DataFrameConcatenated object. If either DataFrame is already a DataFrameConcatenated, it properly extends the underlying list of DataFrames. No data copying occurs during the operation. Returns a new DataFrameConcatenated containing all rows from both input DataFrames.
2109	Exports the DataFrame to a vaex hdf5 file with various options for column selection, ordering, and formatting.
2110	Add a column to the DataFrame with the specified name and data, then update the unfiltered length based on the active fraction of the original length.
2111	Adds method f to the DataFrame class by setting it as an attribute with the method's name.
2112	Registers a new function with vaex, allowing it to be used as an expression method or property. Can be applied as a decorator to functions, optionally with scope and property behavior. The decorated function will be available on vaex DataFrames and can be called with the `df.column.function_name()` syntax or accessed as a property when `as_property=True`. Supports scoping via the `scope` parameter to organize functions into logical groups.
2113	Returns an array where missing values are replaced by a specified value. Handles different data types including object arrays (replacing both NaN values and 'nan' strings) and floating-point arrays (replacing NaN values). Also supports masked arrays by replacing masked values. The function creates copies of arrays when modifications are needed to avoid in-place changes.
2114	Returns the day of the week for datetime values with Monday=0 and Sunday=6.
2115	Returns the ordinal day of the year (1-366) for a datetime column as an expression.

Example:
```
>>> import vaex
>>> import numpy as np
>>> date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
>>> df = vaex.from_arrays(date=date)
>>> df.date.dt.dayofyear
Expression = dt_dayofyear(date)
Length: 3 dtype: int64 (expression)
-----------------------------------
0  285
1   42
2  316
```
2116	Check whether a year is a leap year.

:returns: an expression which evaluates to True if a year is a leap year, and to False otherwise.

Example:

>>> import vaex
>>> import numpy as np
>>> date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
>>> df = vaex.from_arrays(date=date)
>>> df
  #  date
  0  2009-10-12 03:31:00
  1  2016-02-11 10:17:34
  2  2015-11-12 11:34:22

>>> df.date.dt.is_leap_year
Expression = dt_is_leap_year(date)
Length: 3 dtype: bool (expression)
------------------------------
 0  False
 1   True
 2  False
2117	Extracts the year component from a datetime column using pandas' dt accessor.

**Parameters:**
- x: datetime-like data (array-like or Series)

**Returns:**
- ndarray containing the year values extracted from the datetime column

**Example:**
```python
import vaex
import numpy as np
date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
df = vaex.from_arrays(date=date)
df.date.dt.year  # Returns [2009, 2016, 2015]
```
2118	Extracts the month from a datetime column and returns an expression containing the month values.
2119	Returns the month names of a datetime sample in English as a string array.
2120	Extracts the day component from a datetime column and returns it as an expression.

Example:
```python
import vaex
import numpy as np
date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
df = vaex.from_arrays(date=date)
df.date.dt.day
# Returns: Expression = dt_day(date) with values [12, 11, 12]
```
2121	Returns the day names of a datetime sample in English as a string array.
2122	Returns the week ordinal of the year extracted from a datetime column.

This function takes a datetime column as input and returns an expression containing the week number of the year for each date. The week numbering follows the standard ISOcalendar convention where the first week of the year is the one that contains at least 4 days of the new year.

**Parameters:**
- x: datetime column or array

**Returns:**
- Expression containing week ordinal values (int64)

**Example:**
```
>>> import vaex
>>> import numpy as np
>>> date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
>>> df = vaex.from_arrays(date=date)
>>> df.date.dt.weekofyear
0  42
1   6
2  46
```
2123	Extracts the hour component from a datetime column and returns an expression containing the extracted hours.

Example:
```
>>> import vaex
>>> import numpy as np
>>> date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
>>> df = vaex.from_arrays(date=date)
>>> df.date.dt.hour
Expression = dt_hour(date)
Length: 3 dtype: int64 (expression)
-----------------------------------
0   3
1  10
2  11
```
2124	Extracts the minute component from a datetime column.

This function takes a datetime input and returns an expression that extracts the minute values. It uses pandas' datetime accessor to extract minute information from datetime64 arrays. The function is designed to work with Vaex DataFrames where datetime columns can be accessed via the `.dt` accessor.

Example usage:
```python
import vaex
import numpy as np
date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
df = vaex.from_arrays(date=date)
minutes = df.date.dt.minute  # Returns [31, 17, 34]
```

Returns: An expression containing the minute values extracted from the datetime column with dtype int64.
2125	Extracts the second component from a datetime column.

This function takes a datetime input and returns an expression that extracts the second value (0-59) from each datetime sample. It's designed to work with Vaex dataframes and follows the pandas datetime accessor pattern.

**Parameters:**
- x: datetime data (numpy datetime64 or pandas datetime)

**Returns:**
- Expression containing the second values extracted from the datetime column

**Example:**
```python
>>> import vaex
>>> import numpy as np
>>> date = np.array(['2009-10-12T03:31:00', '2016-02-11T10:17:34', '2015-11-12T11:34:22'], dtype=np.datetime64)
>>> df = vaex.from_arrays(date=date)
>>> df.date.dt.second
# Returns expression with values [0, 34, 22]
```
2126	Capitalize the first letter of each string in the input column, converting the first character to uppercase and the rest to lowercase. Returns a new column with the capitalized strings.
2127	Concatenates two string columns on a row-by-row basis, taking two string expressions as input and returning a new expression with the concatenated results.
2128	Check if a string pattern or regex is contained within a sample of a string column, returning a boolean expression that evaluates to True if the pattern is found and False otherwise.
2129	Count the occurrences of a pattern in a string column.

Parameters:
- x: input string column
- pat: a string or regex pattern to search for
- regex: if True, treat pat as a regular expression

Returns:
an expression containing the number of times the pattern is found in each string element

Example:
```
>>> df.text.str.count(pat="et", regex=False)
```
Returns the count of "et" occurrences in each text element.
2130	Returns the lowest indices in each string where the provided substring is found, or -1 if not found.
2131	Extract a character from each string in a column at the specified index position. If the index is out of bounds, returns empty string instead of NaN. Handles negative indices by counting from the end of strings. Returns a new string column with extracted characters.
2132	Returns the lowest indices in each string where the provided substring is found, or -1 if not found. Equivalent to `str.find`.
2133	Converts string samples to lower case.

:returns: an expression containing the converted strings.

Example:

>>> import vaex
>>> text = ['Something', 'very pretty', 'is coming', 'our', 'way.']
>>> df = vaex.from_arrays(text=text)
>>> df
  #  text
  0  Something
  1  very pretty
  2  is coming
  3  our
  4  way.

>>> df.text.str.lower()
Expression = str_lower(text)
Length: 5 dtype: str (expression)
-----------------------------
0    something
1  very pretty
2    is coming
3          our
4         way.
2134	Remove leading characters from a string column by stripping specified characters from the beginning of each string.

**Parameters:**
- `x`: Input string column
- `to_strip`: String containing characters to remove from the beginning (if None, removes whitespace)

**Returns:**
- New string column with leading characters stripped

**Example:**
```
df.text.str.lstrip(to_strip='very ')  removes 'very ' from start of strings
```
2135	Pad strings in a given column with specified width, side, and fill character.

**Parameters:**
- `x`: Input strings to pad
- `width`: The total width of the resulting string
- `side`: Padding side ('left', 'right', or 'both')
- `fillchar`: Character used for padding (default: space)

**Returns:**
- Expression containing the padded strings

**Example:**
```python
df.text.str.pad(width=10, side='left', fillchar='!')
# Pads strings on the left with '!' to make total width 10
```
2136	Duplicate each string in a column by repeating it a specified number of times.

Parameters:
- x: input string data
- repeats: number of times each string sample is to be duplicated

Returns:
- an expression containing the duplicated strings

Example:
For input text=['Something', 'very pretty', 'is coming'] with repeats=2, returns=['SomethingSomething', 'very prettyvery pretty', 'is comingis coming']
2137	Returns the highest index in each string where the specified substring is found, or -1 if not found. Searches from left to right within the specified range.
2138	Returns the highest indices in each string where the provided substring is fully contained between the start and end positions. If the substring is not found, -1 is returned. Same as `str.rfind`.
2139	Fills the left side of string samples with a specified character such that the strings are left-hand justified.

:param int width: The minimal width of the strings.
:param str fillchar: The character used for filling.
:returns: an expression containing the filled strings.

Example:

>>> import vaex
>>> text = ['Something', 'very pretty', 'is coming', 'our', 'way.']
>>> df = vaex.from_arrays(text=text)
>>> df.text.str.rjust(width=10, fillchar='!')
Expression = str_rjust(text, width=10, fillchar='!')
Length: 5 dtype: str (expression)
---------------------------------
0   !Something
1  very pretty
2   !is coming
3   !!!!!!!our
4   !!!!!!way.
2140	Remove trailing characters from a string column by stripping specified characters from the right side of each string. If no characters are specified, removes trailing whitespace. Returns a modified string column with trailing characters removed.
2141	Slice substrings from each string element in a column using specified start and stop positions.

Args:
    x: Input data containing string elements
    start (int): The start position for the slice operation (default: 0)
    stop (int): The stop position for the slice operation (default: None)

Returns:
    An expression containing the sliced substrings

When stop is None, slices from start position to the end of each string.
When stop is specified, slices from start to stop position (exclusive).
The function supports slicing operations on string columns similar to Python's string slicing.
2142	Removes leading and trailing characters from strings in a column. Strips whitespaces by default or specified characters from both sides of each string. Returns an expression with the modified string samples.
2143	Converts all string samples to titlecase.

Returns an expression containing the converted strings.

Example:
>>> import vaex
>>> text = ['Something', 'very pretty', 'is coming', 'our', 'way.']
>>> df = vaex.from_arrays(text=text)
>>> df.text.str.title()
0    Something
1  Very Pretty
2    Is Coming
3          Our
4         Way.
2144	Converts all strings in a column to uppercase and returns an expression containing the converted strings.
2145	Summary: Attempts to convert a numpy array to the most sensible dtype by first trying float conversion, then integer conversion if all values are whole numbers and within int range, with error handling to return original array on failure.
2146	Convert the object into a numpy record array by creating a structured array with fields corresponding to the object's attributes.
2147	Writes properties to a file in Java properties format, including optional comment and timestamp, handling both dictionary-like objects and iterables of key/value pairs.
2148	Writes a comment to a file in Java properties format, handling multi-line comments by prefixing each continuation line with "#".
2149	Writes a single property key-value pair to a file in Java properties format, handling special COMMENT keys and escaping special characters in keys and values.
2150	Incrementally reads properties from a Java .properties file, yielding key/value pairs. If comments=True, includes comments using jprops.COMMENT in place of the key. Takes a readable file-like object as input and returns tuples of (key, value) pairs with unescaped characters.
2151	Wrap a file to convert newlines regardless of whether the file was opened with the "universal newlines" option or not.
2152	Return the version information for all librosa dependencies.
2153	Handle renamed arguments by checking if the old argument value is of type `Deprecated`. If so, return the new value; otherwise, issue a deprecation warning and return the old value.
2154	Sets the FFT library used by librosa. If no library is specified, reverts to the default numpy.fft implementation. Can be used to switch to alternative FFT libraries like pyfftw by passing their numpy-compatible interface.
2155	Beat tracking function that analyzes audio files to detect beat events and saves the timestamps as a CSV file. Takes an input audio file path and output CSV file path as parameters. Uses librosa library to load audio, perform beat tracking with default hop length of 512 samples, estimates tempo, converts frame numbers to time stamps, and saves the beat times to CSV format.
2156	Summary: The `adjust_tuning` function loads an audio file, separates the harmonic component, estimates the tuning frequency, applies pitch correction to align the tuning, and saves the corrected audio. It prints progress messages and returns the tuned audio file.
2157	Converts frame indices to audio sample indices using the formula: samples = frames * hop_length + offset, where offset accounts for FFT windowing effects when n_fft is provided.
2158	Converts sample indices into STFT frames using the specified hop length and optional FFT window size. Returns frame numbers corresponding to the given sample indices, with optional offset to compensate for windowing effects when n_fft is provided.
2159	Converts time stamps into STFT frames by first converting times to samples and then samples to frames.

Parameters:
- times: time values in seconds
- sr: audio sampling rate (default: 22050)
- hop_length: number of samples between successive frames (default: 512)
- n_fft: optional FFT window length to compensate for windowing effects

Returns:
- Frame numbers corresponding to the given times

Example:
```
time_to_frames(np.arange(0, 1, 0.1), sr=22050, hop_length=512)
# Returns: array([ 0,  4,  8, 12, 17, 21, 25, 30, 34, 38])
```
2160	Convert MIDI numbers to musical note strings with optional octave and cent information. Takes a MIDI number or iterable of numbers and returns corresponding note names like 'C0', 'C#0', etc. Supports fractional MIDI values with cent markers when cents=True. Raises ParameterError if cents are requested without octave information.
2161	Convert frequencies from Hertz to Mel scale using either HTK or Slaney formula. Supports both scalar and array inputs.
2162	Convert mel bin numbers to frequencies using either HTK or Slaney formula. Returns frequencies in Hz corresponding to the input mel bins.
2163	Returns the frequency bins for an FFT window.

This function calculates the frequency values corresponding to the bins of a Fast Fourier Transform (FFT) output. It generates evenly spaced frequencies from 0 to half the sampling rate (Nyquist frequency), which covers the meaningful frequency range for real-valued signals.

Parameters:
sr (number > 0): Audio sampling rate in Hz
n_fft (int > 0): FFT window size in samples

Returns:
numpy.ndarray: Array of frequency values from 0 to sr/2, with shape (1 + n_fft/2,)

Example:
fft_frequencies(sr=22050, n_fft=16) returns [0.    , 1378.125, 2756.25 , 4134.375, 5512.5  , 6890.625, 8268.75 , 9646.875, 11025.   ]
2164	Compute the center frequencies of Constant-Q bins given the number of bins, minimum frequency, bins per octave, and tuning deviation from A440.
2165	Compute an array of acoustic frequencies tuned to the mel scale. The mel scale is a quasi-logarithmic function of acoustic frequency designed such that perceptually similar pitch intervals appear equal in width over the full hearing range. The function supports two implementations: the default Auditory Toolbox implementation (htk=False) and the HTK implementation (htk=True). It returns uniformly spaced frequencies on the Mel axis.
2166	Compute the A-weighting of a set of frequencies using the standard A-weighting formula. Takes frequencies in Hz and returns corresponding weighting values in dB. Optionally clips weights below a specified threshold.
2167	Return an array of time values to match the time axis from a feature matrix. If the input is an ndarray, it represents a feature matrix (e.g., STFT, chromagram, or mel spectrogram); if scalar, it represents the number of frames. The function uses `samples_like` to get sample indices and then converts them to time values using `samples_to_time`.
2168	Return an array of sample indices that correspond to the time axis of a feature matrix.

Parameters:
- X : np.ndarray or scalar - feature matrix or number of frames
- hop_length : int > 0 - number of samples between successive frames (default: 512)
- n_fft : None or int > 0 - optional FFT window length to account for windowing effects
- axis : int - axis representing the time axis of X (default: -1)

Returns:
- samples : np.ndarray - sample indices corresponding to each frame of X

The function works with either a feature matrix input or a scalar representing the number of frames, and returns the corresponding sample indices for time alignment.
2169	Compute the hybrid constant-Q transform of an audio signal, using pseudo CQT for higher frequencies and full CQT for lower frequencies based on filter lengths and hop length.
2170	Compute the pseudo constant-Q transform of an audio signal using a fixed FFT size based on the longest CQT filter and hop length, applying windowing, STFT, and basis projection to produce frequency-time energy representation.
2171	Compute the inverse constant-Q transform of a constant-Q representation.

This function reconstructs an audio time-series from its constant-Q transform representation. It handles multiple octaves of CQT data and applies appropriate resampling and scaling for accurate reconstruction.

Parameters:
- C: Constant-Q representation as produced by `core.cqt`
- sr: Sampling rate of the output audio
- hop_length: Number of samples between successive frames
- fmin: Minimum frequency for the CQT
- bins_per_octave: Number of bins per octave
- tuning: Tuning offset in fractions of a bin
- filter_scale: Filter scale factor for time resolution
- norm: Type of norm to use for basis function normalization
- sparsity: Sparsification factor for the CQT basis
- window: Window specification for basis filters
- scale: Whether to scale by square-root of filter lengths
- length: Target length for the output audio
- amin: Deprecated parameter
- res_type: Resampling mode for reconstruction

Returns:
- y: Reconstructed audio time-series

The function caches at level 40 and handles multi-octave CQT reconstruction with proper scaling and resampling.
2172	Generate frequency domain constant-Q filter basis by creating filters, padding to nearest power of 2, normalizing with respect to FFT window length, computing FFT, and sparsifying the result.
2173	Helper function to trim and stack a collection of CQT responses by:
1. Finding the minimum column length across all responses to avoid framing errors
2. Stacking responses in reverse order with aligned column dimensions
3. Trimming bottom frequencies by keeping only the last n_bins rows
4. Ensuring column-contiguity through transposition operations
2174	Compute the filter response with a target STFT hop by calculating the STFT matrix and applying the filter basis.
2175	Compute the number of early downsampling operations based on nyquist frequency, filter cutoff, hop length, and number of octaves. Returns the minimum of two calculated downsample counts.
2176	Perform early downsampling on an audio signal if applicable, reducing computational load for multi-octave CQT processing.
2177	Calculate the accumulated cost matrix D using dynamic programming for DTW algorithm.

Uses dynamic programming to compute the accumulated costs in matrix D based on the pre-computed cost matrix C, allowed step sizes, and weighting parameters. For each position in the matrices, it evaluates all valid step sizes, calculates the cost considering multiplicative and additive weights, and updates the accumulated cost if a lower cost path is found. The function also tracks which step was used to achieve the minimum cost at each position.

Parameters:
- C: pre-computed cost matrix
- D: accumulated cost matrix (updated in-place)
- D_steps: matrix to store the step indices used for each position (updated in-place)
- step_sizes_sigma: allowed step sizes for DTW
- weights_add: additive weights for penalty
- weights_mul: multiplicative weights for penalty
- max_0, max_1: maximum step sizes in each dimension

Returns:
- D: updated accumulated cost matrix
- D_steps: updated matrix with step indices used for each position
2178	Backtracks the optimal warping path using dynamic time warping step information.

This function reconstructs the optimal alignment path by following stored step indices from the final cost matrix position back to the starting point. It traces the path using allowed step sizes to determine the sequence of index pairs that represent the minimal cost warping path between two sequences.

Parameters:
- D_steps: Array containing stored step indices from cost accumulation
- step_sizes_sigma: Array specifying allowed step sizes for DTW

Returns:
- wp: List of index pairs representing the optimal warping path from end to start

The backtracking starts at the bottom-right corner of the cost matrix and works backwards until reaching the first row, making it suitable for standard DTW and subsequence DTW variants.
2179	Viterbi algorithm implementation for hidden Markov model decoding. Performs in-place computation to find the most likely sequence of hidden states given observation probabilities and transition dynamics. Takes log-space inputs for numerical stability and uses dynamic programming with backtracking to reconstruct the optimal state path.
2180	Viterbi decoding algorithm for discriminative state predictions. Given conditional state probabilities and a transition matrix, it computes the most likely sequence of states. It handles optional marginal state and initial state distributions, and can return either the state sequence or the state sequence along with its log probability.
2181	Construct a uniform transition matrix over `n_states`.

Parameters
----------
n_states : int > 0
    The number of states

Returns
-------
transition : np.ndarray [shape=(n_states, n_states)]
    `transition[i, j] = 1./n_states`

Examples
--------

>>> librosa.sequence.transition_uniform(3)
array([[0.333, 0.333, 0.333],
       [0.333, 0.333, 0.333],
       [0.333, 0.333, 0.333]])
2182	Constructs a self-loop transition matrix with specified self-transition probabilities. Each state has a probability `prob[i]` of staying in the same state, and the remaining probability `(1 - prob[i])` is evenly distributed among all other states. The matrix is useful for modeling locally stable states with no additional structure between states. Supports both scalar probabilities (applied to all states) and per-state probabilities.
2183	Constructs a cyclic transition matrix for a given number of states where each state has a self-transition probability and transitions to the next state with the remaining probability. The matrix is appropriate for cyclical state spaces like musical meter positions.
2184	Construct a localized transition matrix with specified width and window function, where transitions are only allowed within a local range of states. The matrix can be wrapped around or have absolute locality, and supports variable widths per state. Returns a row-normalized matrix suitable for state spaces approximating continuous variables.
2185	Detect note onsets in an audio signal by picking peaks in an onset strength envelope, with options for backtracking, different output units, and custom peak picking parameters.
2186	Compute spectral flux onset strength envelope using mean frequency aggregation. Supports audio time-series or pre-computed spectrogram input, with options for lagged differences, local max filtering, detrending, centering, and custom feature extraction functions. Returns normalized onset strength envelope array.
2187	Backtrack detected onset events to the nearest preceding local minimum of an energy function. This function adjusts onset detection results by aligning them with the closest previous minimum in the energy envelope, which is useful for segmentation tasks. It takes a list of onset frame indices and an energy function, then returns the adjusted onset positions. The backtracking process ensures that onsets are aligned to points of decreasing energy, providing more stable segmentation boundaries. The function internally identifies local minima in the energy function and maps each input onset event to its nearest preceding minimum, with special handling for events that occur before any minimum in the signal.
2188	Compute a spectral flux onset strength envelope across multiple channels, where each channel's onset strength is calculated as the mean of the maximum differences between consecutive time frames in the spectrogram. Supports custom feature extraction, aggregation, and channel slicing.
2189	Save time steps to a CSV file. If only times are provided, each time value is written on its own row. If annotations are provided, each line contains the time value and its corresponding annotation separated by the specified delimiter. The time values are formatted using the provided format string. Raises ParameterError if the lengths of times and annotations don't match when annotations are provided.
2190	Writes a time series as a WAV audio file with optional normalization support for mono or stereo floating-point data.
2191	Get a default colormap from the given data based on its type and range. Returns a black and white colormap for boolean data, sequential colormap for non-negative or non-positive data, and diverging colormap for data with both positive and negative values. Supports robust range calculation by discarding top and bottom 2% of data.
2192	Plot the amplitude envelope of a waveform, supporting both monophonic and stereo signals. Long signals are down-sampled to a maximum number of points for efficient visualization. The function allows customization of plotting parameters such as sampling rate, x-axis formatting, and transparency. It returns a matplotlib PolyCollection object representing the plotted waveform.
2193	Helper function to set the current image in pyplot mode. If no axes object is provided, it sets the current image using matplotlib's pyplot interface.
2194	Compute axis coordinates for different axis types, handling both predefined coordinates and coordinate transformations based on the axis type. Returns the appropriate coordinates for the given axis type and parameters.
2195	Checks if "axes" is an instance of an axis object. If not, uses `gca` to get the current axes. Raises ValueError if axes is not a matplotlib.axes.Axes instance.
2196	Sets the axis scaling for matplotlib axes based on the specified axis type and which axis (x or y) to modify, configuring appropriate scale modes and parameters for different audio-related visualizations like mel, log, CQT, and tempo scales.
2197	Get the frequencies for FFT bins, centered at their frequencies and clipped to non-negative range [0, nyquist].
2198	Get the frequencies for Mel bins, adjusting for Mel scale spacing and ensuring proper boundaries.
2199	Get CQT bin frequencies for coordinate conversion, with optional fundamental frequency and bins per octave parameters.
2200	Get chroma bin numbers using linear spacing from 0 to (12.0 * n) / bins_per_octave with n+1 points.
2201	Get time coordinates from frames by converting frame indices to time values using the specified sampling rate and hop length.
2202	Estimates the tuning deviation of an audio signal or spectrogram input. Takes either time-series audio data or a magnitude spectrogram as input, and returns the estimated tuning in fractions of a bin. Uses parabolic interpolation for pitch tracking and applies a median threshold to filter pitch estimates. The tuning is measured relative to A440Hz and returned as a float in the range [-0.5, 0.5).
2203	Pitch tracking function that computes instantaneous frequencies and magnitudes from audio or spectrogram input using parabolic interpolation on thresholded STFT data, with configurable frequency range, threshold, and reference values for pitch detection.
2204	Decomposes an audio time series into harmonic and percussive components using STFT->HPSS->ISTFT pipeline. Returns two audio time series containing the harmonic and percussive elements respectively, with the same length as the input. Supports additional keyword arguments for customizing the HPSS decomposition.
2205	Extract harmonic elements from an audio time-series by applying HPSS (Harmonic/Percussive Separation) decomposition.

Parameters:
- y: audio time series array
- **kwargs: additional arguments passed to librosa.decompose.hpss

Returns:
- audio time series containing only the harmonic portion

The function computes the Short-Time Fourier Transform, applies HPSS decomposition to isolate harmonic components, and then reconstructs the audio signal using the inverse STFT.
2206	Extract percussive elements from an audio time-series by applying HPSS decomposition and inverse STFT.
2207	Time-stretch an audio series by a fixed rate using phase vocoding. Returns a stretched audio time series where rate > 1 speeds up the signal and rate < 1 slows it down. Raises ParameterError if rate is not positive. Uses STFT and inverse STFT for the stretching operation.
2208	Pitch-shifts an audio time-series by a specified number of half-steps using time-stretching and resampling techniques. The function allows for fractional half-step shifts and customizable bins per octave for microtonal adjustments. It returns a pitch-shifted version of the input audio that maintains the same length as the original.
2209	Remix an audio signal by re-ordering time intervals.

Parameters:
- y: np.ndarray [shape=(t,) or (2, t)] - Audio time series
- intervals: iterable of tuples (start, end) - Interval boundaries in samples
- align_zeros: boolean - If True, aligns interval boundaries to zero-crossings

Returns:
- y_remix: np.ndarray [shape=(d,) or (2, d)] - Remixed audio signal

The function takes an audio signal and reorders its time intervals according to the provided intervals. If align_zeros is True, it aligns the interval boundaries to the nearest zero-crossing in the audio signal. The intervals are specified as tuples of (start, end) sample indices. The function returns the remixed audio signal concatenated along the time axis.
```
2210	Helper function that creates a frame-wise non-silent indicator for audio processing, returning a boolean array indicating which frames contain audio above the silence threshold.
2211	Trim leading and trailing silence from an audio signal based on energy thresholds. Returns the trimmed signal and the start/end sample indices of the non-silent portion.
2212	Split an audio signal into non-silent intervals based on energy thresholding. Takes an audio signal and returns start/end sample indices of non-silent segments. Uses frame-based analysis with configurable parameters for frame length, hop length, and silence threshold. Returns intervals as a numpy array where each row represents [start_sample, end_sample] of a non-silent segment.
2213	Phase vocoder implementation for time-stretching STFT data. Given an STFT matrix D and a speed-up rate, it produces a time-stretched version of the spectrogram by interpolating magnitude and accumulating phase information across time steps. The function supports both speeding up (rate > 1) and slowing down (rate < 1) audio while preserving pitch. It uses linear magnitude interpolation and phase unwrapping to maintain audio quality during the time-stretching process.
2214	Convert an amplitude spectrogram to dB-scaled spectrogram.

This function converts an amplitude spectrogram to decibel (dB) scale by first computing the power spectrum (S) and then applying the power_to_db transformation. It handles both real and complex input arrays, though complex inputs will issue a warning about phase information loss. The conversion applies a minimum threshold and dynamic range limiting.

Parameters:
- S: input amplitude spectrogram (np.ndarray)
- ref: reference level for scaling (scalar or callable)
- amin: minimum threshold for input and reference (float > 0)
- top_db: threshold at top_db below peak (float  0)

Returns:
- S_db: amplitude spectrogram in dB scale (np.ndarray)

See Also:
- power_to_db, db_to_amplitude

Notes:
- Caches at level 30
- For complex input, phase information is discarded
- Equivalent to power_to_db(S**2) but more direct for amplitude data
2215	Helper function to compute or retrieve a magnitude spectrogram from audio time-series or existing spectrogram input, using STFT with specified parameters.
2216	HPSS beat tracking function that loads an audio file, applies harmonic-percussive separation to isolate percussive components, tracks beats using onset strength detection, and saves the beat timestamps as a CSV file.
2217	Decompose a feature matrix using matrix factorization techniques.

Given a spectrogram S, this function computes a decomposition into components and activations such that S  components.dot(activations). By default, non-negative matrix factorization (NMF) is used, but any sklearn.decomposition-style object can be specified.

Parameters:
- S: Input feature matrix (e.g., magnitude spectrogram)
- n_components: Number of desired components (defaults to n_features)
- transformer: sklearn-style decomposition object (defaults to NMF)
- sort: Whether to sort components by ascending peak frequency
- fit: Whether to compute components from S or use pre-computed ones
- **kwargs: Additional arguments passed to the default transformer

Returns:
- components: Matrix of basis elements
- activations: Transformed activation matrix

The function supports custom decomposition methods and optional sorting of components by peak frequency. When sort=True, components and activations are returned in order of ascending peak frequency, though this doesn't modify the transformer's internal parameters.
2218	Filter data using nearest-neighbor aggregation in feature space. This function can be used for de-noising spectrograms or feature matrices by replacing each data point with an aggregate (mean, median, or weighted average) of its nearest neighbors. It supports both standard filtering and non-local means when a recurrence matrix is provided. The filtering is applied along a specified axis of the input array.
2219	Nearest-neighbor filter helper function that applies filtering to observation data using a recurrence matrix. Takes sparse matrix data and applies aggregation operation to neighboring observations, handling cases with no neighbors by preserving original values. Returns filtered data array with same structure as input.
2220	Create a Mel filterbank matrix to convert FFT bins into Mel-frequency bins with specified parameters including sampling rate, number of FFT components, number of Mel bands, frequency limits, and normalization options.
2221	Create a filterbank matrix to convert STFT to chroma.
2222	Decorator function that creates windows with fractional input handling, ensuring:
1. Output length equals ceil(x) for fractional input
2. Values from floor(x) onward are set to 0
3. Integer inputs maintain original behavior
Returns a wrapper function that processes window specifications with the specified fractional handling.
2223	Construct a constant-Q basis using a filter bank. Parameters include sampling rate, minimum frequency, number of bins, bins per octave, tuning, window function, filter scale, padding, normalization type, and data type. Returns time-domain CQT basis filters and their lengths.
2224	Return length of each filter in a constant-Q basis.

Parameters:
----------
sr : number > 0 [scalar]
    Audio sampling rate
fmin : float > 0 [scalar]
    Minimum frequency bin.
n_bins : int > 0 [scalar]
    Number of frequencies.  Defaults to 7 octaves (84 bins).
bins_per_octave : int > 0 [scalar]
    Number of bins per octave
tuning : float in `[-0.5, +0.5)` [scalar]
    Tuning deviation from A440 in fractions of a bin
window : str or callable
    Window function to use on filters
filter_scale : float > 0 [scalar]
    Resolution of filter windows. Larger values use longer windows.

Returns:
-------
lengths : np.ndarray
    The length of each filter.

See Also:
--------
constant_q
librosa.core.cqt
2225	Convert a Constant-Q transform basis to chroma bins by mapping CQT bins to chroma bins, with options for frequency center, bin merging, and base C/A orientation. Returns a transformation matrix for converting CQT to chroma representation.
2226	Get the equivalent noise bandwidth of a window function.

Parameters:
----------
window : callable or string
    A window function, or the name of a window function
n : int > 0
    The number of coefficients to use in estimating the window bandwidth

Returns:
-------
bandwidth : float
    The equivalent noise bandwidth (in FFT bins) of the given window function

Notes:
-----
This function caches at level 10.
2227	Compute a window function with support for strings, tuples, numbers, callables, and pre-computed windows. Wrapper for `scipy.signal.get_window` with additional functionality.
2228	Helper function to construct a multirate filterbank using scipy.signal.iirdesign. Creates multiple band-pass filters with specified center frequencies and sample rates, each designed with given filter parameters (Q factor, passband ripple, stopband attenuation, etc.). Returns filter coefficients and corresponding sample rates. Uses either 'ba', 'sos', or 'zpk' output format depending on flayout parameter. Raises ParameterError for invalid inputs.
2229	Helper function for generating center frequency and sample rate pairs for multirate filterbank implementation. Returns center frequencies and corresponding sample rates based on MIDI note values with tuning adjustment, following Mller's pitch filterbank settings. Uses different sample rates (882, 4410, 22050) for different frequency ranges to optimize computational efficiency.
2230	Helper function for window sum-square calculation that fills overlapping windows of audio data with squared window values, handling boundary conditions where the window extends beyond the signal length.
2231	Compute the sum-square envelope of a window function at a given hop length for estimating modulation effects in short-time Fourier transforms.
2232	Build a two-dimensional diagonal filter for smoothing recurrence or self-similarity matrices, with options for custom slope/angle, zero-mean filtering, and window function specification.
2233	Compute the spectral centroid of a signal.

The spectral centroid represents the weighted mean of frequencies in a spectrogram frame, where each frequency bin is weighted by its magnitude. It indicates the "center of mass" of the spectrum and is commonly used as a feature for audio analysis. The function can accept either a time-series signal or a precomputed magnitude spectrogram. If no spectrogram is provided, it computes one using the Short-Time Fourier Transform (STFT) with specified parameters. Optionally, custom center frequencies can be provided instead of using the default FFT bin frequencies.

Parameters:
- y: audio time series (default: None)
- sr: audio sampling rate (default: 22050)
- S: magnitude spectrogram (default: None)
- n_fft: FFT window size (default: 2048)
- hop_length: hop length for STFT (default: 512)
- freq: center frequencies for spectrogram bins (default: None)
- win_length: window length for STFT (default: None)
- window: window function for STFT (default: 'hann')
- center: whether to center pad the signal (default: True)
- pad_mode: padding mode for centering (default: 'reflect')

Returns:
- centroid: array of centroid frequencies with shape (1, t) where t is the number of frames

Raises:
- ParameterError: if input is not real-valued or contains negative energies

Examples:
- From time-series: cent = librosa.feature.spectral_centroid(y=y, sr=sr)
- From spectrogram: cent = librosa.feature.spectral_centroid(S=S)
- With variable frequencies: cent = librosa.feature.spectral_centroid(S=np.abs(D), freq=if_gram)
2234	Compute the spectral roll-off frequency for each frame of a spectrogram. The roll-off frequency is defined as the center frequency where a specified percentage of the total energy of the spectrum is contained in that bin and all bins below it. This can be used to approximate maximum or minimum frequencies by adjusting the roll_percent parameter. Returns an array of roll-off frequencies for each frame.
2235	Compute spectral flatness, a measure that quantifies how noise-like a sound is compared to being tone-like. Returns values in [0, 1], where values close to 1.0 indicate noise-like characteristics.
2236	Get polynomial coefficients by fitting an nth-order polynomial to the columns of a spectrogram.
2237	Compute the zero-crossing rate of an audio time series by framing the signal and calculating the fraction of zero crossings in each frame.
2238	Compute a chromagram from a waveform or power spectrogram using chroma filter bank. Supports various input options including audio time series, power spectrogram, and additional parameters for tuning and normalization. Returns normalized energy for each chroma bin at each frame.
2239	Constant-Q chromagram computation method that converts audio time series into a chromagram using constant-Q transform. Takes audio signal or pre-computed CQT as input, maps it to chroma bins, applies thresholding for sparsity, and normalizes the result. Supports both full and hybrid CQT modes with configurable parameters for frequency range, chroma bins, and normalization.
2240	Compute a mel-scaled spectrogram from audio time-series or a pre-computed spectrogram. If input is audio, its magnitude spectrogram is computed first and then mapped to mel scale using a mel filter bank. If input is already a spectrogram, it's directly mapped to mel scale. Supports various STFT parameters and mel filter bank arguments. Returns mel spectrogram as a numpy array.
2241	Jaccard similarity between two intervals

Parameters
----------
int_a, int_b : np.ndarrays, shape=(2,)

Returns
-------
Jaccard similarity between intervals
2242	Find the best Jaccard match from query to candidates by iterating through candidates and returning the index of the candidate with the highest Jaccard similarity score.
2243	Numba-accelerated interval matching algorithm that finds overlapping intervals between two sets of intervals. For each interval in `intervals_from`, it identifies overlapping intervals in `intervals_to` using binary search on sorted start/end positions. When strict matching is enabled and no overlaps are found, it raises a ParameterError; otherwise, it returns the closest non-overlapping interval based on distance. Returns an array of indices mapping from input intervals to matching target intervals.
2244	Match time intervals from one array to another based on Jaccard similarity, with options for strict or non-strict matching modes.
2245	Match events from one array to another by finding the nearest target events. This function is useful for aligning events such as beats to onsets or frame-aligned events to zero-crossings. It returns an array of indices mapping each source event to its closest target event based on minimum distance. The matching can be constrained to only allow matches to the left, right, or both sides of source events. A target event may be matched to multiple source events. The function raises ParameterError if the input arrays are empty or if the matching constraints cannot be satisfied.
2246	Harmonic salience function that computes overall harmonic energy at each frequency by interpolating harmonics and applying optional weighting and peak filtering. Takes input time-frequency representation and corresponding frequencies, interpolates harmonics using specified interpolation type, applies optional weights and aggregation function (default weighted average), and optionally filters to only peak frequencies. Returns array with same shape as input showing harmonic salience across frequencies.
2247	The `interp_harmonics` function computes energy values at specified harmonics (including sub-harmonics) of a frequency-based energy representation such as spectrograms or tempograms. It takes an input array `x`, corresponding frequency values `freqs`, and a list of harmonic ratios `h_range`, then returns a new array where each slice along the first axis corresponds to the energy at a specific harmonic. The function supports interpolation methods from `scipy.interpolate.interp1d` and handles both 1D and 2D frequency arrays. It's useful for preparing harmonic structures for salience computations and can be applied to various time-frequency representations.
2248	Populates a harmonic tensor from a time-frequency representation by interpolating input energy across specified harmonics and frequencies. Takes input energy array `x`, frequency values `freqs`, and a range of harmonics `h_range`, then fills the output array `harmonic_out` with interpolated values at harmonic multiples of frequencies. Supports both integer harmonics (overtones) and fractional harmonics (subharmonics) with configurable interpolation type and boundary handling.
2249	Populate a harmonic tensor from a time-frequency representation with time-varying frequencies by computing harmonics along a specified axis using 1D harmonic computation for each slice.
2250	Load an audio file as a floating point time series with optional resampling, mono conversion, and audio cropping. Supports various audio codecs through soundfile or audioread libraries. Returns the audio time series and its sampling rate.
2251	Load an audio buffer using audioread with specified offset and duration. Reads audio in blocks, concatenates results, and handles sample rate conversion. Returns audio data and native sample rate.
2252	Force an audio signal down to mono by converting stereo to monophonic time-series.

Parameters:
----------
y : np.ndarray [shape=(2,n) or shape=(n,)]
    audio time series, either stereo or mono

Returns:
-------
y_mono : np.ndarray [shape=(n,)]
    `y` as a monophonic time-series

Notes:
-----
This function caches at level 20.

Examples:
--------
>>> y, sr = librosa.load(librosa.util.example_audio_file(), mono=False)
>>> y.shape
(2, 1355168)
>>> y_mono = librosa.to_mono(y)
>>> y_mono.shape
(1355168,)
2253	Resample a time series from orig_sr to target_sr using specified resampling method.

Parameters:
- y: audio time series (mono or stereo)
- orig_sr: original sampling rate
- target_sr: target sampling rate
- res_type: resampling method ('kaiser_best', 'kaiser_fast', 'fft', 'scipy', 'polyphase')
- fix: adjust length of resampled signal
- scale: scale resampled signal to preserve energy
- kwargs: additional arguments for fix_length

Returns:
- Resampled audio time series with target sampling rate

Raises:
- ParameterError: for polyphase resampling with non-integer sampling rates

Notes:
- Caches at level 20
- Uses resampy by default for high-quality resampling
- Supports integer sampling rates for polyphase method
- Maintains input data type and contiguity
2254	Bounded auto-correlation computation along a specified axis of an input array.

Parameters:
- y: np.ndarray - array to autocorrelate
- max_size: int > 0 or None - maximum correlation lag (defaults to array size if unspecified)
- axis: int - axis along which to autocorrelate (default is -1, last axis)

Returns:
- z: np.ndarray - truncated autocorrelation of y along specified axis, with shape bounded by max_size

The function computes auto-correlation by:
1. Computing power spectrum via FFT
2. Converting back to time domain via inverse FFT
3. Slicing result to maximum size
4. Returning real component if input is real-valued

Example usage:
- Full auto-correlation: autocorrelate(y)
- Limited lag auto-correlation: autocorrelate(y, max_size=100)
2255	Computes Linear Prediction Coefficients using Burg's method for a given time series and filter order.
2256	Returns a signal with click sounds placed at specified time or frame positions. Supports custom click signals, frequencies, and durations, and can synchronize with audio data of specific length.
2257	Returns a pure tone signal as a cosine wave with specified frequency, sampling rate, duration, and phase offset. Supports specifying either signal length or duration, with length taking priority when both are provided. Raises ParameterError if frequency is not provided or neither length nor duration are specified.
2258	Generates a chirp signal that sweeps from `fmin` to `fmax` frequencies. The signal can be either linear or exponential in sweep type, and can be specified by either `duration` or `length`. Returns a numpy array containing the synthesized chirp signal. Raises `ParameterError` if required parameters are missing.
2259	Helper function to get files with specified extensions from a directory.
2260	Phase-vocoder time stretch demo function that loads an audio file, stretches it to a specified speed factor, and saves the output. Takes an input file path, output file path, and speed factor (must be > 0) as parameters. Uses librosa's effects.time_stretch for the stretching operation and librosa.output.write_wav for saving the result.
2261	This function uses argparse to define and parse command-line arguments for a time stretching program. It accepts an input audio file path, an output audio file path, and an optional speed parameter (defaulting to 2.0). The function returns a dictionary containing the parsed arguments.
2262	HPSS demo function that separates harmonic and percussive components from an input audio file using librosa's hpss effect, then saves them as separate wav files. Takes input file path and two output file paths as parameters.
2263	Beat tracking using dynamic programming to detect beats in audio signals. It estimates tempo from onset correlation and picks peaks consistent with the estimated tempo. Input can be raw audio or pre-computed onset envelope. Returns estimated tempo (BPM) and beat locations in specified units (frames, samples, or time).
2264	Internal function that tracks beats in an onset strength envelope by computing local scores, running dynamic programming, reconstructing the beat path, and trimming spurious beats.
2265	Constructs the local score for an onset envelope and given period by convolving the normalized onset envelope with a Gaussian window.
2266	**Summary:**

`__beat_track_dp` implements a dynamic programming algorithm for beat tracking. It takes a local score, period, and tightness parameter to find the optimal beat sequence. The function maintains cumulative scores and backlinks to reconstruct the best beat path. It uses a time window to constrain previous beat candidates and applies a scoring mechanism biased toward the expected period. The algorithm handles edge cases like the first beat and invalid tightness parameters. Returns the backlink array for path reconstruction and cumulative scores for each time step.
2267	Get the last beat from the cumulative score array by finding local maxima, determining the median score at those maxima, and returning the maximum index where the product of cumulative score, maxima indicator, and 2 exceeds the median score.
2268	Convert a recurrence matrix into a lag matrix by transforming coordinates along a specified axis. If `pad=True`, the output is padded with zeros to eliminate the assumption of signal repetition; if `pad=False`, the output is square. Supports both dense and sparse matrices. Raises `ParameterError` for non-square input matrices. Returns the lag matrix in (lag, time) or (time, lag) format depending on the axis.
2269	Convert a lag matrix into a recurrence matrix by rolling lag coordinates back into time coordinates, preserving sparse format if input is sparse.
2270	Wrapper function that applies a given filtering function in the time-lag domain rather than time-time domain, useful for filtering recurrence matrices by converting them to time-lag representation, applying the filter, and converting back to time-time representation.
2271	Sub-divide a segmentation by feature clustering. Given frame boundaries and a data matrix, each interval defined by the boundaries is partitioned into a specified number of segments using constrained agglomerative clustering. If an interval has fewer frames than the number of segments, each frame becomes a sub-segment. Returns an array of sub-divided segment boundaries.
2272	Bottom-up temporal segmentation using temporally-constrained agglomerative clustering to partition data into k contiguous segments. Takes data array, number of segments k, optional clusterer object, and axis for clustering. Returns boundaries of detected segments as frame numbers. Uses sklearn's AgglomerativeClustering with temporal connectivity constraints by default.
2273	Multi-angle path enhancement for self- and cross-similarity matrices using diagonal smoothing filters at multiple tempo ratios, convolving the input matrix with filters and returning the element-wise maximum of the results.
2274	Onset detection function that takes an audio file as input and detects onsets (attack times) using librosa's onset detection algorithm. The function loads the audio file at 22.050 KHz sample rate, applies onset detection with a hop length of 512 frames (~23ms), converts frame numbers to time timestamps, and saves the onset times as a CSV file. The function prints progress messages during loading, detection, and saving operations.
2275	Slice a time series into overlapping frames using stride manipulation to avoid redundant copies. Takes a 1D numpy array `y` and frames it with specified `frame_length` and `hop_length`. Returns an array of shape (frame_length, n_frames) where each column is a frame from `y`. Raises `ParameterError` for invalid inputs including non-contiguous arrays, incorrect dimensions, insufficient buffer size, or invalid hop lengths.
2276	Validate whether a variable contains valid, mono audio data. Raises ParameterError if y is not a numpy.ndarray, not floating-point, has invalid dimensions for mono/stereo audio, or contains non-finite values. Returns True if all validation tests pass.
2277	Summary: `valid_int(x, cast=None)` ensures a value is integer-typed by casting it after an optional transformation function (defaulting to `np.floor`). It validates that the transformation function is callable and returns the integer result of `int(cast(x))`, raising a `ParameterError` if the cast parameter is not callable.
2278	Fix the length of an array to exactly `size` by either trimming or padding along the specified axis. If the array is longer than `size`, it is trimmed; if shorter, it is padded according to the provided kwargs (defaulting to zero padding). Returns the adjusted array with the specified shape.
2279	Sort an array along its rows or columns by computing sorting values along a specified axis. Returns the sorted array and optionally the sorting indices. Supports custom sorting functions and works only with 2D arrays.
2280	Normalize an array along a specified axis using various norms (l-infinity, l1, l2, etc.). Supports thresholding small-norm slices by leaving them unchanged, setting to zero, or filling with uniform values that normalize to 1. Handles edge cases like zero norms and invalid inputs with appropriate error messages.
2281	Find local maxima in an array along a specified axis. An element is considered a local maximum if it's strictly greater than the previous element and greater than or equal to the next element. The first element is never considered a local maximum. Returns a boolean array indicating local maxima positions.
2282	Uses a flexible heuristic to pick peaks in a signal based on local maxima, average thresholding, and temporal spacing constraints. Returns indices of detected peaks.
2283	Sparsifies a matrix by setting small magnitude elements to zero in each row, based on a specified quantile threshold. For each row, it computes the cumulative sum of sorted magnitudes and zeros out elements below the threshold. Returns a sparse CSR matrix with the same shape as the input. Supports inputs with 1 or 2 dimensions, raises ParameterError for invalid inputs or quantile values outside [0, 1.0).
2284	Sparse matrix roll operation that shifts elements along a specified axis, equivalent to numpy.roll but for sparse matrices. Returns a new sparse matrix with the same format as input, handling edge cases like shift values larger than matrix dimensions and supporting axes 0, 1, and -1. For non-sparse inputs, falls back to numpy.roll.
2285	Convert an integer buffer to floating point values for audio data processing. Takes integer-valued waveform data and converts it to float32 format by scaling based on the number of bytes per sample. Returns the rescaled floating point array.
2286	Convert an index array into a list of slice objects, with optional padding to span a specified range and step size.
2287	Synchronizes aggregation of multi-dimensional array data along specified boundaries or slices, optionally padding indices to cover full range. Returns aggregated data with reduced dimension along the specified axis.
2288	Compute a softmask operation robustly. For finite power values, returns `X**power / (X**power + X_ref**power)` with numerical stability. For infinite power, returns a hard (binary) mask `X > X_ref`. Handles edge cases like negative inputs, shape mismatches, and zero values with configurable behavior.
2289	Compute the tiny-value (smallest positive usable number) for an input's data type. Returns the smallest representable positive number for floating-point inputs, or the tiny value for float32 if the input is integer-typed. Primarily useful for numerical underflow thresholds in division or multiplication operations.
2290	Convert a sequence of frame images in a directory into a video file with specified parameters including FPS, codec, and frame range.
2291	Read the next frame from video capture, using cache when possible. Returns the frame as ndarray or None if unsuccessful.
2292	Get frame by index from video capture.

Args:
    frame_id (int): Index of the expected frame, 0-based.

Returns:
    ndarray or None: Return the frame if successful, otherwise None.

Raises:
    IndexError: If frame_id is out of range [0, frame_cnt-1].
2293	Convert a video to frame images by saving each frame as a separate image file in the specified directory, with options to control starting frame, maximum number of frames, filename formatting, and progress display.
2294	Track the progress of tasks execution with a progress bar and return the task results.
2295	Track the progress of parallel task execution with a progress bar using multiprocessing pool.
2296	Flips an image horizontally or vertically based on the specified direction. Takes an image array and a direction string ('horizontal' or 'vertical') as input, and returns the flipped image array. Uses numpy's flip function with appropriate axis parameter (1 for horizontal, 0 for vertical).
2297	Rotates an image by a specified angle around a given center point with optional scaling and border value adjustment. The function uses OpenCV's rotation matrix and affine warping to perform the rotation, with an option to automatically adjust image bounds to contain the entire rotated image. Returns the rotated image as a numpy array.
2298	Clip bounding boxes to fit within image boundaries by constraining their coordinates to the image dimensions.
2299	Scale bounding boxes by a given factor w.r.t. their center, with optional clipping to specified boundaries.
2300	Crop image patches from given bounding boxes with optional scaling and padding.

Steps:
1. Scale the bounding boxes by the given ratio
2. Clip bounding boxes to image dimensions
3. Crop image patches and apply padding if specified

Args:
- img: Input image to crop from
- bboxes: Bounding box coordinates (k, 4) or (4, ) format
- scale: Scaling factor for bounding boxes (default: 1.0)
- pad_fill: Padding value(s) for areas outside image bounds (default: None)

Returns:
- Cropped image patches as list or single ndarray depending on input bbox dimensions

The function handles both single and multiple bounding boxes, applies proper scaling and clipping, and supports padding with specified fill values.
2301	Pad an image to a certain shape by filling padding areas with specified values.
2302	Pad an image to ensure each edge length is a multiple of the specified divisor by calculating the required padding dimensions and applying the padding using the impad function.
2303	Rescales a width-height size tuple by a given scaling factor, returning a new size tuple with integer values.
2304	Resize image to a given size with optional scale factors.

Args:
    img (ndarray): The input image
    size (tuple): Target (w, h)
    return_scale (bool): Whether to return `w_scale` and `h_scale`
    interpolation (str): Interpolation method ("nearest", "bilinear", "bicubic", "area", "lanczos")

Returns:
    tuple or ndarray: (`resized_img`, `w_scale`, `h_scale`) or `resized_img`
2305	Resize image to the same size as a given target image.

Args:
    img (ndarray): The input image.
    dst_img (ndarray): The target image.
    return_scale (bool): Whether to return `w_scale` and `h_scale`.
    interpolation (str): Same as :func:`resize`.

Returns:
    tuple or ndarray: (`resized_img`, `w_scale`, `h_scale`) or `resized_img`.
2306	Resize image while keeping the aspect ratio.

Args:
    img (ndarray): The input image.
    scale (float or tuple[int]): The scaling factor or maximum size.
        If it is a float number, then the image will be rescaled by this
        factor, else if it is a tuple of 2 integers, then the image will
        be rescaled as large as possible within the scale.
    return_scale (bool): Whether to return the scaling factor besides the
        rescaled image.
    interpolation (str): Same as :func:`resize`.

Returns:
    ndarray: The rescaled image.
2307	Register a handler for specified file extensions, validating that the handler is a BaseFileHandler instance and file formats are strings or lists of strings, then store the handler in the file_handlers dictionary indexed by each file extension.
2308	Get priority value from integer, Priority enum, or string representation.

Args:
    priority (int or str or :obj:`Priority`): Priority value to convert

Returns:
    int: The numeric priority value (0-100)

Raises:
    ValueError: If integer priority is outside 0-100 range
    TypeError: If priority is not integer, string, or Priority enum type
2309	Dequantize an array by converting quantized values back to floating-point range.

Args:
    arr (ndarray): Input array to be dequantized
    min_val (scalar): Minimum value for clipping and output range
    max_val (scalar): Maximum value for clipping and output range
    levels (int): Number of quantization levels used
    dtype (np.type): Data type for the output array (default: np.float64)

Returns:
    ndarray: Dequantized array with values scaled back to the original range [min_val, max_val]

The function performs inverse quantization by:
1. Clipping input values to valid range
2. Adding 0.5 offset for proper rounding
3. Scaling by (max_val - min_val) / levels 
4. Shifting by min_val to map to correct range

Raises:
    ValueError: If levels is not a positive integer or min_val >= max_val
2310	Displays an image in a window using OpenCV, with optional window name and wait time for key input.
2311	Draw bounding boxes on an image with specified colors, thickness, and display options.

**Parameters:**
- `img` (str or ndarray): Image to draw on
- `bboxes` (list or ndarray): Bounding boxes coordinates in (x1, y1, x2, y2) format
- `colors` (list[str or tuple or Color]): Colors for each set of bounding boxes
- `top_k` (int): Plot first k boxes only (negative for all)
- `thickness` (int): Line thickness for bounding boxes
- `show` (bool): Whether to display the image
- `win_name` (str): Window name for display
- `wait_time` (int): Wait time for display
- `out_file` (str): Output file path

**Returns:**
- None (displays image and/or saves to file)

**Notes:**
- Supports multiple sets of bounding boxes with different colors
- Automatically handles image loading and drawing operations
- Bounding box coordinates are converted to integers for pixel accuracy
- Can limit number of boxes drawn using top_k parameter
- Uses OpenCV for drawing rectangles on the image
- Returns the modified image after drawing operations
2312	Read an optical flow map from either a numpy array or file path, supporting both regular and quantized flow formats. Returns a (h, w, 2) numpy array representing the optical flow.
2313	Writes optical flow to file, either as a lossless .flo file or as quantized JPEG images. If quantize=False, saves flow in .flo format with specified dimensions and data type. If quantize=True, quantizes the flow using quantize_flow() and concatenates dx and dy components before saving as JPEG. Supports concatenating along either axis 0 or 1 when quantizing.
2314	Recover from quantized flow by dequantizing dx and dy arrays and optionally normalizing with image dimensions.

Args:
    dx (ndarray): Quantized dx.
    dy (ndarray): Quantized dy.
    max_val (float): Maximum value used when quantizing.
    denorm (bool): Whether to multiply flow values with width/height.

Returns:
    ndarray: Dequantized flow.
2315	Loads a state_dict into a module, with optional strict checking and logging. Modified from torch.nn.Module.load_state_dict to default strict=False and always show param mismatch messages. Handles parameter copying, tracks missing/unexpected keys, and provides error handling with optional logger support.
2316	Load checkpoint from a file or URI, supporting modelzoo, URL, and local file formats. Returns the loaded checkpoint dictionary.
2317	Copy a model state_dict to cpu.

Args:
    state_dict (OrderedDict): Model weights on GPU.

Returns:
    OrderedDict: Model weights on CPU.
2318	Save a model checkpoint to file with model state dict, optional optimizer state dict, and metadata containing version and timestamp information.
2319	Initializes an optimizer object from a dictionary or returns the optimizer if it's already an optimizer object. Takes an optimizer configuration dict or optimizer instance and returns a torch.optim.Optimizer object. Raises TypeError if the input is neither a dict nor an optimizer object.
2320	Initialize a logger with optional file output.

Args:
    log_dir (str, optional): Log file directory. If not specified, no log file will be used.
    level (int or str): Logging level.

Returns:
    logging.Logger: Python logger object.
2321	Get current learning rates.

Returns:
    list: Current learning rate of all param groups.

Raises:
    RuntimeError: If optimizer does not exist.
2322	Register a hook into the hook list with specified priority, inserting it in the correct position to maintain priority order.
2323	Start running the training process with specified data loaders, workflow, and maximum epochs. The workflow defines the running order and number of epochs for each phase (e.g., train, val). The method iterates through the workflow phases, executes the corresponding epoch runner for the specified number of epochs, and calls hooks before and after the run. It ensures the training does not exceed the maximum epochs and waits for hooks to finish before exiting.
2324	Registers default hooks for training including LrUpdaterHook, OptimizerStepperHook, CheckpointSaverHook, IterTimerHook, and LoggerHook(s).
2325	Convert a video using ffmpeg with specified options.

This function provides a general API to ffmpeg for video conversion. It constructs an ffmpeg command by mapping keyword arguments to ffmpeg command-line options according to specific rules, then executes the command.

The command format is: `ffmpeg -y <pre_options> -i <in_file> <options> <out_file>`

Options are mapped as follows:
- key=val  "-key val"
- key=True  "-key" 
- key=False  "" (omitted)

Args:
    in_file (str): Input video filename
    out_file (str): Output video filename  
    pre_options (str): Options that appear before "-i <in_file>"
    print_cmd (bool): Whether to print the final ffmpeg command
    **kwargs: Additional ffmpeg options to be passed through

Returns:
    None (executes subprocess.call to run ffmpeg)

Example:
    convert_video('input.mp4', 'output.avi', vcodec='libx264', acodec='aac')
    # Executes: ffmpeg -y -i input.mp4 -vcodec libx264 -acodec aac output.avi
2326	Resize a video by specifying either a target size or resize ratio.

Args:
    in_file (str): Input video filename
    out_file (str): Output video filename
    size (tuple): Expected size (w, h), eg, (320, 240) or (320, -1)
    ratio (tuple or float): Expected resize ratio, (2, 0.5) means (w*2, h*0.5)
    keep_ar (bool): Whether to keep original aspect ratio
    log_level (str): Logging level of ffmpeg
    print_cmd (bool): Whether to print the final ffmpeg command

The function requires either size or ratio to be specified, but not both. If size is provided, the video will be scaled to the exact dimensions. If ratio is provided, the video will be scaled by the given factors. When keep_ar is True, the original aspect ratio is maintained by scaling to fit within the specified dimensions.
2327	Cut a clip from a video by specifying start and end times, with optional codec changes. Supports logging and command printing.
2328	Concatenate multiple videos into a single one using ffmpeg's concat demuxer. Takes a list of video filenames and combines them into one output video file, preserving video and audio codecs by default. Uses a temporary file to specify the input video sequence for ffmpeg.
2329	Load a text file and parse the content as a list of strings, with optional prefix, offset, and maximum number of lines to read.
2330	Load a text file and parse its content as a dictionary where each line contains a key followed by one or more values separated by whitespace or tabs. The first column becomes the dictionary key (converted to the specified key_type), and the remaining columns become the dictionary value(s). Returns the parsed dictionary.
2331	Creates a 3x3 convolutional layer with specified input and output channels, padding, and dilation parameters.
2332	Initialize an object from a dictionary by extracting the 'type' key to determine the object type and using remaining fields as constructor arguments. Supports both string type names (with optional parent module) and direct type objects, with optional default arguments for initialization.
2333	Read an image from a file path or return a numpy array directly.

Args:
    img_or_path (ndarray or str): Either a numpy array or image path. If it is a numpy array, it will be returned as is.
    flag (str): Flags specifying the color type of a loaded image, candidates are 'color', 'grayscale' and 'unchanged'.

Returns:
    ndarray: Loaded image array.

Raises:
    TypeError: If 'img' is neither a numpy array nor a filename.
2334	Read an image from bytes using OpenCV's imdecode function, converting the byte content to a numpy array and decoding it based on the specified flag (color, grayscale, etc.). Returns the loaded image as a numpy array.
2335	Write image array to file using OpenCV's imwrite function, with optional automatic directory creation.
2336	Convert a BGR image to grayscale image, optionally keeping the output dimension. Returns the converted grayscale image.
2337	Converts a grayscale image to BGR format by first ensuring the image has proper dimensions and then using OpenCV's color conversion function.
2338	Cast elements of an iterable object into some type.

Args:
    inputs (Iterable): The input object.
    dst_type (type): Destination type.
    return_type (type, optional): If specified, the output object will be converted to this type, otherwise an iterator.

Returns:
    iterator or specified type: The converted object.
2339	Check whether a sequence is of some expected type.

Args:
    seq (Sequence): The sequence to be checked.
    expected_type (type): Expected type of sequence items.
    seq_type (type, optional): Expected sequence type.

Returns:
    bool: Whether the sequence is valid.
2340	Slice a list into several sublists by a list of given lengths.

Args:
    in_list (list): The list to be sliced.
    lens (int or list): The expected length of each output list.

Returns:
    list: A list of sliced sublists.

Raises:
    TypeError: If lens is not a list of integers.
    ValueError: If the sum of lens does not match the length of in_list.
2341	A decorator factory that checks if specified prerequisites are satisfied before executing a function. It takes a list of prerequisites and a checker function, then validates each prerequisite using the checker. If any prerequisites are missing, it prints an error message and raises a RuntimeError. Otherwise, it executes the original function.
2342	Computes the weighted average of the latest `n` values (or all values if `n=0`) for each key in `val_history` using corresponding weights from `n_history`, storing the results in `output`. Sets `ready` flag to `True`.
2343	Scatters a tensor or list of tensors across multiple GPUs. For tensors, it moves the tensor to the specified device using CUDA with non-blocking transfer. For lists, it recursively scatters elements across devices in chunks. Uses specified CUDA streams for asynchronous operations, with a default stream if none provided. Raises exception for unknown input types.
2344	Convert various input types (Color enum, string, tuple, int, numpy array) to standardized BGR color tuples of 3 integers.
2345	Add check points in a single line for timing measurement. Registers a timer when first called with a given identifier and returns elapsed time since last check point.
2346	Starts the timer if it's not already running, records the start time, and updates the last recorded time.
2347	Returns the total time elapsed since the timer was started in seconds. Raises TimerError if the timer is not running.
2348	Time since the last checking operation in seconds. Raises TimerError if timer is not running. Updates the last check time before returning the duration.
2349	Show optical flow by reading optical flow data, converting it to RGB visualization, and displaying it in a window.
2350	Convert optical flow map to RGB visualization image using a color wheel mapping. Handles invalid values by marking them as zero and normalizes flow magnitudes for proper color mapping. Returns an RGB image suitable for visualization.
2351	Creates a color wheel representation with specified bins for each color range. Returns a numpy array of shape (total_bins, 3) representing RGB colors in the wheel.
2352	Computes the top-k accuracy for given output and target tensors. Returns a list of accuracy percentages for each specified k value.
2353	Scatter inputs to target GPUs with support for DataContainer types. The function recursively distributes tensors and DataContainer objects across multiple GPUs along a specified dimension, handling different data structures (tuples, lists, dicts) while avoiding reference cycles through proper cleanup of the scatter_map function.
2354	Scatter function with kwargs support that distributes inputs and kwargs across multiple GPUs by splitting them along a specified dimension, ensuring both inputs and kwargs have matching lengths by padding with empty tuples/dictionaries as needed.
2355	Fetch all information using aiohttp with timeout handling, encoding support, and retry mechanism. Returns a Response object with request details or retries on failure.
2356	Read and decodes JSON response.
2357	Read response payload and decode.
2358	Process coroutine callback function with error handling for NothingMatchedError and other exceptions.
2359	Async generator that handles multiple HTTP requests either concurrently using asyncio.gather() or sequentially. When is_gather=True, it processes all URLs concurrently and yields responses in order while handling exceptions. When is_gather=False, it processes URLs sequentially and yields responses one by one. Each response gets an added 'index' attribute indicating its position in the original URL list.
2360	Creates and returns a Request object for crawling HTML by combining various configuration options with default values from the instance.
2361	Starts the crawling process by initializing requests from start URLs, creating worker tasks, and managing the request queue until completion.
2362	Normalizes a task by parsing its arguments, ensuring it has an action key, and converting strings to Python objects. Handles parsing errors by providing detailed error information including file and line number. Processes special cases like shell command conversion and raw parameters, then constructs a normalized result dictionary with module action information and arguments.
2363	Parses YAML data with line number information added to each node, storing the line number in a LINE_NUMBER_KEY field and including the filename in a FILENAME_KEY field. Uses Ansible's YAML loader with custom composition and construction methods to track line numbers during parsing. Raises SystemExit with descriptive error message if YAML parsing fails.
2364	Return distribution full name with hyphens replaced by underscores by joining the safer name and version with a hyphen.
2365	Return archive name without extension by combining wheel distribution name with implementation tag, ABI tag, and platform tag.
2366	Add additional requirements from setup.cfg to file metadata_path, handling potential overwrites and updating package information accordingly.
2367	Converts an .egg-info directory into a .dist-info directory by copying relevant metadata, handling file vs directory cases, removing unnecessary files, and writing METADATA and metadata.json files.
2368	Returns a simple text message activity with optional SSML speech hint and input hint settings.
2369	Returns a message activity with suggested actions and optional text/speak content. Takes a list of CardAction objects and optional text/speak parameters, returning an Activity object configured with the specified suggested actions and optional metadata. The returned activity can be sent to a user to present them with a set of interactive options.
2370	Returns a single message activity containing an attachment using the attachment_activity function with list layout.
2371	Returns a message activity that displays a set of attachments in list form, using the specified attachments and optional text, speech, and input hint parameters.
2372	Returns a message that will display a single image or video to a user.
2373	Creates a trace activity based on the provided turn activity with specified name, value, value_type, and label properties.
2374	Sets the telemetry client for logging events, using a NullTelemetryClient if the provided value is None.
2375	Read storeitems from storage by querying Cosmos DB using provided keys and return a dictionary mapping realIds to StoreItems.
2376	Async method to save StoreItems to storage with support for upsert and optimistic concurrency control using ETags. It creates database and container if they don't exist, sanitizes keys, and handles both new document insertion (when ETag is '*' or missing) and updates (when ETag is present) with proper error handling.
2377	Remove storeitems from storage for the given keys. Creates database and container if they don't exist. Handles HTTP failures except for 404 errors. Raises TypeError if encountered.
2378	Create a StoreItem from a CosmosDB result by extracting the document, adding the e_tag, and initializing a StoreItem with the document data.
2379	Create a dictionary representation of a StoreItem by filtering out magic attributes (except e_tag) and returning key-value pairs of the remaining attributes.
2380	Return the sanitized key by replacing forbidden characters (\, ?, /, #, \t, \n, \r) with '*' followed by the Unicode code point of the character.
2381	Creates a database and container by calling get or create methods using the client, database ID from config, and container name from config.
2382	Return the database link by checking if database exists, if not create it.
2383	Return the container link by checking if the container exists or creating it if it doesn't. Query CosmosDB for a container with the given name, and if found, return its ID. If not found, create a new container with that name and return its ID.
2384	Fills event properties and metrics for QnaMessage telemetry event, including knowledge base ID, question text, username (if personal information logging is enabled), and QnA results details. Returns EventData containing properties and metrics that will be sent to BotTelemetryClient.track_event() method.
2385	Returns a ConversationReference object containing the essential identifying information from an activity, which can be serialized to JSON and used later for proactive messaging. The reference includes activity ID, user, bot, conversation details, channel ID, and service URL.
2386	Returns a unique name for a waterfall step based on its index. If the step's qualified name is invalid or contains ">", a default name format "StepXofY" is used instead.
2387	Determine if a channel supports a specified number of suggested actions by checking against predefined limits for each channel. Returns True if the channel supports the given number of actions, False otherwise.
2388	Determine if a channel supports a specified number of card actions.

Args:
    channel_id (str): The channel to check support for.
    button_cnt (int, optional): The number of card actions to check for support. Defaults to 100.

Returns:
    bool: True if the channel supports the specified number of card actions, False otherwise.
2389	Get the Channel Id from the current Activity on the Turn Context.
Returns the Channel Id from the Turn Context's Activity, or empty string if not present.
2390	Determines if a given authentication header is from the Bot Framework Emulator by validating the token format, bearer scheme, and issuer. Returns True if the token was issued by the Emulator, otherwise false.
2391	Returns an attachment for a hero card, raising TypeError if the argument is not a HeroCard instance. Hero cards typically contain a full-width image with text and buttons below the image.
2392	Return instruction parameters by recursively collecting them from sub-instructions in the definition, only when parameters haven't been previously defined.
2393	Method: mirror
Summary: Creates a mirrored copy of a composite instruction by reversing the order of all sub-gates recursively, without inverting any individual gate. Returns a new instruction with the same name suffixed by '_mirror'. If the instruction has no definition, it returns a copy of itself.
2394	Inverts this instruction by creating a new instruction with the same name suffixed with '_dg'. If the instruction is composite (has a definition), it recursively inverts each instruction in the definition by reversing their order and applying the inverse operation to each. For non-composite instructions, it raises a QiskitError if no inverse implementation exists. Returns a fresh Instruction object representing the inverse operation.
2395	Add classical control on register classical and value val. Raises QiskitError if classical is not a ClassicalRegister or if val is negative. Returns self for chaining.
2396	Creates a shallow copy of the instruction, optionally renaming it. Returns the copied instruction with updated name if provided.
2397	Returns a string with an if statement prefix if a control condition exists, otherwise returns the original string.
2398	Return a default OpenQASM string for the instruction, including parameter formatting if parameters exist.
2399	Runs all registered passes on a QuantumCircuit and returns the transformed circuit.
2400	Does a pass and its required passes, handling both transformation and analysis passes while maintaining property sets and valid passes tracking.
2401	Returns a list of appended passes and their options by iterating through the working list and calling dump_passes() on each pass.
2402	Fetches the passes added to this flow controller.

Returns (dict): {'options': self.options, 'passes': [passes], 'type': type(self)}
2403	Constructs a flow controller based on partially evaluated controller arguments, raising TranspilerError for malformed inputs and returning appropriate controller instances.
2404	Apply U gate to a quantum bit.

The method `u_base` applies a U gate (parameterized by theta, phi, and lambda) to a specified quantum bit (qubit). It returns the result of appending the UBase gate operation to the quantum circuit.

Parameters:
- theta, phi, lam: Gate parameters
- q: Qubit to apply the gate to

Returns:
- Result of appending UBase gate to the quantum circuit
2405	Apply a single qubit gate to the qubit.

Args:
    gate(str): the single qubit gate name
    params(list): the operation parameters op['params']
Returns:
    tuple: a tuple of U gate parameters (theta, phi, lam)
Raises:
    QiskitError: if the gate name is not valid
2406	Returns the matrix representation of a single qubit gate operation.

This function takes a gate name and optional parameters, converts the symbolic parameters to floats for performance optimization, and returns the corresponding 2x2 unitary matrix in the standard qubit basis. The matrix follows the general form of a single-qubit rotation gate with parameters theta, phi, and lambda.

Args:
    gate (str): The single qubit gate name
    params (list, optional): Operation parameters 

Returns:
    numpy.ndarray: 2x2 complex numpy array representing the gate matrix

The function internally calls `single_gate_params()` to extract and convert parameters, then constructs the matrix using trigonometric and exponential functions with the standard single-qubit gate convention.
2407	Returns the index string for NumPy.einsum matrix-matrix multiplication to perform A.B where A is an M-qubit matrix, B is an N-qubit matrix (M <= N), and identity matrices are implied on subsystems where A has no support on B. The function takes gate indices and total number of qubits as inputs and returns a format string compatible with numpy.einsum.
2408	Return the index string for NumPy.einsum matrix-vector multiplication to perform A.v where A is an M-qubit matrix and v is an N-qubit vector.
2409	Return the index string for Numpy.einsum matrix multiplication for einsum-based simulator.
2410	Converts a QuantumCircuit object into a DAGCircuit object by copying all qubits, clbits, and instructions from the input circuit to the output DAG circuit.
2411	Function used to fit exponential decay with parameters a (amplitude), tau (time constant), and c (offset).
2412	Function used to fit a decay cosine wave with amplitude, decay rate, frequency, phase, and offset parameters.
2413	Plot coherence data with error bars and fit curve.

This function creates a matplotlib plot showing coherence measurements with the following features:
- Blue error bars for experimental data points
- Red dashed line for fitting curve
- Proper axis labels with units
- Legend showing fit parameters
- Grid and title with experiment name and qubit label
- Rotated x-axis tick labels for better readability

Requires matplotlib to be installed. Raises ImportError if matplotlib is not available.
2414	Convert raw randomized benchmarking data into mean and standard deviation averages across seeds.

Args:
    raw_rb (numpy.array): m x n x l array where m = number of seeds, n = number of Clifford sequences, l = number of qubits

Returns:
    numpy_array: 2 x n x l array where index 0 contains mean values across seeds and index 1 contains standard deviation values across seeds
```
2415	Plot randomized benchmarking data with sequences, mean values with error bars, and fitting curve.
2416	Finds runs containing parameterized gates and splits them into sequential runs excluding the parameterized gates.
2417	Returns the composite parameters (theta, phi, lambda) for the product of two U3 gates, where u3(theta, phi, lambda) = u3(theta1, phi1, lambda1) . u3(theta2, phi2, lambda2).
2418	Convert a Y.Z.Y single qubit gate representation to Z.Y.Z gate representation by solving the rotation equivalence equation and returning the corresponding Euler angles (theta, phi, lambda).
2419	Validates input quantum state for visualization functions by converting it to a density matrix. Accepts either a state vector (1D array) or density matrix (2D array), ensures it's a valid square matrix, and checks if it represents a valid n-qubit quantum state. Returns a 2D numpy array representing the density matrix, raises VisualizationError for invalid inputs.
2420	Trim a PIL image by removing whitespace around the content. Creates a background image with the same mode and size as the input, then finds the difference between the original and background images. Applies a threshold to the difference image and crops the original image to the bounding box of non-zero pixels. Returns the cropped image.
2421	Get the list of qubits that would be covered by drawing a gate, from the minimum index to the maximum index of qubits involved in the instruction, or from minimum index to the end if classical bits are involved.
2422	Converts a QuantumCircuit object into an Instruction object that can be inserted into another circuit, preserving the circuit's structure and operations while creating a flat bit representation.
2423	**Summary:**

The `run` method determines an optimal qubit layout for a given quantum circuit (DAG) based on the best matching qubit connectivity from the device's coupling map. It first checks if the number of qubits in the DAG exceeds the device's capacity, raising a `TranspilerError` if so. Then, it finds the best subset of physical qubits from the coupling map and creates a layout mapping each virtual qubit in the DAG to a physical qubit. Finally, it stores this layout in the property set under the key 'layout'.
2424	Computes the qubit mapping with the best connectivity for a given number of qubits by performing breadth-first search from each node to find the optimal subset of qubits with maximum connections, then applies reverse Cuthill-McKee ordering to reduce bandwidth. Returns an array of qubits representing the best connectivity mapping.
2425	Apply a barrier operation to specified qubits in the circuit. If no qubits are specified, applies to all qubits in all quantum registers. Takes QuantumRegister objects or individual qubits as arguments and returns the modified circuit with the barrier instruction appended.
2426	Compute the mean value of a diagonal observable by calculating the weighted sum of observable values based on experimental counts. Takes a dictionary of outcomes and a diagonal observable in dict, matrix, or list format, and returns the average observable value.
2427	Process an Id or IndexedId node as a bit or register type, returning a list of tuples (Register,index).
2428	Process a custom unitary node by handling its arguments and bits, then creating corresponding DAG operations while managing argument and bit stacks for register arguments.
2429	Process a gate node by extracting its properties and storing them in the gates dictionary. If opaque is True, treat the node as an opaque gate with no body. Otherwise, store the gate's body, arguments, and bitlist information. Set default print behavior to True and store the number of arguments and bits.
2430	Process a CNOT gate node by converting bit IDs and applying CX operations to the DAG, handling cases where qubit registers have different sizes.
2431	Process a measurement node by validating register sizes and applying measurement operations to the DAG.
2432	Process an if node by extracting condition information and recursively processing the conditional statement.
2433	Creates a DAG node from a parsed AST operation node by mapping operation names to their corresponding gate classes and applying the operation to the DAG. Raises QiskitError for unknown operations.
2434	Return the duration of the specified channels by delegating to the timeslots component.
2435	Return the minimum start time for the supplied channels by delegating to the timeslots attribute's ch_start_time method.
2436	Return the maximum start time for the supplied channels by querying the timeslots module.
2437	Returns an iterable of (time, instruction) tuples for flattening the schedule tree, yielding each child schedule's instructions with adjusted timing based on parent schedule.
2438	Validates that a value matches the expected type(s) for the field. Raises an exception if the value type is not in the expected types returned by `_expected_types()`, otherwise returns the value unchanged.
2439	Include unknown fields after dumping by adding them with no processing at all. For each item in valid_data, find keys present in original_data but not in valid_data, and add those key-value pairs to valid_data. Returns the extended valid_data with additional unknown attributes included.
2440	Method `load_additional_data` extends validated data with unknown fields from original data. It takes validated data, a flag indicating if data is a list, and the original data, then adds any fields present in original data but not in validated data. If `many` is True, it processes each item in a list; otherwise, it processes a single dictionary. The method returns the validated data with additional unknown fields added without any processing.
2441	Creates a patched Schema for validating models by overriding the `_deserialize` method of fields to use custom `check_type` validation functions from Qiskit's validation fields.
2442	Validate the internal representation of the instance by running it through the schema validation, raising a ModelValidationError with detailed error information if validation fails.
2443	Adds validation after object instantiation by decorating the init method with schema validation.
2444	Serialize the model into a Python dict of simple types using the bound schema, raising ModelValidationError if data is invalid.
2445	Deserialize a dict of simple types into an instance of this class using its bound schema. Raises ModelValidationError if data is invalid.
2446	The function `qft` implements a quantum Fourier transform (QFT) on a specified number of qubits. It takes a quantum circuit, a list of qubits, and the number of qubits as inputs. The method applies a series of controlled phase gates (cu1) and Hadamard gates to perform the QFT operation, where the controlled phase gates are applied in a specific triangular pattern and each qubit is acted upon by a Hadamard gate.
2447	Partial trace over subsystems of multi-partite vector, converting a vector to a density matrix with specified subsystems traced over.
2448	Flatten an operator to a vector in a specified basis.

Args:
    density_matrix (ndarray): a density matrix.
    method (str): the method of vectorization. Allowed values are
        - 'col' (default) flattens to column-major vector.
        - 'row' flattens to row-major vector.
        - 'pauli'flattens in the n-qubit Pauli basis.
        - 'pauli-weights': flattens in the n-qubit Pauli basis ordered by
           weight.

Returns:
    ndarray: the resulting vector.
Raises:
    Exception: if input state is not a n-qubit state
2449	Devectorizes a vectorized square matrix into its original matrix form using specified devectorization methods.

Args:
    vectorized_mat (ndarray): A vectorized density matrix
    method (str): Devectorization method - 'col' (column-major, default), 'row' (row-major), 'pauli' (Pauli basis), or 'pauli-weights' (Pauli basis ordered by weight)

Returns:
    ndarray: The devectorized matrix

Raises:
    Exception: If input is not a vectorized square matrix or not an n-qubit state

The function supports four devectorization methods:
- 'col': Reshapes using column-major ordering
- 'row': Reshapes using row-major ordering  
- 'pauli' and 'pauli-weights': Converts from Pauli basis representation using tensor products or weight ordering respectively
2450	Convert a Choi-matrix to a Pauli-basis superoperator by computing trace inner products between the Choi matrix and tensor products of Pauli operators, returning a superoperator matrix that acts on input states in the Pauli basis.
2451	Truncates small values of a complex array by setting values below the epsilon threshold to zero. For real arrays, it sets small absolute values to 0.0. For complex arrays, it separately processes real and imaginary parts, setting small values in each component to 0.0. Returns a new array with small values truncated.
2452	Construct the outer product of two vectors. If the second vector is not provided, returns the projector of the first vector. Args: vector1 (ndarray): the first vector; vector2 (ndarray): the (optional) second vector. Returns: np.array: The matrix |v1><v2|.
2453	Calculate the concurrence of a quantum state or density matrix, which quantifies the degree of entanglement between two qubits. The function accepts either a state vector (1x4 array) or density matrix (4x4 array) and returns a float value representing the concurrence. It raises an exception if applied to more than two qubits. The calculation involves computing the eigenvalues of a specific matrix derived from the input state and applying the formula max(0,  - ) where  are the sorted eigenvalues.
2454	Compute the Shannon entropy of a probability vector using the specified logarithm base. The entropy is calculated as H(pv) = - pv[j] log_b(pv[j]) where 0 log_b 0 = 0. Returns a float value representing the entropy.
2455	Compute the von-Neumann entropy of a quantum state by calculating the Shannon entropy of its eigenvalues.
2456	Compute the mutual information of a bipartite quantum state by calculating the sum of entropies of marginal distributions minus the entropy of the total system.
2457	Compute the entanglement of formation of a quantum state, which can be either a bipartite state vector or a 2-qubit density matrix, returning the entanglement measure as a float value.
2458	Compute the Entanglement of Formation of a 2-qubit density matrix using concurrence and Shannon entropy.
2459	Create a flattened schedule by unpacking all instructions from the input schedule into a new Schedule object, preserving the original schedule's name if no new name is specified.
2460	Return schedule shifted by `time` units. The shifted schedule is created by unioning the original schedule with a time-shifted version of itself. If no name is provided, the original schedule's name is used. The time shift is applied by creating a tuple of (time, schedule) and passing it to the union function.
2461	Inserts a child schedule into a parent schedule at a specified time and returns a new schedule containing both.
2462	Return a new schedule with `child` appended to `parent` at the last time of parent's channels over common channels.
2463	Apply u3 gate to the specified qubit.
2464	Return the backend status including name, version, operational status, pending jobs count, and status message.
2465	Start the progress bar with specified number of iterations.

Parameters:
    iterations (int): Number of iterations to run

Sets up the progress bar by recording the start time and storing the iteration count.
2466	Estimates the remaining time left for a process based on completed iterations.

Parameters:
    completed_iter (int): Number of iterations completed.

Returns:
    est_time: Estimated time remaining in DD:HH:MM:SS format.
2467	Disassemble a qobj object into its constituent parts: quantum circuits, run configuration dictionary, and user header dictionary. Returns a tuple containing (circuits, run_config, user_qobj_header) where circuits is a list of quantum circuits, run_config is a dictionary representation of the run configuration, and user_qobj_header is a dictionary containing any user-defined headers from the qobj.
2468	Calculate the Hamming distance between two bit strings by comparing each character position and counting mismatches, raising an error if the strings have different lengths.
2469	Creates a quaternion representing rotation about a specified axis by a given angle. Takes an angle in radians and axis ('x', 'y', or 'z') as inputs, returning a Quaternion object. Raises ValueError for invalid axis inputs.
2470	Generate a quaternion from a set of Euler angles specified by the given rotation order.
2471	Normalizes a quaternion to unit length to represent a valid rotation. If `inplace=True`, modifies the quaternion in place and returns `None`. Otherwise, returns a new normalized quaternion instance.
2472	Converts a unit-length quaternion to a 3x3 rotation matrix using the quaternion components (w, x, y, z) following the standard quaternion-to-matrix conversion formula. Returns the resulting rotation matrix as a numpy array.
2473	Converts a unit-length quaternion to ZYZ Euler angles by:
1. Converting quaternion to rotation matrix
2. Computing three Euler angles using atan2 and acos functions
3. Handling special cases when matrix element [2,2] equals 1 or -1
4. Returns array of three Euler angles in ZYZ order
2474	Process received data for representation by keeping only the specified number of top elements and calculating their proportions, with remaining values grouped under 'rest' key.
2475	Creates an interactive histogram visualization from input data using JavaScript plotting library. Accepts data as list of dictionaries or single dictionary, with options for figure size, sorting, legend, and number of items to display. Generates HTML and JavaScript code to render the histogram in a notebook environment.
2476	Customizes type checking to handle containers by first validating the root value normally, then recursively checking each item in collections while maintaining quick failure for invalid values.
2477	Check that j is a valid index into self, raising QiskitIndexError if out of range for either integer indices or slice objects.
2478	Test if an array is a square matrix by checking if it has exactly 2 dimensions and if the number of rows equals the number of columns.
2479	Test if an array is a diagonal matrix by comparing it with a diagonal matrix formed from its diagonal elements, using optional tolerance values for floating-point comparison.
2480	Test if an array is a symmetric matrix by checking if it equals its transpose within given tolerances.
2481	Test if an array is a Hermitian matrix by checking if the matrix equals its conjugate transpose within given tolerances.
2482	Test if a matrix is positive semidefinite by checking if it is Hermitian and all eigenvalues are non-negative.
2483	Test if an array is an identity matrix, with optional phase ignoring and tolerance settings. Returns True if the matrix is an identity matrix within the specified tolerances, False otherwise.
2484	Test if an array is a unitary matrix by checking if A.A equals the identity matrix.
2485	Transform a QuantumChannel to the Choi representation by converting from various input representations (Operator, SuperOp, Kraus, Chi, PTM, Stinespring) to Choi representation, or returning the data unchanged if it's already in Choi representation.
2486	Transform a QuantumChannel to the SuperOp representation by converting from various input representations (Operator, Choi, Kraus, Chi, PTM, Stinespring) to SuperOp format.
2487	Transform a QuantumChannel to the Kraus representation by converting from other representations (Stinespring, Operator, or Choi) to Kraus form.
2488	Transforms a QuantumChannel to the Chi representation by converting through Choi representation if necessary, or directly returning data if already in Chi representation.
2489	Converts a QuantumChannel to PTM (Pauli Transfer Matrix) representation.

This function transforms quantum channel data from various input representations (Operator, SuperOp, or other) to the PTM representation. If the input is already in PTM representation, it returns the data unchanged. For Operator representation, it uses a direct conversion function. For other representations, it first converts to SuperOperator representation then to PTM using the superoperator_to_ptm conversion. The function validates that the input and output dimensions represent valid n-qubit systems before processing.

Args:
    rep (str): Current representation of the quantum channel ('Operator', 'SuperOp', 'PTM', etc.)
    data (array-like): Quantum channel data to be transformed
    input_dim (int): Input dimension of the quantum channel
    output_dim (int): Output dimension of the quantum channel

Returns:
    array-like: Quantum channel in PTM representation

Raises:
    ValueError: If input_dim and output_dim don't represent valid n-qubit systems
    NotImplementedError: If conversion from current representation to PTM is not implemented
2490	Converts a QuantumChannel to the Stinespring representation by handling different input representations (Operator, Kraus, etc.) and converting them to the Stinespring form through intermediate representations when necessary.
2491	Converts a QuantumChannel to the Operator representation by handling different input representations (Operator, Stinespring, or Kraus) and converting them appropriately.
2492	Transform Operator representation to other representation.

This function converts an operator representation to various quantum channel representations including SuperOp, Choi, Kraus, Stinespring, Chi, and PTM formats. It takes the target representation type, input data, and dimension information as parameters, performing appropriate transformations based on the specified representation. The function raises a QiskitError for invalid representation types.
2493	Transform Stinespring representation to Operator representation by checking if the channel can be converted and returning the operator data.
2494	Transform SuperOp representation to Choi representation by reshuffling the data according to the specified dimensions.
2495	Transform Choi to SuperOp representation by reshuffling the input data according to the specified dimensions.
2496	Transform Kraus representation to Choi representation by converting Kraus operators to vector form and computing outer products.
2497	Convert Choi representation to Kraus representation, handling both CP-maps (with eigen-decomposition) and non-CP-maps (with SVD), returning either a single Kraus set or a pair of left/right Kraus operators.
2498	Transform Stinespring representation to Kraus representation by converting each Stinespring operator into its corresponding Kraus operators through partial tracing and tensor products.
2499	Transform Stinespring representation to Choi representation by reshaping the Stinespring operators and computing the Choi matrix via Einstein summation.
2500	Transforms Kraus representation to Stinespring representation by converting each Kraus operator into a Stinespring dilation matrix. For each input Kraus operator, creates a block matrix where each block corresponds to a Kraus matrix tensored with a basis vector. Returns a tuple containing the two Stinespring operators (dilation matrices) corresponding to the input Kraus operators.
2501	Transform Kraus representation to SuperOp representation by computing the tensor product of conjugate Kraus operators with their corresponding operators.
2502	Transform Chi representation to Choi representation by converting from Pauli basis.
2503	Transform Choi representation to Chi representation by converting to Pauli basis.
2504	Reravel two bipartite matrices by reshuffling indices and computing their tensor product. The function takes two matrices and their respective shapes, computes the Kronecker product, reshapes and transposes the result according to specified dimensions, and returns the final flattened matrix.
2505	Transforms bipartite matrix representation from Pauli basis to standard basis using change of basis matrices. Applies Kronecker products and tensor reshaping to handle multiple qubits, then applies the change of basis transformation with manual renormalization to avoid rounding errors. Returns the transformed data scaled by 2^num_qubits.
2506	Returns True if the input and output dimensions correspond to an n-qubit channel, otherwise raises QiskitError with descriptive message about the dimension mismatch.
2507	Summary: Hides tick lines and labels on a given axis by setting their visible property to False.
2508	Sets the x, y, and z labels according to the specified convention. Supported conventions include "original", "xyz", "sx sy sz", "01", "polarization jones", "polarization jones letters", and "polarization stokes". Raises an exception if the convention is not valid.
2509	Resets Bloch sphere data sets to empty by clearing points, vectors, point_style, and annotations lists.
2510	Add a list of vectors to Bloch sphere.

Args:
    vectors (array_like):
        Array with vectors of unit length or smaller.
2511	Add a text or LaTeX annotation to the Bloch sphere at a specified position defined by either a qubit state or 3D vector, with optional formatting options.
2512	Render the Bloch sphere and its data sets on given figure and axes, clearing existing content if previously rendered, setting up the 3D axes with appropriate limits and styling based on background setting, and plotting all visual components including points, vectors, labels, and annotations.
2513	Method: `plot_front`

Summary: Plots the front half of a sphere using surface and wireframe visualization techniques. The method generates a spherical surface by computing 3D coordinates using parametric equations with u and v angle parameters, then renders both a solid surface and wireframe representation. It also plots equatorial lines projected onto the z=0 plane and x=0 plane to enhance the 3D visualization. The rendering uses configurable color, transparency, and line width settings.

Parameters: None (uses instance variables: `self.axes`, `self.sphere_color`, `self.sphere_alpha`, `self.frame_color`, `self.frame_alpha`, `self.frame_width`)

Returns: None (modifies the axes object directly)
2514	Displays a Bloch sphere with corresponding data sets by rendering the figure and showing it using matplotlib.
2515	Deprecated function that was moved to qiskit.quantum_info.synthesis.two_qubit_kak. Issues a deprecation warning and delegates to the new location.
2516	Constructs the top line of the element by formatting the top connection text with proper padding and centering within the specified width and background characters.
2517	Constructs the middle line of the element by centering content within the specified width and applying padding and filling adjustments based on right_fill, left_fill, and layer_width properties.
2518	Constructs the bottom line of the element by formatting the bottom connection text, applying left and right fill padding if specified, and centering the result within the layer width using the bottom background character.
2519	Returns the maximum length among the top, middle, and bottom elements, representing the total width including the surrounding box.
2520	Get the parameters from an instruction's operation and format them as a list of strings for use in a label. Returns None if there are no parameters or if all parameters are numpy arrays. For numeric parameters (sympy.Number or float), formats them with 5 significant digits; otherwise converts them to strings directly.
2521	Creates a box label by capitalizing the instruction name and appending parameter information in parentheses if parameters exist.
2522	Return the math mode latex string representation of the object. If no nested scope is provided, returns a formatted string with the object's name enclosed in textrm command. If nested scope is provided, validates that the object's name exists in the current scope and recursively evaluates the latex representation from the parent scopes. Raises NodeException if the parameter name is not found in the expected local scope.
2523	Compile a list of circuits into a qobj for execution on a backend, using transpile and assemble functions. This function is deprecated and will be removed in Qiskit Terra 0.9.
2524	Summary: The `_filter_deprecation_warnings()` function configures warning filters to control how deprecation warnings are displayed. It ensures `DeprecationWarning` warnings from the `qiskit` module are always shown (overriding Python's default filtering behavior) by using the internal `_add_filter()` function when available. It also silences `ChangedInMarshmallow3Warning` messages since the code depends on marshmallow 2 and these warnings are too verbose for the current purposes. The function includes a try-except block to handle cases where the internal filtering function may not be available in some Python versions.
2525	Returns a dictionary containing local machine's hardware information including operating system, total memory in GB, and actual CPU count (excluding hyperthreading) with a default of 1 if count can't be determined.
2526	Checks if internet connection exists to a specified host via given port. Returns True if connection is successful within 2 seconds, False otherwise. Handles all exceptions gracefully by returning False if any error occurs during socket connection attempt.
2527	Internal function that monitors and updates the HTML status display of a job until it reaches DONE, CANCELLED, or ERROR state, adjusting check intervals based on job queue position.
2528	Continuous constant pulse generator that returns an array of specified amplitude for given time points.

Args:
    times: Times to output pulse for.
    amp: Complex pulse amplitude.

Returns:
    Array of specified amplitude with length equal to times parameter.
2529	Continuous square wave generator that produces a square waveform with specified amplitude, period, and phase. Takes time values as input and returns corresponding square wave values in the range [-amp, amp]. The waveform is generated using floor functions to create the square pattern, with the phase parameter allowing for waveform shifting.
2530	Creates a continuous triangle wave signal with specified parameters.

**Parameters:**
- times: Array of times to evaluate the wave at
- amp: Complex amplitude defining the wave range [-amp, amp] 
- period: Wave period in units of dt
- phase: Wave phase shift (default: 0)

**Returns:**
- Complex numpy array containing triangle wave values at specified times

**Implementation:**
Uses a sawtooth wave base function with phase adjustment and amplitude scaling to generate a triangle wave, where the wave oscillates between -amp and +amp with the specified period and phase.
2531	Continuous cosine wave function that generates a cosine wave with specified amplitude, frequency, and phase at given time points, returning the result as a complex-valued numpy array.
2532	Enforce that the supplied gaussian pulse is zeroed at a specific width by subtracting the baseline value at the specified offset. If rescale_amp is True, the pulse is rescaled so that the amplitude difference matches the specified value. Returns the modified gaussian samples, optionally with the amplitude scale factor.
2533	Generate a continuous unnormalized Gaussian pulse waveform over specified times with optional zeroing of width and amplitude rescaling. The function computes a Gaussian function with given amplitude, center, and width parameters, and can adjust the pulse to have zeroed boundaries or rescaled amplitude based on additional parameters. Returns either the pulse waveform or a tuple of the pulse waveform and normalized time variables.
2534	Generates a continuous unnormalized Gaussian derivative pulse evaluated at given times. Returns the derivative of a Gaussian function with specified amplitude, center, and width. Optionally also returns the original Gaussian function. The derivative is computed as -x/sigma multiplied by the Gaussian, where x is the deviation from the center.
2535	Creates a continuous Gaussian square pulse with configurable amplitude, center, width, and Gaussian rise/fall portions. Returns a piecewise function combining Gaussian rise/fall segments and a constant square portion.
2536	The `default_pass_manager` function creates a pass manager for quantum circuit compilation that maps circuits to a target hardware topology. It takes basis gates, coupling map, initial layout, and seed as inputs, and returns a configured `PassManager` object. The pass manager applies a sequence of optimization and mapping passes, including unrolling to basis gates, layout selection (trivial or dense), ancilla allocation, swap mapping, CX direction correction, and gate simplification, to produce a circuit that can be executed on the target quantum device.
2537	Returns a default pass manager for simulator that unrolls quantum circuits to specified basis gates without optimization. The pass manager includes unrolling to the given basis gates and applies depth optimization with a fixed point check until the circuit depth stabilizes.
2538	Test if this circuit has the specified register r.

Args:
    register (Register): a quantum or classical register.

Returns:
    bool: True if the register is contained in this circuit.
2539	Mirror the circuit by reversing the instructions, recursively mirroring all instructions without inverting any gate, and return the mirrored circuit.
2540	Invert this circuit by recursively inverting all gates and returning a new QuantumCircuit object with the inverted operations.
2541	Append an instruction to the end of the circuit, modifying the circuit in place. Raises QiskitError if the gate is of a different shape than the wires it is being attached to. Returns a handle to the instruction that was just added.
2542	Method `_attach` is deprecated after version 0.8 and simply calls `self.append(instruction, qargs, cargs)` to attach an instruction to quantum and classical arguments.
2543	Add registers to the circuit. Accepts either Register objects or integers (for creating anonymous registers). If integers are provided, they specify the number of qubits and classical bits. Raises QiskitError if register names conflict or invalid parameters are provided.
2544	Check if a list of qubits contains duplicates and raise an exception if it does.
2545	Checks if all qargs are valid (QuantumRegister, int) tuples and if their registers exist in the circuit, raising QiskitError for invalid qargs or registers.
2546	Check if classical args are valid (tuples of ClassicalRegister and int, exist in circuit, and within range).
2547	Check if two circuits are defined on compatible registers by comparing their quantum and classical registers. Raise QiskitError if circuits have registers with the same name but different specifications.
2548	Return OpenQASM string representation of the quantum circuit by concatenating header, extension library, register definitions, and formatted instructions.
2549	Draws the quantum circuit in the specified output format (text, latex, or matplotlib) with various customization options including scale, styling, bit ordering, and barrier plotting.
2550	Returns the total number of gate operations in the circuit, excluding 'barrier' and 'snapshot' instructions.
2551	Return number of qubits plus clbits in circuit.

Returns:
    int: Width of circuit.
2552	Count each operation kind in the circuit and return a dictionary with the breakdown of how many operations of each kind.
2553	Returns the number of non-entangled subcircuits (connected components) in the circuit by analyzing gate connectivity between qubits and classical bits. If `unitary_only` is True, only the unitary part of the circuit is considered. The method uses a graph-based approach where each qubit/cbit starts as its own subgraph, and gates that connect multiple subgraphs merge them until no more connections are possible.
2554	Binds parameters in a quantum circuit to specified values, returning a new circuit copy with the substitutions applied. Raises QiskitError if any parameters in the input dictionary are not present in the circuit. Clears evaluated expressions from the parameter table in the new circuit.
2555	Assigns a parameter value to matching instructions in-place by iterating through the parameter table and updating instruction parameters.
2556	Plot the interpolated envelope of a pulse with optional saving and interactive display.
2557	Search for SWAP operations to maximize the number of gates that can be applied, using a forward search with depth and width parameters to explore possible qubit rearrangements.
2558	Map gates to physical qubits based on current layout and coupling constraints, returning successfully mapped gates and those that cannot be executed.
2559	Calculate the total distance cost for CNOT gates based on current layout and coupling map, considering only two-qubit gates up to a maximum limit.
2560	Count the mapped two-qubit gates, less three times the number of added SWAPs.
2561	Returns a copy of the source DAG circuit with metadata preserved but empty, containing only a single quantum register that matches the size of the provided coupling map.
2562	Returns a mapped operation node that implements a virtual gate on a given device layout by reassigning qubit arguments according to the layout mapping.
2563	Generate a list containing a single DAG node representing a SWAP gate operation between qubits specified by the given coupling edge, using the provided layout to determine physical qubit mapping.
2564	Run one pass of the lookahead mapper on the provided DAG, mapping it to be compatible with the coupling_map while optimizing for minimal swaps. Returns a mapped DAG circuit. Raises TranspilerError if the coupling map or layout are incompatible with the DAG.
2565	Add a physical qubit to the coupling graph as a node.

Args:
    physical_qubit (int): An integer representing a physical qubit.

Raises:
    CouplingError: if trying to add duplicate qubit
2566	Add a directed edge between source and destination physical qubits in the coupling graph, creating the qubits if they don't already exist.
2567	Return a CouplingMap object for a subgraph of self.

**Parameters:**
- nodelist (list): list of integer node labels

**Returns:**
- CouplingMap: A new coupling map object representing the subgraph

**Behavior:**
Creates a subgraph by filtering the original coupling map to include only the specified nodes. Adds physical qubits to the new coupling map and returns it.
2568	Returns a sorted list of physical qubits by sorting the nodes in the graph, caching the result in _qubit_list for future calls.
2569	Test if the graph is connected and return True if connected, False otherwise.
2570	Compute the full distance matrix on pairs of nodes using shortest path lengths from the graph. Raises CouplingError if the graph is not connected. The distance matrix is stored in self._dist_matrix.
2571	Returns the undirected distance between two physical qubits in the coupling map. Computes and caches the distance matrix if not already computed. Raises CouplingError if either qubit is not present in the coupling graph.
2572	Transpiles one or more quantum circuits for a given backend. This function is deprecated and will be removed in version 0.9; use qiskit.compiler.transpile() instead. It accepts circuits to compile, an optional backend, basis gates, coupling map, initial layout, seed for the mapper, and a pass manager. Returns the transpiled circuit(s) or raises TranspilerError in case of issues.
2573	Apply cu1 gate from control qubit to target qubit with specified angle theta.
2574	Invert all instructions in the object by calling the inverse() method on each instruction and return the modified object.
2575	Adds control qubits to all instructions in the circuit and returns the modified circuit.
2576	Add classical control register to all instructions in the circuit.
2577	Subscribes to an event for execution of a callback when the event is emitted, preventing duplicate registrations. Returns True if successful, False if already subscribed.
2578	Emits an event to all subscribers if the event exists, passing along any provided arguments. If no subscribers exist for the event, the method returns without emitting.
2579	Unsubscribes a callback from a specific event. Returns True if successful, False if no previous subscription exists.
2580	Trigger an event with associated data, calling all subscribed callbacks synchronously through the broker's dispatch method.
2581	Initialize a quantum circuit with given parameters and qubits by appending an Initialize instruction.
2582	This method implements a quantum circuit initialization algorithm based on the "Synthesis of Quantum Logic Circuits" paper by Shende, Bullock, and Markov. It calculates a subcircuit that prepares a specific quantum state by:

1. Generating a disentangling circuit that transforms the desired quantum state to zero
2. Inverting this circuit to create the desired state from the zero state
3. Adding reset operations to ensure qubits start in |0 state
4. Returning the resulting circuit definition for initialization

The implementation includes optimizations to remove zero rotations and double CNOT gates for cleaner circuit representation.
2583	Creates a quantum circuit that transforms the current parameter vector into the |00..0 state by sequentially disentangling qubits from least significant to most significant, using rotation gates determined by the parameter vector.
2584	Static internal method that calculates Bloch sphere angles to transform the zero vector into a given qubit state. Takes a pair of complex numbers representing qubit amplitudes, computes the radial distance, polar angle (theta), and azimuthal angle (phi) needed for the transformation, handling edge cases where the qubit has near-zero magnitude. Returns a tuple containing the complex amplitude and the two angular parameters.
2585	Returns a recursive implementation of a multiplexor circuit that applies a target gate (Ry or Rz) to a target qubit multiplexed over select qubits, using angle weights and recursion to decompose the circuit.
2586	Checks if a value has the format of a virtual qubit, which is either None or a tuple containing a Register object and an integer.
2587	Returns a copy of a Layout instance by creating a new instance of the same type and copying its _p2v and _v2p attributes.
2588	Combines two layouts into an "edge map" that maps virtual qubits from self to virtual qubits from another_layout. Raises LayoutError if another_layout is smaller than self. Returns a dictionary representing the edge map.
2589	Apply Toffoli gate from two control qubits to a target qubit.
2590	Return a new schedule with the given schedule inserted within self at the specified start time by calling the insert operation.
2591	Checks if an attribute name is in the list of attributes to protect and raises TranspilerAccessError if it is.
2592	Converts gate tuples into a nested list of integers by mapping quantum register names to indices and calculating absolute positions based on register sizes.
2593	Run the StochasticSwap pass on a DAG circuit, applying layout and coupling map constraints to produce a mapped DAG. Handles initial layout generation, validates qubit counts, initializes random number generator for stochastic behavior, and executes the mapping algorithm with specified trials. Returns the mapped DAG circuit or raises TranspilerError for incompatible layout/coupling map configurations.
2594	This method updates and returns a DAGCircuit for a new mapped layer in the quantum circuit mapping process. It handles two cases: when the current layer is the first multi-qubit gate layer (where it outputs all previous layers without swaps and sets the initial layout), and when it's a subsequent layer (where it outputs the current layer along with any necessary swap gates). The method constructs the output DAGCircuit by combining quantum registers, applying layout mappings, and composing the appropriate circuit components based on whether swaps are needed.
2595	Return the Pauli group with 4^n elements ordered by weight or tensor.

Args:
    number_of_qubits (int): number of qubits
    case (str): determines ordering of group elements ('weight' or 'tensor')

Returns:
    list: list of Pauli objects

Raises:
    QiskitError: case is not 'weight' or 'tensor'
    QiskitError: number_of_qubits is larger than 4
2596	Construct a Pauli operator from a label string, where each character represents a Pauli operation (I, X, Y, Z) on a qubit, with the qubit index determined by the character's position in the string.
2597	Construct Pauli operator from boolean arrays.

Args:
    z (numpy.ndarray): boolean, z vector
    x (numpy.ndarray): boolean, x vector

Returns:
    Pauli: self

Raises:
    QiskitError: if z or x are None or have different lengths

Initializes the Pauli operator's _z and _x attributes with boolean numpy arrays after validation.
2598	Multiply two Paulis and track the phase, returning the resulting Pauli and its complex phase factor.
2599	Converts the current object to an Operator object by first converting it to a matrix representation.
2600	Converts a Pauli operator to a quantum circuit instruction by creating a circuit with appropriate single-qubit gates (I, X, Y, Z) applied to each qubit according to the Pauli string representation.
2601	Update partial or entire z array with validation checks for qubit count consistency.
2602	Update partial or entire x with validation checks on qubit count when updating whole array.
2603	Inserts or appends Pauli operators at specified indices in the Pauli string. If indices is None, appends at the end. Can accept either Pauli objects or string labels for insertion. Returns self for chaining operations. Raises QiskitError if both paulis and pauli_labels are provided simultaneously.
2604	Append pauli operators to the end of the current Pauli object by delegating to the insert_paulis method with None as the insertion index.
2605	Delete Pauli operators at specified indices and return self.
2606	Returns a random Pauli operator for a specified number of qubits, with optional random seed initialization.
2607	Generate a single qubit Pauli operator at a specified index with given Pauli label and length. Returns a Pauli object with the specified Pauli operator at the target qubit position.
2608	Simulates measuring a single qubit and returns the measurement outcome ('0' or '1') along with its probability.
2609	Generate memory samples from current statevector by calculating measurement probabilities for specified qubits and converting results to hex format.
2610	Adds a measurement instruction to a qubit, updates classical and quantum states based on measurement outcome.
2611	Apply a reset instruction to a qubit by simulating a measurement outcome and projecting onto the outcome state while renormalizing.
2612	Validate an initial statevector to ensure it has the correct length for the number of qubits. Raises a BasicAerError if the statevector length doesn't match the required dimension (2^number_of_qubits). Returns early if no initial statevector is set.
2613	Initialize the statevector for quantum simulation by setting all qubits to |0> state by default, or using a provided initial statevector, then reshape it into a rank-N tensor format.
2614	Return the current statevector in JSON Result spec format by reshaping, expanding complex numbers into real/imaginary pairs, and truncating small values below the chop threshold.
2615	Validate if measure sampling is allowed for a Qobj experiment based on shots count and circuit instructions. Returns early if shots <= 1 or if reset instructions are present. For experiments without explicit config flag, checks that measures are at the end of the circuit with only measure/barrier/id/u0 instructions following them.
2616	Run qobj asynchronously and return a BasicAerJob instance. The method accepts optional backend options including an initial statevector for custom initial states. It generates a unique job ID, creates a BasicAerJob with the run method as callback, submits the job, and returns it.
2617	Runs experiments in a qobj, validates the qobj, executes each experiment, and returns a Result object containing the combined results.
2618	Validates that the number of qubits in the qobj does not exceed the maximum allowed for the backend, and logs warnings for circuits without classical registers or measurements.
2619	Validate an initial unitary matrix by checking that it has the correct shape for the number of qubits. Raises a BasicAerError if the unitary matrix shape doesn't match the required dimensions (2^number_of_qubits, 2^number_of_qubits). Returns early if no initial unitary is set.
2620	Initialize the unitary matrix for quantum simulation by setting it to the identity matrix if no initial unitary is provided, otherwise copy the initial unitary, and reshape it into a rank-N tensor structure.
2621	Return the current unitary in JSON Result spec format by reshaping, expanding complex numbers into real/imaginary pairs, and truncating small values below the chop threshold.
2622	Runs experiments in qobj and returns a Result object containing the execution results, status, and timing information.
2623	Validate qobj semantic constraints for the backend, including qubit count limits, shot restrictions, and unsupported operations. Raises BasicAerError for invalid configurations and logs info messages for shot adjustments.
2624	Determine if obj is a bit by checking if it's a tuple of length 2 where the first element is a Register instance and the second element is an integer less than the length of the register.
2625	**Summary:**

The `run` method assigns circuit qubits to device qubits in a trivial layout by mapping the first n circuit qubits to device qubits 0 through n-1. It first checks if the number of qubits in the input DAG exceeds the device's coupling map size, raising a `TranspilerError` if so. If the check passes, it generates and stores a trivial layout in the property set using the qubit registers from the DAG.

**Key points:**
- Assigns qubits sequentially: circuit qubits  device qubits 0, 1, 2, ...
- Validates qubit count against device capacity
- Uses `Layout.generate_trivial_layout()` for the assignment
- Stores result in `self.property_set['layout']`
2626	Check if current interval has overlap with another interval.

Args:
    interval: interval to be examined

Returns:
    bool: True if current interval has overlap with `interval` otherwise False
2627	Return a new interval shifted by `time` from self

Args:
    time: time to be shifted

Returns:
    Interval: interval shifted by `time`
2628	Return a new Timeslot shifted by the specified time amount, preserving the original timeslot's channel while adjusting its interval accordingly.
2629	Return the earliest start time across specified channels in the collection.
2630	Return the maximum stop time across all timeslots for the specified channels.
2631	Return True if self and timeslots have no overlapping intervals, False otherwise.
2632	Return a new TimeslotCollection merged with a specified `timeslots` by combining all timeslots from both collections into a new TimeslotCollection instance.
2633	Return a new TimeslotCollection with all timeslots shifted by the specified time offset.
2634	Reports build failures on GitHub by creating an issue or comment depending on existing issues.
2635	Sort rho data by computing trace values for Pauli group matrices and mapping them to labels.
2636	Create a paulivec representation graphically displaying the input state vector or density matrix with optional slider and legend features.
2637	Apply RZZ gate to specified qubits with given angle parameter.
2638	Apply Fredkin gate to circuit with given control and target qubits.
2639	Initialize backend properties by extracting CNOT and readout errors, computing swap costs, and setting up graph-based path computations for quantum gate operations.
2640	Creates a program graph where virtual qubits are nodes and 2-qubit gates create weighted edges. Nodes are indexed by qubit identifiers, and edges are weighted by the number of CNOTs between qubit pairs. Returns the total number of qubits.
2641	Selects the next edge to process by prioritizing edges with one mapped endpoint, falling back to the first pending edge if none have mapped endpoints.
2642	Select the best remaining CNOT gate from available hardware qubits based on highest reliability cost.
2643	Select the best remaining hardware qubit for the next program qubit based on reliability scores that consider swap costs with neighboring program qubits and readout errors.
2644	This method implements a noise-adaptive layout selection algorithm for quantum circuits. It maps logical qubits from the program graph to physical qubits on the hardware by:

1. Initializing backend properties and creating a program graph representation
2. Checking that the circuit fits within the available hardware qubits
3. Processing program edges in descending order of weight (importance)
4. For each edge, selecting the best available hardware qubits based on:
   - If both qubits are unmapped, assigns the best CX gate
   - If only one qubit is mapped, assigns the best remaining qubit
5. Handling any remaining unmapped qubits by assigning them to available hardware qubits
6. Creating and returning a final Layout object mapping logical to physical qubits

The algorithm prioritizes qubit assignments based on edge weights and hardware connectivity properties to minimize noise and improve circuit performance.
2645	Return a list of instructions for this CompositeGate, recursively calling itself on nested CompositeGates.
2646	Invert this gate by reversing the order of gates in data and toggling the inverse_flag.
2647	Add controls to this gate by applying q_if to all gates in the data list.
2648	Add classical control register to all gates in the data list.
2649	Return True if the operator is a unitary matrix by checking if the internal data satisfies unitary matrix properties within the specified tolerances.
2650	Return the conjugate of the operator by taking the complex conjugate of its data while preserving the input and output dimensions.
2651	Return the transpose of the operator by transposing its data while preserving input and output dimensions.
2652	Return the matrix power of the operator by computing the n-times composed operator using numpy's matrix_power function. Raises QiskitError if the input and output dimensions are not equal or if the power is not a positive integer.
2653	Return the tensor shape of the matrix operator by combining output dimensions and input dimensions in reverse order.
2654	Convert a QuantumCircuit or Instruction to an Operator by first converting the circuit to an instruction if needed, then creating an identity operator of the appropriate size and appending the instruction to it.
2655	Update the QASM string for an iteration of swap_mapper by composing circuit layers and swap operations based on the current layout and layer information.
2656	Separates a bitstring into substrings based on register sizes and joins them with spaces.
2657	Formats an experiment result memory object for measurement level 0 by converting to a complex numpy array and validating its shape has 2 or 3 indices for avg or single measurement returns respectively.
2658	Format an experiment result memory object for measurement level 1, converting list memory to a complex numpy array and validating its shape to ensure it has 1-2 indices for avg/single measurement return types.
2659	Formats experiment result memory object for measurement level 2 by converting each shot's memory into bitstrings using the format_counts_memory function.
2660	Formats experiment counts by processing memory keys with optional header information for Qiskit user presentation.
2661	Formats a statevector from backend output into a list of Python complex numbers with optional decimal rounding.

Args:
    vec (list): List of [re, im] complex numbers from backend
    decimals (int): Number of decimals to round to, or None for no rounding

Returns:
    list[complex]: List of Python complex numbers
2662	Format a unitary matrix from the backend into a user-presentable complex matrix.

Args:
    mat (list[list]): list of lists of [re, im] complex numbers representing the unitary
    decimals (int): number of decimals to round to, or None for no rounding

Returns:
    list[list[complex]]: formatted unitary matrix with complex numbers
2663	Decorator that ensures a job has been submitted before allowing method execution, raising JobError if submit() hasn't been called yet.
2664	Submit the job to the backend for execution, raising exceptions if submission fails or job already submitted.
2665	Gets the status of the job by querying the Python's future, returning the current JobStatus. Returns JobStatus.RUNNING if future is running, JobStatus.CANCELLED if cancelled, JobStatus.DONE if done without exception, JobStatus.ERROR if done with exception, or JobStatus.INITIALIZING for pending state. Raises JobError if future is in unexpected state and concurrent.futures.TimeoutError if timeout occurs.
2666	**Summary:** Checks if a given LO frequency falls within the bounds of the frequency range.

**Method Signature:** `includes(self, lo_freq: float) -> bool`

**Description:** Determines whether the specified LO frequency (`lo_freq`) is within the valid range defined by the instance's lower bound (`_lb`) and upper bound (`_ub`).

**Parameters:**
- `lo_freq` (float): The LO frequency to check

**Returns:** 
- bool: True if `lo_freq` is within the range [self._lb, self._ub], False otherwise

**Example Usage:**
```python
# Assuming a LoRange instance with _lb=5.0 and _ub=10.0
range_instance.includes(7.5)  # Returns True
range_instance.includes(15.0) # Returns False
```
2667	Creates a bloch sphere representation for visualizing quantum states. Takes a state vector or density matrix as input and displays multiple bloch spheres based on the number of qubits required to represent the state. The function generates HTML and JavaScript code to render the visualization using an external quantum visualization library, allowing for customized figure sizes. Each bloch sphere corresponds to a single qubit and shows the state's projection along the x, y, and z axes using Pauli operators. The visualization is embedded directly in the output using IPython's display functionality.
2668	Embeds default qubit LO frequencies from backend and formats them to list object. If configured LO frequency matches default, returns `None`. Raises `PulseError` when LO frequencies are missing.
2669	Embeds default measurement LO frequencies from backend and formats them to a list object. Returns None if configured LO frequencies match defaults, otherwise returns the formatted list of measurement LOs. Raises PulseError if default measurement frequencies don't exist.
2670	Expand all op nodes in the DAG to the given basis by recursively decomposing non-basis instructions using their definition rules, while skipping basic instructions and already-basis instructions. Raises QiskitError if unable to unroll due to missing decomposition rules. Returns the unrolled DAG circuit.
2671	Create a Q sphere representation for visualizing quantum states. Takes a state vector or density matrix as input and generates an interactive 3D visualization using Q sphere plots. The function processes eigenvalues and eigenvectors to create spherical point representations showing probability and phase information for each quantum state component. Returns an HTML display with embedded JavaScript that renders the visualization in a web browser.
2672	Return the number of combinations for n choose k using the binomial coefficient formula, calculated by multiplying fractions of consecutive integers from (n-k+1) to n divided by integers from 1 to k.
2673	Return the lexicographical index of a combination.

This function calculates the lex index of a combination given the total number of options (n), number of elements (k), and a list representing the combination. It first validates that the list has exactly k elements, then computes the index using a dual map approach with binomial coefficients. The function raises a VisualizationError if the list length doesn't match k.

Args:
    n (int): the total number of options
    k (int): The number of elements  
    lst (list): list representing the combination

Returns:
    int: the lexicographical index for the given combination in lex order

Raises:
    VisualizationError: if length of list is not equal to k
2674	Plot the Pauli vector representation of a quantum state as a bar graph showing expectation values over Pauli matrices.
2675	Gets the unique backends that are available.

Returns:
    list: Unique available backends.

Raises:
    QiskitError: No backends available.
2676	Returns the Instruction object corresponding to the op for the node, or None if not found. Raises QiskitError if the node is not an op node.
2677	Generates a constant-sampled `SamplePulse` with specified duration and amplitude using left sampling strategy.
2678	Generates a zero-sampled `SamplePulse` with specified duration and optional name.
2679	Generates a square wave SamplePulse with specified duration, amplitude, period, and phase using left sampling strategy. If no period is specified, defaults to a single cycle. Returns a SamplePulse object with the specified parameters.
2680	Generates a sawtooth wave SamplePulse with specified duration, amplitude, period, phase, and name. If no period is specified, defaults to a single cycle. Returns a SamplePulse object representing the sawtooth waveform.
2681	Generates a triangle wave SamplePulse with specified duration, amplitude, period, and phase using left sampling strategy. Returns a SamplePulse object representing the discrete triangle wave.
2682	Generates a cosine wave SamplePulse with specified duration, amplitude, frequency, and phase using left sampling strategy. If frequency is not provided, defaults to single cycle. Returns a SamplePulse object with the specified parameters.
2683	Generates a sine wave SamplePulse with specified duration, amplitude, frequency, and phase. If no frequency is provided, defaults to a single cycle. Returns a SamplePulse object with the specified parameters.
2684	Generates an unnormalized Gaussian sample pulse centered at duration/2 with zero padding at t=-1 to prevent discontinuities. Uses left sampling strategy with integrated area _g(amp, sigma) = amp  (2). Requires positive duration, amplitude, and sigma parameters.
2685	Generates an unnormalized Gaussian derivative pulse with specified duration, amplitude, and width parameters using left sampling strategy.
2686	Generates a gaussian square pulse by sampling a continuous gaussian square function. The pulse is centered at duration/2, zeroed at t=-1 and t=duration+1 to prevent discontinuities, and uses a left sampling strategy. The pulse consists of gaussian rise/fall portions of width sigma and a square portion of width (duration-2*risefall). Returns a SamplePulse object with the specified duration, amplitude, and name.
2687	Compute the distance in axis coordinates for the given axis (x or y) by transforming the axes coordinates (0,0) and (1,1) and calculating the difference.
2688	Print the node data with specified indentation, starting with 'qreg' label followed by child node output.
2689	Return an instance of a backend from its class, raising QiskitError if instantiation fails.
2690	Rename a classical or quantum register throughout the circuit by updating register references, node arguments, and edge data while maintaining circuit integrity.
2691	Remove all operation nodes with the specified name by iterating through named nodes and removing each one.
2692	Add all wires in a quantum register to the DAG circuit, including validation checks for register instance type and duplicate names, and wire addition for each qubit in the register.
2693	Add all wires in a classical register to the DAG circuit. Raises DAGCircuitError if the input is not a ClassicalRegister instance or if there's a duplicate register name.
2694	Add a qubit or bit to the circuit by creating paired input and output nodes connected by an edge. Raises DAGCircuitError if trying to add duplicate wire.
2695	Verifies that a given condition is valid by checking if the classical register exists in the circuit's registers. Raises DAGCircuitError if the register is not found.
2696	Return a list of bits in the given condition as [(ClassicalRegister, idx)].
2697	Adds a new operation node to the DAG graph with specified properties including operation, quantum/classical arguments, and optional condition.
2698	Apply an operation to the output of the circuit by adding the operation node and updating the edges in the DAG. Returns the current maximum node. Raises DAGCircuitError if a leaf node is connected to multiple outputs.
2699	Check that wiremap neither fragments nor leaves duplicate registers, returning set of registers to add to self. Raises DAGCircuitError if fragmentation or duplicates exist.
2700	Check that the wiremap is consistent by verifying:
1. All wiremap keys exist in keymap
2. All wiremap values exist in valmap  
3. All key-value pairs have consistent types
Raises DAGCircuitError for invalid mappings or type inconsistencies.
2701	Map a condition tuple's classical register name using a wire mapping dictionary, preserving the condition's integer value while updating the register reference according to the mapping. Returns a new condition tuple with the updated register name, or None if the input condition is None.
2702	Adds a DAG at the end of self using an edge map for qubits and classical bits.
2703	Apply the input circuit to the output of this circuit by mapping qubits and classical bits according to the edge map, checking compatibility of bases, and composing operations in topological order while handling input, output, and operation nodes appropriately.
2704	Check that a list of wires is compatible with a node to be replaced, ensuring no duplicate names and correct length for the operation. Raises DAGCircuitError if checks fail.
2705	Return predecessor and successor dictionaries mapping wires to adjacent nodes.
2706	Maps all wires of an input circuit to predecessor and successor nodes in the current circuit, handling both mapped and unmapped wires, and returns the full predecessor and successor maps.
2707	Yields nodes in topological order using lexicographical sorting based on quantum arguments.
2708	Returns an iterator over edges in the multi-graph, yielding tuples of (source_node, destination_node, edge_data) for each edge.
2709	Get the list of "op" nodes in the dag, optionally filtered by instruction subclass. Returns a list of node ids containing the given op.
2710	Get the list of gate nodes in the dag.

Returns:
    list: the list of node ids that represent gates.
2711	Get the list of "op" nodes with the given name(s).
2712	Returns a list of 2-qubit gates from the circuit, excluding snapshot, barrier, and similar operations.
2713	Returns list of the predecessors of a node as DAGNodes. Accepts either a DAGNode or node id (deprecated).
2714	Returns list of predecessors connected by quantum edges as DAGNodes.
2715	Returns set of the ancestors of a node as DAGNodes. Accepts either a DAGNode or node id (deprecated). Uses networkx ancestors function on the internal multi-graph representation.
2716	Returns a list of quantum successors for a given node in the DAG, where successors are connected by quantum edges. Takes a DAGNode or node id as input and returns a list of successor DAGNodes that are connected via quantum registers. Issues a deprecation warning if called with a node id instead of a DAGNode.
2717	Remove an operation node from the DAG circuit by connecting its predecessors directly to its successors, while maintaining the graph structure and wire connections.
2718	Remove all ancestor operation nodes of the specified node from the DAG. If a node ID is provided (deprecated), it is converted to a DAGNode. Ancestors are identified using networkx and removed via the remove_op_node method, but only if they are operation nodes.
2719	Remove all descendant operation nodes of the specified node from the DAG. If a node ID is provided (deprecated), it will be converted to a DAGNode. Descendant nodes are identified using networkx and only operation nodes (type "op") are removed via the remove_op_node method.
2720	Remove all non-ancestor operation nodes of the specified node in the DAG.
2721	Remove all non-descendant operation nodes of the specified node, keeping only the node and its descendants in the DAG.
2722	Yield a shallow view on a layer of this DAGCircuit for all d layers of this circuit, where each layer represents gates acting on disjoint qubits. Each layer is constructed greedily and returned as a dictionary containing the circuit graph and a partition of qubit lists.
2723	Yield a serial layer for each gate in topological order, where each layer contains only one gate with the same structure as layers().
2724	Yields layers of a multigraph in topological order, where each layer contains nodes with no unvisited predecessors, handling multiple edges with multiplicity counting.
2725	Collects sequences of consecutive non-conditional "op" nodes with specified names into tuples. Groups together gate sequences on the same qubit(s) that form contiguous runs, where each node has exactly one successor. Returns a set of these tuples, ignoring nodes not in the circuit's basis.
2726	Returns an iterator of nodes that affect a given wire in the DAG circuit. If only_ops is True, only operation nodes are returned. Raises DAGCircuitError if the wire doesn't exist in the circuit.
2727	Count the occurrences of operation names and return a dictionary with operation names as keys and their counts as values.
2728	Return a dictionary of circuit properties including size, depth, width, number of classical bits, number of tensor factors, and operation counts.
2729	Generate a TomographyBasis object with optional preparation and measurement functions.
2730	Add state measurement gates to a circuit for Pauli X, Y, or Z basis measurements. For X basis, applies Hadamard gate (u2 with parameters 0, ). For Y basis, applies u2 gate with parameters 0, 0.5. Raises QiskitError for invalid Pauli operations.
2731	Generate a dictionary of tomography experiment configurations for quantum state or process tomography, specifying measurement and preparation bases for given qubits.
2732	Generate a dictionary of process tomography experiment configurations by specifying preparation and measurement bases for quantum process tomography experiments.
2733	Create quantum tomography circuits by appending state preparation and measurement operations to an input circuit based on a tomography set configuration, returning a list of configured tomography circuits for state or process tomography.
2734	Return a results dict for a state or process tomography experiment, including marginal counts, measurement and preparation bases, and circuit data.
2735	Compute marginal counts for a subset of measured qubits by summing up the counts of all possible outcomes for the specified qubits, effectively ignoring the other qubits in the measurement.
2736	Fit a density matrix or process matrix from tomography data using specified methods.

This function reconstructs quantum states or processes from tomography measurement data. It supports two fitting methods:
- 'wizard' (default): Constrains the result to be positive-semidefinite with optional trace and epsilon parameters
- 'leastsq': Standard least squares fitting without positive-semidefinite constraint

The function handles both state tomography data (returning density matrices) and process tomography data (returning Choi-matrices). It accepts additional options for customization including trace normalization, beta parameter for zero-count data handling, and epsilon for eigenvalue truncation.

Args:
    tomo_data (dict): Measurement data from quantum tomography
    method (str): Fitting method ('wizard' or 'leastsq'), default 'wizard'
    options (dict or None): Additional fitting parameters

Returns:
    numpy.array: Reconstructed quantum operator (density matrix or Choi matrix)

Raises:
    Exception: If invalid method is specified
2737	Reconstructs a quantum state from tomography data using unconstrained least-squares fitting. Takes measurement data, optional weights and trace constraint, and returns the reconstructed density matrix as a numpy array. Uses hedged frequencies for robust estimation when dealing with zero-count data.
2738	Returns a projector operator constructed from a list of operators and their eigenstates, using tensor products of basis vectors.
2739	Reconstructs a matrix through linear inversion using weighted least squares fitting.

Args:
    freqs (list[float]): list of observed frequencies
    ops (list[np.array]): list of corresponding projectors
    weights (list[float] or array_like, optional): weights for weighted fitting
    trace (float or None): trace of returned operator

Returns:
    numpy.array: Reconstructed operator matrix

The function performs linear inversion by:
1. Creating weight matrix W from input weights
2. Constructing basis matrix S from projectors
3. Computing weighted least squares solution using pseudoinverse
4. Applying trace normalization if specified
2740	Returns the nearest positive semidefinite operator to an input operator by setting negative eigenvalues to zero and rescaling positive eigenvalues.
2741	Get the value of the Wigner function from measurement results by processing quantum circuit counts and applying parity operations to calculate phase space values.
2742	Add measurement gates to a circuit using an optional measurement function.
2743	A text-based job status checker that continuously monitors a job's status at specified intervals, displaying updates to the console until the job completes, is cancelled, or encounters an error. It dynamically adjusts polling intervals based on job queue position and handles message formatting to prevent display artifacts.
2744	Monitor the status of an IBMQJob instance with optional async support in Jupyter notebooks.
2745	Compute Euler angles (theta, phi, lambda) for a single-qubit unitary matrix such that the matrix equals phase * Rz(phi) * Ry(theta) * Rz(lambda). Raises QiskitError if the input is not a 2x2 matrix or if computation fails.
2746	Return the gate u1, u2, or u3 implementing U with the fewest pulses. The returned gate implements U exactly, not up to a global phase.
2747	Extends a DAG circuit with virtual qubits from the layout that are not already present in the circuit. Raises TranspilerError if no layout is available. Returns the extended DAG circuit.
2748	Creates a VBox widget displaying qubit properties from a backend, including update date and formatted table with frequency, T1, T2, gate errors, and readout error for each qubit.
2749	Creates a tabbed widget for displaying job history with year, month, and week views, using the specified backend to populate the data.
2750	Plots the job history of a user over a specified time interval (year, month, or week) using pie chart visualization. Groups jobs by creation date, counts them per time bin, and displays the distribution with a pie chart showing non-zero bins. Returns a matplotlib figure instance with job count displayed in the center.
2751	```python
def draw(self, **kwargs):
    """Plot the interpolated envelope of pulse.

    Keyword Args:
        dt (float): Time interval of samples.
        interp_method (str): Method of interpolation
            (set `None` for turn off the interpolation).
        filename (str): Name required to save pulse image.
        interactive (bool): When set true show the circuit in a new window
            (this depends on the matplotlib backend being used supporting this).
        dpi (int): Resolution of saved image.
        nop (int): Data points for interpolation.
        size (tuple): Size of figure.
    """
    from qiskit.tools.visualization import pulse_drawer

    return pulse_drawer(self._samples, self.duration, **kwargs)
```

Summary:
Draws and displays the interpolated envelope of a pulse waveform using qiskit's pulse drawer functionality, with options for customization including interpolation method, plotting parameters, and output file settings.
2752	Apply cu3 gate from control qubit to target qubit with specified angles theta, phi, and lambda parameters.
2753	Returns a quantum circuit that creates a Bell state with 2 qubits by applying a Hadamard gate to the first qubit followed by a CNOT gate between both qubits, then measures both qubits.
2754	Transpiles one or more quantum circuits according to specified transpilation targets. Supports various configuration options including backend settings, basis gates, coupling maps, and optimization levels. Can handle single circuits or lists of circuits, returning transpiled circuits with parallel processing. Uses a pass manager for custom transpilation pipelines when specified, otherwise auto-selects based on options. Includes deprecation warning for seed_mapper parameter.
2755	Selects an appropriate PassManager based on transpilation configuration and runs the circuit through it, returning the transpiled circuit.
2756	Execute a list of circuits or pulse schedules on a specified backend, handling transpilation and assembly into a Qobj before submission. Returns a job instance for tracking execution.
2757	Return the primary drive channel of this qubit, raising a PulseError if no drive channels exist.
2758	Return the primary control channel of this qubit, raising PulseError if no control channels exist.
2759	Return the primary measure channel of this qubit, raising PulseError if no measurement channels exist.
2760	Return the primary acquire channel of this qubit, raising PulseError if no acquire channels exist.
2761	Function `input_state` creates an n-qubit input state for Quantum Fourier Transform (QFT) that produces output 1. It applies Hadamard gates to all qubits and inverse phase gates (u1) with angles /2^j to each qubit j, where j ranges from 0 to n-1.
2762	Assemble a list of quantum circuits or pulse schedules into a Qobj for execution on a backend. The function serializes the input experiments and annotates them with headers and configurations. It supports both QASM and pulse experiments, handling parameter binding for circuits and validating input types. The function also manages deprecated parameters and configures runtime options based on backend settings or user-provided arguments.
2763	Removes all handlers from the 'qiskit' logger to disable its logging output.
2764	Create a hinton representation of a density matrix using a 2D city style graph visualization. Takes a density matrix array and optional figure size, processes the data to separate real and imaginary components, and displays an interactive visualization using q-visualizations library. Returns HTML and JavaScript code for rendering the hinton plot in a notebook environment.
2765	Return the process fidelity between two quantum channels using their SuperOp matrices.
2766	Sets the input text data and initializes the lexer with that data.
2767	Pop a PLY lexer off the stack and update the current filename and line number from the popped lexer's qasm_file and qasm_line attributes.
2768	Push a PLY lexer onto the stack to parse the specified filename, saving the current filename and line number to the lexer before creating a new lexer for the given file.
2769	This method processes a DAG circuit by iterating through its nodes and replacing blocks of connected operations with equivalent unitary gates. It maintains the original quantum and classical registers, maps wire indices globally, and processes blocks in topological order. For each block, it creates a subcircuit, simulates its unitary matrix, and replaces the block with a single UnitaryGate. Non-block nodes are added directly to the new circuit. The method returns a new DAG circuit with blocks replaced by their unitary representations.
2770	Get the conversion method for a given instruction from the bound instructions dictionary, raising a PulseError if no method is found.
2771	Converts an AcquireInstruction to a dictionary of required parameters for QOBJ, including timing, qubits, memory slots, and measurement options based on meas_level configuration.
2772	Convert a FrameChangeInstruction to a dictionary format with updated timing information.

The method takes a time shift offset and a FrameChangeInstruction, calculates the new start time by adding the shift to the instruction's start time, and returns a dictionary containing the command name ('fc'), updated start time (t0), channel name, and phase value. The dictionary is then passed through a Qobj model for final formatting.

Args:
    shift (int): Time offset to be added to the instruction start time
    instruction (FrameChangeInstruction): The frame change instruction to convert

Returns:
    dict: Dictionary containing the formatted command parameters with keys 'name', 't0', 'ch', and 'phase'
```
2773	Convert a PersistentValueInstruction to a dictionary format with name 'pv', adjusted time t0, channel name, and value.
2774	Convert a drive instruction by adjusting its time reference and extracting required parameters.

Args:
    shift (int): Offset time to be added to the instruction start time
    instruction (PulseInstruction): The drive instruction to be converted

Returns:
    dict: Dictionary containing the converted instruction parameters with name, adjusted start time (t0), and channel name

The method takes a pulse instruction and returns a dictionary of required parameters by:
1. Extracting the command name from the instruction
2. Calculating the new start time by adding shift to the original start time
3. Getting the channel name from the first channel of the instruction
4. Using the internal _qobj_model to create the final dictionary with these parameters
2775	Return converted `Snapshot` by creating a command dictionary with name, t0 (shift+start_time), label, and type from the instruction, then passing it to the qobj model.
2776	Updates the annotations of a discretized continuous pulse function by adding a 'duration' parameter with type int to the beginning of the annotations dictionary.
2777	Decorator that creates a sampler function for converting continuous pulse functions to discretized pulses. Takes a sample function and returns a decorator that wraps continuous pulse functions with sampler logic, converting them to SamplePulse objects with updated annotations and documentation.
2778	Filter backends based on configuration, status, and custom filters. Supports filtering by backend attributes via keyword arguments and custom callable filters. Returns backends that match all specified criteria.
2779	Resolve backend name from a deprecated name or an alias, checking availability and providing warnings for deprecated names.
2780	Converts a DAGCircuit object to a QuantumCircuit object by reconstructing quantum and classical registers, and adding operations in topological order.
2781	Converts a matrix or list observable to dictionary form with binary string keys representing quantum states and their corresponding observed values.
2782	Update a node in the symbol table, checking for duplicate declarations and raising QasmError if found.
2783	Verify that a qubit identifier matches the gate prototype's declared bits, raising an error if the symbol doesn't exist or isn't properly declared as a bit.
2784	Verifies each expression in a list by recursively checking that all Id elements resolve to the current symbol table, raising QasmError for unresolved identifiers.
2785	Verifies a user-defined gate call by checking that:
1. The gate definition exists in the global symbol table
2. The symbol is actually a gate or opaque type
3. The number of qubits matches between the call and definition
4. The number of arguments matches between the call and definition (if arguments are provided)
Raises QasmError with descriptive messages for any mismatches found.
2786	Verify that a register object is valid by checking:
1. The object name exists in the global symbol table
2. The object type matches the expected type
3. For indexed registers, verify the index is within valid bounds (0 <= index < bound)
2787	Verifies a list of registers by iterating through each child element and ensuring they are properly declared as bits, throwing an error if not.
2788	Compute the column position of a token in the input text.

Input is the input text string and token is a token instance.
Returns the column number (1-indexed) of the token's position in the text,
or 0 if the token is None. The column is calculated by finding the
position of the last newline character before the token and computing
the difference from the token's lexpos.
2789	Sets the parse_deb field to the specified boolean value, raising QasmError if the value is not True or False.
2790	Parse input data using the assigned parser and return the resulting QASM object, raising a QasmError if parsing fails.
2791	Parser runner that parses input data twice with debug mode enabled and converts the abstract syntax tree to string representation.
2792	Parse the data by reading from file if filename is provided, then use QasmParser to parse the data and return the parsed result.
2793	Apply controlled Rz gate from control qubit to target qubit with angle theta.
2794	Return a basis state ndarray for a given bitstring and number of qubits. Converts the binary string representation to a quantum state vector where only one element is 1 and others are 0. Raises QiskitError if the bitstring length exceeds the specified number of qubits.
2795	Maps a pure quantum state to a density matrix (state matrix). If flatten=False, returns a 2^num  2^num density matrix. If flatten=True, returns a flattened 4^num-dimensional vector stacked column-wise from the density matrix.
2796	Calculate the purity of a quantum state by computing the trace of the density matrix squared. For pure states (represented as column vectors), purity is 1.0. For mixed states (represented as density matrices), purity equals the trace of rho.
2797	This method runs a commutation analysis on a DAG (Directed Acyclic Graph) representation of a quantum circuit. It identifies which gates can commute with each other by:

1. Initializing a commutation set dictionary to track gate relationships
2. Building a mapping of gates to their respective qubits
3. Creating edges in the commutation set for each qubit
4. Iterating through gates on each wire to determine commutation groups
5. Grouping gates that can commute with each other into lists
6. Storing the commutation relationships in the property_set for later use

The result is a property_set containing commutation information that can be used for quantum circuit optimization.
2798	Creates a backend widget displaying backend information including name, gate map visualization, qubit count, job pending status, T1 and T2 coherence times, and operational status indicators.
2799	Updates backend monitoring information periodically, tracking status, pending jobs, and operational state of each backend, while managing UI display updates and thread execution.
2800	Generates a jobs_pending progress bar widget with current value, progress bar, and max value display.
2801	**Summary:**

The `run` method performs CX gate cancellation on a DAGCircuit by identifying consecutive CNOT gates and removing redundant operations. It collects all CNOT gate runs, partitions them into chunks with equal gate arguments, and cancels pairs of CNOT gates within each chunk. If a chunk contains an even number of gates, all gates are removed. If odd, only the first gate remains, with the rest being removed. The method returns the transformed DAG circuit with optimized CNOT gate structure.
2802	Return a single backend matching the specified filtering criteria, raising an exception if zero or multiple backends match.
2803	Return the shape for bipartite matrix as a tuple of four dimensions: (input_dim, output_dim, input_dim, output_dim).
2804	Get the number and size of unique registers from bit_labels list.

Args:
    bit_labels (list): list of [register_name, bit_index] pairs

Yields:
    tuple: register_name:size pairs indicating unique register names and their sizes
2805	Truncates long floats using regex matching and formatting.

Args:
    matchobj (re.Match): contains original float
    format_str (str): format specifier (default: '0.2g')
Returns:
    str: returns truncated float

The function takes a regex match object containing a float value and formats it according to the specified format string, returning the truncated float as a string. If no match is found, it returns an empty string.
2806	Return LaTeX string representation of the circuit using the Qconfig package for graphical representation.
2807	Get depth information for the circuit, returning the number of columns and total size of columns.
2808	Get height, width & scale attributes for the beamer page, considering PIL and beamer size limits, aspect ratio, and minimum size constraints.
2809	Loads a QObj schema from a file and caches it for future use. Takes a file path and optional name parameter, reads the JSON schema file, stores it in the module's schema cache under the specified name (or derived from the filename), and returns the loaded schema dictionary.
2810	Generate validator for JSON schema.

Args:
    name (str): Name for validator. Will be validator key in `_VALIDATORS` dict.
    schema (dict): JSON schema `dict`. If not provided searches for schema in `_SCHEMAS`.
    check_schema (bool): Verify schema is valid.
    validator_class (jsonschema.IValidator): jsonschema IValidator instance. Default behavior is to determine this from the schema `$schema` field.
    **validator_kwargs (dict): Additional keyword arguments for validator.

Return:
    jsonschema.IValidator: Validator for JSON schema.

Raises:
    SchemaValidationError: Raised if validation fails.
2811	Load all default schemas into `_SCHEMAS` by joining the schema base path with default schema paths and calling `_load_schema` and `_get_validator` for each schema.
2812	Validates a JSON dictionary against a specified schema, raising a SchemaValidationError if validation fails. Supports both custom schemas and predefined Qiskit standard schemas.
2813	Return a cascading explanation of the validation error in a formatted string.
2814	**Summary:** The `majority` function implements a majority gate circuit using three quantum controlled operations. It takes a quantum register `p` and three qubits `a`, `b`, `c` as input. The function applies two CNOT gates (controlled-X gates) from qubit `c` to qubits `a` and `b`, followed by a CCNOT gate (Toffoli gate) with `a` and `b` as controls and `c` as the target. This creates a quantum circuit that outputs 1 if at least two of the three input qubits are 1, effectively implementing a majority function.
2815	Unmajority gate implementation using three quantum gates: CCX (Toffoli) gate followed by CX (CNOT) gates to perform the reverse operation of a majority gate.
2816	Converts a QuantumCircuit to a LaTeX string for circuit visualization.

Args:
    circuit (QuantumCircuit): input circuit to convert
    scale (float): scaling factor for the output image (default: 0.7)
    filename (str): optional file path to write the LaTeX output to
    style (dict or str): styling options or style file path
    reverse_bits (bool): whether to reverse bit ordering in registers (default: False)
    plot_barriers (bool): whether to include barriers in visualization (default: True)
    justify (str): justification style ('left', 'right', or 'none', default: 'left')

Returns:
    str: LaTeX string containing the circuit diagram formatting

The function processes the circuit into layered instructions, generates a QCircuitImage object with specified formatting options, and returns the resulting LaTeX code. If a filename is provided, the LaTeX output is also written to that file.
2817	Draws a quantum circuit using matplotlib with customizable styling and layout options, returning a matplotlib figure object for visualization.
2818	Return a random dim x dim unitary Operator from the Haar measure using Gram-Schmidt orthogonalization.
2819	Generate a random density matrix of specified length and rank using the given method ('Hilbert-Schmidt' or 'Bures'). Returns a density matrix as a numpy array, raises QiskitError for invalid methods.
2820	Returns a normally distributed complex random matrix with specified dimensions, where each real and imaginary component is sampled from the normal distribution.
2821	Generate a random density matrix from the Hilbert-Schmidt metric by creating a Ginibre matrix, computing its Gram matrix, and normalizing by its trace.
2822	Generate a random density matrix from the Bures metric by creating a positive matrix from the sum of identity and random unitary, multiplying it with a Ginibre matrix, and normalizing by its trace.
2823	Return a list of custom gate names in this gate body.
2824	Returns the n-times composition channel as a SuperOp object by computing the matrix power of the superoperator matrix. Raises QiskitError if input and output dimensions are not equal or if the power is not an integer.
2825	This method composes two quantum channels by combining their superoperator representations. It takes another channel (`other`) and qubit arguments (`qargs`) to determine how they should be composed. The composition can be done in front or at the back of the current channel, which affects how input and output dimensions are updated. 

The method performs tensor contractions by:
1. Computing tensor contraction indices based on qubit positions
2. Reshaping the current and other channel data into tensor form
3. Using einsum operations to perform the matrix multiplication with proper index contractions
4. Returning a new SuperOp channel with the composed operation and updated dimensions

The composition respects qubit ordering conventions where qubit 0 corresponds to the rightmost position in tensor products, and handles both left and right multiplication scenarios.
2826	Convert a QuantumCircuit or Instruction to a SuperOp by first converting the circuit to an instruction if needed, then initializing an identity superoperator of appropriate size and appending the instruction.
2827	Return a circuit with a barrier before last measurements by identifying final operations, creating a barrier layer, moving final operations to the new layer, and merging adjacent barriers.
2828	Convert a list of circuits into a Qobj for backend execution.

This function converts quantum circuits into a Qobj (Quantum Object) that can be executed on quantum backends. It's a deprecated utility that serves as a wrapper around the newer `qiskit.compiler.assemble()` function. The function issues deprecation warnings for several parameters that will be removed in future versions.

Parameters:
- circuits: List of QuantumCircuit objects or a single QuantumCircuit
- qobj_header: Optional QobjHeader containing metadata
- qobj_id: Optional identifier for the Qobj (deprecated)
- backend_name: Optional backend name (deprecated)
- config: Optional configuration dictionary (deprecated)
- shots: Optional number of shots (deprecated)
- max_credits: Optional maximum credits (deprecated)
- basis_gates: Optional basis gates (deprecated)
- coupling_map: Optional coupling map (deprecated)
- seed: Optional random seed (deprecated)
- memory: Optional memory flag (deprecated)

Returns:
- Qobj: The assembled quantum object ready for backend execution

Note: This function is deprecated and will be removed in Qiskit Terra 0.9. Use `qiskit.compiler.assemble()` instead.
2829	Expand 3+ qubit gates using their decomposition rules, recursively unrolling until maximum node degrees are 2, raising QiskitError if gates are not decomposable.
2830	Expand a given gate into its decomposition by walking through the DAG and replacing each non-basis node with its decomposition rule, while preserving the register structure and handling classical registers appropriately.
2831	This method calculates and defines the quantum circuit implementation for a unitary operation. For a 1-qubit unitary, it uses Euler angle decomposition to convert the unitary matrix into a U3 gate. For a 2-qubit unitary, it uses the KAK decomposition to decompose the unitary into a sequence of quantum gates. The resulting gate definitions are stored in the `self.definition` attribute.
2832	Validates that the value is of the correct type for the schema's model, handling both single values and collections. Raises ValidationError with appropriate error messages if type validation fails.
2833	Validate if it's a list of valid item-field values by checking each element against the container's validation rules, raising a ValidationError with all errors if any element is invalid.
2834	Set the absolute tolerance parameter for float comparisons, validating that the value is non-negative and within class-defined maximum tolerance limits.
2835	Sets the relative tolerance parameter for float comparisons, validating that it's non-negative and within maximum allowed tolerance bounds.
2836	Reshape input and output dimensions of operator.

Args:
    input_dims (tuple): new subsystem input dimensions.
    output_dims (tuple): new subsystem output dimensions.

Returns:
    Operator: returns self with reshaped input and output dimensions.

Raises:
    QiskitError: if combined size of all subsystem input dimension or
    subsystem output dimensions is not constant.
2837	Return tuple of input dimensions for specified subsystems. If no subsystems specified, returns all input dimensions. If subsystems specified, returns dimensions only for those subsystems in the specified order.
2838	Return tuple of output dimensions for specified subsystems. If no subsystems specified, return all output dimensions. If subsystems specified, return dimensions for only those subsystems in the specified order.
2839	Make a copy of current operator by creating a new instance with the same data and dimension information.
2840	Return the composition of an operator with itself n times.

Args:
    n (int): the number of times to compose with self (n>0).

Returns:
    BaseOperator: the n-times composed operator.

Raises:
    QiskitError: if the input and output dimensions of the operator are not equal, or the power is not a positive integer.
2841	Method `_automatic_dims` checks if input dimensions correspond to qubit subsystems. If `dims` is None, it sets dimensions equal to size. If dimensions don't match size, it raises a QiskitError. For integer dimensions, it calculates the number of qubits and returns either `num_qubits * (2,)` if the dimension is a power of 2, or `(dims,)` otherwise. For tuple/list dimensions, it returns the dimensions as a tuple.
2842	Perform matrix multiplication on a tensor using NumPy's einsum operation. Contracts specified indices of a tensor with a matrix and returns the resulting tensor. Supports both left and right multiplication modes with customizable index shifting. Raises QiskitError if the matrix does not have an even number of indices.
2843	Override `_deserialize` to customize the exception message when schema selection fails during deserialization.
2844	Override `_serialize` to customize exception handling, specifically catching `TypeError` exceptions related to invalid schema data and raising a `ValidationError` with a specific error message instead.
2845	Check if a value matches at least one of the possible choices by validating against ModelTypeValidator fields. Returns the result of the first successful validation or raises a ValidationError if none match.
2846	Return the state fidelity between two quantum states, handling cases for pure states and mixed states represented as state vectors or density matrices.
2847	Apply real scalar function to singular values of a matrix using SVD decomposition.

Args:
    a (array_like): (N, N) Matrix at which to evaluate the function
    func (callable): Callable object that evaluates a scalar function f

Returns:
    ndarray: Value of the matrix function specified by func evaluated at `A`
2848	Returns a new Snapshot object with the same parameters as the current instance.
2849	Set snapshot label to specified name.

Args:
    name (str or None): label to assign to snapshot

Raises:
    TypeError: If name is not a string or None

The label method assigns a string label to a snapshot object. If the provided name is not a string, it raises a TypeError exception. This method is used to set descriptive labels for snapshots in quantum circuit operations.
2850	Return True if QuantumChannel is a unitary channel by converting to operator and checking if it's unitary within given tolerances, or False if conversion fails.
2851	Converts a channel to its unitary representation Operator by transforming the channel's representation into a matrix and wrapping it in an Operator object with appropriate input and output dimensions.
2852	Converts a quantum channel to a Kraus or UnitaryGate circuit instruction. If the channel is unitary, it creates a unitary gate instruction; otherwise, it creates a Kraus instruction. Raises QiskitError if the input is not an N-qubit CPTP quantum channel.
2853	Converts input data into a QuantumChannel subclass object or Operator object, handling various conversion methods in priority order: direct QuantumChannel instances, objects with `to_quantumchannel` method, objects with `to_channel` method, or fallback to Operator initialization.
2854	Create a Graphene Enum for sorting SQLAlchemy model queries with customizable name and symbol naming convention.
2855	**Summary:**

The `patch_strptime()` function performs monkey patching on Python's internal `_strptime` module to ensure consistent date parsing behavior regardless of system locale settings. It replaces the locale-dependent language functions with English equivalents, preventing issues that occur when system locales are set to non-English languages (like fr_FR) where date parsing would otherwise fail due to translated month and day names. The function loads the original `_strptime` and `_calendar` modules, overrides their language-related attributes with fixed English values, and returns the patched `strptime_time` function for use in date parsing operations.
2856	Get an ordered mapping of locale codes to locale instances, either from provided locales or constructed from languages and region. Supports ordering control and conflicting locale handling.
2857	Yields locale instances based on provided language codes, locale codes, and region information, with options to control ordering and handling of conflicting locales.
2858	Check if all tokens are valid for the locale by verifying they match relative regex, exist in the object, or are digits. Returns True if all tokens are valid, False otherwise.
2859	Split a date string into tokens using locale translations, optionally preserving formatting and handling relative time expressions.
2860	Parse date and time from a given date string using specified formats, languages, locales, and settings. Returns a datetime object if successful, otherwise returns None.
2861	Parses the time component from date strings by removing unwanted patterns and attempting to parse the remaining string.
2862	Check if the locale is applicable to translate a date string by validating its tokens against the locale's dictionary.
2863	Translate a date string to its English equivalent by processing numerals, normalizing unicode, splitting into tokens, applying relative translations, and joining the result while optionally preserving formatting.
2864	Parse a date string using multiple formats and return a dictionary with 'period' and 'obj_date' values. Try each format in date_formats until a valid parse is found. If the format doesn't include day information, set period to 'month' and use the last day of the month. If the format doesn't include year information, use the current year. Apply timezone settings to the parsed date object. Return None for date_obj if no format matches.
2865	Returns an ammo generator based on configuration. Supports multiple ammo file types (phantom, slowlog, line, uri, uripost, access, caseline) and URI styles. Validates that only one ammo source is specified (either uris or ammo_file). For phantom ammo files, automatically detects the format from the first line. Raises appropriate errors for invalid configurations or unsupported ammo types.
2866	Translates HTTP error codes to network codes, returning 0 for success or 314 for assertion failures when param1 length is 3 or less. For longer param1 values, extracts the exception code and returns corresponding network code from KNOWN_EXC dictionary, logging unknown exceptions with code 41.
2867	Translates exception strings to HTTP codes. If the input string has 3 or fewer characters and represents a valid integer, returns that integer. Otherwise, extracts the last word from the string and checks if it's in KNOWN_EXC keys - if so, returns 0, otherwise logs a warning and returns 0.
2868	Read phantom tool specific options including threads, modules path, additional libraries, log level, timeout, and create necessary log files and stream configurations for both main and multi streams.
2869	Generate phantom tool run configuration file by composing stream configurations, setting up benchmark blocks and statistics, and writing the final configuration to a temporary file using a template.
2870	Method `get_info` creates a merged configuration summary from multiple streams by copying the first stream's data and aggregating properties from all streams. It combines step schedules, load schemes, loop counts, ammo files, ammo counts, durations, and instance counts. The method handles step merging by summing step values and tracking their occurrences, sets default values for various configuration parameters, and raises a ValueError if total ammo count is zero. The merged result is returned as a configuration object with consolidated stream information.
2871	Composes a benchmark configuration template by preparing stepper settings, handling SSL transport options, setting method streams, log configurations, protocol settings, binding options, and reply limits, then substituting these values into a template file based on whether the configuration is for a main or additional benchmark. Returns the final configuration string.
2872	This function monitors stdout and stderr streams for new content and logs the output. It uses select() to check which streams have data available for reading, then reads and logs the content from each stream. The function logs stdout messages at DEBUG level and stderr messages at WARN level, with optional comment prefixes for identification.
2873	Helper function to convert time string with units to seconds. Parses strings like "2h30m" and converts to total seconds, supporting units: ms, s, m, h, d, w. Raises ValueError for unsupported units.
2874	Summary: Reads and configures stepper wrapper options including ammo file, loop limits, load profile, instances, URIs, headers, HTTP version, caching settings, and chosen cases. Expands user paths and processes configuration options for stepper functionality.
2875	Generates test data by creating or loading stepper information, handling caching and publishing status updates.
2876	Generate stepped data filename based on cache settings and parameters, or use default "ammo.stpd" filename. When caching is enabled, creates a hash of various configuration parameters to generate a unique cache filename, including load profile, headers, URIs, and ammo details. When caching is disabled, returns the default filename.
2877	Read stepper information from a JSON cache file and return it as a StepperInfo object.
2878	Writes stepper information to a JSON file with formatted indentation.
2879	Method `__make_stpd_file` generates a stpd file using the Stepper class by creating a Stepper instance with various load testing parameters and writing the output to a file.
2880	Creates a Load Plan from a schedule, publishes duration and steps information, and returns the load plan object.
2881	Return the requests per second (RPS) at time t, linearly interpolating between minrps and maxrps over the duration. Returns 0 for times outside the valid range [0, duration].
2882	Execute a command and raise RuntimeError if the exit code is non-zero.
2883	Method `decode_monitoring` processes monitoring data by iterating through timestamped data points, extracting host information and metrics, and converting them into structured points with timestamps. It returns a list of formatted monitoring points.
2884	Make a set of points for a given label including overall quantiles, overall meta, net codes, proto codes, and histograms.
2885	Publishes a value to the status with the given key, logging the action and using the core's publish method.
2886	Helper function to aggregate code counts by regex mask match. Iterates through codes dictionary, matches each code against provided regex pattern, and sums up counts for matching codes. Returns total count of matched codes.
2887	Stops all worker threads by setting the quit flag, waiting for them to finish their current jobs, clearing the task queue, and joining the feeder thread. Handles exceptions during queue cleanup.
2888	A feeder method that runs in a separate thread within the main process, responsible for reading tasks from a plan and feeding them into a task queue while managing worker lifecycle. It handles quitting signals, worker completion, and publishes termination tasks to all workers. The method also includes retry logic for posting killer tasks and ensures proper cleanup and worker joining on termination or interruption.
2889	Initialize logging with file and console handlers, setting up different log formats and filters for stdout and stderr output.
2890	Override config options with user specified options by applying shorthand options from user_options if they exist.
2891	Method: configure

Summary: Prepares the system for execution by setting up configuration options, acquiring a lock file, loading configurations and plugins, and handling lock-related settings. The method attempts to acquire a lock with retry logic, loads default and user-specified configurations, and sets up plugin loading while respecting lock ignore settings.

Parameters: 
- options (dict): Configuration options including lock directory, lock fail behavior, and configuration files

Returns: None

Side effects: 
- Sets core configuration options
- Acquires filesystem lock with retry logic
- Loads configurations and plugins into the core
- May raise RuntimeError if lock acquisition fails and lock_fail option is set
2892	Method __graceful_shutdown performs a graceful shutdown by calling shutdown routines, including plugins_end_test and plugins_post_process, then returns the resulting status code.
2893	Collects data and statistics from queues, caches them by timestamp, and sends matching pairs to listeners. When end=True, notifies listeners for any remaining data items without matching statistics.
2894	Notifies all listeners about aggregate data and stats by calling their on_aggregated_data method with the provided data and stats parameters.
2895	Returns a marker function of the requested marker_type. Supports integer marker types (up to 3) and string marker types ('uniq', 'uri'). When enum_ammo=True, returns an enumerator that increments a counter each time it's called. Raises NotImplementedError for non-existent marker types.
2896	Parse a duration string into milliseconds. Supports units 'd' (days), 'h' (hours), 'm' (minutes), 's' (seconds), and fractional values. Returns total milliseconds.
2897	Start local agent by executing a Python process with specified arguments including telegraf path and host, optionally killing old processes, and return the session.
2898	Starts a remote agent by executing a shell command through SSH asynchronous session, logs the command, and initializes a reader thread to handle output buffer. Returns the SSH session object.
2899	Method `__discover_jmeter_udp_port` searches for a JMeter UDP port in the JMeter log file by matching a regular expression pattern against lines in the log. It reads the log file line by line, looking for a line containing "Waiting for possible shutdown message on port <port_number>". If found, it extracts and returns the port number as an integer. If no port is discovered after 10 attempts with 1-second delays between attempts, it logs a warning and returns None.
2900	Method `__add_jmeter_components` modifies a JMX file by removing problematic WorkBench components, injecting user-defined variables, and adding appropriate JMeter writer components based on version and logging requirements. It reads the original JMX file, processes its content to handle WorkBench settings, prepares variable definitions, selects the appropriate template based on JMeter version and logging settings, creates a new JMX file with the modifications, and returns the path to the new file. The method handles XML parsing exceptions and file system errors during temporary file creation.
2901	Gracefully terminates a running process by first attempting to terminate it orderly, then forcefully killing it if necessary, while handling potential errors and closing associated stderr file.
2902	Parse lines and return stats by splitting on tabs, converting timestamp to int, and creating stats items for new timestamps.
2903	Creates a criterion object from a configuration string by parsing the criterion type and parameters, then instantiating the appropriate criterion class from custom criterions or raising an error for unsupported types.
2904	Method: getconfig(self, filename, target_hint)
Summary: Loads and parses an XML configuration file, extracts host information, and returns a list of host configurations based on the provided target hint. Raises RuntimeError if the configuration file cannot be read.
2905	Creates a startup configuration file for agent commands, handling existing files by using temporary files, and writes startup, shutdown, and source commands to the config. Returns the path to the created configuration file.
2906	Checks if available disk space meets the minimum requirement, raises RuntimeError if not enough space.
2907	Method `__check_mem` checks available RAM memory against a configured limit. It retrieves the free memory using `psutil.virtual_memory()`, converts it to MB, logs the memory usage, and raises a `RuntimeError` with a descriptive message if the free memory falls below the specified limit. The method is designed to prevent operations from proceeding when insufficient memory is available.
2908	Gets the width and height of the terminal viewport by attempting multiple methods: ioctl system calls, environment variables (LINES/COLUMNS), and fallback to default size (30, 120). Returns a tuple of (width, height).
2909	Gets the next line for the right panel, truncating it if it exceeds the panel width while preserving markup formatting.
2910	Truncates an array of line chunks according to maximum visible width, preserving markup tags and handling text overflow with ellipsis.
2911	Renders the left panel blocks by calculating available space, handling blank spacing, and formatting lines with proper truncation and markup cleaning. Returns a list of formatted lines for display.
2912	Main method to render screen view, handling terminal sizing, panel calculations, widget rendering, and final output composition with left and right panels.
2913	Add a widget to the right panel info widgets dictionary with a unique index, automatically resolving conflicts by incrementing the index until an available slot is found.
2914	Right-pad lines of a block to make them all equal width by adding spaces to shorter lines, returning the maximum width and the padded lines.
2915	Calculate visible length of string or list/tuple of strings by removing markup characters and counting remaining characters.
2916	Creates a load plan timestamps generator from a schedule of instances. The generator produces timestamp sequences based on schedule commands like 'ramp', 'wait', 'line', 'const', and 'step'. It uses a LoadPlanBuilder to parse the schedule and generate timestamps. The function also publishes load plan metadata including duration, steps, and instance count. Returns an iterator that yields timestamps according to the defined load pattern.
2917	Format level string with percentage sign for relative levels, otherwise return level as-is.
2918	Add a right panel widget to the screen instance, with debug logging if no screen exists.
2919	Send a request to the writer service with retry logic for network errors and maintenance situations.
2920	Loads and instantiates plugin classes based on configuration, handling deprecated plugin names and logging debug information about the loading process.
2921	Retrieve a plugin of the specified class, raising KeyError if none is found. Returns the last matching plugin if multiple are found.
2922	Retrieve a list of plugins of the specified class type, raising KeyError if no matches are found.
2923	Move or copy a single file to the artifacts directory, optionally keeping the original file. If the file doesn't exist or if a file with the same name already exists in the destination, it logs a warning and returns without performing the operation. The destination file is set to have read/write permissions for owner and read-only permissions for group and others.
2924	Add a file to be stored as a result artifact during post-processing, with an option to keep the original file.
2925	Generate a temporary file name in the artifacts directory, close the file handle, and set read/write permissions for owner and read-only for group and others.
2926	Read configs set into storage
2927	Flush current statistics to a file by writing the config data to the specified filename or default file.
2928	Get options list with requested prefix from a configuration section, filtering by optional prefix and returning a list of tuples containing option names (with prefix removed) and their values.
2929	Return sections that start with the specified prefix.
2930	Decode statistical data from a chunk and yield formatted statistics items.
2931	Returns an info object from cache or phantom, or None if phantom doesn't exist.
2932	Prepare for monitoring by installing agents on configured hosts. Parse configuration to get agent settings, then create appropriate client (localhost or SSH) for each host. Install monitoring agent via the client, and collect configuration files and scripts for artifact management.
2933	Poll agents for data and process their results. Returns the number of collected data items.
2934	Sends collected data to all registered listeners by creating a deep copy of the data for each listener to process.
2935	Method `__detect_configuration` determines which plugin configuration to use (telegraf or monitoring) by checking available options in the core configuration. It handles three main cases: when both configs are specified (raises ValueError), when only telegraf is specified (returns 'telegraf'), when only monitoring is specified (returns 'monitoring'), and when neither is specified (uses default target logic). The method returns the appropriate SECTION name or None for defaults, and raises ValueError with descriptive error messages when configuration conflicts are detected.
2936	Stores metric data in tree structure and calculates offset signs: negative sign (-1) for CYAN (lower than previous), positive sign (1) for YELLOW (higher than previous), zero sign (0) for WHITE (initial or equal values).
2937	Decode agents JSON data and calculate differences for specified metrics, returning timestamped prepared results with decoded keys.
2938	Start subscribing to channels by separating them into WebSocket and NATS channels, then send subscription requests to the appropriate connections.
2939	Run the event loop forever, subscribing to initial channels and closing gracefully when done.
2940	Close any open connections by closing the websocket and polygon connections if they exist.
2941	Perform a single HTTP request with retry logic for rate limiting. Raises RetryException for 429 responses and APIError for API errors containing error codes. Returns JSON response body for successful 200 responses, or None for empty responses.
2942	Submits a new order with the specified parameters, including optional limit and stop prices, and returns an Order object.
2943	Get an order by ID and return an Order object.
2944	Get an open position for the given symbol and return it as a Position object.
2945	Get a list of assets with optional status and asset_class filters, returning a list of Asset objects.
2946	Get an asset by symbol and return an Asset object.
2947	Creates a joining subplan that fanned out a single value to multiple parallel steps and then coalesces them into a single output for downstream dependencies. Takes a list of parallel execution steps, creates a join step that passes through their outputs, and returns an execution subplan containing all parallel steps plus the join step, with a handle to the joined output.
2948	Function `dict_param` validates that the input `obj` is a native Python dictionary. If `obj` is not a dictionary, it raises a type mismatch exception. If key_type or value_type are specified, it also validates the types of keys and values in the dictionary. Returns the validated dictionary.
2949	Ensures the input object is either a dictionary or None, raising an exception if it's neither. If None, returns an empty dictionary. If a dictionary, validates key-value types if specified and returns the dictionary.
2950	Constructs an event logger that wraps a callback function to process event records. Takes a callable callback that receives event records, and returns a logger handler that formats log messages into event records and passes them to the provided callback. Uses a structured logger handler with debug level logging.
2951	Constructs a JSON event logger that records event records to a specified JSON file path. Returns a logger configured with a JSON handler that processes log records into structured event records with metadata, using a single handler logger setup.
2952	Create an RCParser instance by reading a config file from the specified path. If no path is provided, use the default config path. Raise ConfigFileError if the file doesn't exist. Return a new RCParser instance with the parsed configuration.
2953	Get config dictionary for the given repository, returning None if section not found or raising configparser.Error for invalid files. Returns dictionary containing repository URL, username, and password.
2954	Formats a configuration dictionary into a GraphQL-compatible string representation with proper indentation and formatting.
2955	Get a pipeline by name, constructing and caching it if necessary. Raises DagsterInvariantViolationError if pipeline not found. Returns PipelineDefinition instance.
2956	Return all pipelines as a list by mapping get_pipeline method over pipeline_dict keys and performing uniqueness check through _construct_solid_defs.
2957	This function continuously polls a process queue for the next event, blocking with a timeout until an item is available. If the queue is empty, it checks if the process is still alive. If the process has died, it attempts to drain any remaining items from the queue. If both the process is dead and the queue is empty, it returns a special constant indicating the process is dead and queue is empty. The function will infinite loop if the child process gets stuck in an infinite loop. The function is unreachable after the while True loop.
2958	Execute a pipeline using a message queue for communication, handling process initialization, repository validation, pipeline execution with error handling, and cleanup operations including sending process start/done signals and closing the message queue.
2959	Waits until all processes are complete and no processes are enqueued, using a lock-based polling mechanism with 0.1 second intervals.
2960	Creates a Field configuration schema that defines the type, optionality, defaults, and description for configuration data. Returns a FieldImpl object with the specified parameters, validating that the provided dagster_type is valid for configuration use.
2961	Builds the execution plan by constructing a dependency dictionary from steps and their inputs, then returns an ExecutionPlan object with the pipeline definition, step dictionary, dependencies, and persisted artifacts.
2962	Builds an ExecutionPlan from a pipeline definition and environment config by processing solids in topological order, handling inputs, transform functions, and outputs through a _PlanBuilder object.
2963	Build a subset pipeline containing only specified solids and their dependencies. Takes a pipeline definition and list of solid names, filters solids to only those in the name list, builds dependency mapping for internal dependencies only, and returns new pipeline with filtered solids and dependencies.
2964	Return the solid named "name". Throws if it does not exist.

Args:
    name (str): Name of solid

Returns:
    SolidDefinition: SolidDefinition with correct name.
2965	Constructs and returns a list of shell commands for building and publishing a Python package to PyPI. The commands include cleaning the dist directory, executing additional optional steps, building the package as a source distribution and wheel, and uploading it using twine. An optional nightly flag can be set to append '--nightly' during the build process.
2966	Tags all submodules for a new release by ensuring version consistency across git tags and version.py files, validating PEP 440 compliance, and creating new git tags and commits.
2967	Creates a pipeline context definition that passes through a pre-existing execution context. Useful for testing scenarios where a manual context needs to be provided to a PipelineDefinition. Returns a dictionary containing the context definition under the default context name.
2968	A decorator that annotates functions to extract selected properties from a config_value and create an input schema for a custom type. Takes a Selector config class as argument and returns a wrapped function that processes the config_value by extracting its single item and passing it to the decorated function.
2969	A decorator for annotating functions that select and materialize properties from config values based on a selector configuration. Takes a Selector config class and returns a wrapped function that extracts the selector key and value from config_value and passes them to the decorated function along with a runtime value, then creates an output schema using the resolved config type and selector function.
2970	Automatically wraps a block of text using TextWrapper with specified formatting options and outputs each line using the line method.
2971	Download an object from S3 using the provided context and return the path to the downloaded file.
2972	Uploads a file object to Amazon S3 using the provided context and configuration, returning the bucket and key where the file was uploaded.
2973	Wraps user-space code execution in an error boundary that ensures all user errors are wrapped in DagsterUserCodeExecutionError while preserving the original stack trace. Catches exceptions from user code, re-raises them as the specified error class with additional context, and passes through existing DagsterError instances without modification.
2974	Creates directories recursively, similar to 'mkdir -p' command. Creates all intermediate-level directories needed to contain the specified path. Silently ignores existing directories. Raises OSError for other errors.
2975	Wraps a user-provided function in an error boundary and ensures it yields exactly one value from a generator, raising appropriate errors for zero or multiple yields.
2976	Creates a context-free logger for pipeline initialization failures, using default console logging and optional custom loggers from run configuration.
2977	Whether the solid execution was successful by checking if any step succeeded and no steps failed.
2978	Returns True if all step events in input_expectations, output_expectations, and transforms are of type STEP_SKIPPED, indicating the solid execution was skipped.
2979	Return dictionary of transformed results with output names as keys, or None if execution failed. Reconstructs pipeline context to materialize values.
2980	Returns the transformed value for a given output name from a pipeline execution result, or None if the execution was unsuccessful. Raises an error if the specified output name doesn't exist in the solid definition. Reconstructs the pipeline context to materialize the value when found.
2981	Returns the failing step's data from the solid's execution, if any exists.
2982	Creates a permissive dictionary configuration type that allows partial field specification with type checking for specified fields while ignoring unspecified fields.
2983	Validates that a dataset string follows the format "project.dataset" or "dataset" using regex pattern matching.
2984	Validates that a table string follows the format "project.dataset.table" or "dataset.table" using regex pattern matching.
2985	Execute user-specified transform for a solid with error handling, logging, and metrics tracking. Processes inputs through transform steps, yields results, and logs information about any omitted outputs when the number of emitted results doesn't match expected output definitions.
2986	Creates a Dagster type from an existing Python class by wrapping it in the Dagster type system with optional schema and serialization configurations.
2987	A decorator factory for creating resource definitions. When called with a function directly (e.g., `@resource`), it returns a ResourceDefinition using that function as the resource_fn. When called with arguments (e.g., `@resource()`), it returns a wrapper function that creates a ResourceDefinition with the provided config_field and description. Supports both bare decorator usage and decorator with arguments.
2988	Creates a PagerDuty Event API v2 event with the specified parameters including summary, source, and severity. Supports different event actions (trigger, acknowledge, resolve), deduplication, timestamps, component/group classification, event class, and custom details. Returns the created event object.
2989	Groups execution steps by solid, in topological order of the solids.
2990	Method to acquire database connection parameters from settings, mapping them to connection kwargs with default values for blank fields.
2991	Creates a new database connection using provided connection parameters, closes any existing connection first, sets up the connection with OrderedDict as document class, and returns the specified database connection.
2992	Creates and returns an active database connection cursor using the instance's connections.
2993	Closes the database client connection if one exists, handling any database errors that may occur during the closing process.
2994	Creates a model instance by converting dictionary values to appropriate Python types using the model's field definitions.
2995	Overrides the standard to_python method to correctly translate Mongo array to a Python list, handling None values and converting dictionary representations to model instances.
2996	Returns the formfield for the array by setting default parameters including form_class, model_container, model_form_class, name, and mdl_form_kw_l, then updating with any provided kwargs before calling the parent's formfield method.
2997	Converts a dictionary value to a model instance, handling None values and existing model instances correctly.
2998	Filters the queryset for the instance this manager is bound to by adding hints, applying database hint if specified, and filtering with core filters.
2999	Computes a matrix of expected false positives for all possible sub-intervals of set sizes under uniform distribution assumption. Takes cumulative counts and size domain as input, returns a 2D array where each element [l,u] represents the expected number of false positives for interval [l,u].
3000	Computes the matrix of expected false positives for all possible sub-intervals of the complete domain of set sizes by iterating through all inclusive interval pairs [l, u] and calculating the expected number of false positives for each interval.
3001	Computes the optimal partitions of a sorted set of sizes into a specified number of partitions to minimizing total expected false positives. Returns the partition bounds, total false positives, and cost matrix for subproblems. Raises ValueError for invalid partition counts. Uses dynamic programming approach to find optimal partitioning.
3002	Compute optimal partitions given a distribution of set sizes by first checking edge cases (num_part < 2 or num_part >= len(sizes)), then calculating normalized frequencies and using a helper function to determine the best partition boundaries. Returns a list of (lower, upper) tuples representing each partition's size bounds.
3003	Compute the functions C1 and C2 using the given parameters, with special handling for the case when both r1 and r2 are zero (returning the limits A1 and A2 directly). For non-zero r1 and r2, calculate C1 and C2 using the formulas: C1 = (A1*r2 + A2*r1)/(r1+r2) and C2 = (A1*r1 + A2*r2)/(r1+r2).
3004	Initialize the slots of the LeanMinHash by setting the random seed and parsing the hash values into the internal state.
3005	Compute the byte size after serialization of the object, which includes a seed integer (8 bytes), a length indicator (4 bytes), and hash values (4 bytes each).
3006	Serialize this lean MinHash into a buffer using the specified byte order. The serialization format consists of: 1) 8 bytes for the seed integer, 2) 4 bytes for the number of hash values, and 3) the hash values themselves (4 bytes each). The buffer must be large enough to hold the serialized data, and the byte order can be specified using standard Python struct format characters.
3007	Deserialize a lean MinHash from a buffer.

Args:
    buf (buffer): Buffer that implements the buffer interface (e.g., bytearray).
    byteorder (str, optional): Byte order of serialized data. Use one of '@', '=', '<', '>', '!'. Default is '@'.

Return:
    datasketch.LeanMinHash: The deserialized lean MinHash object.

Example:
    lean_minhash = LeanMinHash.deserialize(buf)
3008	Update this MinHash with a new value by hashing it and applying permutations to maintain the minimum hash values.
3009	Merge another MinHash with this one by taking the union (minimum hash values) of both MinHash objects, ensuring they have the same seed and number of permutation functions.
3010	Create a MinHash object that represents the union of multiple MinHash objects by taking the element-wise minimum of their hash values.
3011	Index all sets given their keys, MinHashes, and sizes into optimal partitions. Can only be called once on an empty index. Raises ValueError if index is not empty, entries is empty, or set size is not positive. Creates optimal partitions based on set sizes and inserts each entry into the appropriate partition based on its size.
3012	Query for keys referencing sets with containment greater than threshold using MinHash and query set size, yielding matching keys through indexed MinHash structures.
3013	Create a new weighted MinHash given a weighted Jaccard vector by computing hash values based on logarithmic transformations and random sampling.
3014	Remove the specified key from the index, including all associated hash table entries. Raises ValueError if the key doesn't exist. Handles pickling if pre-pickling is enabled.
3015	Updates the HyperLogLog data structure with a new byte value by hashing it and adjusting the appropriate register based on the hash result.
3016	Estimates the cardinality of data values using HyperLogLog algorithm with three correction ranges: small range correction using linear counting, normal range without correction, and large range correction. Returns the estimated cardinality as an integer.
3017	Merge another HyperLogLog with this one, making this the union of the two by taking element-wise maximum of their register values, raising ValueError if precisions don't match.
3018	Reset the current HyperLogLog to empty by initializing all registers to zero.
3019	Computes the average precision at k between two lists of items, measuring the quality of ranked predictions against actual relevant items.
3020	Computes the mean average precision at k between two lists of lists of items, where k is the maximum number of predicted elements to consider. Returns the mean average precision score across all input lists.
3021	Index all keys in the hashtables and sort them for searchable results.
3022	Return the approximate top-k keys with highest Jaccard similarities to the query set using MinHash indexing.
3023	Closes all hashtable connections and cleanup client resources.
3024	Return ordered storage system based on the specified config, supporting both in-memory dictionary and Redis storage types with optional naming for Redis containers.
3025	Returns an unordered storage system (either in-memory dict or Redis) based on the specified configuration. The storage contains keys and values where values are unordered sets. For dict storage, uses DictSetStorage; for Redis storage, uses RedisSetStorage with the provided name prefix.
3026	Returns serialized user data for JWT serialization by using the configured USER_DETAILS_SERIALIZER or default UserDetailsSerializer.
3027	Sets the social login process state to connect rather than login by modifying the social_login state.
3028	Selects the correct text from Japanese number alternatives, returning either the kanji number or kana reading based on the reading parameter, and chooses the preferred alternative when multiple options are available.
3029	Parse a scoped selector string into scope and selector components, handling macro notation (%) by converting it to the format 'scope/name/macro.value'. Raises ValueError if macro notation is used with .value suffix. Returns a tuple of (scope, selector).
3030	Parse a single statement, which can be a BindingStatement, ImportStatement, IncludeStatement, or None if EOF is reached. Handles whitespace, comments, and syntax errors while parsing different statement types. Returns the parsed statement object or raises a syntax error for invalid statements.
3031	Parse a single literal value by trying multiple parsers in order, returning the first successful parse result or raising a syntax error if all parsers fail.
3032	Advances the parser to the next line by consuming tokens until the line number changes, updating the current token to the next token in the token generator.
3033	Try to parse a configurable reference (@[scope/name/]fn_name[()]). Returns a tuple of (was_parsed, reference) where was_parsed indicates if a configurable reference was found and parsed, and reference is the parsed configurable reference or None if not found. If a configurable reference is found, advances tokens and handles optional parentheses. Raises syntax error if parentheses are mismatched. Uses delegate to resolve the configurable reference.
3034	Augments an exception's message and re-raises it by creating a proxy class that inherits from the original exception type, appending the new message to the original exception's string representation, and preserving the original exception's attributes and traceback information.
3035	Convert an operative config string to markdown format by processing each line according to specific rules: lines not starting with '#' are indented, lines starting with '#' have the '# ' removed and are processed for special cases like headers and None values, and empty lines are filtered out.
3036	Writes Gin's operative configuration to a file and optionally adds a markdown summary of it to TensorBoard. Creates the output directory if needed, retrieves the global step value from the session, and saves the config with a filename indicating the global step. If summarization is enabled, converts the config to markdown format and writes it as a text summary to the TensorBoard event file.
3037	Ensures that a function can be cleanly wrapped by functools.wraps by handling special types like "wrapped_descriptor" and "method-wrapper" that otherwise cause issues during wrapping. For these special types, it creates a lambda wrapper with the appropriate attributes copied from the original function. For regular functions, it returns them unchanged.
3038	Decorates a function or class with the given decorator, with special handling for classes including optional subclassing to preserve class metadata and behavior.
3039	Returns a string representation of `value` that can be parsed back to the original value using `parse_value`, or `None` if not possible. The function uses `repr()` to get a literal representation and verifies it can be parsed correctly, handling syntax errors gracefully.
3040	Clears the global configuration by removing parameter values, dynamically imported modules, and optionally constants. It preserves configurable functions and classes in the registry while resetting configuration state.
3041	Binds a parameter value to a configurable function in the Gin configuration system. Takes a binding key (either string or tuple format) and a value, then stores this binding in the global configuration dictionary under the specified scope and parameter name. Raises RuntimeError if config is locked, or ValueError if the configurable function doesn't exist or the parameter is invalid. The binding takes effect for subsequent calls to the configurable function in the specified scope.
3042	Returns the currently bound value for a specified configuration parameter.

This function retrieves the value bound to a configurable parameter identified by a binding key. The binding key follows the format 'scope/selector/configurable.parameter'. It checks if the configurable exists in the global configuration and if the specified parameter has a bound value, raising ValueError exceptions for missing configurables, missing parameters, or invalid configurations.

Args:
    binding_key (str): The key identifying the configurable parameter in format 'scope/selector/configurable.parameter'

Returns:
    The bound value for the specified parameter

Raises:
    ValueError: If configurable doesn't exist, parameter has no bound value, or configuration is invalid
3043	Returns True if `arg_name` might be a valid parameter for `fn_or_cls`, meaning `fn_or_cls` either has a parameter named `arg_name` or has a `**kwargs` parameter.
3044	Gets cached argspec for `fn`, using inspect.getfullargspec or inspect.getargspec depending on Python version, with fallback to fn.__call__ if TypeError occurs.
3045	Returns the names of the positional arguments that were supplied to a function based on the provided arguments.
3046	Returns the names of all positional arguments to the given function by analyzing its argument specification and excluding any default parameters.
3047	Retrieves default values for configurable parameters of a function, filtered by whitelist and blacklist criteria. Returns a dictionary mapping parameter names to their default values, with caching support.
3048	Opens a new configuration scope for Gin, allowing parameter bindings to be restricted to specific sections of code. Can be used with a `with` statement to create nested scopes, where configurable functions inherit parameters from higher-level scopes. Supports passing a scope name, existing scope, or `None`/empty string to clear active scopes. Yields the resulting scope (list of active scope names). Raises `ValueError` for invalid scope names.
3049	Decorator to make a function or class configurable by registering it with the global configuration system, allowing its parameters to be set via `bind_parameter` or `parse_config`. Supports explicit naming, whitelisting, and blacklisting of parameters to control configurability. Can be used with or without parameters, and works for both functions and classes (with class constructors' parameters being made configurable).
3050	Retrieve the "operative" configuration as a config string, including all parameter values used by configurable functions during program execution. The output includes imports, macros, and parameter bindings sorted lexicographically, with proper formatting and line continuation. Parameters that can't be represented as literals are excluded.
3051	Parse parameter bindings from a file, string, or list of strings to configure global settings. Supports scoping, references to other configurables, and can skip unknown configurables or imports.
3052	Function that registers file readers for use in parse_config_file. When called as a decorator, it registers a file reader function along with a readability check function. When called as a regular function, it takes a file reader function and readability check function as arguments and registers them. Raises TypeError if incorrect number of arguments are provided.
3053	Parse a Gin config file by iterating through registered file readers to find a compatible one, then parse the config content using `parse_config` with optional unknown configurable handling. Raises IOError if the file cannot be read by any registered reader.
3054	Parses a list of Gin configuration files followed by additional bindings, with optional finalization. If no config files or bindings are provided, they default to empty lists/strings. Each config file is parsed sequentially, followed by parsing the bindings. If `finalize_config` is True (default), the configuration is finalized after parsing. Unknown configurables and imports can be skipped instead of causing errors based on the `skip_unknown` parameter.
3055	Parses and returns a single Gin value by validating that the input is a string type and then using ConfigParser with ParserDelegate to parse the value.
3056	A function that should be called after parsing all Gin config files to execute registered finalize hooks. These hooks can inspect and potentially modify the Gin config by returning a dictionary mapping binding keys to new or updated values, ensuring all hooks see the original config. Raises RuntimeError if called twice, or ValueError if multiple hooks attempt to modify the same key.
3057	Returns an iterator over all values in a nested structure, handling strings as atomic values and recursively traversing mappings and iterables.
3058	Returns an iterator over ConfigurableReference instances in the given config, optionally filtered by a specific configurable function/class.
3059	Creates a constant that can be referenced from gin config files using the macro syntax. The constant can be accessed in config files with the format `%CONSTANT_NAME`. Raises ValueError if the constant name is invalid or already exists. Stores the constant value in a Gin-internal dictionary until program termination.
3060	Decorator for an enum class that generates Gin constants from values. Generated constants have format `module.ClassName.ENUM_VALUE`. Raises TypeError when applied to a non-enum class.
3061	Retrieves all selectors matching a partial selector string, returning complete matching selectors while handling exact matches differently.
3062	Returns all values matching `partial_selector` as a list by finding matching selectors and mapping them to their corresponding values.
3063	Returns the minimal selector that uniquely matches the given complete selector by traversing a selector tree and finding the shortest unique path, or raises KeyError if the selector is not found.
3064	Translate a Mopidy search query to a Spotify search query by mapping fields, transforming year values, and formatting the query with proper field:value pairs.
3065	Parse the Retry-After header from a response and return the delay in seconds, handling both numeric values and HTTP date formats. Returns 0 if no Retry-After header is present or if the value is invalid.
3066	Validates a new property value before setting it, raising PropertyError for read-only properties or invalid values.
3067	Get the property description as a dictionary with added property link.
3068	Sets the current value of the property after validation.
3069	Get the thing at the given index, returning None if index is invalid or non-integer.
3070	Initialize the handler with a list of Things and allowed hostnames.

Args:
    things: list of Things managed by this server
    hosts: list of allowed hostnames
3071	Sets default CORS headers allowing all origins and common HTTP methods (GET, HEAD, PUT, POST, DELETE) with specified headers support.
3072	Validate Host header - if present and in allowed hosts list, proceed; otherwise raise HTTP 403 error.
3073	Handle GET requests for a thing, supporting both regular HTTP and WebSocket connections. For WebSocket requests, delegate to WebSocketHandler.get(). For HTTP requests, return the thing's description as JSON with a WebSocket link. Return 404 if the thing doesn't exist.
3074	Handle incoming WebSocket messages by parsing JSON and dispatching to appropriate handlers for property setting, action execution, or event subscription management. Returns error responses for malformed messages or unsupported message types.
3075	Handle a POST request to perform actions on a thing. Retrieves the thing by ID, parses JSON request body, executes specified actions, and returns a 201 Created response with action descriptions. Returns 404 if thing doesn't exist or 400 if request body is invalid JSON.
3076	Handle a DELETE request for a specific action of a thing. Returns 204 (No Content) on successful deletion, 404 (Not Found) if the thing or action doesn't exist.
3077	Start listening for incoming connections by registering a WebThing service via zeroconf and starting the tornado server on the specified port.
3078	Returns a dictionary describing the action with its href, timestamps, status, and optional input/completion data.
3079	Start performing the action by setting status to 'pending', notifying the thing of the action, performing the action, and then finishing it.
3080	Finish performing the action by setting status to 'completed', recording completion timestamp, and notifying the associated thing.
3081	Get the event description as a dictionary containing the event name as key and a dictionary with timestamp and optional data as value.
3082	Get the default local IP address by creating a UDP socket and connecting to a non-routable IP address to determine the local interface's IP address. Returns '127.0.0.1' if the operation fails.
3083	Get all IP addresses from network interfaces, filtering out link-local addresses. Returns a sorted list of IPv4 and IPv6 addresses, with IPv6 addresses formatted in brackets.
3084	Sets a new value for this object, notifying any forwarder and external update listeners of the change.
3085	Notify observers of a new value, updating the last known value and emitting an 'update' signal if the new value is different from the previous one.
3086	Return the thing state as a Thing Description dictionary containing name, href, context, type, properties, actions, events, and links.
3087	Sets the href prefix for this object and all its associated properties and actions.
3088	Returns a dictionary mapping property names to their descriptions by converting each property using its `as_property_description()` method.
3089	Get the thing's actions as an array. If action_name is provided, returns descriptions for that specific action, otherwise returns descriptions for all actions.
3090	Get the thing's events as an array. If event_name is provided, returns descriptions for only that specific event; otherwise returns descriptions for all events.
3091	Add a property to this thing by setting its href prefix and storing it in the properties dictionary.
3092	Remove a property from this thing by deleting it from the properties dictionary using the property's name as key.
3093	Get a property's value by name. Returns the property's value if found, otherwise returns None.
3094	Returns a dictionary mapping property names to their values by iterating through all properties in self.properties.
3095	Sets a property value by finding the property first and then setting its value. If the property is not found, the method returns without doing anything.
3096	Get an action by name and ID. Returns the action if found, otherwise returns None.
3097	Add a new event to the events list and notify all subscribers about the event.
3098	Add an available event with given name and metadata to the available_events dictionary, initializing an empty set of subscribers for that event.
3099	Perform an action on the thing by validating inputs and creating an action instance. Returns the created action or None if validation fails or action is not available.
3100	Remove an existing action by name and ID, canceling it and removing it from the actions list. Returns True if the action was found and removed, False otherwise.
3101	Add an available action by storing its metadata and class in the available_actions dictionary, and initialize an empty list for tracking instances in the actions dictionary.
3102	Remove a websocket subscriber from the list of subscribers and unregister it from all available events.
3103	Add a websocket subscriber to a specific event by associating the websocket with the event name in the available_events dictionary.
3104	Remove a websocket subscriber from a specific event by deleting the websocket connection from the event's subscribers list, if both the event and websocket exist in the available events dictionary.
3105	Notify all subscribers of a property change by sending a JSON message containing the property name and its current value through WebSocket connections.
3106	Notify all subscribers about an action status change by sending a JSON message containing the action description through WebSocket connections.
3107	Notify all subscribers of an event by serializing the event data to JSON and sending it through WebSocket connections, while gracefully handling closed connections.
3108	Custom annotate function that allows using existing field names as annotation aliases by temporarily renaming them during the annotation process.
3109	Updates all rows matching the filter with the given fields and returns the number of affected rows. Uses a custom PostgreSQL compiler to execute the update query and sends update signals for each modified row.
3110	Creates multiple new records in the database using either custom conflict handling or standard Django bulk_create. Supports returning either model instances or dictionaries with the inserted data.
3111	Creates a new record in the database with optional custom conflict behavior. If conflict resolution is specified via `.on_conflict()`, it uses a custom insert compiler to handle the operation and returns the primary key of the created record. Otherwise, it delegates to Django's standard `create()` method and returns the primary key of the created record.
3112	Creates a new record in the database and returns the complete model instance. Uses standard Django create() when no special conflict behavior is specified, otherwise executes a custom insert compiler. Returns the model instance with fields mapped from database columns to model attributes.
3113	Builds a SQL compiler for an insert query by validating row fields, creating model objects, and configuring a PostgreSQL insert query with conflict handling options.
3114	Summary: Checks if a field modifies its value during pre_save processing by comparing the field's value before and after the pre_save method is called, returning True if the value changes.
3115	Gets the fields to use in an upsert operation by splitting them into insert fields and update fields. Insert fields are those that should be included in the INSERT statement, while update fields are those that should be updated on conflict. The method handles special cases like fields with defaults, primary keys, and magical fields that modify the model on their own. Returns a tuple of (insert_fields, update_fields).
3116	When a model instance is saved (created or updated), this function sends either a 'create' signal or an 'update' signal based on whether the instance was newly created or modified.
3117	When a model instance is deleted, this function sends a delete signal with the instance's primary key.
3118	Selects the first non-None field value from the specified fields in reverse order, returning a default value if all fields are None. Uses Django's Case-When expressions to evaluate each field and return the appropriate value.
3119	Resolves expressions within a dictionary by calling `resolve_expression` on each value that has this method, returning a new HStoreValue with the resolved results.
3120	Compiles an HStore value into SQL by processing each key-value pair. For each pair, if the value has an `as_sql` method, it recursively compiles it; otherwise, it formats the value as a string or NULL. The resulting SQL uses `hstore()` functions combined with `||` concatenation operator. Returns the compiled SQL string and an empty parameters list.
3121	Returns a cloned instance of this expression with potentially re-labeled alias based on the provided relabels mapping.
3122	Adds extra conditions to existing JOIN operations in a query by converting regular Join objects into ConditionalJoin objects that can accommodate additional constraints.
3123	Checks if a field with the specified name is an HStoreField and returns a tuple indicating the result and the field instance.
3124	Sets the values to be used in the query by specifying fields for INSERT and UPDATE operations. Takes a list of objects, insert fields that will be overwritten on existing rows, and optional update fields that are only used for updates. Configures insert values and stores update fields for later use.
3125	Creates a REQUIRED CONSTRAINT for the specified hstore key by generating and executing SQL code with a formatted constraint name, table name, field name, and key value.
3126	Renames an existing required constraint for an hstore key from an old table/field combination to a new table/field combination.
3127	Drops the required constraint for a specified hstore key by constructing and executing a SQL statement that removes the constraint from the given table.
3128	Gets the name for a CONSTRAINT that applies to a single hstore key, formatted as '{table}_{field}_required_{postfix}'.
3129	Creates the SQL statement for creating an index, handling different Django versions by setting the appropriate template and condition parameters for the index creation statement.
3130	Creates a custom setup.py command class that executes a list of shell commands when run.
3131	Gets the base class for the custom database back-end, defaulting to Django PostgreSQL back-end. Allows custom back-end configuration through POSTGRES_EXTRA_DB_BACKEND_BASE setting, ensuring the specified base eventually inherits from PostgreSQL back-end. Raises ImproperlyConfigured if the base class is invalid or doesn't inherit from PostgreSQL back-end.
3132	Method `prepare_database` prepares the configured database by enabling the `hstore` extension if it's not already enabled. It calls the parent's `prepare_database` method, then attempts to create the `hstore` extension using a database cursor. If a `ProgrammingError` occurs (typically due to permission issues), it logs a warning message indicating that table migrations with hstore columns may fail, and suggests connecting as a superuser or manually adding the extension.
3133	Override the base class method to handle hstore field values without casting all values to strings, preserving expressions and handling None values properly.
3134	Builds the RETURNING part of the query for PostgreSQL, quoting the primary key column name.
3135	Builds and returns SQL INSERT statements by rewriting the base SQL with optional ID return capability.
3136	Rewrites an SQL INSERT query to include ON CONFLICT clause based on the conflict action. Returns the rewritten SQL query and new parameters. Supports UPDATE and NOTHING conflict actions, raises SuspiciousOperation for invalid actions.
3137	Rewrites an INSERT SQL query to include ON CONFLICT DO UPDATE clause with specified conflict target, update columns, and returning clause.
3138	Rewrites an SQL INSERT query to include ON CONFLICT DO NOTHING clause with conflict target handling and conditional returning logic.
3139	Builds the `conflict_target` for the ON CONFLICT clause by validating and formatting column names or tuples containing column names and hstore keys into a comma-separated string enclosed in parentheses.
3140	Gets the field on a model with the specified name, returning the field if found or None if not. Handles special 'pk' case for primary key and checks both field names and column names.
3141	Formats a field's name for SQL usage by retrieving the model field and applying SQL quoting.
3142	Formats a field's value for SQL usage by normalizing the field name, retrieving the model field, and preparing the value using SQLInsertCompiler without applying pre_save modifications.
3143	Creates a UNIQUE constraint for specified hstore keys by generating and executing SQL code that formats the constraint name, table name, and columns using PostgreSQL's hstore syntax.
3144	Renames an existing UNIQUE constraint for specified hstore keys when changing table or field names.
3145	Drops a UNIQUE constraint for the specified hstore keys by generating and executing the appropriate SQL statement using the constraint name derived from the model, field, and keys parameters.
3146	Gets the name for a UNIQUE INDEX that applies to one or more keys in a hstore field. Arguments: table (table name), field (hstore field), keys (key name or tuple of names). Returns: The name for the UNIQUE index.
3147	Iterates over keys marked as "unique" in the specified field, composing and yielding each key combination. Returns early if no uniqueness attribute is found.
3148	Adds an extra condition to this join by appending a field-value pair to the extra_conditions list.
3149	Compiles a JOIN clause into SQL by extending the parent's SQL compilation with additional conditions. It constructs extra WHERE conditions based on `extra_conditions` and appends their parameter values to the existing parameters. The method modifies the SQL string to incorporate these extra conditions into the JOIN clause's WHERE clause, returning the final SQL string and parameter list.
3150	Returns the approximate 95% confidence level for Student's T distribution based on degrees of freedom. Uses lookup table for df <= 80, with special cases for df >= 100 and df >= 200 returning 1.984, 1.960 respectively. For degrees of freedom greater than or equal to the highest table value, returns the corresponding value from the lookup table.
3151	Computes the pooled sample variance for two samples by calculating the weighted average of their individual variances based on degrees of freedom.
3152	Calculate a t-test score for the difference between two samples by computing the pooled sample variance, mean difference, and returning the standardized test statistic.
3153	Determine whether two samples differ significantly using a Student's two-sample, two-tailed t-test with alpha=0.95. Returns a tuple of (significant, t_score) where 'significant' indicates if samples differ significantly and 't_score' is the t-test score.
3154	Return a topological sorting of nodes in a graph using iterative depth-first search. Takes a list of root nodes and a function to get parent nodes, returns nodes in topological order.
3155	N-Queens solver that yields solutions as tuples where each element represents the column position of a queen in that row, ensuring no two queens attack each other by checking diagonal conflicts through set comparisons of row-column and row+column differences.
3156	UCT tree search implementation that selects moves using the UCT algorithm, performs random playouts, and updates node statistics along the search path.
3157	Selects a move by first trying unexplored children randomly, then fallback to the best child according to UCT value, or passes if no options available.
3158	Summary: Executes a random playout on the board until the game ends or maximum moves are reached, with players making random moves until both pass.
3159	Filters out Python 2 only benchmarks from the benchmark set if the base version is Python 3 or higher, logging skipped benchmarks.
3160	Expands benchmark names recursively by replacing group names with their constituent benchmarks, yielding actual benchmark names with all groups fully expanded.
3161	Generates a list of strings with repeated prefixes and suffixes for benchmarking. Each string consists of '-' or 'P' characters repeated n times, followed by a fixed substring ('Perl', 'Python', 'PythonPython', or 'a5,b7,c9,'), followed by '-' or 'P' characters repeated n times. The strings are stored in a list and returned.
3162	Initialize benchmark strings by creating prefixed and suffixed strings for regex testing, cached by prefix/suffix lengths.
3163	Returns the domain of the B-Spline as a tuple (start, end) where start is the knot at index (degree-1) and end is the knot at index (len(knots)-degree).
3164	Fetch messages from a channel starting from a given date. Returns a generator that yields posts with user data attached. Stops fetching when posts older than the specified date are encountered or when no new posts are available. Uses pagination to retrieve all posts.
3165	Parse posts from raw JSON data and yield them in the correct order based on the 'order' key.
3166	Fetch user data for a given username by making a request to the users endpoint.
3167	Fetch entries from the RSS url by calling the parent class's fetch method with the specified category and return a generator of entries.
```
3168	Fetch RSS entries from a feed by getting entries from client, parsing them, and yielding each entry as a generator while counting total entries.
3169	Returns the RSS argument parser with a required URL argument for the RSS feed.
3170	Fetch bugs from a Bugzilla repository updated since a given date, returning a generator of bugs.
3171	Get information about a list of bugs from a specified date, with optional offset and maximum number of bugs to return.
3172	Get the comments for the specified bug identifiers.

Parameters:
- bug_ids: list of bug identifiers

Returns:
- Response containing the comments for the given bugs
3173	Get the history of the given bugs by calling the API endpoint with bug identifiers. Takes variable number of bug IDs as input and returns the response containing history data.
3174	Get the attachments of the given bugs.

:param bug_ids: list of bug identifiers
:returns: response containing attachments data
3175	Get issue notes and their emoji awards from GitLab client, returning a list of note dictionaries with emoji data attached.
3176	Fetch merge requests from GitLab client, filter out blacklisted ones, and enrich each merge request with additional data including notes, emojis, and versions before yielding them.
3177	Get merge notes and their award emoji data for a given merge request ID.
3178	Get merge versions by fetching version data from the client, parsing JSON responses, and removing diffs from each version before returning the complete versions list.
3179	Get merge requests from pagination with optional date filtering.
3180	Get the merge full data for a specific merge request ID by constructing the API path and fetching the response text.
3181	Get the merge versions from pagination for a specific merge request ID.
3182	Get merge version detail by fetching from the specified path containing project, merge request, and version information.
3183	Get notes for a given item type and id using pagination, with sorting by updated_at in ascending order.
3184	Get emojis from pagination for a given item type and ID.
3185	Get emojis associated with a specific note by retrieving emoji data from the GitLab API endpoint for note emojis, using the specified item type, item ID, and note ID to construct the API path and fetching items with pagination parameters.
3186	Calculate the seconds until token requests reset by finding the difference between the current time and the next full token regeneration time. Returns 0 if reset time has already passed.
3187	Return the items from GitLab API using links pagination

The `fetch_items` method retrieves items from the GitLab API using pagination by following the 'next' links in the response. It starts with the initial URL constructed from the base URL, owner, repository, and provided path. The method yields items as they are fetched, tracking the current page and total pages (if available) for logging purposes. It continues fetching pages until there are no more items or no 'next' link is present in the response. The method handles pagination automatically by parsing the URL parameters to determine the current page number and total pages, and updates the URL for subsequent requests accordingly.
3188	Initialize rate limit information by fetching project data from the API and updating rate limit settings, while handling HTTP errors appropriately.
3189	Returns the GitLab argument parser with configuration options for GitLab Enterprise URL, rate limiting, blacklist IDs, API retries, and positional owner/repository arguments.
3190	Fetch messages from the channel sent since a given date, returning a generator of messages.
3191	Extracts the identifier from a Slack item by combining the 'ts' timestamp with either the 'user' ID, 'comment.user' ID, or 'bot_id' field, since Slack messages don't have a unique identifier.
3192	Fetch the total number of members in a conversation by handling pagination of members list. The method retrieves members from a conversation using the conversation ID, processes the response, and continues fetching additional pages using cursor-based pagination until all members are counted. Returns the total member count.
3193	Fetch information about a specified channel by making a request to the channel info endpoint with the channel parameter.
3194	Fetch user information by user ID using the specified resource and parameters.
3195	Returns a configured Slack argument parser with required API token, max items limit, and channel identifier arguments.
3196	Extracts and converts the update time from a Bugzilla item's 'delta_ts' field to a UNIX timestamp, ignoring timezone information during conversion.
3197	Parse a Bugzilla CSV bug list and return an iterator of dictionaries containing bug summaries.
3198	Parse Bugzilla bugs details XML stream and return a generator of bug dictionaries. Raises ParseError if XML is invalid or contains no bugs.
3199	Parses Bugzilla bug activity HTML and yields formatted activity events as dictionaries containing 'Who', 'When', 'What', 'Removed', and 'Added' fields. Raises ParseError if HTML is invalid or activity table is not found. Handles empty activity cases and properly processes rowspan attributes for multiple changes on the same date.
3200	Logout from the server by calling the logout API endpoint and closing the HTTP session.
3201	Get metadata information in XML format by calling CGI_BUG endpoint with XML parameter.
3202	Get a summary of bugs in CSV format for bugs updated from a specified date.
3203	Get bug information in XML format for a list of bug identifiers, excluding attachment data.
3204	Get the activity of a bug in HTML format.

Parameters:
- bug_id: bug identifier

Returns:
- HTML formatted bug activity data

Calls the bug activity CGI endpoint with the specified bug ID and returns the response.
3205	Fetch events from the server for a given category and date range, including comments and rsvps, with optional filtering of classified fields.
3206	Fetch events from a specified group within a date range, yielding each event with added comments and rsvps, while stopping when events exceed the specified end date.
3207	Fetch events pages from a given group, handling Meetup API specific formatting requirements for parameters and yielding pages of results while managing HTTP 410 errors.
3208	Fetch the comments of a given event by joining the group, event ID, and comments resource, then yield pages of comments using the fetch method with pagination.
3209	Fetch the RSVPs for a given event in a group.

This method constructs a URI to retrieve RSVP information for a specific event within a group, adds fixed parameters for field selection and response types, and then fetches the data in pages using the `_fetch` method, yielding each page of results.
3210	Fetch an Askbot HTML question body by retrieving HTML pages incrementally until all pages are collected, handling redirect exceptions gracefully.
3211	Fetch all comments for an Askbot question and its answers, returning them as a dictionary keyed by object IDs.
3212	Build an Askbot HTML response by parsing question information from HTML pages, including user info, comments, and answers, then return a dictionary with the parsed question data.
3213	Retrieve question pages using the API, yielding each page's data while handling pagination and request exceptions.
3214	Retrieve a raw HTML question and all its information by making a request to the specified URL path with pagination support.
3215	Retrieve a list of comments by a given post ID, using either new or old URL schema based on availability. Handles HTTP 404 by falling back to old URL schema and HTTP 500 by returning empty list. Returns raw comment data as string.
3216	Parse the question info container from HTML question, extracting author information from the first container and optional updated_by information from the second container if it exists and contains user info.
3217	Parse the answers of a given HTML question, including related comments, and return a list of answer objects with their metadata such as ID, score, summary, acceptance status, and timestamps for creation and updates along with user information.
3218	Parse the number of answer pages from HTML question content for pagination.

Parameters:
    html_question (str): Raw HTML question element

Returns:
    int: Number of pages for pagination, defaulting to 1 if no paginator found
3219	Parse user information from HTML container, extracting user ID, username, reputation, badges, website, and country when available.
3220	Fetch items by category using appropriate Gerrit client version, yielding reviews from a generator.

The method selects between two fetcher implementations based on the Gerrit client version (2.8 vs other versions) and yields reviews from the selected fetcher, starting from a specified date.
3221	Parse a Gerrit reviews list by joining isolated JSON reviews into an array and filtering items that contain a 'project' key.
3222	Fetch reviews from Gerrit 2.8 API by separating open and closed reviews, then yield them in chronological order based on lastUpdated timestamp, handling pagination when review counts reach max_reviews limit.
3223	Return the Gerrit server version, caching the result after the first retrieval. Executes a command to get the version string, parses it using regex to extract major and minor version numbers, and returns them as a list. Raises BackendError if the version string is invalid or cannot be parsed.
3224	Get reviews starting from last_item using the specified filter. Executes a Gerrit command and returns the raw data as a UTF-8 string.
3225	Return the item to start from in next reviews group based on Gerrit version and pagination support.
3226	Method: __execute
Summary: Executes a Gerrit command by delegating to either archive or remote execution based on the from_archive flag, returning the command response.
3227	Execute a gerrit command against the archive by sanitizing the command, retrieving the response from the archive, and raising any RuntimeError exceptions that occur during retrieval.
3228	Execute a gerrit command with retry logic up to MAX_RETRIES times. If command fails, log error and wait before retrying. Store command result in archive if enabled. Raise RuntimeError if all retries fail.
3229	Returns the Gerrit argument parser with SSH and Gerrit-specific options including user, max reviews, blacklist, host key check disabling, and SSH port configuration.
3230	Fetches and returns issue data from the client by ID, parsing the raw issue response from JSON format.
3231	Get attachments of an issue by iterating through issue collection data and yielding each attachment entry.
3232	Get messages of an issue and fetch owner data for each message.
3233	Fetch activities on an issue and yield each activity with additional user data.
3234	Fetch and return user data associated with a given user link, returning an empty dictionary if no user name is found.
3235	Get user data by username from URL, cache results, and handle 404/410 errors gracefully.
3236	Get issue data by its ID by constructing a URL path, sending a request, and returning the raw text response.
3237	Get a collection list of a given issue by querying the specified collection name associated with the issue ID.
3238	Builds and returns the appropriate URL project based on whether a package is specified, calling either __get_url_distribution_package() or __get_url_distribution() methods.
3239	Fetch items from Launchpad API with pagination, yielding raw content pages while handling HTTP errors and following next collection links.
3240	Fetch paginated subscriptions from Groups.io API using given token, returning an iterator of subscriptions with specified items per page.
3241	Find the ID of a group by its name through iteration of subscriptions list, raise BackendError if not found.
3242	Fetch requests from groupsio API with error handling for HTTP status codes.
3243	Returns a Groupsio argument parser with required API token, optional mbox path and SSL verification arguments, and a required group name argument.
3244	Generate a UUID by creating a SHA1 hash of colon-separated string values. Takes variable arguments, validates each is a non-empty string, joins them with ':', hashes the result, and returns the hex digest as a UUID. Raises ValueError for invalid (non-string, empty, or None) arguments.
3245	Fetch items using the given backend class, optionally storing them in an archive via a manager. Returns a generator of items, with error handling to remove corrupted archives if needed. Supports category filtering and classified field removal.
3246	Fetch items from an archive manager using the specified backend class and arguments, returning only items archived after the given date through a generator.
3247	Find available backends by discovering Perceval backends and commands under a specified package and its sub-packages, returning tuples of Backend classes and BackendCommand classes.
3248	Fetch items from the repository based on category and optional filtering. Supports filtering out classified fields but incompatible with archiving. Returns a generator of items with metadata applied. Raises BackendError for invalid categories or incompatible parameters.
3249	Fetch questions from an archive and yield metadata for each item. Raises ArchiveError if no archive is provided.
3250	Remove classified or confidential data from an item by filtering out fields defined in `CLASSIFIED_FIELDS`. Returns the item with confidential data removed.
3251	Parse a list of arguments into an argparse.Namespace object with validated parameters, handling date conversions, compatibility checks between archive-related arguments, and setting aliases. Remove unset category attribute and raise AttributeError for incompatible argument combinations.
3252	Adds authentication arguments to the parser, including options for basic authentication (username/password) and/or token authentication (API token).
3253	Activate archive arguments parsing by adding command line arguments for archive path, disabling archiving, fetching from archives, and setting archived since date.
3254	Sets up output arguments parsing with options for specifying output file and JSON line formatting.
3255	Fetch and write items from a backend source to JSON output, using archive manager if specified.
3256	Initialize archive manager based on parsed arguments, creating ArchiveManager instance if archive_path is specified and no_archive flag is not set, otherwise set to None.
3257	Extracts and converts the update time from a MBox item's 'Date' field to UNIX timestamp format.
3258	Parse a mbox file and return an iterator of email messages as dictionaries.
3259	Fetch and parse messages from a mailing list, filtering by date and validation, yielding parsed messages while logging statistics.
3260	Copy the contents of a mbox to a temporary file and return the temporary file path.
3261	Validates that a message contains mandatory fields ('Message-ID' and 'Date') with non-empty values and a valid date format. Returns False and logs warnings if validations fail, otherwise returns True.
3262	Convert a CaseInsensitiveDict message to a regular dict while normalizing special headers like Message-ID and Date to consistent field names.
3263	Return a Message representation for the given key, reading from a file and handling multiple character encodings for the 'From' header.
3264	Fetch commits from a Git repository or log file with optional filtering by date range, branches, and synchronization flags. Returns a generator of commits in chronological order, respecting parameters like `from_date`, `to_date`, `branches`, `latest_items`, and `no_update`. Ignores `from_date` and `branches` when fetching from log files or when `latest_items` is enabled. Raises `RepositoryError` on access errors.
3265	Fetch items from a Git repository based on the specified category and filters.

This method retrieves commits from either the Git log or repository history based on the provided parameters. It supports filtering by date range, branches, and other criteria. The method returns a generator that yields commit items one at a time, making it memory-efficient for large repositories.

Parameters:
- category: The category of items to fetch
- from_date: Start date for filtering commits
- to_date: End date for filtering commits
- branches: Branches to include in the fetch
- latest_items: Whether to fetch only the latest items
- no_update: Whether to skip updates

Returns:
- A generator of commit items

The method handles EmptyRepositoryError gracefully and logs the total number of commits fetched upon completion.
3266	Parse a Git log file and return an iterator of dictionaries containing commit information.

**Parameters:**
- filepath: path to the log file

**Returns:**
- a generator of parsed commits

**Raises:**
- ParseError: raised when the format of the Git log file is invalid
- OSError: raised when an error occurs reading the given file
3267	Initialize repositories directory path by setting git_path based on parsed arguments, using git_log if available, otherwise constructing path from uri or using git_path directly, and store it as gitpath attribute.
3268	Returns a Git argument parser with support for branch filtering, repository path options, fetch modes, and required URI parameter.
3269	Parse the Git log stream and yield parsed commit objects as they are encountered, along with the final commit if any.
3270	Clone a Git repository by making a bare copy of the repository stored in `uri` into `dirpath`. The repository can be either local or remote. Returns a `GitRepository` class having cloned the repository. Raises `RepositoryError` when an error occurs cloning the given repository.
3271	Count the total number of objects (packed and unpacked) in a Git repository by executing `git count-objects -v` command and parsing its output. Returns the total object count or raises RepositoryError on parsing or execution failures.
3272	Check if the repository is in a detached state by verifying if HEAD is a symbolic reference. Returns True if detached (HEAD is not symbolic), False if not detached (HEAD is symbolic). Raises RepositoryError if unable to determine the state.
3273	Update repository from its remote by fetching 'heads' refs and pruning deleted refs.
3274	Synchronize the repository with its origin by fetching new objects and updating references, returning a list of new commit hashes.
3275	Method `rev_list` retrieves commit history from a Git repository using `git rev-list --topo-order`. It accepts an optional list of branch names to filter commits. If `branches` is `None`, it fetches all commits from all branches, tags, and origin remotes. If `branches` is an empty list, it fetches no commits. Otherwise, it fetches commits from the specified branches. The method yields each commit hash from the rev-list output. It raises `EmptyRepositoryError` if the repository is empty and `RepositoryError` for execution errors. The method uses `--topo-order` to maintain topological ordering of commits.
3276	Reads the commit log from a Git repository using specified filters and options, returning a generator of log lines. Supports date filtering, branch selection, and custom encoding. Raises exceptions for empty or error-prone repositories.
3277	Shows data of a set of commits using Git show command with specified options, returning a generator of output lines. When no commits are specified, shows data about the last commit. Handles empty repository and execution errors.
3278	Fetch changes from remote repository and store them in a pack, returning the pack name and fetched refs.
3279	Read commits from a git pack file by executing git verify-pack and parsing the output to extract commit hashes ordered from oldest to newest.
3280	Update references by removing old ones and adding new ones, then prune the repository to remove old branches.
3281	Method `_discover_refs` retrieves the current list of local or remote Git references (branches and tags). It accepts a `remote` parameter to determine whether to fetch remote references from 'origin' or local references from the repository. For remote references, it uses `git ls-remote` and for local references, it first checks if the repository is empty and raises an `EmptyRepositoryError` if so, then uses `git show-ref`. The method handles specific error codes gracefully and returns a list of `GitRef` objects representing the refs.
3282	Update a Git reference by either setting it to a new hash value or deleting it. Executes the git update-ref command with appropriate arguments based on the delete flag. Logs debug information on success or warning messages if the operation fails during the sync process.
3283	Run a command with a non blocking call, returning output as encoded bytes iterator. Raises RepositoryError on command failure.
3284	Reads stderr output from a subprocess, logging each line and capturing error messages when the process fails.
3285	Execute a command with optional directory and environment settings, returning stdout as bytes. Raises RepositoryError on non-zero exit codes unless they're in ignored_error_codes list. Logs command execution and errors.
3286	Fetch tweets from the TwitterSearch API with specified filters and return a generator of tweets. Supports filtering by ID range, geolocation, language, and result type (mixed, recent, popular).
3287	Fetch tweets based on given parameters and yield them one by one while tracking date ranges and unique tweet IDs.
3288	Fetch tweets for a given query with optional filtering parameters, returning a generator of tweet results.
3289	Returns the Twitter argument parser with backend token requirement and various Twitter-specific arguments including max items, entities inclusion, geo code, language, tweets type, and rate limiting options.
3290	Fetch data from Google API for a given category, returning a generator of items by calling the parent class's fetch method with the specified category and no additional keyword arguments.
3291	Fetch Google hit items for a given category and keywords, parse the raw hits, and yield them as a generator. Logs the fetching process and completion status.
3292	Parse Google Search API hits and return structured JSON data with hit count, timestamp, and search keywords.
3293	Fetch information about a list of keywords by making a search request to Google and returning the response text.
3294	Extracts the update time from a GitHub item by converting the 'updated_at' field to a UNIX timestamp, or returns 'fetched_on' for forked items.
3295	Extracts the category from a GitHub item, returning 'pull_request', 'repo', or 'issue' based on item attributes.
3296	Fetches pull requests within a date range and enriches them with additional data fields like user information, review comments, and commit details.
3297	Get repository information including stars, watchers, and forks metrics. Fetches raw repository data from client, converts it to JSON format, adds a timestamp indicating when the data was fetched, and yields the complete repository information with the timestamp included.
3298	Get all reactions for a specific issue by fetching reaction data from the client, parsing JSON responses, and enriching each reaction with user information before returning the complete reactions list.
3299	Get reactions on issue comments by fetching comment reactions from client, parsing JSON data, and augmenting each reaction with user information. Returns a list of reaction dictionaries with associated user data.
3300	Get issue assignees by converting raw assignee data into user objects.
3301	Get pull request requested reviewers by fetching user data for each requested reviewer from the API response.
3302	Get pull request commit hashes by fetching commit data from the client and extracting SHA hashes from JSON response.
3303	Get pull review comment reactions for a given comment ID, including user data for each reaction.
3304	Get user and org data for the login
3305	Get reactions for a specific issue by fetching items from the reactions endpoint associated with the given issue number, using pagination parameters and sorting by updated date in ascending order.
3306	Fetch issues from a GitHub repository updated since a given date, returning a generator of issues with pagination and sorting by update date.
3307	Fetch pull requests from a GitHub repository updated since a given date, yielding them as JSON strings.
3308	Get repository data by constructing the repository URL path using the base URL, owner, and repository name, then fetch and return the repository data as text.
3309	Get requested reviewers for a pull request by fetching from the requested_reviewers endpoint.
3310	Get pull request commits for a given PR number by fetching items from the commits endpoint with pagination support.
3311	Get reactions for a specific pull request review comment by comment ID.
3312	Get user information and update the user cache. First checks if user is already in cache, if not fetches user data from API and stores it in cache before returning it.
3313	Get the user public organizations for a given login. Returns cached results if available, otherwise fetches from GitHub API. Handles 404 errors gracefully by returning an empty array string instead of raising an exception.
3314	Get the remaining API points for a given token by querying the rate limit endpoint and parsing the response header.
3315	Return array of all tokens remaining API points by temporarily disabling archiving during rate limit checks.
3316	Method that selects the best API token from multiple available tokens based on remaining API points and updates the current token and session headers.
3317	Check if GitHub API tokens need to be switched based on rate limit usage and thresholds. Returns True when approaching minimum rate limit or when API usage exceeds the predefined switch threshold, False otherwise. Updates the last checked rate limit in both cases.
3318	Update rate limits data for the current token by fetching from the rate_limit endpoint and handling potential HTTP errors.
3319	Initializes metadata information for archive storage by inserting basic identification and retrieval information into a database table. The method stores repository identifier, backend details, category, parameter specifications, and creation timestamp. It handles database operations with proper error handling and logging, while also setting instance attributes for metadata access. Raises ArchiveError on database initialization failures.
3320	Stores a raw item in the archive with the given URI, payload, headers, and data, generating a unique identifier using the provided parameters. Raises ArchiveError on storage errors.
3321	Retrieve a raw item from the archive using the provided URI, payload, and headers. The method derives a hashcode from these parameters to locate the corresponding data in the archive. It returns the archived data if found, otherwise raises an ArchiveError. The method uses SQLite to query the archive table and pickle to deserialize the retrieved data.
3322	Create a brand new archive at the specified path by initializing a SQLite database with metadata and archive tables. Raises ArchiveError if the archive file already exists. Returns the created archive instance.
3323	Generate a SHA1 hash code based on URI, payload, and headers for use as unique identifiers in an archive.
3324	Method `_verify_archive` checks the integrity of an archive by verifying that tables were created and contain valid data. It counts rows in the archive and metadata tables, raises ArchiveError if metadata is corrupted (multiple entries) or missing while entries exist, and logs debug information about archive integrity status.
3325	Load metadata from the archive file by executing a SELECT query on the metadata table, fetching the first row, and populating instance attributes with the retrieved data. If no metadata is found, log a debug message indicating empty metadata.
3326	Fetch the number of rows in a specified table by executing a COUNT(*) query and return the result. Raises ArchiveError if the archive file is invalid.
3327	Create a new archive file with a random SHA1 hash as its name, organized in subdirectories by the first two characters of the hash. Returns an Archive object or raises ArchiveManagerError on failure.
3328	Remove an archive file from the filesystem at the specified path, raising ArchiveManagerError if the archive is invalid or cannot be removed.
3329	Search archives based on origin, backend name, category and creation date criteria, returning a sorted list of archive file paths that match the search parameters.
3330	Search archives using specified filters and yield matching archive paths with their creation timestamps.
3331	Retrieve file paths from the base directory using os.walk() and yield each file location.
3332	Check if a file is compressed (gz, bz2, or zip) by examining its magic number bytes. Returns the compression type or None if not supported.
3333	Generate a range of months between from_date and to_date, returning tuples of consecutive month pairs.
3334	Converts an email message object into a case-insensitive dictionary with headers as key-value pairs and message body organized by content type. Handles both simple and multipart messages, decoding payloads with proper character encoding. Returns a requests.structures.CaseInsensitiveDict containing all headers and a 'body' key with plain and/or HTML content. Raises ParseError on encoding errors.
3335	Remove invalid XML characters from an XML stream by replacing control and illegal characters with whitespace.
3336	Converts an XML stream into a dictionary representation where attributes are stored as single elements, child nodes are stored in lists, and text content is stored under the '__text__' key. Handles XML parsing errors and removes invalid XML characters before processing.
3337	Parse a Redmine issues JSON stream and return a generator of parsed issues.
3338	Get information about a list of issues from Redmine, filtered by update date and optional pagination parameters. Returns JSON response containing issue data.
3339	Get information for a specific issue by its ID, including attachments, changesets, children, journals, relations, and watchers.
3340	Get the information of the given user by calling an API endpoint with the user ID and returning the response.
3341	Summary: The `_call` method performs an HTTP request to fetch a specified resource from a Redmine API. It constructs the request URL using the base URL and resource name, adds an API token to the parameters if available, logs the request details, and returns the text content of the response.
3342	Fetch data from a Docker Hub repository including pulls, stars, and description metrics.
3343	Fetch Dockher Hub items for a given category using provided backend arguments and return a generator yielding parsed repository data with fetch timestamp.
3344	Fetch information about a specific repository by owner and repository name from DockerHub API.
3345	Map custom fields to include extra information like id, name, and value for matching fields.
3346	Filter custom fields from a given set of fields and return them as a dictionary keyed by field ID.
3347	Parse a JIRA API raw response and yield issues from the response items.
3348	Retrieve all items from a given date via API pagination, yielding results incrementally while logging status updates.
3349	Retrieve all issues from a given date by making API calls to the search endpoint.
3350	Retrieve all comments for a given issue by making a GET request to the comments endpoint and return the comment items.
3351	Retrieve all available fields by making a request to the field endpoint and return the response text.
3352	Fetch builds from Jenkins URL for a given category, returning a generator of builds.
3353	Retrieves all jobs from Jenkins API endpoint and returns the response text.
3354	Retrieve all builds from a job by making an API request to the Jenkins job endpoint, with support for blacklist filtering and detailed depth configuration. Returns the API response text containing build information.
3355	Parse a StackExchange API raw response and yield questions from the response items.
3356	Retrieve all questions from a given date, handling pagination and rate limiting by yielding questions page by page until all questions are fetched.
3357	Returns the StackExchange argument parser with specific arguments for StackExchange sites, question tags, and maximum questions limit.
3358	Fetch items from a MediaWiki instance based on category and API version, yielding pages either through reviews API (for MediaWiki 1.27+) or fallback pages API.
3359	Get the maximum date in unixtime format from a list of reviews by converting each review timestamp to UTC and tracking the highest timestamp value.
3360	Fetches wiki pages from MediaWiki >=1.27 backend URL, yielding pages as generators. Handles pagination, skips already processed pages, and logs page processing statistics.
3361	Retrieves all pages from a specified namespace starting from a given continuation point, with pagination support.
3362	Retrieve recent pages from specified namespaces starting from a given continuation point.
3363	Fetch messages from the Telegram server with optional filtering by chat and offset. Returns a generator of messages, raising ValueError if chats list is empty.
3364	Parse a Telegram JSON messages list and return an iterator of message dictionaries.
3365	Method `_filter_message_by_chats` checks if a Telegram message can be filtered based on a list of chat identifiers. It returns `True` if the message was sent to any chat in the provided list, or if the chat list is `None`. Otherwise, it returns `False`. The method extracts the chat ID from the message and checks if it exists in the provided list of chats.
3366	Fetch messages that a bot can read, optionally starting from a given offset. When offset is provided, all previous messages are removed from the server. Returns the API response containing the messages.
3367	Fetch articles from a newsgroup with given category and offset.

This method retrieves articles from a specified newsgroup, parsing and yielding them one by one. It handles various exceptions during parsing or fetching, logging warnings for skipped articles while maintaining counts of successfully fetched and failed articles. The method uses the NNTP client to fetch article overviews and individual articles, applying appropriate error handling for temporary network issues and parsing errors. It returns a generator of parsed article objects.

Parameters:
- category: The category of items to fetch
- kwargs: Backend arguments including offset parameter

Returns:
- Generator of parsed articles

Logging:
- Info: Shows fetch operation details including group, host, and offset
- Debug: Displays total number of articles to fetch
- Warning: Logs parsing errors and fetch failures with article IDs
3368	```python
def metadata(self, item, filter_classified=False):
    """NNTP metadata.

    This method takes items, overriding `metadata` decorator,
    to add extra information related to NNTP.

    :param item: an item fetched by a backend
    :param filter_classified: sets if classified fields were filtered
    """
    item = super().metadata(item, filter_classified=filter_classified)
    item['offset'] = item['data']['offset']

    return item
```

Summary:
Overrides the metadata method to add NNTP-specific information by calling the parent's metadata method and setting the offset field from the item's data.
3369	Parse a NNTP article from a string and return it as a dictionary. Raises ParseError on encoding errors.
3370	Fetch NNTP data from the server or from the archive based on the from_archive flag.
3371	Fetch article data by article_id and return structured data containing number, message_id, and lines.
3372	Fetch data from NNTP by executing a specified command method with given arguments, handling temporary errors and storing the result in archive if available.
3373	Fetch data from the archive by executing a command with given arguments, raising an ArchiveError if no archive is provided or re-raising NNTPTemporaryError if encountered.
3374	Creates an HTTP session with configured retry behavior for both HTTP and HTTPS requests.
3375	Sets up the rate limit handler with specified parameters including sleep behavior, rate limits, and header names for rate limit information extraction. Configures rate limit tracking variables and validates the minimum sleep rate against maximum allowed rate.
3376	Method `sleep_for_rate_limit` handles rate limit enforcement by sleeping for the required time if rate limit is exceeded, or raising a `RateLimitError` if sleeping is disabled. It calculates the time needed to reset the rate limit and logs appropriate messages during the process.
3377	Update the rate limit and reset time from response headers, logging the values if present.
3378	Parse a Supybot IRC log file and return an iterator of message dictionaries. Raises ParseError for invalid format and OSError for file reading errors.
3379	Retrieve Supybot archives after a given date, filtering by date and sorting results chronologically.
3380	Lists all archive file paths stored in the directory specified by `self.dirpath` by walking through all subdirectories and returning a list of full file paths.
3381	Parse a Supybot IRC stream and returns an iterator of dictionaries containing log entry information (date, type, nick, body). Raises ParseError if invalid line is found during parsing.
3382	Parse timestamp section from a line using regex matching, returning timestamp and message components, or raise ParseError if format is invalid.
3383	Parse message section by matching input line against multiple regex patterns and return corresponding token type, nick, and body content, or raise ParseError for invalid messages.
3384	Fetch topics from a given category based on a date filter, yielding each topic as it's retrieved. The method logs the start and completion of the fetch process, including the number of topics retrieved.
3385	Parse a topics page JSON stream into a generator of topic tuples containing (id, last update date, pinned status).
3386	Retrieves a topic with the specified topic_id identifier by making an API call to the topic endpoint with the API key as a parameter. Returns the response from the API call.
3387	Retrieve a post by its ID using the API.

This method fetches a specific post identified by `post_id` from the posts endpoint. It includes the API key in the request parameters and returns the response from the API call.

Parameters:
- post_id: identifier of the post to retrieve

Returns:
- API response containing the post data

Example URL structure: http://example.com/posts/10.json
3388	Fetch tasks from a given category starting from a specific date, yielding each task as a generator and logging the total count of fetched tasks.
3389	Parse a Phabricator tasks JSON stream and return a generator of parsed tasks.
3390	Parse a Phabricator users JSON stream and return a generator of parsed user dictionaries.
3391	Retrieve tasks updated from a specified date, yielding results in batches until all tasks are fetched.
3392	Retrieve tasks transactions for the given task identifiers.
3393	Retrieve users by their identifiers.

**Parameters:**
- `phids`: Variable length argument list of user identifiers

**Returns:**
- Response containing user data

**Method:** GET

**API Endpoint:** PHAB_USERS
3394	Retrieve data about PHIDs by calling the PHAB_PHIDS endpoint with the provided PHIDs parameter.
3395	Call a Phabricator Conduit method with the given parameters and return the response text, raising a ConduitError if the server returns an error.
3396	Extracts the identifier from a Confluence item by combining its 'id' and 'version' fields in the format "<content>#v<version>".
3397	Parse a Confluence summary JSON list and return an iterator of dictionaries, where each dictionary represents a content summary.
3398	Get the contents of a repository using pagination, starting from a given date. The method ignores seconds in the date parameter as the API only supports hour and minute precision. It yields responses from the API call with cql query filtering contents updated since the specified date, limited by max_contents parameter. Optionally accepts an offset to start fetching from a specific position.
3399	Get the snapshot of a content for the given version.

**Parameters:**
- `content_id`: fetch the snapshot of this content
- `version`: snapshot version of the content

**Returns:**
- The snapshot of the specified content at the given version

**Method behavior:**
Fetches a historical snapshot by making a call to the resource endpoint with version, status, and expand parameters, then returns the first (and only) response item.
3400	Parse the result property, extracting the value and unit of measure from XML, converting the value to float, and creating a Measurement object.
3401	Return a capabilities URL by adding missing parameters (service, request, version) to the service URL.
3402	Reads and parses a WFS capabilities document from the given URL, returning an etree object of the parsed XML content using the instance's capabilities URL method and openURL with specified timeout and authentication credentials.
3403	Parse a WFS capabilities document from XML string or bytes, returning a WFSCapabilitiesInfoset instance. Raises ValueError if input is not string or bytes type.
3404	Parse the result element of the observation type by finding the MeasurementTimeseries element and creating a MeasurementTimeseries object.
3405	Helper function to build a WFS 3.0 URL by joining the base URL with an optional path and preserving any existing query string parameters.
3406	Get attribute elements from a complex type by finding all element children of the specified complex type in the XML schema.
3407	Constructs a Fiona schema dictionary based on XML elements and namespace mappings. Parses element attributes to determine geometry types using predefined mappings and property data types. Returns a schema dictionary with 'properties' and 'geometry' keys, or None if no valid schema components are found.
3408	Get url for describefeaturetype request

Returns a URL with proper WFS DescribeFeatureType parameters including service, request, version, and typeName.
3409	**Summary:**

The function `complex_input_with_reference()` demonstrates how to use the `ComplexDataInput` class with a reference to a document in a Web Processing Service (WPS) execution. It performs the following steps:

1. Creates a WPS client connection to a local service at 'http://localhost:8094/wps'
2. Sets up a process ID ('wordcount') with a complex data input pointing to an HTML document (Alice in Wonderland from Project Gutenberg)
3. Configures output parameters to be returned as references with a specified MIME type
4. Executes the WPS process with the given inputs and output configuration
5. Monitors the execution progress and prints status information including completion percentage and status messages
6. Outputs details about each process output, including identifier, data type, data content, and reference information

The function showcases how to handle complex data inputs with external references in WPS workflows, particularly useful for processing large documents or files that should be accessed via URL rather than being embedded in the request.
3410	Get the list of Movie genres.

Args:
    language: (optional) ISO 639-1 code.

Returns:
    A dict respresentation of the JSON returned from the API.
3411	Get the list of TV genres with optional language parameter and return the API response as a dictionary.
3412	Get the list of movies for a particular genre by id, with optional filtering parameters like page, language, include_all_movies, and include_adult. Returns a dictionary representation of the JSON response from the API.
3413	Get basic movie information for a specific movie id with optional language and append_to_response parameters.
3414	Get the alternative titles for a specific movie id.
3415	Get the cast and crew information for a specific movie id.

Args:
    append_to_response: (optional) Comma separated, any movie method.

Returns:
    A dict representation of the JSON returned from the API.
3416	Get the external ids for a specific movie id.
3417	Get the plot keywords for a specific movie id and return the JSON response from the API as a dictionary.
3418	Get a list of recommended movies for a movie.
3419	Get the release dates and certification for a specific movie id.
3420	Get release date and certification information by country for a specific movie id.
3421	Get the translations for a specific movie id.
3422	Get similar movies for a specific movie ID with optional parameters like page, language, and append_to_response, returning a dictionary representation of the API's JSON response.
3423	Get the reviews for a particular movie id.

Args:
    page: (optional) Minimum value of 1.  Expected value is an integer.
    language: (optional) ISO 639-1 code.
    append_to_response: (optional) Comma separated, any movie method.

Returns:
    A dict representation of the JSON returned from the API.
3424	Get the changes for a specific movie id, grouped by key and ordered by date descending. Returns changes from the last 24 hours by default, with a maximum range of 14 days. The language is included on translatable fields.
3425	Get the list of upcoming movies that refreshes every day, with a maximum of 100 items. Supports optional page number and language parameters.
3426	Get the list of movies currently playing in theatres with optional pagination and language parameters.
3427	Get the list of popular movies on The Movie Database. This list refreshes every day.

Args:
    page: (optional) Minimum value of 1. Expected value is an integer.
    language: (optional) ISO 639-1 code.

Returns:
    A dict representation of the JSON returned from the API.
3428	Get the list of top rated movies with optional pagination and language parameters.
3429	Get the rating and list status of a movie for a specific user account. Requires a valid session ID. Returns JSON response containing whether the movie has been rated, added to favorites, or watchlist.
3430	This method allows users to rate a movie by sending a POST request to the API with a rating value. It requires either a session ID or guest session ID for authentication. The method constructs the request path using the movie ID, prepares a payload with the rating value, and sends the request. The response from the API is then processed and returned as a dictionary.
3431	Get the movie credits for a specific person id.
3432	Get the TV credits for a specific person id.

Args:
    language: (optional) ISO 639-1 code.
    append_to_response: (optional) Comma separated, any person method.

Returns:
    A dict respresentation of the JSON returned from the API.
3433	Get detailed information about a credit record with optional language parameter, returns JSON response with credit details including episodes and season information.
3434	Discover TV shows by different types of data like average rating, number of votes, genres, the network they aired on and air dates.
3435	Get system wide configuration info and return it as a dictionary response from the API.
3436	Get the list of supported certifications for movies. Returns a dict representation of the JSON response from the API.
3437	Get basic account information by calling the info API endpoint, update account attributes with the response data, and return the JSON response. This method should be called before other Account methods to initialize the account session.
3438	Get the list of movies on an account watchlist with optional pagination, sorting, and language parameters.
3439	Generate a valid request token for user based authentication, required to ask the user for permission to access their account. Returns a dictionary representation of the JSON response from the API.
3440	Authenticates a user with TMDb credentials and returns the API response. Validates the user's token, username, and password against TMDb's authentication system. Requires a verified TMDb account. Returns a dictionary representation of the JSON API response.
3441	Generate a session ID for user-based authentication that's required for write methods. Takes a request_token as argument and returns a dictionary representation of the API's JSON response.
3442	Generate a guest session ID by making a GET request to the 'guest_session_new' endpoint and return the JSON response.
3443	Get a list of rated movies for a specific guest session id.
3444	Check if a movie id is already added to a list and return the API response as a dictionary.
3445	Create a new list with the specified name, description, and optional language, using the current session ID for authentication. Returns the API response as a dictionary.
3446	Remove a movie from a user-created list by sending a POST request with the movie ID and session information, then update the instance attributes with the API response.
3447	Clears all items within a list by sending a POST request to the API endpoint. Requires a valid session ID and confirmation argument. Returns a dictionary representation of the JSON response from the API. This is an irreversible action that should be treated with caution.
3448	Get the content ratings for a TV Series.

Args:
    language: (optional) ISO 639 code.
    append_to_response: (optional) Comma separated, any collection method.

Returns:
    A dict representation of the JSON returned from the API.
3449	Get similar TV series for a specific TV series ID with optional parameters like page, language, and append_to_response, returning a dictionary representation of the API's JSON response.
3450	Get the list of TV shows that are currently on the air by looking for TV shows with episodes airing in the next 7 days. Supports optional page and language parameters. Returns a dictionary representation of the API's JSON response.
3451	Get primary information about a TV season by its season number, including optional language and append_to_response parameters. Returns a dictionary representation of the API's JSON response.
3452	Get the cast & crew credits for a TV season by season number. Returns a dict representation of the JSON returned from the API.
3453	Get the external ids stored for a TV season by season number.
3454	Get primary information about a TV episode using season and episode number combination, with optional language and append_to_response parameters. Returns JSON response from the API.
3455	Get the TV episode credits by combination of season and episode number.

Returns:
    A dict respresentation of the JSON returned from the API.
3456	Get the external ids for a TV episode by combination of a season and episode number.
3457	Set attributes of the object to values from a dictionary response, allowing direct access to response data as object attributes instead of dictionary key access.
3458	Search for movies by title with various optional filters and return the API response as a dictionary.
3459	Search for collections by name with optional query parameters and return JSON response.
3460	Search for TV shows by title with various optional filters and return JSON response.
3461	Search for people by name with optional filtering and pagination parameters, returning a dictionary representation of the API's JSON response.
3462	Search for companies by name using the provided query parameters and return the JSON response from the API.
3463	Search for keywords by name using the provided query parameters and return the JSON response from the API.
3464	Search movie, TV show, and person collections with a single query, returning a dictionary representation of the JSON response from the API.
3465	Normalize and tokenize text using NIST mteval-v11a.pl preprocessing rules, with optional language-independent and language-dependent transformations.
3466	Function `cook_refs` processes reference sentences for BLEU score calculation by normalizing the references, counting n-grams up to order `n`, and tracking maximum n-gram counts across all references. It returns a tuple containing the lengths of each reference and the maximum n-gram counts.
3467	The `cook_ref_set` function processes a reference sentence by normalizing it and counting n-grams up to size n. It returns a tuple containing the reference length, n-gram counts dictionary, and a frozenset of the counts for use in BLEU score calculations.
3468	Complementary error function implementation using approximation formula. Takes a float input x and returns the complementary error function value using a rational approximation with a series of nested multiplications and exponentials. The function handles both positive and negative inputs by returning 2-r for negative inputs and r for positive inputs.
3469	Creates sentence alignment for two texts composed of multiple blocks, ensuring block boundaries are not crossed. Takes source and target blocks (each containing sentence lengths) and alignment parameters, returning a list of sentence alignment lists. Raises ValueError if the number of blocks differs between texts.
3470	Get descriptors in a module, optionally searching recursively through submodules. Returns an iterator of Descriptor objects found in the module.
3471	Register Descriptors from json descriptor objects.

Parameters:
    obj(list or dict): descriptors to register

Returns:
    None

The method converts a single json descriptor object to a list if necessary, then registers each descriptor by converting json objects to Descriptor instances using `Descriptor.from_json()`.
3472	Register descriptors with optional version and 3D ignore flag, handling various descriptor-like inputs through internal registration method.
3473	Outputs a message either through a progress bar (if available) or directly using print.
3474	Check if a descriptor is a calculatable descriptor class.

Returns True if the descriptor is a class that inherits from Descriptor, optionally including abstract classes.
3475	Convert object to JSON serializable dictionary with name and optional arguments.

Returns:
    dict: Dictionary containing object name and arguments if present

Example output formats:
- {"name": "object_name"} 
- {"name": "object_name", "args": {...}}
3476	Get 3D coordinate.

Returns:
    numpy.array[3, N]: coordinate matrix

Raises:
    AttributeError: if 3D coordinate is not required in 2D descriptor
3477	Calculate atomic surface area for a given atom index by computing the accessible surface area based on neighboring atoms and spherical sampling.
3478	Calculate all atomic surface areas and return a list of float values.
3479	Construct SurfaceArea from RDKit Mol object by extracting atomic radii and positions, then creating surface area object with specified solvent radius and mesh level.

Key steps:
1. Calculate atomic radii using Van der Waals radii plus solvent radius
2. Extract 3D positions from specified conformer
3. Create and return SurfaceArea instance with radii, positions, and mesh level
3480	Create Descriptor instance from json dict by looking up descriptor classes in cached registry and using _from_json helper function.
3481	Replace missing values with a specified value in the object.

Parameters:
    value: value to replace missing values with (default: np.nan)

Returns:
    A new object with missing values replaced by the specified value

The method iterates through the values, replacing any missing values (detected by `is_missing()`) with the provided `value`, while keeping non-missing values unchanged. It returns a new instance of the same class with the updated values.
3482	Delete missing values from the object, returning a new instance with only non-missing values and their corresponding descriptions.
3483	Get items as iterable of (Descriptor, value) pairs by zipping keys and values.
3484	Convert Result to dict with optional raw key formatting.

Parameters:
    rawkey(bool): 
        * True: dict key is Descriptor instance
        * False: dict key is str

Returns:
    dict
```
3485	Access descriptor value by descriptor name or instance.

>>> from mordred import Calculator, descriptors
>>> from rdkit import Chem
>>> result = Calculator(descriptors)(Chem.MolFromSmiles("C1CCCCC1"))
>>> result.name["C2SP3"]
6

Returns a GetValueByName object that allows accessing descriptor values by their names. The first time this property is accessed, it builds a mapping from descriptor names to their computed values for efficient lookup.
3486	A decorator that logs function calls by recording the function name, arguments, and return value to the debug output.
3487	Decorator to synchronize function execution using a threading lock.
3488	Show progress messages to stderr with overwriting behavior, but only when output is directed to a terminal.
3489	**Summary:** The `message` function outputs a formatted message to stdout. It first clears any progress indicators, then formats the input message string `msg` using the provided `args` tuple, and finally writes the formatted text followed by a newline character to the standard output. The function is documented with a docstring indicating it's for "Program message output."
3490	Utility function to handle runtime failures gracefully by displaying error messages, optionally showing exception information and stack traces, then terminating the program or raising an exception.
3491	Get a temporary filename for atomic download by creating a unique 15-character random string appended to the target name with a .tmp extension, and add it to the TEMP_FILES set.
3492	Function to atomically rename a temporary file to target location or delete it if no target is specified, and remove it from the TEMP_FILES collection if present.
3493	Clean up temporary files by removing all files listed in TEMP_FILES if they exist.
3494	Get the fixed part of the path without wildcard by splitting on PATH_SEP, iterating through components, and stopping at the first wildcard character ('*' or '?'). Returns the joined fixed path components.
3495	Returns a list of legal parameter names for a given AWS API method by analyzing the boto3 service model, or an empty list if the method is not found or requires no parameters.
3496	Merge command line options with existing parameters, carefully handling dictionary-type parameters by merging them instead of overwriting.
3497	Adds API parameters to an optparse parser by iterating through EXTRA_CLIENT_PARAMS and creating options with 'API-' prefix.
3498	Terminate all threads by deleting the queue and forcing child threads to quit. If exc_info is provided, store it. Attempt to process all remaining items in the queue, ignoring empty queue exceptions.
3499	Adds a single task to the task queue with the specified function name, arguments, and keyword arguments.
3500	Utility function to wait for all tasks to complete and threads to terminate by joining task queue, sending termination signals to workers, and waiting for each worker thread to finish execution.
3501	Increase the processed task counter and display progress message showing completed tasks, remaining tasks (if any), and active threads.
3502	Retrieve S3 access keys from the environment, or None if not present.
3503	Retrieve S3 access keys from the command line, or None if not present.
3504	Retrieve S3 access key settings from s3cmd's config file, if present; otherwise return None.
3505	Initializes S3 access keys by attempting to retrieve them from command line arguments, environment variables, or s3cfg configuration file in that order of precedence.
3506	Connect to S3 storage using BotoClient with either provided credentials or default configuration, raising RetryFailure exception on connection errors.
3507	List all S3 buckets and return their information including name, directory indicator, size, and creation date.
3508	Walk through a S3 directory with support for multiple wildcards, handling trailing slashes and automatic directory detection, returning sorted results with directories listed before files.
3509	Walk through local directories from root basedir and return a list of all file paths.
3510	Expand S3 paths by replacing wildcards with actual file names, emulating shell expansion behavior. Takes a source path (or list of paths) and returns a list of matching file names. Disables recursive option during expansion to avoid unwanted recursion. Returns empty list if no matches found and ignore_empty_source is False, otherwise raises runtime failure.
3511	Upload a single file or directory to S3 by adding task to queue. If source is directory and recursive mode is enabled, uploads all files recursively. Otherwise, uploads single file or omits directory with warning message.
3512	Upload files to S3 using a thread pool. Can handle multiple files or recursive directory copying. If target ends with path separator, uploads each source file to target directory maintaining structure. If target doesn't end with path separator, uploads single file or raises error for multiple sources. Uses ThreadPool for concurrent uploads.
3513	Creates a new S3 bucket using the provided source URL. Returns a response indicating success or failure of the bucket creation operation.
3514	Get privileges from S3 object metadata and apply them to target file by changing its permissions.
3515	Prints the contents of files from an S3 source by expanding the source, iterating through each file, and outputting the file contents to the console.
3516	Downloads a single file or directory by adding a task to the queue. If the source ends with a path separator and recursive mode is enabled, it downloads all files in the directory recursively. Otherwise, it downloads the single file to the target location.
3517	Downloads files from S3 source to target location, handling multiple files with wildcards and recursive directory structures using thread pooling. Supports both single file and directory targets with appropriate error handling.
3518	Copy a single file or directory by adding a task to the queue, with optional recursive directory copying and source deletion.
3519	Copy files from source to target, handling multiple files with wildcards and recursive mode while maintaining directory structure. Supports optional deletion of source files after copying.
3520	Delete files from S3 by walking through the source path, collecting all file objects (excluding directories), and batch deleting them using a thread pool.
3521	Generic version of directory walk that returns a list of file paths relative to the base directory for comparison purposes. For S3 paths, it uses s3walk and strips the base path from each file path. For local paths, it uses local_walk and computes relative paths from the given directory.
3522	Syncs files between directories, supporting local-to-local, local-to-S3, and S3-to-S3 operations with optional deletion of removed files.
3523	Calculate MD5 hash code for a local file by reading it in blocks and updating the hash digest.
3524	Get or calculate MD5 value of the local file. Returns the cached MD5 value if already calculated, otherwise calculates and caches it using the file_hash method.
3525	Create all directories in the path to the target file, ensuring they exist. If the directory path doesn't exist, attempt to create it using makedirs. Handle potential race conditions in multi-threaded environments. Raise a Failure exception if directory creation fails due to reasons other than the directory already existing.
3526	Check if local file and remote file have the same MD5 hash by comparing against ETag, md5, or md5 in Metadata. Returns True if hashes match, False otherwise.
3527	Partially matches a path and a filter path with wildcards, returning True if they match. Handles trailing slashes and supports recursive directory walking with multiple level wildcards.
3528	A thread worker function that recursively walks through S3 directories, filtering results based on a given path pattern. It uses pagination to handle large result sets, processes subdirectories first, and adds matching objects (files or directories) to the result list according to recursive settings and path matching criteria.
3529	Check file items against specified conditions and append matching items to result list. Supports filtering by last modified date before/after timestamps, and handles directory items differently based on file-only flag.
3530	Get the privileges of a local file by retrieving its octal permissions from the file's stat information, raising a Failure exception if the operation fails.
3531	Lookup an S3 object using the provided S3 URL and return None if the object doesn't exist.
3532	Read a chunk of data from a local file at specified position and return it as a StringIO object.
3533	Uploads a file to S3 with support for both single-part and multipart uploads, handling initialization, chunked uploads, and completion/finalization of multipart operations.
3534	Verify that the downloaded file size matches the expected content length from the object metadata, raising a RetryFailure exception if they don't match.
3535	Write a chunk of data to a local file at a specified position.
3536	Copy a file from source to target using S3, with support for multipart copy operations and optional source deletion. For single-part copies below the size threshold, use direct copy. For larger files, initiate multipart upload and process in chunks. If MPI is provided, copy a specific part of the file. Finalize the operation upon completion or handle failures appropriately.
3537	Main entry point that handles commands by dispatching to individual command handlers based on the first argument. Raises InvalidArgument if no command is provided or if the command is unknown.
3538	Method `validate` checks if input arguments match the expected format patterns. It accepts a format string with pipe-separated options (cmd, s3, local) and validates each argument against the corresponding format. The method supports multiple format options per position (comma-separated) and raises `InvalidArgument` exceptions for mismatches or incorrect parameter counts. It also handles special validation for S3 URLs and command handlers.
3539	Pretty prints S3 object listing results with aligned columns. Calculates maximum width for each column (timestamp, size, name) and formats output accordingly. Handles timestamp normalization and directory indicators.
3540	Handler for ls command that lists S3 buckets when no arguments are provided, or lists S3 objects at the specified path when arguments are given.
3541	Handler for mb command that validates arguments and creates an S3 bucket with the provided name.
3542	Handler for put command that validates arguments, handles shell expansion for source files, and uploads files to S3 using the S3 handler.
3543	Handles the get command by validating arguments and retrieving files from S3 or local storage to a target directory.
3544	Handler for cat command that validates the command and prints files from S3 source using s3handler.
3545	Handler for dsync command that sets recursive, sync_check, and force options to True, validates the command arguments, and calls dsync_files method on the S3 handler with source and target parameters.
3546	Handler for cp command that validates the command and copies files between S3 locations using the S3 handler.
3547	Handler for mv command that validates the command and moves files between S3 locations by copying and deleting the source files.
3548	Handler for del command that validates the command structure, extracts the source argument, and deletes files using the S3 handler.
3549	Handler for size command that iterates through S3 object sizes and outputs them in tab-separated format with source and size.
3550	Handler for total_size command that calculates and displays the total size of specified S3 objects by summing up individual sizes returned by s3handler().size().
3551	Search for date information in the string using REGEX_DATE pattern. If found, extract the date components (year, month, day) and create a date object. Remove the matched date string from the original value. Return tuple of (date object, modified string). If no date pattern is found, return current UTC date and original string unchanged.
3552	Search for time information in the string using regex, extract time components to create a datetime.time object, and return the time object along with the string with time information removed.
3553	Search for timedelta information in the string and return a timedelta object along with the remaining string after removing the matched timedelta pattern.
3554	Method `check_dict` takes a json string value and attempts to parse it into a Python dictionary using `json.loads()`. If successful, it returns the parsed dictionary. If parsing fails, it raises an `OptionValueError` with a formatted error message indicating the invalid dictionary value for the given option.
3555	Discover gateways using multicast by sending a "whois" command and listening for "iam" responses, configuring known gateways from configuration and adding newly discovered gateways to the gateways dictionary.
3556	Start listening by creating a multicast socket and beginning a listening thread.
3557	Get data from gateway by sending a read command for the specified sid and return processed push data from the response.
3558	Pushes data broadcasted from gateway to device, validates the data, parses it according to protocol version, and invokes registered callbacks for the device session. Returns True if successful, False otherwise.
3559	Get key using token from gateway by encrypting the token with AES-CBC encryption and returning the hexadecimal representation of the ciphertext.
3560	Handles exceptions in RQ worker processes by reporting them to Rollbar with job context information.
3561	Initializes and configures the Rollbar error tracking integration for a Pyramid application by setting up tweens, hooks, and configuration options.
3562	Sets up a default logging handler with timestamp, level, name, and thread information formatting if no existing handlers are found.
3563	Returns the current request object by trying multiple framework-specific getters (Bottle, Flask, Pyramid, Pylons) in sequence until one succeeds, returning None if all fail.
3564	Initializes the Rollbar module with the provided configuration settings, including access token, environment, and various transforms for scrubbing and serializing data. It sets up logging, agent handling, and transforms for payload processing, and ensures the module is only initialized once.
3565	A decorator that simplifies error handling for AWS Lambda functions by capturing exceptions, reporting them, and re-raising them while maintaining the original function's metadata through functools.wraps.
3566	Reports an arbitrary string message to Rollbar with specified level and context information, handling exceptions gracefully.
3567	Searches a project for items matching the specified criteria, returning only requested fields. Supports searching by title with optional additional filters (status, level, environment) and allows specifying which fields to return. Returns an empty list if no title is provided.
3568	Creates a .rollbar log file for use with rollbar-agent, validates the file extension, sets up logging with FileHandler and specific formatter, and returns the logger instance.
3569	Returns a dictionary describing the logged-in user using data from `request`, checking `rollbar_person`, `user`, or `user_id` attributes in that order. Returns None if no valid user data is found.
3570	Adds Lambda context information to the given data dictionary if a Lambda context is available, including remaining time, function name, version, ARN, and request ID, while handling exceptions and clearing the context afterward.
3571	Adds request data to the payload by building and filtering request information, logging any exceptions that occur during the process.
3572	Returns True if local variables should be recorded for a given frame, which is determined by either being the last frame or coming from a file within the project's root directory.
3573	Builds and returns request data dictionary based on the request object type, handling various frameworks including webob, django, werkzeug, tornado, bottle, sanic, falcon, and plain WSGI requests.
3574	Returns a dictionary containing server environment information including hostname, process ID, command line arguments (if available), and branch/root settings from SETTINGS.
3575	Builds and returns a full payload dictionary containing an access token and transformed data.
3576	Initializes Rollbar error reporting with a test environment, sets up a TCP server on port 8000 using Echo protocol, and starts the reactor to handle incoming connections.
3577	This function composes a Hangul character from its constituent parts: initial consonant (chosung), medial vowel (joongsung), and final consonant (jongsung). It takes three parameters - chosung and joongsung are required, while jongsung is optional - and returns the corresponding Hangul Unicode character by calculating its code point based on the indices of the constituent parts. If any of the input characters are not valid Hangul components, it raises a NotHangulException.
3578	This function decomposes a Hangul letter into its constituent components (initial consonant, vowel, and final consonant). It first validates that the input is a valid Hangul letter, then checks if it's already a standalone component (initial, vowel, or final consonant). For compound Hangul letters, it calculates the character's index and decomposes it into its individual components using predefined arrays (CHO, JOONG, JONG). If the decomposition fails, it provides debugging information about the indices and components before raising an exception. The function returns a tuple containing the decomposed components in the order: (initial consonant, vowel, final consonant).
3579	Check whether a Hangul letter contains a Jongsung (final consonant). Raises exceptions for invalid inputs and returns True if the letter has a final consonant, False otherwise.
3580	Add josa at the end of a word based on the last Hangul letter's jongseong (final consonant). If the word ends with a non-Hangul character, uses a substitute. Returns the word with appropriate josa attached.
3581	Returns true if node is inside the name of an except handler. Traverses up the AST tree until finding an ExceptHandler parent, then checks if the current node matches the handler's name.
3582	Return True if the given node is inside a lambda expression, False otherwise. The function traverses up the AST parent chain until it finds a Lambda node or reaches the root.
3583	Returns all elements from nested lists and tuples recursively.
3584	Checks if an assignment in an except handler clobbers an existing variable. Returns (True, args for W0623) if clobbering occurs, (False, None) otherwise. Handles both attribute assignments (AssignAttr) and name assignments (AssignName), checking against builtins and outer scope variables.
3585	Returns True if the node references the built-in "super" function, False otherwise. Checks if the node's name is "super" and belongs to the built-in namespace.
3586	Returns True if the node contains only raise statements and no other executable code.
3587	Returns True if the given Name node is used as a default argument value in a function or lambda definition.
3588	Returns True if the given AST node is used as a function decorator, False otherwise. Checks the node's parent hierarchy to determine if it's located within a Decorators node, while stopping at statement boundaries or specific scope nodes.
3589	Returns True if the given frame is a Class node and the node is present in the subtree of its bases attribute.
3590	Returns the highest parent node that is not an AssignName, Tuple, or List node.
3591	A decorator factory that creates a decorator to store message strings in a function's `checks_msgs` attribute for later use by checker methods.
3592	Given a format string, return an iterator of all the valid format fields, handling nested fields recursively. Returns field names from the format string, including nested ones, and handles invalid format strings by raising IncompleteFormatString exception.
3593	Returns the specified argument from a function call node based on either positional index or keyword argument name. Raises ValueError if neither position nor keyword is provided, and NoSuchArgumentError if the specified argument is not found.
3594	Return True if the given class node is a subclass of exceptions.Exception.
3595	Check if an exception handler catches a specific error type or types. Returns True if the handler catches any of the given errors, False otherwise. Supports exception classes, exception names (strings), or tuples of errors. Handles edge cases where handler type is None by returning True.
3596	Detects if a given function node is decorated with a property decorator by checking its decorators and returning True if a property decorator is found, False otherwise.
3597	Determine if a function node has a decorator with a specified qualified name.
3598	Return the ExceptHandler or TryExcept node in which the given node is nested.
3599	Check if a given node is from a fallback import block by examining surrounding try-except context for import statements or ImportError handling.
3600	Return the collections of handlers managing the specified exception within a try-except block.

Args:
    node (astroid.NodeNG): A node that may be wrapped in a try-except structure.
    exception (builtin.Exception or str): The exception type or name to search for.

Returns:
    list: A list of exception handlers that catch the specified exception, or None if no try-except context is found.
3601	Check if a node is within a TryExcept block that handles a specific exception. Returns True if the node is protected by exception handling, False otherwise. If no specific exception is provided, it looks for bare except clauses.
3602	Returns True if the given class node contains any abstract methods defined within the class itself (not inherited).
3603	Returns the inferred value for a given AST node, or None if inference fails or there's ambiguity.
3604	Return the inferred type for a node if there is exactly one possible type, otherwise return None. Handles cases where inference fails or multiple types are possible.
3605	Check if a given function node is a singledispatch function by examining its decorators for register calls to singledispatch functions.
3606	Check if postponed evaluation of annotations is enabled by verifying if 'annotations' is imported from '__future__' in the module.
3607	Split the names of the given module into subparts.

For example,
    _qualified_names('pylint.checkers.ImportsChecker')
returns
    ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']
3608	Get a prepared module name from an import node, converting relative imports to absolute names when necessary.
3609	Returns a string representation of imports as a tree structure, where each line shows a module name optionally followed by files in parentheses, with proper indentation to visualize the hierarchical relationship between modules.
3610	Creates a dependencies graph from provided information and adds a descriptive message to the report section indicating the graph has been written.
3611	Method: visit_import

Summary: This method handles import statement processing by checking for reimports, import renames, multiple imports, deprecated modules, preferred modules, and relative imports. It also records imported modules and checks their positioning within the code structure.

Key operations:
- Checks for reimports and import as renames
- Identifies multiple imports and reports them
- Validates deprecated and preferred modules
- Processes relative imports and records imported modules
- Ensures proper positioning of imports
- Maintains import tracking for the module
3612	Visits an `import from` statement and performs multiple checks including import renaming, misplaced future imports, deprecated modules, preferred modules, wildcard imports, same-line imports, and reimports. It also records the import and checks the import's position and relative imports. For each imported name, it adds the module to the imported modules list.
3613	Check if an import node is positioned correctly (must come before other instructions). Send a "wrong-import-position" message if the import appears after other instructions.
3614	Records the import relationship by tracking which package imports from where, handling both regular imports and relative imports from AST nodes.
3615	Checks that imports in a module follow the correct order: standard library, third-party, and local imports. Uses isort to determine import categories and reports violations using the 'wrong-import-order' message. Returns lists of standard, external, and local imports.
3616	Check if a relative import is used when absolute import is activated or when level is specified, and add a relative-import message if so.
3617	Method to notify about imported modules for dependency analysis, handling import-self cases, recording dependencies, and updating import graphs while considering cyclic import rules.
3618	Check if a module is deprecated and add a message if it is.
3619	Check if a module has a preferred replacement and add a message if it does.
3620	Method `_report_external_dependencies` generates a formatted tree representation of external dependencies and appends it to a section. It retrieves external dependency information, converts it into a tree structure using `_make_tree_defs`, validates that the tree is not empty (raising `EmptyReportError` if it is), and then converts the tree to a string representation using `_repr_tree_defs`. Finally, it appends the formatted tree as verbatim text to the provided section.

**Key operations:**
1. Gets external dependencies info
2. Converts to tree definitions 
3. Validates non-empty tree
4. Converts tree to string representation
5. Appends verbatim text to section

**Exceptions:** `EmptyReportError` when no dependencies exist
3621	Builds either internal or external dependency graph by filtering dependencies based on package boundaries. Returns a defaultdict set graph where keys are importees and values are sets of importers, filtered according to whether the dependency is internal (within same package) or external (across packages).
3622	Read configuration file and return list of options, ignoring missing files.
3623	Insert default command-line options into sys.argv by retrieving default options, reversing their order, and inserting each option at position 1 of the argument list.
3624	Returns True if the node should be treated based on its visibility and the current mode. Checks if the node's visibility (retrieved via `get_visibility`) is NOT filtered out by the current mode (`self.__mode`) using the visibility mode mapping (`VIS_MOD`).
3625	Returns the entry and leave callback methods for a given node type from the handler, caching the results for performance.
3626	Visits a node and its children recursively, executing entry and exit callbacks. Returns the result of the exit callback or None.
3627	Check that all message IDs in the messages list have consistent checker IDs. Validates that the checker ID portion (characters 2-3) of each message ID matches the first message's checker ID. Raises InvalidMessageError if inconsistency is found.
3628	Visits a Call node to analyze function calls and check for various code issues including open mode errors, redundant assertions, thread instantiation problems, subprocess parameter issues, shallow copy problems, environment function usage, and deprecated method calls.
3629	Check if a datetime was infered and emit boolean-datetime warning if so.
3630	Check that the mode argument of an open or file call is valid, and report bad-open-mode error if invalid.
3631	Method that processes and stores message information from different types of messages within a path context.
3632	Display messages using the specified layout by printing formatted JSON data to the output stream.
3633	Returns the title for an object by combining the node's name with its module name if module_names is enabled.
3634	Sets default configuration options by processing module names and ancestor/associated show levels, with priority given to explicit configuration values over default behavior.
3635	Returns True if builtins should be shown based on configuration, False otherwise. Shows builtins only if show_builtin is True OR if the node's root name is not the builtins name.
3636	Adds a class node to the diagram by visiting it and storing it with its title.
3637	Return ancestor nodes of a class node, yielding each ancestor that passes the show_node filter, up to the specified level.
3638	Return associated nodes of a class node up to a specified level, yielding ClassDef nodes that pass the show_node filter.
3639	Extract classes recursively from a class diagram node, including ancestors and associated nodes up to specified levels.
3640	Method `leave_project` exits the pyreverse.utils.Project node and returns the generated diagram definition. If `pkgdiagram` exists, it returns both `pkgdiagram` and `classdiagram`; otherwise, it returns a tuple containing only `classdiagram`.
3641	Adds import-from nodes to package diagram dependency tracking.
3642	Return a class diagram definition for the given class and its related classes by constructing a ClassDiagram object and extracting associated classes based on inheritance and association levels.
3643	Get the diagrams configuration data by generating class diagrams from the project classes and falling back to default diagram generation if no classes are specified, then extract relationships for each diagram.
3644	Check if the given owner should be ignored based on matching module or class names against ignored lists, including pattern matching for modules.
3645	Returns a list of similar attribute names to the given name within a distance threshold, limited by max_choices.
3646	Summary: The `_emit_no_member` function determines whether a "no-member" error should be emitted for a given attribute access. It checks various conditions to ignore certain cases, such as when the owner has decorators, dynamic attribute access methods (`__getattr__`, `__getattribute__`), is a mixin, or is explicitly ignored. It also handles special cases like super objects, enums, and protected attributes. The function returns `False` to suppress the error when any of these ignored conditions are met, and `True` otherwise.
3647	Check if the given node has a parent of the specified type by traversing up the parent chain until finding a matching node type or reaching the statement's parent boundary.
3648	Check if the given name is used as a variadic argument by comparing it against all variadics.
3649	Verify if a given call node has variadic nodes without context, handling cases of nested call functions where variadic arguments are incorrectly inferred as empty Tuple or Dict by astroid, which could lead pylint to incorrectly believe a function call receives too few arguments.
3650	This method checks if an accessed attribute exists on the inferred nodes of a given AST node. It handles various cases like generated members, ignored classes/modules, and opaque inference results to avoid false positives. If the attribute is missing, it adds a message indicating the issue. The method uses inference to determine the type of the object being accessed and then checks if the attribute exists using `getattr`. It also handles special cases like augmented assignments and emits appropriate messages when attributes are not found. The method stops checking once it finds a valid attribute or when it determines that further checking would be unreliable due to ambiguous inference results.
3651	Check if assigning to a function call where the function possibly returns something valuable. If the function has no return statements, emit "assignment-from-no-return" message. If all return statements return None, emit "assignment-from-none" message.
3652	Check if an uninferable Call node actually calls a function, particularly focusing on property decorators and callable return values.
3653	Detects TypeErrors for unary operands and adds a message for invalid unary operand types.
3654	Return an iterator on interfaces implemented by the given class node, optionally excluding inherited interfaces. Handles cases where interfaces might be missing or uninferable.
3655	Returns a Project instance from a list of files or modules by building AST representations and adding them to the project.
3656	**Method Summary:**

`visit_package` handles ASTroid Package nodes by optionally generating a unique ID for the node and recursively visiting all sub-elements.

**Parameters:**
- `node`: An astroid.Package node to be processed

**Functionality:**
1. If tagging is enabled (`self.tag` is True), assigns a unique ID to the node using `generate_id()`
2. Iterates through all values in the package node and recursively visits each sub-element

**Key Features:**
- Conditional unique ID assignment based on `tag` attribute
- Recursive traversal of package contents
- Maintains ASTroid visit pattern for package nodes
3657	Method: visit_functiondef
Purpose: Process an AST function definition node by setting up locals_type mapping and optionally generating a unique ID
Parameters: self, node (astroid.Function node)
Behavior: 
1. Checks if node already has locals_type attribute
2. Creates defaultdict mapping for locals_type if it doesn't exist
3. Generates and assigns unique ID to node if tagging is enabled
4. Returns early if locals_type already exists
3658	Handle assignment name nodes during AST traversal, managing local variable types and ensuring proper frame handling while avoiding duplicate processing.
3659	Handles an astroid.assignattr node by updating instance attributes type information, merging inferred values with existing ones for the attribute name.
3660	Visit an astroid.Import node and resolve module dependencies by processing each imported name in the node.
3661	Visits an astroid.ImportFrom node to resolve module dependencies by analyzing import statements and tracking imported modules.
3662	Returns 0 if the module should not be added to dependencies, 1 if it's a standard module, and 0 for all other cases.
3663	Notify an imported module to analyze dependencies, handling relative imports and maintaining a list of dependent module paths.
3664	Returns ANSI escape code for given color and style parameters. Supports both named colors and 256-color mode, with comma-separated multiple styles. Raises KeyError for invalid identifiers. Returns empty string if no color or style specified.
3665	Summary: The `colorize_ansi` function wraps a message string with ANSI escape codes to apply specified colors and styles. It takes three parameters: `msg` (the message to colorize), `color` (color identifier), and `style` (style identifier). If neither color nor style is provided, the original message is returned unchanged. The function uses `_get_ansi_code` to generate the appropriate escape codes and `ANSI_RESET` to reset formatting. Invalid color or style identifiers will result in the message being returned without formatting. The function returns a string with ANSI escape codes applied, or the original message if no formatting is requested or if invalid codes are specified.
3666	Register reporter classes (TextReporter, ParseableTextReporter, VSTextReporter, and ColorizedTextReporter) with the provided linter instance.
3667	Manage message handling for different types and path context, writing module headers when needed and processing messages.
3668	Displays a layout by printing a blank line and then formatting the given layout to the output stream using TextWriter.
3669	Handles different types of messages, colorizes output using ANSI escape codes, and manages module separation in the output.
3670	Method: open_graph
Description: Opens a VCG (Visual Classification Graph) graph by writing the graph header to the output stream and setting up the necessary attributes.

Parameters: 
- self: The instance of the class
- **args: Keyword arguments containing graph attributes to be written

Functionality:
1. Writes the graph header "{\n" to the output stream with current indentation
2. Increments the indentation level for subsequent content
3. Writes graph attributes using the _write_attributes method with GRAPH_ATTRS constant and provided arguments

The method effectively starts a new graph definition in VCG format with the specified attributes.
3671	Draws a node with the specified title and attributes by writing node data to the stream.
3672	Draws an edge from a source node to a target node with optional edge type and attributes.
3673	Check new string formatting by validating format strings, arguments, and format specifiers against the provided node and function.
3674	Process non-raw string tokens to check for bad escapes, identifying anomalous unicode escapes and backslashes that don't form valid escape sequences.
3675	Display a section as text by incrementing section counter, writing a newline, formatting layout children, decrementing section counter, and writing another newline.
3676	Display an evaluation section as text by incrementing section counter, formatting children, decrementing counter, and adding a blank line.
3677	Displays a table as text by calculating column widths and rendering the table content.
3678	Formats and writes a table with specified layout, content, and column widths using horizontal and vertical separators.
3679	Register old ID and symbol for a renamed warning to allow continued use in suppressions.
3680	Register all messages from a checker by first checking consistency and then registering each message individually.
3681	Registers a MessageDefinition with consistency checks, storing it by symbol and registering alternative names for both msgid and symbol, while also updating category-based message lists.
3682	Check if a symbol is already used either as a message definition or alternative name, and raise an exception if duplicates are found.
3683	Raises an InvalidMessageError when a symbol is duplicated, providing a formatted error message that lists both conflicting symbols in alphabetical order.
3684	Raise an error when a msgid is duplicated, showing both msgids in sorted order.
3685	Returns the MessageDefinition object(s) for a given message ID or symbol, searching through alternative names and message definitions. Raises UnknownMessageError if the message ID or symbol is not found. Supports both numeric and symbolic message identifiers.
3686	Generates a user-consumable representation of a message by returning either the message ID or the ID along with the symbol, depending on whether there is a single definition or multiple definitions for the given message ID.
3687	Display help messages for the given message identifiers, handling unknown message errors gracefully by printing the error and continuing with other messages.
3688	Output a sorted list of message documentation in ReST format, filtering out messages that shouldn't be emitted.
3689	This function initializes a documentation builder that generates ReST format documentation for all Pylint extension modules. It discovers Python files in the extensions directory, excludes deprecated and private modules, and creates a comprehensive documentation file listing all available extensions. The function also provides examples of how to activate these extensions via the .pylintrc configuration file.
3690	Returns the number of CPU cores available, using sched_getaffinity when possible, falling back to multiprocessing.cpu_count(), with a minimum of 1.
3691	Creates a messages type report showing error occurrence statistics, sorted by frequency in descending order, excluding informational messages (those starting with "I"). Raises EmptyReportError if no errors are detected.
3692	Prepare sys.path for running linter checks by adding paths from arguments to sys.path in order, avoiding duplicates, and reset sys.path to original value upon exiting context.
3693	Load and register pylint plugin modules from a list of module names, skipping already loaded plugins.
3694	Loads and executes configuration hooks for all dynamic plugins by iterating through plugin modules and calling their load_configuration() method if it exists.
3695	Method `set_option` overrides the parent class method to handle special options. It processes options defined in `_options_methods` or `_bw_options_methods` by calling corresponding methods after validating CSV format input. For deprecated options, it shows a warning and converts the option name. It also handles the "output-format" option by updating the reporter name and loading the reporter if available. For all other options, it calls the parent class method with error handling for unsupported actions.
3696	Register a new checker by adding it to the checkers dictionary, registering its reports and options, adding its messages to the messages store, loading default configurations, and disabling it if specified.
3697	Disables all reporters by iterating through all reports and disabling each one individually.
3698	Disable all checkers and enable Python 3 warnings. If error mode is active, only enable Python 3 errors. Load disable option from config file and set the python3 porting mode flag.
3699	Return all available checkers as a list, including the current instance and all checkers from the _checkers dictionary values, excluding the current instance itself.
3700	Get all checker names that the linter knows about, excluding "master", and return them sorted alphabetically.
3701	Returns the list of checkers needed for activated messages and reports, sorted by priority in descending order. Disables reporters if reports are not configured. Includes the main checker and any additional checkers that have enabled messages or reports.
3702	Method `expand_files` takes a list of modules, expands them using `utils.expand_modules` while considering blacklists, handles any errors that occur during expansion by setting the current module and adding appropriate messages, and returns the expanded results.
3703	Sets the currently analyzed module name and initializes its statistics. If no module name is provided and no file path is given, the method returns without doing anything. Otherwise, it notifies the reporter of the module change, stores the module name and file path, and initializes statement and message category counts for the module in the statistics dictionary.
3704	Check a module from its astroid representation, handling syntax errors, processing tokens, running raw and token checkers, and walking the AST.
3705	Create global evaluation report with code rating and comparison to previous run.
3706	**Summary:** Optik callback that prints help information for a specified message and exits the program. Takes an option, option name, value, and parser as parameters, splits and strips the value, retrieves help message from linter's messages store, then exits with status code 0.
3707	Method that serves as an optik callback to print full documentation and exit the program.
3708	Method `cb_list_messages` is an optik callback that prints available messages by calling `list_messages()` on the linter's messages store, then exits the program with status code 0.
3709	Lists all check groups that pylint knows about, printing each checker name and exiting with status 0.
3710	Wraps text to a specified line length with optional indentation for the first and subsequent lines.
3711	Returns the module name and frame identifier string for a given node by traversing up the frame hierarchy, collecting module name and object names in the call stack.
3712	Returns decoded line from specified encoding or defaults to system default encoding, handling LookupError exceptions gracefully.
3713	Determines if a filename's basename matches any regex pattern in a blacklist. Returns True if matched (blacklisted), False otherwise.
3714	Load all modules and packages in the given directory, looking for a 'register' function in each one to register pylint checkers.
3715	Return the input string formatted as a comment by adding "# " prefix to each line and joining them with newlines.
3716	Returns the user input's value from a 'compiled' value by handling different data types:
- Lists and tuples: join elements with commas
- Dictionaries: join key-value pairs with colons
- Compiled regex patterns: return the pattern string
- Boolean values with 'yn' type: return "yes" or "no"
- Strings with whitespace: wrap in single quotes
- Other values: return as-is
3717	Formats an options section using INI format, optionally printing documentation comments and the section header before writing the options.
3718	Formats options using INI format, writing to a stream with help comments and properly formatted key-value pairs, handling multiline values and comments.
3719	Insert a child node at the specified index and set its parent pointer to self.
3720	Overrides the append method to include an assertion that checks child is not already in parents, for easier problem detection.
3721	Return the ancestor nodes as a list, starting with the direct parent and recursively including all ancestors up to the root node. Returns an empty list if the node has no parent.
3722	Formats and writes the given layout to the specified stream, handling unicode strings by attempting to write them directly or encoding them with the specified encoding if the direct write fails.
3723	Method: `get_table_content`

Summary: This method extracts and returns the content of a table as an aligned list of lists, where each inner list represents a row of cells. It processes the table cells sequentially, organizing them into rows based on the specified number of columns. Missing cells are filled with empty strings to ensure consistent row lengths.

Parameters:
- `table`: A table object containing cell data and column specifications

Returns: A list of lists where each inner list contains the string values of cells in a row, properly aligned

Key functionality:
1. Iterates through computed table cell content
2. Organizes cells into rows based on column count
3. Handles row transitions when column limit is reached
4. Fills incomplete rows with empty strings
5. Returns structured table data as string values
3724	Computes the formatting of child layouts by temporarily redirecting output to streams, yielding formatted strings for each child element.
3725	Collects block level options line numbers by walking the AST and manages message state tracking for the module.
3726	Handles reporting of ignored messages by tracking suppressed messages based on message ID and line numbers, storing them in a mapping structure for later reference.
3727	Registers a report with the given parameters, storing it in the reports dictionary under the specified checker. The report is stored as a tuple containing the uppercase report ID, title, and callback function.
3728	Render registered reports by iterating through report order, checking if each report is enabled, and executing report callbacks to generate sections that are then appended to the main report section.
3729	Adds statistics entries to the statistic dictionary, raising AssertionError if there are key conflicts. Key names ending with underscore are stripped of the underscore before insertion. Returns the updated statistics dictionary.
3730	Get the name of the property that the given node is a setter for.

**Parameters:**
- node: The node to get the property name for.

**Returns:**
- The name of the property that the node is a setter for, or None if one could not be found.
3731	Get the property node for the given setter node by finding the property decorator in the same class. Returns the property node if found, otherwise returns None.
3732	Check if a return node returns a value other than None.

**Parameters:**
- `return_node`: The return node to check (astroid.Return)

**Returns:**
- `bool`: True if the return node returns a value other than None, False otherwise
3733	Gets all possible raised exception types for a given raise node, ignoring caught exceptions. Returns a set of exception type names that could be raised by the node.
3734	Process a module to inspect its source file and find messages that are activated or deactivated by ID, then add messages to the linter to use symbolic message instead.
3735	Method `process_module` inspects a module's source file to detect encoding issues. It first determines the file encoding (using the module's specified encoding or defaulting to "ascii"), then reads through each line of the file using a stream. For each line, it calls `_check_encoding` to validate the encoding against the determined encoding, passing along the line number and content. This helps identify potential encoding-related problems in the source code.
3736	Method processes tokens to find and report FIXME problems in comments, handling pylint disable clauses and emitting warnings when FIXME patterns are detected.
3737	Check if a name is a future import from another module by examining import statements. Returns True if the name is imported from the future module, False if not, and None if an exception occurs during module import.
3738	Returns True if the given statement is inside the else branch of a for loop statement.
3739	Get overridden method if any from parent class ancestors. Returns the method node if found, None otherwise.
3740	Return extra information for unpacking-non-sequence and unbalanced-tuple-unpacking errors, including definition location and code content when appropriate.
3741	Detects whether two frames share a global scope by checking their parent scopes and ensuring they are not under function scopes. Returns True if the frames share a global scope and the frame's line number is less than the definition frame's line number, indicating a potential forward reference issue.
3742	Checks if a name node has a corresponding assignment statement in the same scope by examining all AssignName nodes in the scope and returning True if any match the name.
3743	Mark a name as consumed by moving it from the to_consume dictionary to the consumed dictionary and remove it from to_consume.
3744	Check if global variables are properly defined and accessed. Verify that names imported exist in the global scope, handle module-level globals, check for undefined global variables, and ensure proper global statement usage.
3745	Return True if the node is not in a local class scope as an assignment, False otherwise.
3746	Return True if there is a node with the same name in the to_consume dict of an upper function scope, False otherwise.
3747	This method checks for errors in tuple unpacking operations. It verifies that the number of target variables matches the number of values being unpacked, and that the object being unpacked is iterable. The method handles special cases like inside abstract classes, comprehensions, and variable-length arguments, and reports two types of errors: "unbalanced-tuple-unpacking" when there's a mismatch between targets and values, and "unpacking-non-sequence" when trying to unpack a non-iterable object.
3748	Updates consumption analysis for metaclasses by checking class definitions and removing consumed items to prevent false positive unused-import and unused-variable warnings.
3749	Return a list of subpackages for the given directory by recursively searching through subdirectories and checking for __init__.py files to identify valid Python packages.
3750	This function is a setup entry point that configures and executes the installation of a Python package using either setuptools or distutils. It handles package discovery, sets up entry points for command-line scripts, manages dependencies, and configures various package metadata. The function dynamically adjusts its behavior based on whether setuptools is being used, and returns the result of the setup() call with comprehensive package configuration including author information, classifiers, data files, and testing requirements.
3751	Overrides the install_lib class run method to additionally install included directories. First calls the parent class's run method, then manually installs directories specified in include_dirs by copying them to the installation directory while excluding certain pattern-matched files based on Python version.
3752	Creates a table reporting similarity statistics between current and previous versions, showing duplicated lines count and percentage along with their differences.
3753	This function provides command-line access to a code similarity detection tool. It parses command-line arguments to configure detection parameters like minimum lines for duplicates and options to ignore comments, docstrings, and imports. It processes input files through a SimilarityDetector class and exits after completion.
3754	Appends a stream to be searched for similarities, handling optional text encoding and catching Unicode decode errors.
3755	Computes similarities between appended files by grouping duplicate line pairs into ensembles, then returns them sorted in descending order by similarity number.
3756	Display computed similarities on stdout, showing similar line groups with their file references and actual lines, then print total lines count, duplicates count and percentage.
3757	Finds similar consecutive line sequences between two linesets, yielding the length and positions of matching segments that exceed a minimum line threshold.
3758	Iterates through similarities among all file pairs by generating a cartesian product of linesets and finding common elements between each pair.
3759	Return an iterator of (index, stripped_line) pairs starting from the specified index.
3760	Creates an index mapping each non-empty line to a list of its line numbers in the stripped lines collection.
3761	Check if a definition signature is equivalent to a call by comparing arguments, keyword arguments, and variadic arguments.
3762	Check equality of two AST nodes by comparing their specified attributes.

Args:
    node_a (astroid.node): First node to compare
    node_b (astroid.node): Second node to compare  
    attr_name (str): Name of attribute to compare

Returns:
    bool: True if attributes are equal, False otherwise
3763	Check if original and overridden methods arguments have different default values. Returns True if one of the overridden arguments has a default value different from the original, False if methods don't have arguments or if all default values match. Handles various astroid node types for comparison including constants, classes, tuples, and lists.
3764	Determine if two methods have different parameters by comparing their positional parameters, keyword-only parameters, and variadic parameters (vararg and kwarg). Returns True if there are any differences that could lead to inconsistencies, False otherwise. Special handling is included for Python special methods where parameter name differences are ignored.
3765	Safely infers the return value of a function call. Returns None if inference fails, multiple values are inferred, or there's ambiguity. Otherwise returns the inferred value.
3766	Sets the given node as accessed by adding it to the scopes dictionary under the node's attribute name within its frame. If the node does not belong to a class (frame is None), the method returns without making changes.
3767	Method `visit_classdef` initializes the visit variable `_accessed` and performs several checks on class definitions including base classes, `__init__` method existence, slots, proper bases, and consistent MRO.
3768	Check if a class has a consistent method resolution order (MRO) or duplicate bases, and report inconsistencies or duplicates as appropriate messages.
3769	Check that a class inherits from proper base classes, detecting inheritance from non-classes or invalid base classes, and warn about useless object inheritance.
3770	This method visits function definitions to check method arguments, overriding, and potential issues like useless super delegation, incorrect first argument types, and method hiding by attributes. It also handles property decorators and checks method signatures against overridden parent methods.
3771	Check if a function node is an useless method override that only delegates to parent class via `super()` with same parameters. Returns early if not a method, has decorators, multiple statements, or non-call statement. Validates super call attributes and MRO pointer match. Ensures parameter signatures match between overridden and current method, and annotations are consistent. If all checks pass, reports a "useless-super-delegation" message.
3772	Method checks if a method could be a function instead. It ignores class, static, and abstract methods, initializers, and overridden methods. If the method doesn't use 'self' and isn't excluded by the above conditions, it adds a "no-self-use" warning.
3773	Check if an AssignAttr node is assigned to a class slot. Returns early if the assigned attribute is not in the class slots, unless it's a property, descriptor, or __class__ assignment with same layout slots. Emits "assigning-non-slot" warning for invalid assignments.
3774	Check if a name node represents access to a class member and register it if so. Specifically, when the node's name matches the last attribute in `_first_attrs` or when the last attribute is empty, mark that the method could potentially be a function rather than a method.
3775	Check that accessed members are defined, handling class attributes, instance attributes from parent classes, and instance attributes. Report access-member-before-definition when a member is accessed before its definition in the same method.
3776	Check that a class implements all abstract methods from its base classes, skipping abstract classes themselves and methods that are redefined or overridden.
3777	Check that the signature of two given methods matches. Returns True if the signatures match, False otherwise.
3778	Check if an astroid.Name node corresponds to the first attribute variable name (self, cls, or mcs) for method parameters.
3779	Return True if the given statement node raises an exception.
3780	Check if exception context is properly set - it should be either None or an exception instance. Reports error if context is a constant that is not None, or if it's not a class definition and doesn't inherit from standard exceptions.
3781	This method checks for proper usage of the `super()` function in method definitions. It verifies that:

1. The code is within a method of a class (not a standalone function)
2. The `super()` call has the correct arguments - specifically that the first argument is the class name
3. It detects problematic `super()` usage patterns that could lead to recursion loops:
   - Calling `super(type(self), self)` 
   - Calling `super(self.__class__, self)`
4. It ensures proper super() usage for both old-style and new-style classes
5. In Python 3, it allows missing super() arguments since they're optional
6. It adds appropriate error messages for detected issues

The method analyzes AST nodes to identify and validate super() calls within class methods.
3782	Displays results from a layout tree by adding report ID to the first child's data and calling internal display method.
3783	Check if a class node is a typing.NamedTuple class by examining its ancestors for a specific typing namedtuple name.
3784	Check if a class definition represents an Enum class by examining its base classes and their ancestors. Returns True if the class inherits from enum.Enum, False otherwise.
3785	Check if a class definition defines a Python 3.7+ dataclass by examining its decorators. Returns True if the class is decorated with @dataclass, False otherwise.
3786	Initialize visit variables including stats collection, returns list, branches defaultdict, and statements list.
3787	Check the size of class inheritance hierarchy and number of instance attributes, raising warnings if limits are exceeded.
3788	This method checks the number of public methods in a class definition against configured limits. It first counts public methods defined directly in the class (excluding those starting with underscore) and warns if there are too many. Then, it also counts all public methods including inherited ones and warns if there are too few, but only for regular classes (excluding enums, dataclasses, and namedtuples). The method uses two different thresholds: `max_public_methods` for upper limit and `min_public_methods` for lower limit.
3789	Increments the branches counter for if statements and checks boolean expressions. Handles branching logic including elif cases and ensures proper branch counting.
3790	Checks if an "if" statement's boolean expression exceeds the maximum allowed count and reports an error if it does.
3791	Check if a node's docstring contains spelling errors by examining each line of the docstring for misspellings.
3792	Formats the message according to the given template using the namedtuple's fields as formatting parameters.
3793	Check if a given token is a trailing comma by verifying it's a comma that trails an expression on the same line, ensuring no other expressions follow until the end of the line, and confirming the context indicates a return or yield statement.
3794	Check if a given node is an actual elif statement by verifying it follows an "else" clause and exists in the recorded elifs collection.
3795	Check if an if statement can be simplified to a boolean expression. Returns early if the statement is an elif, has multiple branches, or doesn't match the simplification pattern. Validates that both branches return boolean constants and that the first branch's value is truthy. If all conditions are met, adds a message indicating the statement can be simplified to either `return bool(test)` or `var = bool(test)`.
3796	Check if a StopIteration exception is raised inside a generator function and add a message if it is.
3797	Check if an exception inherits from StopIteration by examining its method resolution order (MRO) against the StopIteration class qualified name.
3798	Check if a StopIteration exception is raised by a call to the next() function within a generator. If the next() call doesn't have a default value and doesn't already handle StopIteration, and the first argument is not an infinite iterator, then report a stop-iteration-return message.
3799	Updates and checks the number of nested blocks within functions or methods, tracking block hierarchy and emitting messages when nested block levels change.
3800	Get the duplicated types from the underlying isinstance calls.

**Parameters:**
- `node` (astroid.BoolOp): Node which should contain a bunch of isinstance calls.

**Returns:**
- `dict`: Dictionary of the comparison objects from the isinstance calls, to duplicate values from consecutive calls.
3801	Check isinstance calls that can be merged together when they are combined with "or" operation, identifying duplicated type names and adding a message suggesting to merge them.
3802	Check for chained comparisons in boolean operations and report cases where comparisons like `a < b and b < c` could be chained as `a < b < c`, while avoiding incorrect simplifications when variables appear in multiple unrelated comparisons.
3803	Returns True if the node represents a ternary-like expression in the form "condition and true_value or false_value", where all components are simple boolean expressions.
3804	Check that all return statements inside a function are consistent, ensuring either all returns are explicit with values or all returns are empty with possible implicit return. Reports inconsistent-return-statements message if the return statements are not consistent.
3805	Check if a node ends with an explicit return statement, handling various node types including Return, Call, While, Raise, and If statements, with special cases for exception handling and recursion through child nodes.
3806	This method detects when a `for` loop uses `range(len(...))` for indexing and suggests using `enumerate()` instead. It analyzes the loop's iterator to ensure it's a proper `range(len(object))` call, then checks if the loop body accesses elements by index using subscript notation. If both conditions are met, it reports a "consider-using-enumerate" warning. The method includes several validation checks to ensure the pattern is correctly identified and avoids false positives, such as when iterating over `self` in an `__iter__` method or when the subscript isn't in the same scope.
3807	Checks if Graphviz is available for the specified output format. If not available, prints an error message and exits with code 32.
3808	Method summary:

**run(self, args)**
Validates input arguments, sets up Python path, creates project from files, generates dependency analysis using linker and handler, then writes output in either VCG or DOT format based on configuration. Returns 0 on success, 1 if no arguments provided.

Key operations:
- Validates arguments and shows help if empty
- Inserts current directory to Python path for local module imports
- Creates project from file arguments with configuration settings
- Builds dependency graph using linker and diadefs handler
- Writes output using appropriate writer (VCG or DOT) based on format configuration
- Cleans up Python path in finally block
- Returns exit code (0 for success, 1 for no args)
3809	Writes a package diagram by emitting nodes for each module and edges for package dependencies. Modules are sorted by title to ensure predictable ordering. Each module is emitted as a node with its figure ID stored, and dependencies are emitted as edges between the corresponding figure IDs.
3810	Writes a class diagram by emitting nodes for objects and edges for relationships including inheritance, implementation, and association links.
3811	Initializes a DotWriter with layout options and stores the file name.
3812	Initializes a VCGWriter for a UML graph by opening a file, creating a VCGPrinter instance, and setting up the graph with specified layout parameters.
3813	Returns True if a message may be emitted using the current interpreter based on version constraints.
3814	Return the help string for the given message id, including optional checker reference and Python version restrictions.
3815	Returns a copy of the environment variables with PYTHONPATH set to the current sys.path.
3816	Function `lint(filename, options=())` - Runs Pylint on the specified file, handling Python package imports correctly by traversing up the directory tree to find the package root. It executes Pylint from this root directory and adjusts the output filenames to match the original file path for compatibility with Emacs. The function returns the Pylint exit code.
3817	Function `py_run` executes pylint from Python by creating a subprocess. It accepts command options as a string, and optional parameters for standard output/stderr handling. If `return_std` is True, it returns a tuple of StringIO objects containing the process's standard output and error. Otherwise, it returns None. The function automatically manages stdout/stderr streams based on whether they are provided and whether std output should be returned. It detects the Python executable and constructs the command to run pylint using `epylint.Run()`.
3818	Recursive function that finds cycles in a graph using depth-first search, storing canonical representations of cycles in the result list.
3819	Returns the source code, generating it from lines if not already generated.
3820	Generates a graph file from the source code using the specified renderer. Creates a temporary .dot file, writes the source to it, then uses subprocess to call the renderer with appropriate parameters to generate the output file in the specified format (defaulting to PNG). If a mapfile is provided, it also generates a map file. Returns the path to the generated output file.
3821	Formats an options section using ReST (reStructuredText) formatted output, including section title, documentation, option help text, and default values.
3822	Registers a numeric message ID to inform users that a symbolic message ID could be used instead. Adds message information to by_id_managed_msgs list if the message ID exists in msgs_store, handling UnknownMessageError gracefully.
3823	Disables output of a message with the given id by setting its status to disabled and registering it as a managed message.
3824	Enable a previously disabled message with the given id by setting its status to enabled and registering it as managed.
3825	Get the message symbol for a given message id, returning the original message id if it doesn't exist.
3826	Return True if the message associated with the given message description is enabled, checking both confidence settings and message definitions.
3827	Adds a message to the report given by ID or name, expanding the message string using provided arguments. Supports both AST checkers (which provide node argument) and raw/token checkers (which provide line argument).
3828	Method: `print_full_documentation`

Summary: Outputs full Pylint documentation in ReStructuredText (ReST) format to a specified stream. The documentation includes global options, switches, and detailed information about individual checkers' options, messages, and reports. If no stream is provided, outputs to standard output. The method organizes checker information by checker name and formats it using ReST syntax with appropriate section headers and formatting.
3829	Helper method to print documentation for a pylint checker, including its title, module information, docstring, options, messages, and reports, formatted for reStructuredText documentation.
3830	Return the length of the indentation on the given line, counting spaces as 1 character and tabs as _TAB_LENGTH characters.
3831	Returns a line with | markers for given bar positions and a ^ marker for bad position, along with a delta message suggesting how to fix the indentation.
3832	Get an indentation string for hanging indentation, consisting of the line-indent plus a number of spaces to fill up to the column of this token.
3833	Records the first non-junk token at the start of a line, checking if it's a block opener and storing its position.
3834	Returns the valid indentation offsets for a token at a given position, considering whether the token is a closing bracket and the current context in the continuation stack. The method determines valid indentations based on whether the token is a closing bracket (returning valid outdent strings) or not (returning valid continuation strings), and handles special cases like dictionary comprehensions that may reset two indentation levels.
3835	Extracts indentation information for hanging indent after brackets. Returns state and valid positions for hanging indentation based on bracket type and context. Handles block openers, dictionary values, and general hanging indents with appropriate indentation levels and alignment strings.
3836	Extracts indentation information for a continued indent by analyzing token indentation levels and returning appropriate continued indent objects based on whether the next token indicates a block opener.
3837	Pushes a new token for continued indentation on the stack based on whether the token is followed by end-of-line, using different handling methods for hanging indents after brackets versus continuations inside brackets.
3838	Process a new line by checking for unnecessary semicolons, storing non-junk tokens, and performing line-level checks.
3839	Check for unnecessary parentheses after keywords. Returns early if next token is not a paren, or if parentheses are needed for tuple syntax or generator expressions. Reports superfluous parentheses for keywords like 'not', 'return', 'yield' when they are followed by a colon and contain no commas. Handles special cases for 'and'/'or' operators and yields within expressions.
3840	Method `_has_valid_type_annotation` checks if a token stream contains valid PEP-484 type hints by examining tokens backwards from a given index. It validates type annotations by ensuring they're inside parentheses, looking for colon separators, and properly handling bracket nesting. Returns `True` if a valid type annotation is detected, `False` otherwise.
3841	Check the spacing around a single equals sign based on context: requires spaces for type annotations and general cases, prohibits spaces when inside parentheses or lambda expressions.
3842	Check that a binary operator is surrounded by exactly one space on both sides.
3843	Method `visit_default` checks node line numbers and processes them if not already done. It handles special cases for try/finally blocks, manages multi-statement lines, and collects source lines for analysis. The method tracks visited lines and performs line-by-line processing while handling attribute errors gracefully.
3844	Check for lines containing multiple statements, while skipping appropriate edge cases like nested context managers, try-except-finally blocks, single-line if statements, and single-line class definitions.
3845	Check lines for maximum character limit and trailing whitespace, handling special line endings and disable directives.
3846	Method to check the indentation level of a string and validate it against an expected level, reporting messages for mixed indentation or bad indentation issues.
3847	Check if a node is being used as an iterator in various contexts such as for loops, comprehensions, built-in functions, unpacking assignments, containment checks, and yield from statements.
3848	Checks if an import node is located within a conditional context (try/except, if statement, or if expression).
3849	This method detects references to "bad" built-in functions in Python code. It checks if a node represents a built-in name, verifies whether it's in the list of bad built-ins, and ensures that the usage isn't properly guarded by exception handling. If all conditions are met, it adds a diagnostic message indicating the use of a prohibited built-in function.
3850	Looks for indexing exceptions by checking if a subscript node's value is an instance of a standard exception class, and reports an "indexing-exception" message if found. Handles inference errors gracefully by returning early.
3851	This method checks for deprecated attribute access patterns in the AST. It specifically looks for usage of the removed `xreadlines` attribute and warns about it. For exception objects, it checks if `.message` is being accessed on exceptions that don't have this attribute explicitly defined, and for module objects, it checks for deprecated attributes using a helper method. The method handles inference errors gracefully by returning early if inference fails.
3852	This method visits an exception handler node to check for improper exception unpacking and potential variable leakage. It first checks if the exception handler uses unpacking (tuple/list) and raises a message if so. Then it looks for names that might leak out of the except block by finding names in the same scope that are assigned after the except block but not used within it, potentially causing exception escape issues.
3853	Visits a raise statement to check for raising strings or old-style raise syntax. Ignores empty raises and validates the exception value using inference.
3854	Function `find_pylintrc()` searches for a pylint configuration file by checking multiple locations in order of priority:
1. Local files: "pylintrc" or ".pylintrc" in current directory
2. Parent directories: traverses up the directory tree looking for "pylintrc" or ".pylintrc" files
3. Environment variable: uses PYLINTRC if set and file exists
4. User home directory: checks ~/.pylintrc then ~/.config/pylintrc
5. System-wide: checks /etc/pylintrc

Returns the absolute path to the first found pylint rc file, or None if no file is found.
3855	Validates an option value based on its specified type and returns the validated result. If the type is not specified, it returns the original value. Uses a validator function to perform the actual validation based on the option dictionary's type definition.
3856	Expands the default value for an option by replacing a default tag in the help text with the actual default value from configuration, while avoiding override of configuration file values.
3857	Method `_match_long_opt` takes an option string and checks if it exists in the object's `_long_opt` collection. If the option is not found, it raises a `BadOptionError` exception. If found, it returns the option string unchanged. This method disables option abbreviations by requiring exact matches for long options.
3858	Registers an options provider by inserting it into the providers list based on priority, then processes its options either as individual options or grouped options, creating option groups when appropriate.
3859	optik callback for setting provider options, handles both long and short command line options by converting them to their long form and setting the corresponding global option with the provided value.
3860	Sets an option on the correct option provider by accessing the option through the internal _all_options dictionary and calling its set_option method.
3861	Generate a configuration file based on current configuration, writing to specified stream or stdout. Groups options by section, skips deprecated options, and formats output with uppercase section headers.
3862	Loads configuration file values and dispatches them to option providers, skipping undeclared options.
3863	Loads command line configuration and returns additional arguments by parsing command line arguments and updating configuration options.
3864	Add a help section with specified title and description to the command line parser, creating a dummy option group for documentation purposes.
3865	Return the usage string for available options at the specified help level.
3866	Initialize the provider using default values by iterating through options and setting their default values.
3867	Returns the configuration attribute name corresponding to an option by getting the "dest" attribute from option definition, or falling back to replacing hyphens with underscores in the option name.
3868	Return the dictionary defining an option given its name. Raises OptionError if the option does not exist in the section.
3869	Return an iterator on options grouped by section, yielding tuples of (section, [list of (optname, optdict, optvalue)]), with None section first, followed by other sections sorted alphabetically.
3870	Determines if a BoundMethod node represents a method call by checking if it's an instance of astroid.BoundMethod, if its bound is an astroid.Instance, and if the caller type and method names match the optional restrictions provided. Returns True if all conditions are met, False otherwise.
3871	Checks if an AST node represents a string with complex formatting specifications. Returns True if the string uses format specifications, False otherwise. Handles cases where the node cannot be inferred or contains invalid format strings.
3872	Initializes the checker state for a new module by clearing previous state and setting up logging module configuration, including storing logging module names, format style, and processing import mappings for logging modules.
3873	Method that checks if a module uses a non-Python logging module by examining import statements and tracking logging module names.
3874	Adds the imported logging module name to _logging_names set when a Python built-in logging module is imported.
3875	This method analyzes function calls to identify logging method invocations. It checks if a call is made to a logging method either by:
1. Direct attribute access on logging-related objects (like `logger.info()`)
2. Method calls on Logger class instances

The method determines the logging method name and delegates validation to `_check_log_method()`. It handles inference errors gracefully and only processes actual logging calls.
3876	This method checks that the format string tokens in a logging call match the supplied arguments. It analyzes the format string to determine the required number of arguments based on the format style (old or new), then compares this with the actual number of arguments provided. If there's a mismatch in the number of arguments, it reports appropriate error messages. It also handles special cases like constant non-string format strings and unsupported format characters.
3877	Returns True if the given node is inside a loop structure (for loop, list comprehension, set comprehension, dict comprehension, or generator expression).
3878	Returns the loop node (For or While) that contains the given break node in its arguments. Traverses up the AST tree from the break node's parent until it finds a loop node that is not in an "orelse" block. Returns None if no such loop node is found.
3879	Returns True if a loop may end up in a break statement, False otherwise. Checks all break statements within the loop and verifies if they break out of the current loop (not inner loops).
3880	Returns a tuple of property classes and names from the configuration, where property classes are fully qualified names and property names are extracted from the qualified names.
3881	Determine the name type that a function's name should match based on its properties and decorators.

This function analyzes an AST node representing a function to classify it into one of three categories:
- 'function': Regular function that is not a method
- 'method': Instance or class method
- 'attr': Property getter/setter methods

The classification is based on:
1. Whether the node represents a method (using `node.is_method()`)
2. Presence of decorators like @property, @abc.abstractproperty, or prop_method.{setter,getter}
3. Configuration-based property classes and names

Returns the appropriate name type string based on these checks.
3882	Generate a report showing the percentage of different types (module, class, method, function) that are documented and have bad names, along with total counts and differences.
3883	Returns True if the object is a method redefined via decorator, such as a property setter. Checks if any decorator is an Attribute where the expression name matches the node name.
3884	Returns True if the given AST node is a function call with exactly one positional argument, False otherwise.
3885	Check that a Starred expression is used in an assignment target, ignoring cases where it's used in function calls or PEP 448 unpacking scenarios.
3886	Check that a name is both nonlocal and global, and report an error if found.
3887	Check if abstract class is being instantiated with abc.ABCMeta as metaclass when visiting a function call node.
3888	Check that loops with else clauses contain break statements. If an else clause exists without early exits, report a "useless-else-on-loop" message.
3889	Check that a node is inside a for or while loop, and report an error if it's not. Continue statements in finally blocks are also checked.
3890	Initializes visit variables and statistics for the linter, setting up try-finally tracking and adding statistics for modules, functions, methods, and classes.
3891	This method visits expression nodes to detect statements that have no effect. It handles string statements (treating docstrings differently) and ignores certain expression types like function calls, yields, awaits, and ellipses. For other expressions, it checks if they contain function calls and reports either "expression-not-assigned" (if function calls are present) or "pointless-statement" (if no function calls exist).
3892	Check if a lambda expression is suspicious by verifying if its body is a function call with identical arguments. Returns early if the lambda has default arguments, if the body is not a call expression, or if it involves chained calls. Ensures that ordinary arguments match between the lambda and the called function, and that keyword arguments are properly aligned. If all conditions are met, it reports an "unnecessary-lambda" message.
3893	Check for assert statements used on tuples with two elements.
3894	Check for duplicate keys in dictionary literals by examining constant keys and reporting duplicates.
3895	Check for unreachable code by examining the next sibling statement of a node and report unreachable code as a message if found.
3896	Check that a node is not inside a finally clause of a try...finally statement, skipping the check if a parent node of specified breaker classes is found.
3897	Check that the argument to `reversed` is a sequence, raising `bad-reversed-sequence` message for invalid arguments.
3898	This method visits assignment name nodes to check for naming violations at different scopes. It handles module-level constants, class definitions, variables in functions, and class attributes, while also checking for inline variable assignments and import redefinitions. The method uses various helper functions to determine the appropriate naming check based on the assignment context and frame type.
3899	Method to check if a name matches the expected pattern for a given node type, handling special cases like exempting class definitions from invalid name checks and multi-naming matches, while tracking bad names and raising warnings for invalid ones.
3900	Check if a node has a non-empty docstring, reporting missing or empty docstrings with appropriate messages and statistics tracking.
3901	Check if comparing to a literal value (constant, list, tuple, dict, or set) and report a warning if found.
3902	Creates subgraphs for `if` and `for` statements by parsing nodes and adding them to the graph collection, handling both global loop cases and nested subgraphs.
3903	Parses the body and any `else` block of `if` and `for` statements, handling loose ends and connecting them to a bottom node in the control flow graph.
3904	Visits an ASTroid Module node to analyze code complexity. Uses a PathGraphingAstVisitor to traverse the module's body and calculate complexity for each graph. If any graph's complexity exceeds the configured maximum, it adds a "too-complex" message with the node name and actual complexity level.
3905	This method walks through a checker object's directory to find and collect visit and leave methods for different node types. It processes methods that start with "visit_" or "leave_" prefixes, checks if they're enabled, and adds them to the appropriate event lists. It also handles default visit methods that get applied to node types not explicitly covered. The method maintains sets of visited and left node IDs to track which node types have been processed, and ensures default methods are applied to any node types that don't have specific handlers.
3906	Method `walk` processes an AST node by calling visit events on all registered checkers for that node type, recursively traverses all child nodes, and then calls leave events. It also maintains a count of statements encountered during traversal. The method handles backwards compatibility for deprecated node aliases by preferring methods associated with the deprecated names when applicable.
3907	Creates a relationship between two objects and stores it in a dictionary grouped by relation type.
3908	Returns a relationship of the specified type from the given object, or raises KeyError if not found.
3909	Return visible attributes with optional class names by collecting instance attributes, local variables, and property decorators from a node, filtering them based on visibility rules, and formatting them with class type information.
3910	Returns visible methods from a node's values, filtering for FunctionDef nodes that are not decorated with property and whose names pass the show_attr check, then sorts them by name.
3911	Add a diagram object with given title and node, ensuring node is unique and storing it in both _nodes dictionary and objects list.
3912	Return class names from a list of nodes that are not already present in the diagram.
3913	Return all class nodes in the diagram by filtering objects whose node is an instance of astroid.ClassDef.
3914	Return a class by its name, raising KeyError if not found.
3915	Return all module nodes in the diagram by filtering objects whose node attribute is an instance of astroid.Module.
3916	Returns a module by its name, raising KeyError if not found.
3917	Returns a module by its name, handling both absolute and relative imports. Searches through available modules and checks for matches against the module name, package-qualified names, and relative import patterns. Raises KeyError if no matching module is found.
3918	Add dependencies created by from-imports to a module's node.
3919	Removes the current grant from cache and logs the deletion operation. Required by oauthlib implementation. Returns None.
3920	Returns the appropriate query object for the model, either from the model's 'query' attribute or from the session's query method.
3921	Returns the User object if found and password matches, otherwise returns None.
3922	Returns a Token object filtered by either access token or refresh token parameters.
3923	Creates a Token object and removes all expired tokens that belong to the user. Takes a token object and OAuthlib request object as parameters. If the request has a user, uses that user; otherwise uses the current user. Filters tokens by client_id and user_id, deletes existing tokens, then creates a new token with expiration time and commits it to the session. Returns the created token object.
3924	Creates a Grant object with given parameters including client ID, authorization code, and request details, then saves it to the session with a 100-second expiration.
3925	Get the Grant object with the given client ID and code

Parameters:
- client_id: ID of the client
- code: The authorization code

Returns:
- The Grant object if found, None otherwise
3926	Prepare HTTP request parameters by setting default method, handling GET with parameters, and formatting URI accordingly.
3927	Initializes the extension with a Flask app instance and stores it in app.extensions using the state key.
3928	Registers a new remote application with the given name and parameters, optionally storing it in the remote_apps dictionary if register=True. Returns the created OAuthRemoteApp instance.
3929	Sends an HTTP request to a remote server with optional OAuth authentication, supporting both OAuth1 and OAuth2 protocols. Handles URL encoding or JSON formatting of request data, manages headers, and processes the response through an OAuthResponse wrapper. Supports GET requests with URL-encoded parameters and other HTTP methods with optional content type specification.
3930	Returns a redirect response to the remote authorization URL with the signed callback given, handling both OAuth1 and OAuth2 flows with optional parameters and state handling.
3931	Handles an OAuth1 authorization response by signing the access token request, making the HTTP request, and returning the parsed response data. Raises OAuthException if token is not found or if the response is invalid.
3932	Handles an OAuth2 authorization response by preparing request arguments, making HTTP requests to obtain access tokens via either POST or GET methods, and returning the parsed response data while raising exceptions for invalid responses.
3933	Handles authorization response by checking for OAuth verifier or authorization code, processing the appropriate response type, and cleaning up session tokens before returning the response data.
3934	Handles an OAuth callback by decorating a function to automatically process authorized responses, with a deprecation warning in favor of `authorized_response`.
3935	Creates a hashable tuple for a given token to be used as a dictionary key, handling both dictionary and tuple tokens by converting dictionaries to sorted tuples and raising TypeError for other types. Returns a tuple containing the application class name, application name, and the hashable token representation.
3936	Creates or retrieves a cached client instance using a hashed token for identification. If a client already exists in the cache for the given token, it returns the cached instance; otherwise, it creates a new client via the subclass implementation and stores it in the cache for future use.
3937	Creates an OAuth1Session client using either a token tuple/list or dictionary containing access token information.
3938	Creates a context manager that enables OAUTHLIB_INSECURE_TRANSPORT environment variable for debugging with insecure transport when app is in debug or testing mode, restoring original setting after use.
3939	Confirms OAuth1 authorization request by extracting parameters, validating credentials against defined realms, creating authorization response, and handling potential OAuth1 errors by redirecting to error URI.
3940	Request token handler decorator that wraps a function to handle OAuth1 request token creation, extracting parameters from the request and returning appropriate HTTP responses including error handling for OAuth1 errors.
3941	Get client secret from request client object, retrieving the client if necessary.
3942	Get request token secret for a given client key and token. Returns the secret if token exists and matches the client key, otherwise returns None.
3943	Get access token secret from token object or token getter. Returns None if no token found.
3944	Get the default realms for a client by checking the client object's default_realms attribute, returning an empty list if not found or if no client is associated with the request.
3945	Get the realms associated with a request token, returning an empty list if no realms are found or if the token is invalid.
3946	Get redirect URI for a request token, logging the operation and retrieving the redirect URI from either the request token or by fetching it using a grant getter.
3947	Retrieves a previously stored RSA key for a client. If the client is not set on the request, it fetches the client using the provided client_key. If the client has an rsa_key attribute, it returns that key; otherwise, it returns None.
3948	Validates the supplied client key by checking if a client exists for it. If no client is found on the request, attempts to retrieve one using the client getter. Returns True if a client is successfully obtained, False otherwise.
3949	Validates that a request token is available for a given client by checking if the token exists and belongs to the specified client key. Returns True if validation passes, False otherwise.
3950	Validates that an access token is available for a client. Logs the validation attempt and retrieves the token if not already present in the request. Returns True if token is found and assigned to the request, False otherwise.
3951	Validate that a timestamp and nonce combination is unique for a given client key. Checks if the nonce already exists for the timestamp and client key. If it exists, returns False to indicate duplicate usage. If not, stores the nonce and returns True to indicate successful validation.
3952	Validate if a redirect_uri is allowed for a given client by checking against the client's registered redirect URIs.
3953	Validate if the token has permission for the specified realms by checking if the token's realms supersede the required realms.
3954	Validates that a verifier exists and is associated with the given client key and token. Returns True if the verifier is valid and belongs to the specified client, False otherwise. The method also sets the request.user attribute to the user associated with the verifier.
3955	Verify if a request token exists by checking the request object or retrieving it via _grantgetter, and return True if found, False otherwise.
3956	Verify if the realms in the token match the requested realms. Returns True if realms match or if realms are not enabled, False otherwise.
3957	Save access token to database using a tokensetter function that creates and persists a Token object with client, user, token, secret, and realms information from the provided token and request parameters.
3958	Method `save_request_token` saves an OAuth request token to the database by using a grantsetter function that creates and persists a Grant object with the token details, request client, redirect URI, and requested realms. The method logs the token saving operation.
3959	Save verifier to database using a verifiersetter function that associates the verifier with a request token and attaches the current user.
3960	The `error_uri` method returns the URI of the error page that should be displayed when an error occurs. It first checks for a configured error URI in Flask config (`OAUTH2_PROVIDER_ERROR_URI`). If not found, it looks for an error endpoint (`OAUTH2_PROVIDER_ERROR_ENDPOINT`) and returns the URL for that endpoint. If neither is configured, it defaults to '/oauth/errors'.
3961	Method `confirm_authorization_request` handles consumer confirmation of authorization by:
1. Extracting scope and credentials from the request
2. Creating an authorization response using the server
3. Handling various OAuth2 errors including fatal client errors and standard OAuth2 errors
4. Preserving state parameter for authentication errors per RFC 6749
5. Returning appropriate responses or error pages

The method processes authorization requests, validates scopes and credentials, and manages error cases with proper state handling and redirection.
3962	Verify current request and retrieve OAuth data. If the request is valid, returns a tuple of (valid, request) where request contains the authenticated user. If invalid, returns (False, None). Can be used as an alternative to the require_oauth decorator when needed.
3963	Return client credentials based on the current request, checking first if client_id is already set on the request, then falling back to parsing the Authorization header for HTTP Basic authentication credentials.
3964	Determine if client authentication is required for the current request based on RFC6749 standards. Returns True if client authentication is required for password, authorization_code, or refresh_token grant types, and the client is confidential. Returns False otherwise.
3965	Authenticates a client using client credentials from the request. Extracts client ID and secret, validates against stored client information, and returns True if authentication succeeds or False otherwise. Supports empty client secrets as per OAuth2 specification.
3966	Authenticate a non-confidential client by validating the client ID and attaching the client object to the request.

**Parameters:**
- `client_id`: Client ID of the non-confidential client
- `request`: The Request object passed by oauthlib

**Returns:**
- `True` if authentication succeeds, `False` otherwise

**Behavior:**
1. If client_id is None, extracts credentials from request
2. Logs the authentication attempt
3. Retrieves client using either existing client on request or client getter
4. Returns False if client not found
5. Attaches authenticated client to request for convenience and returns True
3967	Get the list of scopes associated with the refresh token for use in refresh token grant flow.
3968	Confirms that the requested scopes for a refresh token match the originally granted scopes. If no scopes are requested, it accepts the default behavior. Returns True if scopes match, False otherwise. Note: This method is deprecated and will be replaced by `get_original_scopes` in future oauthlib versions.
3969	Returns the default redirect URI for a given client by retrieving the client object and accessing its default_redirect_uri attribute.
3970	Returns the default scopes for a given client by fetching the client object and retrieving its default_scopes attribute.
3971	Invalidates an authorization code by destroying its associated grant token. Retrieves the grant using the client ID and code, then deletes it if found.
3972	Save the authorization code by persisting it through the grant setter and return the client's default redirect URI.
3973	Save the Bearer token by calling the token setter and return the default redirect URI.
3974	Validate bearer token by checking if token exists, has not expired, and has required scopes. Returns False if validation fails, otherwise populates request object with token details and returns True.
3975	Validate that a client_id belongs to a valid and active client, attaching the client object to the request if valid. Returns True if validation passes, False otherwise.
3976	Validate authorization code by checking if it exists, is not expired, and populate request state, user, and scopes from the grant.
3977	Validate that a client is authorized to use the requested grant type, allowing default grant types ('authorization_code', 'password', 'client_credentials', 'refresh_token') unless the client has explicitly defined 'allowed_grant_types'. For 'client_credentials' grant type, ensure the client has a user property and set it in the request. Returns True if validation passes, False otherwise.
3978	Validate that a refresh token is valid and belongs to the specified client, setting request attributes if validation succeeds.
3979	Validate that a client is authorized to use the requested OAuth response type ('code' or 'token'). Returns True if the response type is allowed, False otherwise. If the client has an 'allowed_response_types' attribute, it checks if the requested response type is in that list. Otherwise, it allows both 'code' and 'token' response types by default.
3980	Validate that the client is authorized to access the requested scopes by checking against client's validation method or default scopes.
3981	Validates user credentials and attaches user object to request if valid. Returns True if authentication succeeds, False otherwise. If user getter is not configured, authentication is disabled and returns False.
3982	Revoke an access or refresh token based on the provided token and optional token type hint. If the token is valid, delete it and return True; otherwise, log an error and return False.
3983	Update required parameters for OAuth2.0 API calls with default values from session and QQ app configuration, allowing for additional data to be merged.
3984	Recursively converts all dictionary keys to strings while preserving the nested structure. Returns a new dictionary with string keys and the same values, handling nested dictionaries by applying the same conversion recursively. If the input is not a dictionary, returns it unchanged.
3985	Function to modify Weibo API authorization header by replacing 'Bearer' with 'OAuth2' to comply with non-standard server requirements.
3986	Creates a remote app and registers it using the provided OAuth configuration and parameters.
3987	Creates a remote app using the provided OAuth instance with processed keyword arguments, without registering it.
3988	Extract request parameters including URI, HTTP method, body, and headers from the Flask request object, while safely handling the Authorization header and removing sensitive WSGI headers.
3989	Converts text to bytes type if it isn't already, using specified encoding (default: utf-8). Returns input text unchanged if it's already bytes or empty.
3990	Decode a base64 string to regular text using the specified encoding (default is utf-8).
3991	Create a Flask response object with specified headers, body, and status code.
3992	Returns the cached clients dictionary from the current OAuth extension state, raising a RuntimeError if the OAuth extension is not initialized in the current app context.
3993	Adds a remote application instance, applying custom attributes and returning the application. If the name differs from the original or additional keyword arguments are provided, creates a copy of the application with the specified overrides.
3994	Creates and adds a new remote application with specified name and OAuth version, defaulting to version 2 if not specified. Accepts additional attributes for the remote application. Supports OAuth 1 and OAuth 2 protocols, raising an error for unknown versions. Returns the added remote application.
3995	Method Summary:
`check_exception` - Repeatedly calls a method that raises an exception, catching and ignoring the exception each time. The method creates X509 certificate objects and attempts to get their public key, which raises an Error exception that is caught and suppressed. This is likely a test method to verify exception handling behavior.

Parameters: None

Returns: None

Side effects: Creates multiple X509 objects and triggers exception handling behavior during execution.

Note: Uses `xrange` which suggests Python 2 syntax, and `Error` exception type is referenced but not imported or defined in the snippet.
3996	The `check_success` method repeatedly generates DSA key pairs and creates X509 certificates with those keys, then extracts the public keys from the certificates. It performs this operation for a specified number of iterations, with nested loops that run a small number of times each. The method appears to be testing or validating the functionality of PKey and X509 objects in a cryptographic context.
3997	Method that tests private key loading with encrypted PEM and passphrase callback by iterating through a specified number of times.
3998	Test loading an encrypted private key with an incorrect passphrase callback that returns "hello, public" instead of the correct passphrase.
3999	Test loading private key with encrypted PEM and passphrase callback that returns non-string value, expecting ValueError exception.
4000	Create a CRL object with 100 revoked objects and call get_revoked method repeatedly.
4001	Method that creates multiple copies of an empty X509 Revoked object and manually frees each copy to prevent memory leaks.
4002	Create a certificate request with the specified key and subject information, signed with the given digest method.
4003	Generate a certificate given a certificate request, issuer certificate and key, serial number, and validity period. The function sets the certificate's serial number, validity period, issuer and subject names, public key, and signs it with the issuer's private key using the specified digest method. Returns the signed certificate as an X509 object.
4004	Creates a decorator that raises NotImplementedError for OpenSSL functions not present in this build, instead of AttributeError from cryptography. Takes a flag and error message as parameters, and returns a decorator that checks the flag - if false, wraps the function to raise NotImplementedError with the provided error message, otherwise returns the original function unchanged.
4005	Loads trusted SSL certificates from a file or directory to verify certificate chains. Takes a certificate file path and optional certificate directory path, with both parameters being bytes or unicode strings. Either cafile or capath can be None, but not both. Loads the certificates into the SSL context for validating server certificates during SSL connections. Raises an exception if loading fails.
4006	Sets the passphrase callback function that will be invoked when loading a private key with a passphrase. The callback must accept three parameters (max length, verify flag, userdata) and return a byte string passphrase. Optional userdata can be provided to be passed to the callback. Raises TypeError if callback is not callable.
4007	Load a certificate chain from a file into the SSL context.

Parameters:
    certfile (bytes or unicode): The name of the certificate chain file in PEM format.

Returns:
    None

Raises:
    Various exceptions if the certificate file cannot be loaded or is invalid.
4008	Load a certificate from a file into the SSL context.

This method reads a certificate from the specified file and loads it into the SSL context for use in TLS connections. The certificate file can be in either PEM or ASN.1 format. If the file cannot be loaded, an exception will be raised describing the error.

Args:
    certfile (bytes or unicode): The path to the certificate file
    filetype (int, optional): The encoding format of the file, either FILETYPE_PEM or FILETYPE_ASN1. Defaults to FILETYPE_PEM.

Returns:
    None

Raises:
    TypeError: If filetype is not an integer
    OpenSSLError: If the certificate file cannot be loaded or is invalid
4009	Load a certificate from an X509 object into the SSL context. Raises TypeError if cert is not an X509 instance. Raises an error if the certificate loading fails.
4010	Add a certificate object to the SSL context's extra certificate chain. Raises TypeError if the input is not an X509 instance. Returns None. If the addition fails, the certificate is freed and an error is raised.
4011	Loads a private key from a file into the SSL context.

Parameters:
- keyfile: Path to the key file (bytes or unicode)
- filetype: Key file encoding (FILETYPE_PEM or FILETYPE_ASN1, defaults to FILETYPE_PEM)

Returns: None

Raises: TypeError if filetype is not an integer, or certificate-related exceptions if loading fails.
4012	Load a private key from a PKey object into the SSL context. Raises TypeError if pkey is not a PKey instance. Raises passphrase exception if loading fails.
4013	Load trusted certificates from a PEM format file and set them as the list of CA certificates to send to clients. The certificates are not automatically trusted and must be configured separately. Returns None.
4014	Sets the maximum depth for certificate chain verification on this Context object.
4015	Load ephemeral Diffie-Hellman parameters from a file and set them on the SSL context. Takes a file path as input and returns None. Uses OpenSSL's BIO and DH functions to read the parameters from a PEM file and configure the temporary DH settings for the context.
4016	Sets the list of ciphers to be used in this SSL context by calling the underlying OpenSSL library function. Validates that the input is a byte string and raises a TypeError if not. Includes special handling for OpenSSL 1.1.1 where invalid cipher strings would otherwise not raise an error - it checks if the resulting cipher list contains only TLS 1.3 ciphers and raises an Error exception in that case to maintain backward compatibility with applications that expect error handling for invalid cipher strings. The method returns None.
4017	Set the list of preferred client certificate signers for this server context by configuring the certificate authorities that will be sent to the client when requesting a client certificate. Takes a sequence of X509Name objects representing the certificate authorities. Returns None. Raises TypeError if any item in the sequence is not an X509Name object. The certificate authority list is stored in the SSL context.
4018	Adds a CA certificate to the list of preferred signers for this context, which will be sent to the client when the server requests a client certificate. Validates that the certificate authority is an X509 instance and uses OpenSSL's SSL_CTX_add_client_CA function to perform the addition.
4019	Sets a callback function to be called when clients specify a server name. The callback receives the Connection instance as an argument. Uses a wrapper function to adapt the callback signature for OpenSSL's TLS extension server name callback mechanism. The callback is registered with the SSL context using SSL_CTX_set_tlsext_servername_callback.
4020	Enable support for negotiating SRTP keying material by setting the TLS extension use SRTP option on the SSL context with the specified protection profiles.
4021	Sets up a callback function to handle Next Protocol Negotiation (NPN) options offered by a server. The callback is invoked with the connection and a list of offered protocols, and should return the chosen protocol. This functionality is deprecated and warns users accordingly.
4022	Set the list of protocols to offer during Application Layer Protocol Negotiation in TLS connections. The method takes a list of bytestrings representing the protocols to offer to the server, formats them according to ALPN requirements, and configures the SSL context with these protocols.
4023	Sets an ALPN protocol selection callback function that will be invoked on the server when a client offers protocols using ALPN. The callback receives the connection and a list of offered protocols, and should return the chosen protocol.
4024	Sets up OCSP callback functionality for TLS/SSL context by configuring both server and client OCSP callbacks with the provided helper and data, using OpenSSL's TLS extension status callback mechanisms.
4025	Sets a callback function to provide OCSP data for stapling to TLS handshakes on the server side. The callback receives the connection and optional data, and must return OCSP data as bytes or empty bytes if none is available. An optional data parameter can be provided to avoid complex lookups during callback execution.
4026	Sets a callback function to validate OCSP data stapled to TLS handshake on the client side. The callback receives the connection, OCSP assertion data, and optional context data, and must return True if the OCSP data is valid or False if invalid or certificate is revoked. Optional arbitrary data can be passed to the callback for context.
4027	Sets the session context for this connection to a new SSL context.

Args:
    context: A Context instance representing the new session context to use.

Raises:
    TypeError: If context is not a Context instance.

The method updates the internal SSL context using the OpenSSL library and stores the new context reference.
4028	Retrieve the server name extension value from the client hello message, returning None if not present. Returns a byte string containing the server name or None.
4029	Sets the server name indication (SNI) extension value to send in the TLS client hello message. Takes a byte string parameter representing the server name, validates it doesn't contain null bytes, and calls the underlying OpenSSL library function to set the extension. Raises TypeError for invalid input types or null bytes.
4030	Receive data on the connection by reading up to `bufsiz` bytes, with optional MSG_PEEK flag support. Returns the received data as a string.
4031	Receive data on the connection and copy it directly into the provided buffer, rather than creating a new string. Returns the number of bytes read into the buffer.
4032	Reads bytes from the SSL connection's memory BIO buffer.

This method retrieves data from the write end of a memory BIO associated with the connection. It's used to drain buffers that may have filled up due to various SSL operations. The method handles the underlying BIO reading and error processing, returning the actual bytes read or raising exceptions for BIO errors.

Parameters:
    bufsiz (int): Maximum number of bytes to read

Returns:
    bytes: The data read from the BIO buffer

Raises:
    TypeError: If the connection wasn't created with a memory BIO or bufsiz isn't an integer
    OpenSSL.SSL.Error: If BIO reading fails
    OpenSSL.SSL.WantReadError: If SSL socket would block on read
    OpenSSL.SSL.WantWriteError: If SSL socket would block on write
4033	Renegotiate the session by calling the OpenSSL library's SSL_renegotiate function. Returns True if renegotiation can be started, False if already pending.
4034	Send the shutdown message to the Connection.

:return: True if the shutdown completed successfully (i.e. both sides have sent closure alerts), False otherwise (in which case you call :meth:`recv` or :meth:`send` when the connection becomes readable/writeable).
4035	Retrieve the list of ciphers used by the Connection object.

:return: A list of native cipher strings.
4036	Get CAs whose certificates are suggested for client authentication. Returns a list of certificate authorities for server connections, empty for client connections until server connection is established.
4037	Sets the shutdown state of the Connection by calling the underlying SSL_set_shutdown function with the provided state parameter.
4038	Retrieve the random value used with the server hello message.

:return: A string representing the state
4039	Retrieve the random value used with the client hello message.

:return: A string representing the state
4040	Retrieve the master key for this SSL session as a byte string, or None if no session exists.
4041	Export keying material for application use based on RFC 5705. Takes a label, output length, and optional context, returns the exported key material bytes. Uses OpenSSL's SSL_export_keying_material function internally.
4042	Returns the OpenSSL session currently used by this context, or None if no session exists.
4043	Get the name of the currently used cipher, returning None if no connection has been established.
4044	Get the number of secret bits of the currently used cipher. Returns the number of secret bits or None if no connection has been established.
4045	Get the protocol version of the currently used cipher, returning None if no connection exists.
4046	Retrieve the protocol version of the current connection, returning the TLS version (e.g., "TLSv1.2") or "Unknown" for unsuccessful connections.
4047	Get the protocol that was negotiated by NPN. Returns a bytestring of the protocol name, or empty string if no protocol has been negotiated yet.
4048	Sets the client's ALPN protocol list for TLS protocol negotiation by specifying which protocols to offer to the server.
4049	Get the protocol that was negotiated by ALPN. Returns a bytestring of the protocol name, or empty string if no protocol has been negotiated yet.
4050	Allocates a new OpenSSL memory BIO with optional initial buffer data, ensuring automatic cleanup via garbage collector. If no buffer is provided, creates an empty memory BIO. If buffer is provided, creates a memory BIO populated with the buffer data while maintaining reference to prevent premature garbage collection. Returns the managed BIO object.
4051	Converts the contents of an OpenSSL BIO object into a Python byte string by retrieving the memory data from the BIO buffer.
4052	Sets the time value of an ASN1 time object to a string representation.

Args:
    boundary: An ASN1_TIME pointer which will have its value set
    when: A bytes string representation of the desired time value

Raises:
    TypeError: If when is not a bytes string
    ValueError: If when does not represent a time in the required format
    RuntimeError: If the time value cannot be set for some other reason
4053	Get the time value from an ASN1 time object, converting ASN1_TIME to ASN1_GENERALIZEDTIME if necessary. Returns the time as bytes string or None if empty.
4054	Return a single elliptic curve object selected by name. Raises ValueError if the curve is not supported.
4055	Dumps a public key to a buffer in either PEM or ASN.1 format. Takes a key type parameter (FILETYPE_PEM or FILETYPE_ASN1) and a PKey object, returns the key data as bytes. Raises ValueError for invalid type arguments and OpenSSL errors if dumping fails.
4056	Load a public key from a buffer of specified type (PEM or ASN.1) and return it as a PKey object.
4057	Signs a data string using the given key and message digest, returning the signature. Takes a PKey, data to sign, and digest method as parameters. Uses OpenSSL's EVP signature functions internally.
4058	Verify a signature for a data string using the provided certificate and digest method. Raises an exception if the signature is incorrect.
4059	Dump a certificate revocation list to a buffer in the specified format (PEM, ASN.1, or TEXT).
4060	Converts the key to a cryptography library key format, returning either a public or private key object depending on whether the key is public-only.
4061	Generate a key pair of the specified type and number of bits, storing it in the current object. Supports RSA and DSA key types. Raises TypeError for incorrect parameter types and ValueError for invalid bit sizes. Returns None.
4062	Check the consistency of an RSA private key, equivalent to OpenSSL's RSA_check_key. Returns True if consistent, raises Error if inconsistent, or TypeError if key is public only or not RSA type.
4063	Load the set of elliptic curves supported by the OpenSSL library and return them as a set of cls instances.
4064	Get, cache, and return the elliptic curves supported by OpenSSL as a set of class instances.
4065	Creates a new OpenSSL EC_KEY structure initialized with this curve, automatically garbage collected when the Python object is destroyed.
4066	Return the DER encoding of this name as bytes.
4067	Returns the components of this name as a sequence of 2-tuples containing name-value pairs.
4068	Returns the short type name of this X.509 extension as a byte string.
4069	Returns the ASN.1 encoded data of the X509 extension as bytes.
4070	Converts the certificate signing request to a cryptography library format.

This method exports the current certificate signing request object into a format compatible with the `cryptography` library's `CertificateSigningRequest` class. It uses the OpenSSL backend from the cryptography package to create and return a properly formatted certificate signing request object.

**Returns:** A `cryptography.x509.CertificateSigningRequest` object

**Version:** Added in version 17.1.0
4071	Set the public key of the certificate signing request object using the provided PKey instance.
4072	Get the public key of the certificate signing request.

:return: The public key.
:rtype: :py:class:`PKey`
4073	Return the subject of this certificate signing request as an X509Name object. Creates a new X509Name that wraps the underlying subject name field, sharing the same underlying data. Modifying the returned name will affect the original certificate signing request. The returned object is owned by the signing request and will keep it alive as long as it exists.
4074	Add X.509 extensions to the certificate signing request. Takes an iterable of X509Extension objects, validates each extension, and adds them to the request. Raises ValueError if any element is not an X509Extension. Returns None.
4075	Get X.509 extensions in the certificate signing request.

:return: The X.509 extensions in this request.
:rtype: :py:class:`list` of :py:class:`X509Extension` objects.

.. versionadded:: 0.15
4076	Verifies the signature on a certificate signing request using the provided public key. Returns True if the signature is correct, raises OpenSSL.crypto.Error if the signature is invalid or there's a verification problem.
4077	Converts the certificate to a cryptography library certificate object.

This method exports the current certificate instance as a ``cryptography.x509.Certificate`` object using the cryptography library's OpenSSL backend. It imports the necessary `_Certificate` class from `cryptography.hazmat.backends.openssl.x509`, retrieves the OpenSSL backend, and constructs a new certificate object using the underlying `_x509` attribute.

**Returns:**
    ``cryptography.x509.Certificate`` - A cryptography library certificate object

**Version:** 17.1.0 (added)
4078	Sets the version number of the certificate. The version value is zero-based (0 = V1). Raises TypeError if version is not an integer. Calls the underlying OpenSSL library function to set the version.
4079	Get the public key of the certificate.

:return: The public key.
:rtype: :py:class:`PKey`
4080	Sets the public key of the certificate to the provided PKey instance, performing type checking and OpenSSL library call.
4081	Signs a certificate using the provided private key and digest algorithm. Raises TypeError if the key is not a PKey instance, ValueError if the key is public-only or uninitialized, or if the digest method is not available. Returns None upon successful signing.
4082	Return the signature algorithm used in the certificate as a bytes string. Raises ValueError if the signature algorithm is undefined.
4083	Return the digest of the X509 object using the specified digest algorithm, formatted as colon-delimited hex pairs.
4084	Sets the serial number of the certificate to the provided integer value, handling conversion to hexadecimal format and proper OpenSSL library calls for ASN.1 integer representation.
4085	Return the serial number of this certificate as an integer.
4086	Adjusts the certificate's expiration timestamp by the specified number of seconds.
4087	Adjusts the certificate's validity start timestamp by the specified number of seconds. Raises TypeError if amount is not an integer. Modifies the certificate in place and returns None.
4088	Check whether the certificate has expired by comparing the expiration date with current UTC time.

Returns True if the certificate has expired, False otherwise.
4089	Return the issuer of this certificate as an X509Name object. Creates a new X509Name that wraps the underlying issuer name field, so modifications to it will affect the underlying certificate and any other X509Name referring to this issuer. The returned name is tracked for invalidation purposes.
4090	Sets the issuer of this certificate by calling the underlying OpenSSL library function X509_set_issuer_name with the provided issuer parameter, and clears the issuer cache.
4091	Return the subject of this certificate as an X509Name object. Creates a new X509Name that wraps the underlying subject name field, so modifications to it will affect the underlying certificate and any other X509Name references to this subject. The returned name is tracked for invalidation purposes.
4092	Sets the subject of this certificate to the specified X509Name object, then clears the subject invalidator.
4093	Add extensions to the certificate by iterating through the provided extensions and validating each one is an X509Extension object. For each valid extension, add it to the certificate using the OpenSSL library, raising an error if any extension fails to be added.
4094	Get a specific extension of the certificate by index.

Extensions on a certificate are kept in order. The index parameter selects which extension will be returned.

:param int index: The index of the extension to retrieve.
:return: The extension at the specified index.
:rtype: X509Extension
:raises IndexError: If the extension index was out of bounds.

.. versionadded:: 0.12
4095	Adds a trusted certificate to the store. Raises TypeError if certificate is not an X509 object. Handles duplicate certificates gracefully by silencing errors for OpenSSL versions >= 1.1.0i, and asserting certificate already exists for older versions. Returns None on successful addition.
4096	Add a certificate revocation list to this store. The CRL will only be used if associated flags are configured to check certificate revocation lists. Returns None if successful.
4097	Set the time against which certificates are verified by configuring the verification parameter with the provided time value.
4098	Initialize the X509 store context for certificate verification operations. This method sets up the necessary structures for validating X509 certificates using the OpenSSL library. It initializes the store context with the provided store, certificate, and null parent certificate. The method raises an exception if the initialization fails. Note that calling this method multiple times without cleanup can lead to memory leaks.
4099	Convert an OpenSSL native context error failure into a Python exception, including error details and associated certificate information.
4100	Verify a certificate in the current context, raising an X509StoreContextError if validation fails. Reinitializes the store context before verification and ensures proper cleanup afterward.
4101	Sets the serial number by converting a hexadecimal string to an ASN.1 integer and assigning it to the revoked certificate object. Raises ValueError if the hex string is invalid.
4102	Get the serial number from an X509 revoked certificate as a hexadecimal string encoded in ASCII bytes.
4103	Sets the reason for certificate revocation. If reason is None, deletes the existing reason. Otherwise, validates that reason is a byte string, converts it to lowercase with spaces removed, looks up the corresponding reason code, creates a new ASN.1 enumerated reason extension, and adds it to the revoked certificate. Raises TypeError if reason is not None or a byte string. Returns None.
4104	Get the reason for this certificate revocation, or None if no reason is specified. Returns the reason as bytes or None.
4105	Set the revocation timestamp by updating the ASN.1 TIME value of the revocation date.
4106	Converts the CRL object to a cryptography library CertificateRevocationList instance for use with the cryptography package.
4107	Return the revocations in this certificate revocation list as a tuple of Revoked objects. The returned revocations are copies, so mutating them won't affect the original CRL.
4108	Get the CRL's issuer as an X509Name object.
4109	Signs the CRL using the provided issuer certificate and private key with the specified digest method, setting the issuer name and sorting the CRL before signing.
4110	Export the CRL as a string in the specified format, signed with the given certificate and key.
4111	Returns the type name of the PKCS7 structure as a string.
4112	Sets or replaces the CA certificates within the PKCS12 object with the provided iterable of X509 certificates, or unsets them if None is provided. Raises TypeError if the iterable contains non-X509 instances.
4113	Export a PKCS12 object as a string with optional passphrase, iteration counts for encryption and MAC steps.
4114	Signs a certificate request using the provided private key and digest type. Raises ValueError if the key is missing private part, uninitialized, or if the digest method is unsupported. Returns None upon successful signing.
4115	Verifies a signature on a certificate request using the provided public key. Returns True if the signature is correct, raises OpenSSL.crypto.Error if the signature is invalid or there's a verification problem.
4116	Generate a base64 encoded representation of this SPKI object.

:return: The base64 encoded string.
:rtype: :py:class:`bytes`
4117	Get the public key of this certificate.

:return: The public key.
:rtype: :py:class:`PKey`
4118	Sets the public key of the certificate. Takes a public key parameter and returns None.
4119	Converts OpenSSL library failures into Python exceptions by retrieving error information from the OpenSSL error queue and raising the specified exception type with error details.
4120	Converts text to bytes and warns when text is encountered, useful for handling mixed text/bytes parameters.
4121	Returns a color printing function based on terminal availability. If stdout is a terminal, returns a function that prints messages with specified color formatting using `print_tokens`. If stdout is not a terminal (e.g., when piping or redirecting output), returns a fallback function that simply prints the message without color formatting. The color is determined by the `col` parameter passed to the factory function.
4122	Return extra configuration options for TrelloIssue class including label import settings and template configuration.
4123	Returns a generator that yields issue dictionaries by iterating through boards, lists, and cards from a remote service, attaching board and list names as extra metadata and including annotations for each issue.
4124	Returns taskwarrior annotations by wrapping get_comments and building annotations from card comments.
4125	Returns an iterator of board objects to pull cards from. If 'include_boards' is specified in config, uses those board IDs; otherwise fetches all member boards from Trello API.
4126	Returns a list of filtered Trello lists for a given board, applying include and exclude list configurations to filter the results.
4127	Returns an iterator for the cards in a given list, filtered according to configuration values of trello.only_if_assigned and trello.also_unassigned.
4128	Returns an iterator for the comments on a certain card by making an API request to the card's actions endpoint with filtering for commentCard type and memberCreator username fields.
4129	Builds the full URL to the API endpoint by combining the base API URL with the given path and context parameters.
4130	Pagination utility method that fetches JSON data from a URL with optional authentication, handles pagination through Link headers, and supports nested key extraction. It automatically follows pagination links until all results are retrieved, with special handling for GitHub 404 errors when using token authentication. Returns a flattened list of results from all pages.
4131	Utility function that parses GitHub's Link header field into a dictionary mapping link relations to URLs. Takes a link field string and returns a dict where keys are link relation types and values are the corresponding URLs. Returns empty dict if input is empty.
4132	Retrieve all GitHub issues matching a given query, extract repository information from each issue, and return a dictionary mapping issue URLs to tuples of (repository, issue data). If repository extraction fails, log a critical error and skip that issue.
4133	Grab all the pull requests for a given tag by fetching from the client and returning a list of tuples containing the tag and each pull request.
4134	Aggregate all issues from every target using multiprocessing workers, with optional debug mode that runs sequentially. Creates a queue to collect issues from parallel processes, handles errors by terminating all workers, and yields issues as they become available while managing process lifecycle.
4135	Return a main config value converted to specified type, or default if key doesn't exist.
4136	Get any defined templates for configuration values, where each template is associated with a Taskwarrior field and can be used to override the field's value using Jinja template syntax.
4137	Validates generic options for a particular target and ensures that certain options (only_if_assigned, also_unassigned, default_priority, add_tags) are prefixed with the class's CONFIG_PREFIX instead of being defined directly on the target.
4138	Return True if the issue should be included based on configuration rules:
- If 'only_if_assigned' is set, include only if issue owner matches the assigned owner or if 'also_unassigned' is True and owner is None
- If 'only_if_author' is set, include only if issue author matches the specified author
- Otherwise, include all issues (return True)
4139	Creates an RST-compatible table from a 2D grid of cells, formatting each cell to have consistent width and adding proper dividers between rows.
4140	Execute a shell command to retrieve a password, returning the first line of stdout if successful, or raising an error with stderr content if the command fails.
4141	Method: `getint(self, section, option)`

Summary: This method retrieves an integer value from the configuration parser, with support for empty values. It first attempts to parse the specified option as an integer. If that fails with a ValueError, it checks if the value is an empty string. If so, it returns None; otherwise, it raises a ValueError indicating that the value must be an integer or empty.

Parameters:
- `section`: The configuration section name
- `option`: The configuration option name

Returns: 
- Integer value if parsing succeeds
- None if the value is an empty string
- Raises ValueError for invalid integer values

Behavior: Accepts both valid integers and empty values, treating empty strings as None, while rejecting invalid integer formats.
4142	Pull down tasks from forges and add them to taskwarrior tasks, using configuration from bugwarriorrc. Uses a lockfile to prevent concurrent execution. Handles errors gracefully with timeout and runtime exception handling.
4143	Method: get_data(self, url)
Description: Performs an HTTP GET request to the specified URL and returns the response as JSON data.
Parameters: 
- url (str): The fully qualified URL to send the GET request to
Returns: JSON response data from the requested URL
Side effects: Makes an HTTP request using the requests library with additional kwargs configured in self.requests_kwargs
4144	Pages through an object collection from the bitbucket API and returns an iterator that lazily goes through all 'values' of all pages in the collection.
4145	Function `find_local_uuid` finds the local UUID of a given issue by matching it against TaskWarrior tasks using specified keys or legacy description matching. It accepts a TaskWarrior instance, a list of key combinations for identification, the issue object, and an optional legacy matching flag. The function returns a single UUID if exactly one match is found, raises `MultipleMatches` if more than one match is found, or raises `NotFound` if no match is found. It also raises a `ValueError` if the issue has no description.
4146	Merge array field from remote_issue into local_task by preserving local entries and appending unique remote entries. When hamming=True, compares entries using Hamming distance (useful for annotations). Returns count of new values added to the field.
4147	Returns a list of UDAs defined by given targets by building configuration overrides for the UDAs specified in the passed-in services.
4148	Parse a JIRA sprint string into a dictionary of its fields and values.
4149	Gets valid user credentials from storage, performing OAuth2 flow if necessary. Returns obtained credentials.
4150	Computes ROUGE-N scores efficiently for multiple sequence pairs by pre-computing n-grams. Takes a list of sequences and pairs of sequence IDs, returns rouge n scores (f, r, p) for each pair. Raises KeyError if sequence IDs are out of bounds.
4151	Calculates p-values for gene set enrichment analysis using hypergeometric testing. Takes a query gene set, gene sets dictionary, and background database size to compute enrichment p-values for each gene set category. Returns tuples of category names, p-values, overlap counts, gene set sizes, and overlapping gene names. Uses scipy's hypergeometric distribution to compute right-tailed probabilities for overrepresentation analysis.
4152	Performs Benjamini-Hochberg false discovery rate (FDR) correction on p-values. Returns corrected p-values and rejection decisions for multiple hypothesis testing.
4153	Standardizes the mean and variance of a DataFrame along a specified axis. Returns a normalized DataFrame with mean of 0 and variance of 1 across the specified axis (0 for columns, 1 for rows). If axis is None, returns the original DataFrame unchanged.
4154	Create a heatmap visualization of a DataFrame with optional z-score normalization and customizable styling.

**Parameters:**
- `df`: DataFrame from expression table
- `z_score`: Z-score axis (0 or 1) for data normalization, None to skip normalization
- `title`: Gene set name for heatmap title
- `figsize`: Heatmap figure size
- `cmap`: Matplotlib colormap
- `xticklabels`: Whether to show x-axis tick labels
- `yticklabels`: Whether to show y-axis tick labels
- `ofname`: Output filename to save the figure

**Returns:**
- Figure object

**Functionality:**
- Applies z-score normalization if specified
- Reverses row order of the DataFrame
- Creates heatmap with colorbar
- Sets appropriate tick positions and labels
- Configures figure styling and removes spines
- Saves figure to file if output name is provided
- Handles command-line vs interactive environments appropriately
4155	Function to remove spines and ticks from matplotlib axes.

Parameters:
- ax: axes object to modify
- spines: list of spine names to keep ('left', 'right', 'top', 'bottom'). If empty list is provided, all spines and ticks are removed.

The function removes unwanted spines by setting their color to 'none' and controls tick visibility based on which spines are kept.
4156	Function `prepare_argparser` creates and configures an argument parser for a gene set enrichment analysis tool. It sets up a top-level parser with version information and sub-commands for various analyses including GSEA, prerank, single-sample GSEA, plotting, Enrichr, and BioMart. The function returns the configured argument parser object.
4157	Adds argument parser for the 'prerank' function to run GSEApy Prerank tool on preranked gene lists, including input file arguments (ranking metric file, gene set database, phenotype labels), output arguments, and advanced GSEA options (permutations, gene set size limits, weighting, sorting order, random seed, and threads).
4158	Adds a 'replot' command to reproduce GSEA desktop output figures with input directory, output options, and weight parameters.
4159	Adds the 'enrichr' command-line subparser for performing GO analysis using the Enrichr API, including arguments for input gene lists, gene sets, organism, description, cutoff values, background, and output plotting options.
4160	Computes the enrichment score (ES) and related statistics for gene set enrichment analysis using the GSEA algorithm. Calculates ES, null ES values from permutations, hit indices, and running enrichment scores. Supports different weighting schemes and permutation-based statistical testing.

**Parameters:**
- gene_list: Ordered list of gene names
- gene_set: Set of genes to test for enrichment  
- weighted_score_type: Weighting scheme (0=classic, 1=standard, 1.5, 2)
- correl_vector: Correlation scores for genes
- nperm: Number of permutations for null distribution
- rs: Random state for shuffling
- single: Whether to return single score or maximum
- scale: Whether to scale the running enrichment score

**Returns:**
- ES: Enrichment score (-1 to +1)
- ESNULL: Null enrichment scores from permutations
- Hits_Indices: Indices of genes in gene_set within gene_list
- RES: Running enrichment score vector
4161	Builds a shuffled ranking matrix by permuting class labels and computing ranking metrics. Returns sorted indices and values of the ranking matrix for specified method (e.g., signal-to-noise, t-test) with optional ascending/descending order.
4162	A function that ranks genes based on expression differences between two phenotypes using various statistical methods. It calculates rankings using methods like signal-to-noise ratio, t-test, fold change ratios, or log2 ratios, and returns a sorted pandas Series with gene names as index and their corresponding rankings as values.
4163	Compute nominal p-values for Gene Set Enrichment Analysis using the empirical distribution.

The function calculates p-values by comparing the observed enrichment scores (es) against a null distribution (esnull). For each enrichment score, it uses the appropriate tail of the null distribution based on whether the observed score is positive or negative. Positive scores use the upper tail (comparing against values >= es), while negative scores use the lower tail (comparing against values < es). The calculation is vectorized using numpy for efficiency, returning an array of p-values corresponding to each input enrichment score.
4164	Computes nominal p-values, normalized enrichment scores (NES), and False Discovery Rate (FDR) q-values for gene set enrichment analysis. Calculates NES using null distribution normalization and determines FDR by comparing the proportion of null distributions exceeding the NES threshold to the proportion of observed scores exceeding the same threshold, handling both positive and negative NES values separately. Returns zip of original scores, normalized scores, p-values, and FDR values.
4165	Get available marts and their names by concatenating mart names and descriptions into a DataFrame with "Name" and "Description" columns.
4166	Get available datasets from the specified mart and return them as a DataFrame with "Name" and "Description" columns.
4167	Get available attributes from the selected dataset and return them as a DataFrame with columns "Attribute" and "Description".
4168	Get available filters from the selected dataset and return them as a DataFrame with columns "Filter" and "Description".
4169	Method: query

Description: Performs ID mapping using BioMart by querying a specified dataset with given attributes and filters, returning the results as a DataFrame.

Parameters:
- dataset (str, optional): The BioMart dataset to query (default: 'hsapiens_gene_ensembl')
- attributes (list, tuple, optional): List of attributes to retrieve (default: ['ensembl_gene_id', 'external_gene_name', 'entrezgene', 'go_id'])
- filters (dict, optional): Dictionary of filters to apply to the query
- filename (str, optional): Path to save the results file (default: generates path in DEFAULT_CACHE_PATH)

Returns: pandas.DataFrame containing the query results with columns matching the specified attributes

Note: The method may take several minutes to complete and uses the BioMart XML service for querying. Results are cached to the specified filename or default cache path.
4170	Run Gene Set Enrichment Analysis on gene expression data with customizable parameters for gene sets, permutations, scoring methods, and output options, returning a GSEA object containing enrichment results.
4171	Run Gene Set Enrichment Analysis with single sample GSEA tool, accepting various data formats and gene set inputs, with options for normalization, permutation testing, plotting, and result visualization. Returns a SingleSampleGSEA object containing enrichment scores and related statistics.
4172	Run Gene Set Enrichment Analysis with pre-ranked correlation defined by user. Return a Prerank object containing enrichment results including enrichment scores, normalized enrichment scores, p-values, FDR, gene set sizes, matched genes, and leading edge genes.
4173	Function `replot` is the main function to reproduce GSEA desktop outputs. It takes an input directory containing GSEA results, processes the data, and generates new figures in the specified format. The function accepts parameters for output directory, weighted score type, figure size, file format, and gene set size constraints. It returns generated figures in the specified format (default is PDF). The function uses a Replot class to perform the actual plotting operations and returns the results.
4174	Sets the number of CPU cores to be used, ensuring it's between 1 and the available CPU count minus 1. If the specified number of processes exceeds available CPUs, it caps the cores to CPU count minus 1. If processes is less than 1, it sets cores to 1. The result is converted to an integer and stored in self._processes.
4175	Load gene set dictionary from GMT file or dictionary, filter gene sets by size criteria, and store the filtered results.
4176	Return active Enrichr library names from the official API by fetching dataset statistics and extracting library names.
4177	Downloads Enrichr gene set libraries, converts them to GMT format, and saves them to disk. Returns a dictionary of gene sets.
4178	Creates a heatmap matrix for GSEA analysis by filtering data based on two phenotype classes and storing the result.
4179	Save GSEA results to CSV or TXT files, including statistics like ES, NES, p-value, FDR, gene set size, matched size, genes, and leading edge genes. The results are also stored in OrderedDict and DataFrame formats for further analysis.
4180	Load and preprocess gene expression data from DataFrame or file, handling duplicates, missing values, and filtering based on class vectors.
4181	**Summary:**

The `run` method executes the main procedure of the Gene Set Enrichment Analysis (GSEA). It begins by validating input parameters and parsing phenotype labels and gene expression data. The expression data is then ranked using a specified ranking metric. Gene sets are filtered based on the available genes and loaded from a GMT file. The core GSEA computation is performed in parallel, calculating enrichment scores (ES), normalized enrichment scores (NES), p-values, and False Discovery Rate (FDR). Results are saved into reports and figures, and a heatmap is generated. Optionally, plots are created, and temporary directories are cleaned up if necessary. The method returns control after completing all steps.
4182	GSEA prerank workflow execution that loads rankings, filters gene sets, computes GSEA statistics (ES, NES, pval, FDR, RES), generates reports and figures, and creates plots unless plotting is disabled.
4183	Runs single sample GSEA workflow with permutation procedure for each sample in the input dataframe, computing enrichment scores and saving results.
4184	Runs single sample GSEA workflow with multiprocessing support, calculating enrichment scores for each sample and generating plots for each gene set.
4185	Save enrichment scores (ES) and normalized enrichment scores (NES) to CSV files. The method normalizes ES values by the entire dataset range as per Barbie et al., 2009, and writes both raw and normalized scores to separate files in the specified output directory.
4186	Main replot function that parses GSEA output files (results.edb, .rnk, gene_sets.gmt, .cls), extracts enrichment terms and gene sets, calculates enrichment scores, and generates plots for each enrichment term using gseaplot. It handles both regular and prerank GSEA results, and saves plots to the specified output directory.
4187	Enrichr API function for gene set enrichment analysis. Takes a gene list and Enrichr libraries as input, performs enrichment analysis on the specified organism, and returns an Enrichr object containing results. Supports various output formats and plotting options, with parameters for adjusting significance cutoff, background gene retrieval, figure size, and verbosity. The function can handle gene lists from files or python lists, and supports multiple organisms including human, mouse, yeast, fly, fish, and worm.
4188	Parse gene_sets input file type, handling multiple input formats (list, string, dict) and converting .gmt files to dictionaries while validating against enrichr libraries.
4189	Parse gene list from various input types (list, DataFrame, Series, or file) and convert to standardized format. Handles BED files, weighted gene lists, and plain gene lists. Returns genes as newline-separated string and sets internal gene list with proper type conversion based on Entrez ID detection.
4190	Sends a gene list to the enrichr server for analysis and returns the job ID. Raises an exception if the analysis fails.
4191	Compare the input gene list with the genes successfully recognized by Enrichr to determine successful recognition count.
4192	Method: `get_background`

Summary: Retrieves background genes for gene set enrichment analysis. The method supports multiple input sources: 
1. From a local file if the background parameter is a valid file path
2. From package included data files in the gseapy package
3. From Biomart database queries for species-specific background genes

The method returns a set of background genes, which can be either Entrez IDs or gene names depending on the input configuration. It handles caching of downloaded data and logs appropriate messages during the process.
4193	Runs Enrichr enrichment analysis for a single sample gene list across multiple gene set libraries, handling both local custom gene sets and online Enrichr libraries, with optional output saving and plotting.
4194	Create a cube primitive with specified size, centering, and color properties using meshlab filters.
4195	Creates an icosphere mesh with specified radius, subdivisions, and optional color. Supports diameter input, applies vertex colors if specified, and returns None.
4196	Create a torus mesh with specified major and minor radii, segments, and optional color. The torus is generated using a filter script with parameters for horizontal and vertical radii, subdivisions, and can override radius settings based on inner and outer diameters. Optional vertex coloring can be applied to the mesh.
4197	Creates a high-resolution plane with specified vertex segmentation for edges only, useful for creating simplified cube bottoms. Supports different muparser versions with conditional logic for vertex deformation functions. Optionally centers the plane and applies vertex coloring.
4198	Creates a high-resolution box with specified segments and optional coloring. The function generates a box with customizable dimensions, segment counts per axis, and bottom type (simple or full). It uses grid and plane operations to build the geometry, rotates and translates components into position, joins all parts together, and applies optional centering and coloring. Returns None.
4199	Function `color_values(color)` reads from `color_names.txt` to find the red, green, and blue values for a given color name. It returns these RGB values as a tuple. If the color name is not found, it prints an error message and returns default white color values (255, 255, 255).
4200	Check if a variable is a list and is the correct length. If variable is not a list, it will make it a list of the correct length with all terms identical. If the length is incorrect, it prints an error message and exits.
4201	Make a variable a list if it is not already, and ensure it has the specified number of terms by repeating the first element if necessary.
4202	Write filter to FilterScript object or filename

Args:
    script (FilterScript object or filename str): the FilterScript object or script filename to write the filter to.
    filter_xml (str): the xml filter string

Returns:
    None
4203	Apply LS3 Subdivision Surface algorithm using Loop's weights with specified parameters including iterations, loop weight scheme, edge threshold, and selection option.
4204	Merge together all vertices that are closer than the specified threshold distance, similar to uniting duplicate vertices with tolerance support.
4205	Close holes in a mesh that are smaller than a specified edge threshold.

Args:
    script: The FilterScript object or script filename to write the filter to.
    hole_max_edge (int): Maximum number of edges composing the hole boundary (default: 30).
    selected (bool): Only close holes with at least one boundary face selected (default: False).
    sel_new_face (bool): Select newly created faces after closing holes (default: True).
    self_intersection (bool): Prevent creation of self-intersecting faces during hole closing (default: True).

Layer stack: No impacts
MeshLab versions: 2016.12, 1.3.4BETA
4206	Split non-manifold vertices until it becomes two-manifold by moving vertices along the average vector from their position to the centroid of connected faces, with adjustable displacement ratio.
4207	Snap together adjacent mismatched borders by snapping border vertices to closest boundary edges based on a distance ratio threshold, with optional vertex welding.
4208	Translates a script geometry by adding offset values to x, y, and z coordinates using a custom geometric function implementation.
4209	A geometric rotation function that applies rotation transformations to a script along specified axes (x, y, or z) using trigonometric calculations. It converts the angle to radians and utilizes a vertex function to perform the rotation by applying the appropriate rotation matrix formulas for the selected axis. The function supports accurate geometric rotation compared to built-in alternatives and exits with an error for invalid axis names.
4210	Scales a script geometrically along the x, y, and z axes using the specified value(s). If a single value is provided, it applies uniformly to all three axes. The scaling is performed using geometric functions for improved accuracy compared to built-in methods. Returns None.
4211	Creates a geometric function using cylindrical coordinates (r, theta, z) that converts cylindrical coordinates to Cartesian coordinates (x, y, z) for mesh processing in MeshLab. Uses radius 'r', angle 'theta' (with 0 degrees at +X axis), and height 'z' functions to define new coordinates. Handles different MeshLab versions by using either builtin atan2 or custom mp_atan2 function. The function substitutes 'r' and 'theta' variables in input functions and returns None.
4212	Wrap a mesh around a cylinder with specified radius, pitch, and taper parameters. The function deforms the mesh geometry using mathematical transformations to create a cylindrical surface with optional helical twist and radial tapering. The deformation is applied by modifying vertex coordinates according to cylindrical coordinate transformations, where the y=0 plane aligns with the cylinder's surface. The pitch parameter creates a helical structure with specified axial pitch, while the taper parameter modifies the radius along the z-axis. Custom pitch and taper functions can be provided for more complex deformations.
4213	Function `bend` transforms a mesh by bending it around a cylinder with specified radius and angle. It applies optional pitch and taper effects, and allows control over straight sections at the start and end of the bend. The function uses mathematical expressions to calculate new vertex positions based on cylindrical coordinates and conditional logic to apply the bend only within specified limits.
4214	Deforms a mesh along a parametric curve by calculating tangent, normal, and binormal vectors at each point, then applying a transformation to create a new point based on the xy cross-section. The method uses vector operations to compute the curve's geometric properties and applies them to deform the mesh accordingly.
4215	Transfer vertex colors to texture colors by creating a filter script that generates a texture from mesh vertex colors with specified parameters including texture dimensions, overwrite options, and filling behavior.
4216	Transfer mesh colors to face colors using a FilterScript object or script filename, with an option to apply color mapping to all meshes.
4217	Creates a new mesh by resampling the current mesh using uniform volumetric representation with marching cubes algorithm. Builds a distance field from the original surface and reconstructs a new surface at a specified offset distance. Supports options for vertex merging, discretization, multisampling, and thickening to create double-sided surfaces. The resampling process uses a uniform grid where each voxel stores the signed distance to the original surface, allowing precise surface reconstruction at different distances from the original geometry. The filter creates a new 'Offset mesh' layer and requires a non-zero offset for thickening operations.
4218	Surface reconstruction algorithm that creates watertight surfaces from oriented point sets using the Screened Poisson method. Takes point cloud data and generates a mesh surface while handling visibility layers, depth adaptation, and various reconstruction parameters like scale, point weight, and iterations. Creates a new layer named 'Poisson mesh' containing the reconstructed surface.
4219	Turns a mesh into a surface with Voronoi-style holes by generating a Voronoi diagram on the mesh surface, selecting and deleting parts based on quality criteria, and applying Laplacian smoothing to the result.
```
4220	Select all faces and/or vertices of the current mesh.

Args:
    script: the FilterScript object or script filename to write the filter to
    face (bool): If True the filter will select all the faces
    vert (bool): If True the filter will select all the vertices

Layer stack: No impacts

MeshLab versions: 2016.12, 1.3.4BETA
4221	Selects faces and vertices within a specified vertex quality range using MeshLab's "Select by Vertex Quality" filter, with options for minimum/maximum quality values and inclusive selection criteria.
4222	Boolean function using muparser lib to perform face selection over current mesh. Supports parenthesis, per-vertex variables, and boolean operators. Variables include vertex coordinates, normals, colors, quality, texture coordinates, and face properties. Takes a FilterScript object or script filename and a boolean function string as input.
4223	Boolean function using muparser lib to perform vertex selection over current mesh. Supports per-vertex variables and boolean operators, with options for strict face selection. Works with MeshLab versions 2016.12 and 1.3.4BETA.
4224	Selects all vertices within a cylindrical radius by applying a vertical cylindrical filter based on the specified radius and inclusion criteria.
4225	Select all vertices within a spherical radius by applying a radial constraint function centered at the specified point.
4226	Flatten all or only the visible layers into a single new mesh. Transformations are preserved. Existing layers can be optionally deleted. Creates a new layer "Merged Mesh" and changes current layer to the new layer. Optionally deletes all other layers. UV textures are not currently preserved. merge_visible parameter cannot change layer visibility from meshlabserver.
4227	Renames a mesh layer's label in MeshLab scripts. Can be used for outputting MLP files where filenames depend on layer labels. Accepts either a FilterScript object or script filename, with optional layer number parameter. Updates the layer stack with the new label. Supports MeshLab versions 2016.12 and 1.3.4BETA. Returns None.
4228	Change the current layer by specifying the new layer number. If no layer number is provided, defaults to the last layer (if script is a FilterScript object) or first layer (if script is a filename). Modifies the current layer in the layer stack.
4229	Duplicate a layer in MeshLab script. Creates a copy of the specified layer (or current layer if none specified) with label '*_copy'. The new layer is added to the layer stack and becomes the current layer. Supports both FilterScript objects and file-based scripting. Returns None.
4230	Delete all layers below the specified layer number, useful for MeshLab 2016.12 compatibility. If no layer number is specified, uses the current layer. Moves to layer 0 if necessary, then deletes layers 0 through (layer_num-1).
4231	Function `handle_error` provides error handling for subprocess programs with interactive user choices. It displays error information including program name, command, and log file, then prompts the user to choose from four options: retry ('r'), continue ('c'), exit ('x'), or exit and delete files ('xd'). The function returns a boolean indicating whether the calling program should break out of a loop. If user selects 'x' or 'xd', the program exits with status 1. If 'xd' is chosen, it also deletes TEMP3D files and log file. If 'c' is selected, it returns True to continue execution. If 'r' is selected, it returns False to retry the command.
4232	Create a new mlx script file with opening tags and process input files, handling STL files specially by changing layers and running merge_vert. If no input files are provided, create a temporary dummy file to work around MeshLab's requirement for an input file. Return the current and last layer indices.
4233	Add new mesh layer to the end of the stack.

Args:
    label (str): new label for the mesh layer
    change_layer (bool): change to the newly created layer

Returns:
    None
4234	Delete a mesh layer at the specified layer number and adjust the current layer if necessary.
4235	Save filter script to an mlx file. Prints warning if no filters to save. Writes opening tags, filters, and closing tags to the specified file.
4236	Run the meshlab script with optional temporary file handling and parse output metrics.
4237	The `main()` function generates a 3D shield model with a star pattern and colored rings using the MeshLab library. It defines parameters for the star shape, ring thickness, and sphere deformation. The function creates concentric annuluses for the shield's front, adds a back surface, and constructs a central star using multiple rotated diamonds. Finally, it combines all elements, applies a spherical deformation, and saves the result as a PLY file.
4238	Computes the Hausdorff Distance between two mesh layers by sampling one mesh and finding the closest points on the other mesh. Supports various sampling options for vertices, edges, faces, and faux edges. Optionally saves sample points and their distances as new layers. Returns None.
4239	Create a new layer with point sampling using Poisson-disk distribution algorithm. Generates samples according to the method described in "Efficient and Flexible Sampling with Blue Noise Properties of Triangular Meshes" by Corsini et al. Supports various parameters for controlling sampling density, Monte Carlo over-sampling, geodesic distance approximation, subsampling, refinement, and exact sample count generation. Creates a 'Poisson-disk Samples' layer and optionally a 'Montecarlo Samples' layer if requested.
4240	Creates a new layer with point sampling of a mesh element (vertex, edge, or face) using uniform subsampling. The function generates a MeshLab filter script that samples at most one point per mesh element, with equal probability for each element type. The sampling can be configured for vertices, edges, or faces with a specified number of samples. The filter is written to the provided script object and a new layer named 'Sampled Mesh' is added to the layer stack.
4241	Create a new layer with a subsampled version of mesh vertices using a grid-based clustering strategy. The subsampling can use either averaging or closest-to-center strategies, and can be applied to either all vertices or just selected ones. The result is placed in a new 'Cluster Samples' layer.
4242	Flat plane parameterization filter with projection plane selection and aspect ratio preservation options.
4243	Creates a trivial per-triangle parametrization filter with specified parameters including side dimension, texture dimension, border size, and method selection, then writes it to the given script.
4244	Voronoi Atlas parameterization function that generates XML filter configuration for mesh parametrization with specified region count and overlap settings.
4245	Compute a set of topological measures over a mesh by creating a filter script that applies the "Compute Topological Measures" filter to the mesh. The function takes either a mlx.FilterScript object or a script filename as input, writes the appropriate XML filter to the script, and enables topology parsing if the input is a FilterScript object. This function does not impact the layer stack and is compatible with MeshLab versions 2016.12 and 1.3.4BETA. Returns None.
4246	Parse a MeshLab log file to extract mesh topology information including vertices, edges, faces, and mesh properties like manifold status and genus.
4247	Parse a MeshLab log file to extract Hausdorff distance metrics including number of points and various distance statistics.
4248	Color function that generates RGBA colors for mesh vertices using muparser expressions. Supports per-component color functions or predefined HTML color names, with support for various vertex attributes in expressions. Returns None.
4249	This function generates a Voronoi vertex coloring filter for MeshLab that projects points from a source mesh onto a target mesh and colors the target mesh based on geodesic distances from the projected points. It supports backward distance calculation and works with MeshLab versions 2016.12 and 1.3.4BETA. The filter is written to either a FilterScript object or a script file.
4250	Color mesh vertices in a repeating sinusoidal rainbow pattern using a sine wave function that can propagate in different directions (sphere, x, y, z) or custom increment functions. The color is calculated using separate sine functions for each color channel (RGBA) with configurable amplitude, center, frequency, and phase parameters. An alpha channel can be optionally included or set to full opacity. The function supports both single values and per-channel tuples/lists for all parameters. It requires a FilterScript object or script filename as input.
4251	A muparser atan2 function implementation for older versions (<2.1.0) that calculates the arctangent of y/x with proper quadrant handling, returning a muparser string expression.
4252	Computes the cross product of two 3x1 vectors represented as lists of 3 strings, returning a list of muparser formatted strings for each component (i, j, k) using the formula: i = u1*v2 - u2*v1, j = u2*v0 - u0*v2, k = u0*v1 - u1*v0.
4253	Multiply each element of vector v1 by the given scalar and return a new vector with the results.
4254	Add a new Per-Vertex scalar attribute to current mesh and fill it with the defined function. The specified name can be used in other filter functions. Supports per-vertex variables (x, y, z, nx, ny, nz, r, g, b, a, q, rad, vi, ?vtu, vtv, ?ti, ?vsel) and mathematical expressions with parentheses, boolean operators (and, or, <, >, =), and standard arithmetic operations. The attribute can be accessed by other filters using the specified name.
4255	Flip mesh faces orientation by inverting normals, with options to force flipping or limit to selected faces only.
4256	Compute normals for point sets without using triangle connectivity, useful for datasets with no faces. It allows specifying the number of neighbors for normal estimation, smoothing iterations, flipping normals based on viewpoint, and setting the viewpoint position.
4257	Taubin smoothing filter implementation based on the lambda & mu parameters, applying forward and backward smoothing steps for fair surface design. Supports selected face filtering and multiple MeshLab versions.
4258	A laplacian smooth filter that constrains vertex movement along the view direction, with customizable iterations, viewpoint, and selection options.
4259	Function `polylinesort` is designed to sort separate line segments from an OBJ format file into continuous polylines and calculate their lengths. However, the function is marked as "NOT FINISHED; DO NOT USE" and currently returns `None`. It reads vertex and line segment data from the input file, but the actual polyline sorting and length measurement logic is incomplete. The function includes basic file extension validation and logging capabilities, but the core functionality for organizing line segments into polylines is not implemented.
4260	Measures mesh topology by analyzing geometric properties and returns a dictionary containing vertex count, edge count, face count, unreferenced vertices, boundary edges, parts count, manifold status, non-manifold edges and vertices, genus, and holes information.
4261	Measures mesh geometry, AABB, and topology by creating a filter script, running measurement computations, and returning the results. For ML version 1.3.4BETA, it also processes AABB data from a temporary file and logs the results. Returns tuple of (aabb, geometry, topology).
4262	Measures a dimension of a mesh along a specified axis by creating cross-sections at given offsets and calculating the AABB (Axis-Aligned Bounding Box) to determine min, max, and total length values.
4263	Returns a filename with lowercase extension if an extension exists, otherwise returns the original filename unchanged. Only the file extension (if present) is converted to lowercase, preserving the original case of the filename's main portion.
4264	Patches a Flask app's request class to limit maximum content length for file uploads. When size is provided (default 64MB), it sets the max_content_length attribute to reject uploads larger than the specified size. If size is None, it uses the app's MAX_CONTENT_LENGTH configuration setting instead. This prevents disk space exhaustion from large file uploads by rejecting requests that exceed the size limit with an HTTP error. The function creates a new request class that inherits from the original and overrides the max_content_length attribute.
4265	Helper function that extracts configuration for a single upload set from app configuration, handling defaults and validating required settings. Returns an UploadConfiguration object with destination, base_url, allow_extns, and deny_extns.
4266	Configures upload sets for a Flask app by retrieving their settings from the app's configuration and storing them on the app object. It handles multiple upload sets, sets default configurations, and conditionally registers the uploads blueprint only if needed to serve the upload sets.
4267	Returns the current configuration by checking if `_config` is set directly, otherwise looks up the configuration from the current application's upload set config based on the instance name, or raises a RuntimeError if accessed outside a request context.
4268	Returns the URL for a file uploaded to this set. If the base URL is not set, uses `url_for` with the '_uploads.uploaded_file' endpoint. Otherwise, appends the filename to the base URL.
4269	Returns the absolute path of a file in the upload set, optionally within a subfolder.
4270	Returns True if a given file extension is allowed based on the configuration's allow and deny lists. An extension is allowed if it's in the allow list OR if it's in the available extensions but not in the deny list.
4271	Method `resolve_conflict` resolves naming conflicts when copying files to a target folder. It takes a target folder path and original basename, splits the name and extension, then appends an underscore and incrementing number to the name until it finds a unique filename that doesn't already exist in the target folder. The method returns the new unique basename.
4272	Returns the version string found in the __version__ variable of a given filename. Raises RuntimeError if version cannot be found.
4273	Removes duplicate objects from a list while preserving order by using object IDs for comparison.
4274	Returns the count difference between two collections of Python objects by processing them through in-memory object cleaning and type-based counting.
4275	Formats object counts by parsing object representations with regex, extracting type and name information, and returning a sorted list of (type name, count) tuples in descending order by count.
4276	Tracks memory usage on line events within specified target modules, recording line number, resident memory size, function name, and file name in an events list.
4277	Returns processed memory usage by organizing events into a resulting list with memory values converted to MB, updating existing entries when conditions match, or appending new entries otherwise.
4278	Returns a dictionary with counts of overhead objects including self, _resulting_events, _events_list, and _process, with additional counts for dict references.
4279	Returns the memory overhead by calculating the difference between the current RSS memory usage and the initial RSS memory size.
4280	Profiles memory usage for a package by tracking code events and computing memory overhead during execution.
4281	Returns memory statistics for a module by compiling and executing its code while tracking memory overhead.
4282	Returns memory statistics for a function by tracking memory overhead during execution using a code events tracker.
4283	Collects memory statistics for a specified Python program by profiling object creation and formatting the results with timestamps and event counts.
4284	Returns a set of module filenames from a Python package by iterating through modules in the specified package path and constructing their full file paths.
4285	Runs a function in a separate process using multiprocessing, handling exceptions and returning the function's output. Uses a manager dictionary to share data between processes and includes error handling for exceptions that occur in the separate process.
4286	Determines the type of run object by checking if it's a tuple (returns 'function'), parsing the first part of the object string, and then checking if that part is a directory (returns 'package') or otherwise returns 'module'.
4287	Initializes profiler with a module by setting up profiling configuration, parsing the run object to extract the module name and arguments, creating a global namespace appropriate for module execution, and updating the system path to include the module's directory.
4288	Initializes the profiler to profile a package by setting the profiling method, extracting the package name from the run object, and replacing system arguments.
4289	Initializes profiler with a function by setting the profile function, storing the run object and its arguments, and creating an object name identifier with the function name and source file location.
4290	Replaces sys.argv with the run object and optional run arguments to properly pass to the script.
4291	Samples the current stack trace and records it in internal statistics. Captures function names, filenames, and line numbers from the stack frames, storing the count of each unique stack pattern in `self._stats`. Resets the profiler timer to continue sampling at regular intervals.
4292	Inserts a call stack into a call tree structure by traversing each function in the stack and creating nodes as needed, updating the sample count at the final node.
4293	This method recursively counts samples in a call tree structure by traversing all child nodes and accumulating their sample counts into the parent node's sample count. It returns the total sample count for the current node and its subtree.
4294	Formats a call tree node for UI display by calculating sample percentages and generating color hashes for visualization.
4295	Returns the call tree representation by building a tree structure from statistics data, filling sample counts, and formatting the result.
4296	Runs a statistical profiler on a package and returns profiling results including call tree statistics, runtime information, and sample counts.
4297	Runs a statistical profiler on a module and returns profiling results including call statistics, runtime, and sample data.
4298	Runs a statistical profiler on a function and returns profiling results including runtime, call statistics, and execution result.
4299	Transforms profiling statistics into UI-ready records sorted by cumulative time percentage in descending order.
4300	Runs cProfile on a package and returns profiling statistics including call information, timing data, and timestamps.
4301	Runs cProfile on a module and returns profiling statistics including call statistics, timing information, and timestamps.
4302	Runs cProfile on a function and returns profiling statistics including execution time, call counts, and results.
4303	Initializes the database by connecting to it, executing the database schema script, and committing the changes.
4304	Returns all existing guestbook records by querying the database for name and message entries ordered by ID in descending order, then renders them using a Jinja2 template.
4305	Adds a single guestbook entry by inserting the name and message from form data into the database and redirects to the home page.
4306	This function handles profiler requests based on the URI parameter. It executes different runner functions depending on whether the URI is 'main' (runs show_guestbook) or 'add' (runs add_entry), both with 'cmhp' as a parameter, then redirects to the home page.
4307	Starts an HTTP server with optional browser opening and debug mode handling. Takes host, port, profiler statistics, and flags to control browser behavior and debug output. Uses a stats handler to serve profiling data through a custom server implementation. If debug mode is disabled, redirects stderr to /dev/null. Handles keyboard interrupt gracefully by stopping the server and exiting cleanly.
4308	Handles index.html requests by reading the profile HTML file and returning its content with text/html content type.
4309	Handles static file requests by reading the requested file and returning its content with appropriate MIME type based on file extension.
4310	Handles HTTP GET requests by looking up the requested URI in the uri_map, falling back to _handle_other if not found. It retrieves content and content type from the handler, compresses the content using gzip, and sends a 200 response with appropriate headers including Content-Type, Content-Encoding (gzip), and Content-Length, followed by the compressed content.
4311	Handles HTTP POST requests by reading gzip-compressed JSON data from the request body, decompressing and parsing it, updating an internal profile dictionary with the parsed data, and sending back a gzip-compressed JSON response with the original request data length.
4312	Sends an HTTP response with the specified status code, optional message, and headers. If headers are provided, they are sent followed by ending the headers section.
4313	Checks whether a given module path belongs to the standard library or installed modules. Returns True if the path is in 'site-packages' or matches any standard library path pattern, False otherwise.
4314	Records the execution time of each line of code by tracking timestamp differences between line executions and storing the results with file path, line number, and runtime.
4315	Filters code from standard library by yielding non-standard library lines while aggregating runtime from standard library lines.
4316	Fills code heatmap and execution count dictionaries by iterating through lines without stdlib, incrementing execution counts and accumulating runtimes for each module path and line number.
4317	Skips lines in src_code according to skip_map, which contains (line, length) tuples specifying which lines to skip. Returns a list of lists where each inner list is either ['line', line_number, line_content] or ['skip', length] indicating skipped lines. Merges consecutive skip entries when possible.
4318	Calculates heatmap for package by running the module and collecting execution statistics. Returns object name, total runtime, and formatted heatmaps for valid files.
4319	Formats heatmap data for UI display by reading source file, calculating skipped lines, and aggregating execution statistics.
4320	Calculates heatmap for module by reading source code, executing it with profiling, and formatting the execution statistics into a structured result containing runtime information and heatmaps for each file.
4321	Profiles a function by calculating its heatmap and returning execution statistics including runtime, source code, and execution counts.
4322	Runs profilers on a run_object based on the provided configuration, returning collected statistics. Raises AmbiguousConfigurationError for duplicate configuration options and BadOptionError for unknown options. Supports verbose output to show which profilers are being executed.
4323	Runs profilers on a function and sends the profiling statistics to a specified host and port. Executes the function with given arguments and returns its result while also collecting and transmitting profiling data.
4324	Return probability estimates for the RDD containing test vector X.

Parameters
----------
X : RDD containing array-like items, shape = [m_samples, n_features]

Returns
-------
C : RDD with array-like items , shape = [n_samples, n_classes]
    Returns the probability of the samples for each class in
    the models for each RDD block. The columns correspond to the classes
    in sorted order, as they appear in the attribute `classes_`.
4325	Return log-probability estimates for the RDD containing the test vector X. For non-BlockRDD inputs, delegates to the parent class implementation. For BlockRDD inputs, applies the parent class's predict_log_proba method to each block using map operation.
4326	Fit Gaussian Naive Bayes according to X, y by processing training vectors and target values using distributed computation, then update the model parameters with the averaged results.
4327	Create sparse feature matrix from analyzed documents using vocabulary mapping, handling out-of-vocabulary items and supporting binary encoding.
4328	Sort features by name and return a mapping index that reorders the matrix, while modifying the vocabulary in place to have new sequential indices based on sorted feature names.
4329	Remove too rare or too common features by pruning terms based on document frequencies, modifying the vocabulary to keep only terms within specified frequency ranges and limited by a maximum count. Returns the indices of kept features and the set of removed terms.
4330	Fit and transform documents to a term-document matrix, learning vocabulary and applying feature limiting based on document frequency parameters.
4331	Transform documents to document-term matrix by extracting token counts from raw text documents using fitted vocabulary, returning a sparse matrix of shape [n_samples, n_features].
4332	Converts the current object to an equivalent StandardScaler instance with the same parameters and attributes.
4333	Wraps a Scikit-learn Linear model's fit method to work with RDD input by mapping the fit operation across distributed data and aggregating results.
4334	Wraps a Scikit-learn Linear model's predict method to work with RDD input by mapping the predict operation across distributed data.
4335	Fit linear model by calling SparkLinearRegression on the provided RDD data.
4336	Fit all transforms sequentially and then fit the final estimator on transformed data, returning the fitted pipeline.
4337	Fit all transforms sequentially on the data, then apply fit_transform on the final estimator with the transformed data.
4338	Applies transformers to input data Z sequentially, then calls the score method of the final estimator on the transformed data.
4339	Performs hyperparameter search by fitting the estimator on different parameter combinations using cross-validation, stores the results, and fits the best estimator on the entire dataset if refit is True.
4340	Compute the score of an estimator on a given test set using a specified scorer function, and validate that the returned score is a number.
4341	Fit k-means clustering on the input data. If using 'k-means||' initialization, trains an MLlib KMeans model; otherwise, fits the model distributed across partitions and aggregates results. Returns the fitted model instance.
4342	Predict the closest cluster each sample in X belongs to. In the vector quantization literature, `cluster_centers_` is called the code book and each value returned by `predict` is the index of the closest code in the code book.

Parameters
----------
X : ArrayRDD containing array-like, sparse matrix
    New data to predict.

Returns
-------
labels : ArrayRDD with predictions
    Index of the cluster each sample belongs to.
4343	Distributed method to predict class labels for samples in X.

Parameters
----------
X : ArrayRDD containing {array-like, sparse matrix}
    Samples.

Returns
-------
C : ArrayRDD
    Predicted class label per sample.
4344	Checks if the data types in an RDD match expected types. For BlockRDD, verifies that the dtype matches expected types. For DictRDD, checks that each column's type matches the expected type for that column. Returns True if all types match the expectations, False otherwise. Raises TypeError if arguments are invalid types.
4345	Learn a list of feature name -> indices mappings by creating a vocabulary from input feature names and storing the mapping.
4346	Fit the variance threshold calculator by computing empirical variances from input data.

This method calculates the variance of each feature in the input data and stores the results in `self.variances_`. It handles both dense and sparse matrices, using distributed computing via RDD operations to efficiently compute statistics across blocks of data. The method also validates that at least one feature meets the specified variance threshold, raising a ValueError if no features satisfy the minimum variance requirement.

Parameters:
- X: {array-like, sparse matrix}, shape (n_samples, n_features) - Sample vectors from which to compute variances
- y: any - Ignored parameter for sklearn compatibility

Returns:
- self: Returns the fitted instance

The method internally uses map-reduce operations to compute combined statistics across data blocks, handling both sparse matrices (using mean_variance_axis) and dense arrays (using numpy operations). It raises a ValueError if no feature meets the variance threshold.
4347	Fit LSI model to X and perform dimensionality reduction on X. If algorithm is "em", uses expectation-maximization SVD with distributed data persistence for computation. Otherwise, falls back to parent class implementation for non-distributed SVD. Returns reduced version of X as dense array.
4348	Transforms the input data using the pre-trained TruncatedSVD model for dimensionality reduction.

Parameters:
    Z : {array-like, sparse matrix, DictRDD}, shape (n_samples, n_features)
        New data to be transformed. Can be a regular array, sparse matrix, or DictRDD.

Returns:
    X_new : array, shape (n_samples, n_components)
        Reduced version of input data. This will always be a dense array with fewer dimensions.

The method handles both regular arrays/sparse matrices and DictRDD inputs, performs validation checks, and applies the pre-fitted transformation using Spark's distributed computing capabilities.
4349	Pack RDD elements into blocks of specified size using a collection constructor.
4350	Packs an iterator of tuples into tuples of arrays or scipy.sparse matrices, with optional batching. Takes an iterator of tuples, groups elements by position across tuples, and packs them into the specified data types. If batch size is specified, yields batches when limit is reached, otherwise yields single batch with all elements.
4351	Blocks an RDD into numpy arrays, scipy sparse matrices, or pandas data frames based on the data type of the first element. Handles different data types by mapping to appropriate RDD classes (DictRDD, SparseRDD, ArrayRDD, or BlockRDD) with optional block size specification. Returns an empty RDD unchanged if it's empty, and uses the first element to determine the blocking strategy.
4352	Equivalent to map, compatibility purpose only. Column parameter ignored. Transforms the RDD using the provided function and returns an instance of the same class or a specialized RDD type (ArrayRDD, SparseRDD, or BlockRDD) based on the specified dtype.
4353	Returns the shape of the data by calculating the total size of the first dimension and combining it with the shapes of subsequent dimensions from the first element.
4354	Returns the data as a numpy array by mapping each partition to convert its elements to arrays and then concatenating all results.
4355	Transforms one or more columns in a DictRDD using a provided function. If no column is specified, applies the function to all columns (equivalent to map). Supports type specification for transformed columns and returns a new DictRDD with the transformation applied. The transformation function must return an iterable with the same length as the number of columns being transformed.
4356	Returns the mask value for a specific permission (Read/Write/Execute) and position (User/Group/Other) of a file's bit permissions. Returns 0 if no permissions exist, otherwise returns a positive value.
4357	Checks if a file is only writable by root by examining the file's permissions and ownership. Returns True if only root can write to the file, False otherwise.
4358	Function `check_config` validates a configuration file by attempting to read it through the `Config` class. If successful, it prints a success message using the provided print function; otherwise, it raises an `InvalidConfig` exception. The function takes two parameters: `file` (path to config file) and `printfn` (print function for success message, defaulting to built-in `print`). It returns `None`.
4359	Reads and validates a configuration file, making the parsed data accessible as a dictionary in the instance. Raises InvalidConfig exception for parsing or validation errors.
4360	Get the arguments to execute a command as a specified user, using sudo for non-root users. Returns a list of command arguments including the shell, execute parameter, and command. If user is 'root', returns the shell and command directly. Otherwise, prepends sudo with appropriate flags to execute as the specified user.
4361	Execute a command in a subprocess with timeout support, returning stdout and stderr or raising an ExecuteError on failure.
4362	Execute a command on a remote machine via SSH by constructing and returning an SSH command array with optional port specification and working directory changes.
4363	Validate configuration data and raise InvalidConfig on error. Checks that content-type and body options are used only with allowed HTTP methods, normalizes content-type using aliases, and validates JSON body format.
4364	Get HTTP Headers to send by combining default headers with request-specific headers.

Returns:
    HTTP Headers as a dictionary
rtype: dict
```
4365	Return the "data" value from self.data, using default_body if available. If data is a dictionary, return it as a JSON string; otherwise return the data as-is.
4366	Returns the Home Assistant API URL for sending events, raising an exception if the event option is not configured.
4367	Returns the IFTTT Webhook URL by formatting the url_pattern with the event name and API key from the device configuration. Raises InvalidConfig if either the API key or event name is missing.
4368	Return source mac address for this Scapy Packet, with special formatting for Amazon devices.
4369	A callback function that processes discovered network packets by:
1. Tracking unique source MAC addresses to prevent duplicates
2. Converting packets to readable text format
3. Displaying device information in magenta color if from Amazon, otherwise normal color
4. Adding new MAC addresses to a global list for duplicate tracking
4370	Print help information and scan devices on screen, showing discovered devices with yellow colored help text.
4371	Execute the device by calling its execution instance. If no execution method exists, log a warning and send failure confirmation. If execution fails, catch the exception, send error confirmation, and re-raise. If successful, format success message and send confirmation. Return the execution result or a default success message.
4372	Send success or error message to configured confirmation device, with error handling for communication failures.
4373	Method `on_push` handles button press events by checking if sufficient time has passed since the last execution based on a delay setting, updating the last execution time, and then executing the device command. It uses the device's source MAC address as a key to track timing and defaults to a constant delay when no specific delay is configured.
4374	Execute a device by creating a new thread to run the device's execute method with root permissions if allowed.
4375	Start daemon mode and begin scanning devices.

Parameters:
- root_allowed (bool): Only used for ExecuteCmd
- Returns: loop

The method configures root permission settings and initiates device scanning using the provided callback functions and interface settings.
4376	Converts an OFX transaction to a posting, handling both regular and investment transactions with appropriate account mappings and metadata.
4377	Returns the main ledger file path by checking environment variable LEDGER_FILE, then ~/.ledgerrc configuration file, or returns None if not found.
4378	Function to run unit test suite with support libraries and Python versions.
4379	Returns the long description by transforming README.md into a usable format, replacing relative references to SVG images with absolute HTTPS references.
4380	Creates a PrecalculatedTextMeasurer instance from a JSON stream by parsing the mean character length, character lengths, and kerning pairs from the loaded JSON object.
4381	Returns a reasonable default PrecalculatedTextMeasurer by loading default character width data from a compressed JSON file, falling back to an uncompressed JSON file, or raising an error if neither is available. Uses caching to avoid repeated loading.
4382	Creates a GitHub-style badge as an SVG image with customizable text, colors, links, and optional logo. Supports left and right text sections with individual styling and linking options, or a single link for the entire badge. Can embed logos directly in the SVG. Uses a template system and text measurement for proper sizing.
4383	Generate an iterable of characters supported by a font file by examining its Unicode character maps.
4384	Generates the subset of characters that can be encoded using any of the provided encodings by attempting to encode each character with each encoding and yielding those that succeed.
4385	Returns a mapping between each character and its width in pixels by measuring with the provided TextMeasurer.
4386	Writes precalculated text measurer data to a JSON stream including character lengths and kerning information.
4387	Convolve a 2D image with a 2D Gaussian kernel by applying 1D Gaussian convolution separably along rows and columns.
4388	Generate a 1D Gaussian kernel with specified width and sigma parameters, normalized so that all values sum to 1. The kernel is created by calculating Gaussian values for each position based on the formula exp(-((x-))/(2)) where  is the center position and  is the standard deviation.
4389	Converts a PIL image to numpy grayscale array and alpha array. Returns a tuple of (gray, alpha) where gray is the grayscale representation and alpha is the transparency channel if present.
4390	Main function for pyssim that compares an image with a list of images using the SSIM metric, supporting both complex wavelet SSIM and standard SSIM computation with optional image scaling.
4391	Computes the Structural Similarity Index (SSIM) value between a reference image and a target image. Takes a target image (as string path, PIL.Image, or SSIMImage object) and returns a float SSIM value representing structural similarity. Uses Gaussian filtering and applies the SSIM formula with constant values c_1 and c_2 for numerical stability.
4392	Computes the Structural Similarity Index (SSIM) between two PIL Image objects using a Gaussian kernel for spatial filtering. Takes two images as input and returns a float value representing their structural similarity. The SSIM calculation uses a Gaussian kernel with specified width and sigma parameters for smoothing.
4393	Destroy SyncObj by stopping autoTickThread, closing connections, and cleaning up resources. If autoTick is enabled, sets destroying flag; otherwise, immediately performs destruction.
4394	Sets a new code version across all cluster nodes, validating version constraints before applying the change.
4395	Dumps different debug info about cluster to dict and return it
4396	Dumps debug information about the cluster to the default logger by retrieving status data and logging each key-value pair.
4397	Find the node to which a connection belongs.

**Parameters:**
- conn: connection object (TcpConnection)

**Returns:**
- corresponding node or None if the node cannot be found (Node or None)
4398	Binds the server if not already bound, read-only node, or binding attempts too frequent. Raises TransportNotReadyError if bind fails after max retries.
4399	Method `_onNewIncomingConnection` handles new incoming TCP connections by:
1. Adding the connection to unknown connections set
2. Setting up encryption if available
3. Registering message reception callback
4. Registering disconnection callback

Parameters:
- `conn`: TcpConnection object representing the new connection

The method prepares the connection for communication by establishing callbacks for message handling and disconnection events.
4400	Handles incoming messages on new connections, managing encryption setup, utility commands (status, add, remove, set_version), and associating connections with Node objects. For non-utility messages, it either maps the message to an existing node or creates a readonly node, then sets up the connection for further messaging and triggers appropriate connection callbacks.
4401	Callback function that handles utility messages by sending back the result status (SUCCESS/FAIL) along with the command and its arguments through the connection.
4402	Check whether this node should initiate a connection to another node based on type, connection prevention rules, and address comparison.
4403	Connect to a node if necessary, checking connection state, connection policies, and retry timing constraints before establishing connection.
4404	Handles outgoing connection establishment by setting up encryption or sending node identity. If encryption is enabled, configures message callback and sends random key; if disabled, sends node address and triggers connection callback.
4405	Handles incoming messages on new outgoing connections for encryption key exchange. Once key exchange is complete, switches to regular message handling and triggers connection callbacks.
4406	Method `_onDisconnected` is a callback handler that manages disconnection events for TCP connections. When a connection terminates, it removes the connection from unknown connections tracking, identifies the associated node, and handles the disconnection appropriately by either calling node disconnection handlers or readonly node disconnection handlers, followed by attempting to reconnect if necessary. The method takes a connection object as parameter and returns nothing.
4407	Add a node to the network by storing it in the nodes set and address mapping, and establish a connection if required.
4408	Drop a node from the network by removing its connections and cleaning up associated data structures. If the node has an active connection, it disconnects it while preventing automatic reconnection. For TCPNodes, it removes the node from _nodes and _nodeAddrToNode dictionaries. For other nodes, it removes from _readonlyNodes. Finally, it removes any last connection attempt record for the node.
4409	Send a message to a specified node and return whether the operation was successful. Returns False if the node is not connected or if the connection becomes disconnected during the send operation.
4410	Destroy this transport by clearing all callbacks, dropping all connected nodes, unbinding the server, and disconnecting unknown connections.
4411	**put(self, item):** Adds an item to the queue if space is available. Returns `True` if the item was successfully added, `False` if the queue is full and the item cannot be placed.
4412	Puts an item into the queue if there is space available. Returns True if successful, False if the queue is full.
4413	Extracts and returns the smallest item from the priority queue, or returns the default value if the queue is empty.
4414	Attempt to acquire a lock with the given lockID. Returns True if the lock is acquired, False if another process already acquired it. Can operate in synchronous mode (waiting until acquisition or failure) or asynchronous mode (using a callback for results). Supports optional timeout parameter.
4415	Check if a lock is acquired by the current instance.

Parameters:
- lockID (str): Unique lock identifier.
Returns:
- bool: True if lock is acquired by ourselves, False otherwise.
4416	Release a previously acquired lock with optional synchronization and callback mechanisms.
4417	A decorator that wraps check functions and returns an error response with stacktrace if the wrapped function raises an exception. It logs debug information about the check being performed and formats error responses with "ok", "error", and "stacktrace" fields. If the wrapped function takes arguments, it logs the check name and argument name, and prefixes the error response with the argument name.
4418	A decorator that requires authentication tokens for access to views, checking both Authorization header and GET parameters against configured tokens.
4419	Sets Elasticsearch connection parameters including hosts, SSL configuration, and timeout. Accepts a single host or list of hosts, with optional SSL support and certificate path specification. Creates a connection using the specified parameters.
4420	Creates Elasticsearch indexes for the given list of index names with optional custom settings, skipping indexes that already exist.
4421	Function `migrate_indexes` updates index mappings by creating new indexes with updated field mappings for aggregate indexes and reindexing data. It converts the "fo" field type from "long" to "text" with keyword sub-field, then deletes the old index. Forensic indexes are currently not processed.
4422	Strips metadata from a report by duplicating org_name, org_email, and report_id to the JSON root level and removing the report_metadata key to align with Elastic output format.
4423	Saves aggregate DMARC reports to Kafka by processing report dictionaries, adding date ranges and metadata, and sending individual records to the specified Kafka topic while handling potential Kafka errors.
4424	Extracts XML content from a zip or gzip file, or returns XML directly if the input is already XML. Handles file paths, file-like objects, and bytes input. Returns the extracted XML as a string. Raises InvalidAggregateReport for invalid files or encoding errors.
4425	Parses a DMARC aggregate report from a file path, file-like object, or bytes input, extracting XML content and returning a structured report through parallel or sequential processing.
4426	Converts parsed forensic reports to flat CSV format with headers, handling both single reports and lists of reports by flattening nested structures and joining list fields.
4427	Parses a DMARC aggregate or forensic report file from a path, file-like object, or bytes, with optional DNS resolution and parallel processing support. Returns an OrderedDict containing the report type and parsed report data.
4428	Returns a list of IMAP server capabilities by fetching and processing the server's capabilities response, removing byte string formatting and logging the results.
4429	Save report data in the given directory, creating JSON and CSV files for aggregate and forensic reports, and store sample files in a subdirectory.
4430	Creates a zip file containing parsed report output by:
1. Saving results to a temporary directory
2. Walking through the directory structure
3. Adding files and subdirectories to the zip with proper relative paths
4. Cleaning up temporary files
5. Returning the zip file as bytes

The function handles nested directories recursively and maintains the original directory structure in the zip archive.
4431	Emails parsing results as a zip file attachment using SMTP, with support for SSL/TLS encryption, authentication, and custom message parameters. The function creates a zip archive of the results, configures the email with specified headers and body, and sends it to a list of recipients. It handles various SMTP exceptions and SSL errors gracefully.
4432	Saves a list of DMARC aggregate report dictionaries to Splunk by transforming each report record into a structured format and sending it via Splunk HEC POST request. If a single dictionary is provided, it's converted to a list. Each report record is enriched with metadata and authentication results, then formatted as JSON and posted to Splunk. SSL certificate verification can be skipped based on configuration. Exceptions are raised for HTTP errors or invalid responses from Splunk HEC.
4433	Saves forensic DMARC reports to Splunk by converting report dictionaries to JSON format and sending them via HTTP POST to Splunk HEC endpoint, with error handling for certificate verification and response codes.
4434	Decodes a base64 string with optional padding, returning the decoded bytes. If the input string has invalid padding, it automatically adds the required padding characters ('=') to make its length a multiple of 4 before decoding. The function first converts the input string to bytes using ASCII encoding, then handles padding adjustment if necessary, and finally uses base64.b64decode() to perform the actual decoding.
4435	Gets the base domain name for a given domain using the Public Suffix List, with optional fresh PSL download.
4436	Resolves an IP address to a hostname using reverse DNS query with optional caching and custom nameservers. Returns the reverse DNS hostname if successful, None otherwise.
4437	Converts a human-readable timestamp string into a Python DateTime object, with optional UTC conversion.
4438	Function `get_ip_address_country` retrieves the ISO country code for a given IP address using the MaxMind Geolite2 Country database. It first checks for the database in multiple system paths, downloads it if not found or if older than 7 days, and then queries the database for the country code. The function supports parallel processing mode and handles cases where the IP address is not found in the database. Returns `None` if the database cannot be downloaded or the IP address is not found.
4439	Returns reverse DNS and country information for a given IP address, with optional caching and parallel processing support.
4440	Converts an Outlook MSG file to RFC 822 format using the msgconvert Perl utility. Takes MSG file bytes as input and returns the converted RFC 822 string. Raises ValueError if input is not a valid MSG file or EmailParserError if msgconvert utility is not found. Handles temporary file creation and cleanup automatically.
4441	Converts a comma separated string to a list, removing leading whitespace from each element.
4442	Function `cli_parse` processes a report file using DNS parsing with specified parameters. It handles parser errors by returning the error and file path, and uses a global counter with locking to track processing progress. The function supports parallel processing and returns parsed results along with the file path.
4443	Puts a connection into a drain state where all subscriptions are immediately drained and publishers are drained before closing the connection, or drains a specific subscription if sid is provided. Raises exceptions if connection is closed, connecting, or reconnecting. Uses async operations with timeout handling and notifies via error callback on timeout.
4444	Sends a PUB command to the server on the specified subject with the given payload, after validating connection state and payload size limits.
4445	Publishes a message with a reply subscription for responses, including connection state checks and payload size validation.
4446	Sends a PUB command to the NATS server with the specified subject, reply, payload, and payload size, updating statistics and flushing pending commands. Raises ErrBadSubject if the subject is empty.
4447	Sets up an asynchronous subscription that processes each message with a separate task. Deprecated since version 7.0, will be removed in version 9.0. Returns the subscription ID.
4448	Removes a subscription from the client based on the subscription sequence ID, optionally after receiving a specified number of messages. Raises exceptions if the connection is closed or draining. If not reconnecting, sends auto-unsubscribe commands.
4449	Sends a ping to the server to ensure written data has reached the server and measure roundtrip time. Raises ErrTimeout if pong not returned within timeout period.
4450	Selects the next available server from the server pool for connection, handling reconnection attempts and backoff retries. Returns the connected server or raises ErrNoServers if no servers are available.
4451	Processes raw error messages from the server, handles specific errors like stale connections and authorization violations, creates appropriate error objects, and initiates connection closure with callbacks if necessary.
4452	Process protocol errors by attempting reconnection if allowed, otherwise disconnect and close the client.
4453	Generates a JSON string with connection parameters for sending CONNECT command to the server, including authentication info and client options.
4454	Process PONG response from server by completing the corresponding future, updating statistics, and decrementing outstanding ping counter.
4455	Process MSG sent by server, update statistics, handle subscription and message delivery, with slow consumer detection and error reporting.
4456	Process INFO lines from server to update client with latest cluster information for server discovery and connection URL management.
4457	Process INFO from server, establish CONNECT with authentication, set up reading and ping interval tasks.
4458	Coroutine that continuously consumes pending commands from a queue and flushes them to a socket, handling connection state, I/O errors, and cancellation gracefully.
4459	Coroutine that continuously reads bytes from server and feeds them to protocol parser, handling various errors and stopping conditions.
4460	Computes and saves coactivation maps by performing a meta-analysis comparing studies that activate within a seed region to those that don't. Takes a dataset, seed definition (image or coordinates), optional threshold and radius parameters, and outputs meta-analysis images to a specified directory.
4461	Decodes a set of images using specified methods and returns results as a pandas DataFrame. Supports single image files, lists of filenames, or numpy arrays as input. Results can be saved to CSV or returned as a numpy array with specified decimal rounding. Uses different decoding methods (pearson correlation, dot product, or roi association) based on the instance's method attribute.
4462	Load feature data from a 2D ndarray on disk into feature_images and generate sequential feature_names.
4463	Load feature image data from image files, validating that feature names and images lists have the same length, and store the loaded images with their corresponding names.
4464	**Method Summary:**

`_pearson_correlation` computes Pearson correlation coefficients between input images and feature images across voxels. It takes an array of images to decode and returns a 2D array of correlation values between features and images.

**Parameters:**
- `imgs_to_decode`: ndarray of images to decode with voxels in rows and images in columns

**Returns:**
- n_features x n_images 2D array of Pearson correlation coefficients

**Processing:**
Converts input arrays to float type and computes correlations using `_xy_corr` method.
4465	Dot product decoding implementation that computes the dot product between transposed input images and feature images, then transposes the result.
4466	This function implements two types of feature selection methods. It supports K-best feature selection where the top K features are selected based on statistical tests, and random best feature selection where K features are randomly chosen from all available features. The function takes a feature selection method string (like "10-best" or "5-randombest"), feature matrix X, and target vector y, then returns the indices of selected features. For K-best selection, it uses SelectKBest from sklearn with warning suppression, while for random best selection, it randomly shuffles and picks the first K features.
4467	Function `get_studies_by_regions` prepares data for classification tasks using neuroimaging masks. It loads Nifti masks, identifies studies associated with each mask based on activation thresholds, optionally removes overlapping studies, and constructs feature matrices (X) and class labels (y). The function supports filtering by specific studies and features, and can apply regularization to the feature matrix. It returns a tuple of the feature matrix and class labels.
4468	Returns a list of indices representing the order in which requested features appear in the dataset's feature names.
4469	Performs classification on specified brain regions defined by masks, retrieving studies associated with each mask at a given threshold, optionally filtering by studies and features, and training a classifier to predict study classes. Supports multiple classification methods (SVM, ERF, Dummy) with optional cross-validation, parameter grid search, and regularization. Returns feature matrix X, class labels y, and optionally the trained classifier depending on output parameter.
4470	Wrapper function for scikit-learn classification that implements various classification methods and cross-validation. Supports different classifier types (ERF by default), cross-validation with custom scoring, class weighting, feature selection, and multiple output options including classifier object, scores, feature selection results, and predictions. Returns structured results based on the specified output type.
4471	Fit the classifier to the training data X and outcomes y, setting class weights and returning the fitted classifier.
4472	Sets the class_weight parameter of the classifier based on the provided class_weight strategy and target labels y. If class_weight is 'auto', it calculates class weights inversely proportional to class frequencies in y. If class_weight is None, it removes class weights. Handles ValueError exceptions by either silently passing or issuing a warning when class weight setting fails.
4473	Fits the classifier using cross-validation on the provided data. Sets up cross-validation folds based on the specified method (e.g., '4-Fold'), applies feature selection if specified, performs cross-validated fitting using GridSearchCV or manual feature selection, and finally fits the classifier on the entire dataset. Returns the mean cross-validation score.
4474	Fits a classifier model to either dataset features or voxels against target variable y. The method rotates the dataset data 90 degrees and uses it as input X to train the sklearn classifier.
4475	Aggregates voxel data within specified regions to create a matrix of ROIs x mappables, where each ROI value represents the proportion of active voxels. Supports various input formats for datasets and regions, with optional binarization and zero-value removal. Returns a 2D numpy array with ROIs in rows and mappables in columns.
4476	Returns a 2D numpy array of randomly selected voxels from a dataset for predictive analysis baselines.
4477	Returns the top 40 words from each topic in a trained topic model by sorting topic components in descending order and selecting the highest-scoring words based on feature names.
4478	The `pearson` function computes the Pearson correlation coefficients between a row vector `x` and each row vector in a 2D array `y`. It works by:

1. Vertically stacking `x` and `y` into a data matrix
2. Calculating the mean of each row and centering the data by subtracting the means
3. Computing the Euclidean norms (standard deviations) of the centered data
4. Calculating the dot product between the centered vectors
5. Normalizing by the product of the norms to obtain correlation coefficients

The function returns an array of correlation coefficients, where each coefficient represents the Pearson correlation between vector `x` and each corresponding row in array `y`.
4479	Function fdr calculates the False Discovery Rate (FDR) threshold by sorting p-values and comparing them against a null hypothesis distribution to find the maximum significant p-value at the specified false discovery rate q (default 0.05). It returns the threshold p-value or -1 if no significant results are found.
4480	Load activation data from a text file, ensuring mandatory columns exist, transform coordinates to target space using a transformer, and convert XYZ coordinates to IJK indices using matrix transformations.
4481	Creates and stores a new ImageTable instance based on the current Dataset, optionally updating the smoothing kernel radius.
4482	Retrieves study IDs or data based on specified criteria including features, expression, mask, or peaks. Supports intersection of multiple criteria, with options to return IDs, activation data, or feature weights. Includes validation for argument combinations and handles various selection methods like feature-based, expression-based, mask-based, and peak-based retrieval.
4483	Constructs a new FeatureTable from file by adding features to existing ones or replacing them based on the append parameter. Supports features input as text files or pandas DataFrames.
4484	Returns feature names from the feature table. If features parameter is provided, returns ordered names for those specific features. Otherwise, returns all feature names in the table.
4485	Returns a dictionary mapping feature names to their study counts, where studies are tagged with features meeting or exceeding the specified threshold.
4486	Load a pickled Dataset instance from file, handling potential UnicodeDecodeError for Python3 compatibility, and convert feature table from CSR to SDF format if present.
4487	Method: save(self, filename)
Description: Pickles the Dataset instance to the specified file. Before pickling, it converts the feature table from SDF to CSR format if it exists, and then converts it back to SDF format after pickling. The pickling uses the highest protocol (-1) for optimal performance.
4488	Returns a subset of image data as a 2D numpy array with voxels in rows and studies in columns. Can filter by study IDs and voxel indices, and optionally return dense or sparse matrix format.
4489	Slices and returns a subset of feature data based on specified study IDs and features. If ids or features are provided, filters the data accordingly. Returns a pandas DataFrame with study IDs as rows and features as columns, converted to dense format by default (or sparse if dense=False and no ID filtering is applied).
4490	Returns features in the order they appear in the database by finding their indices in the data columns and returning them in that sequence.
4491	Returns a list of study IDs that meet specified feature-based criteria. Searches for studies containing specified features with weights exceeding a given threshold, using a specified aggregation function (default sum). Can optionally return feature weights along with study IDs.
4492	Searches for features that match the given search criteria.

Args:
    search (str, list): A string or list of strings defining the query.

Returns:
    A list of matching feature names.
4493	Method: `get_ids_by_expression`

Description: Parses a given expression using a PEG (Parsing Expression Grammar) lexer and parser to retrieve study IDs that match the expression criteria.

Parameters:
- `expression` (str): The expression to parse
- `threshold` (float, optional): Threshold value for filtering (default: 0.001)
- `func` (callable, optional): Function to apply during parsing (default: `np.sum`)

Returns: Array of study IDs that match the parsed expression

Processing flow:
1. Creates and builds a lexer instance
2. Creates a parser with the dataset, threshold, and function parameters
3. Builds the parser
4. Parses the expression and returns the keys' values from the result
4494	Convert FeatureTable to SciPy CSR matrix by converting data to dense format, then storing columns, index, and sparse CSR matrix values in a dictionary.
4495	A decorator that issues deprecation warnings for functions. When applied to a function, it warns users that the function will be deprecated in future versions. It can accept an optional custom deprecation message, otherwise uses a default warning message. The decorator preserves the original function's behavior while issuing the appropriate deprecation warning when the function is called.
4496	Converts 3D coordinates from one coordinate space to another using affine transformation matrix. Takes foci coordinates and transformation matrix as input, returns transformed coordinates in the target space.
4497	Converts XYZ coordinates to matrix indices using a transformation matrix. Takes an N x 3 array of XYZ coordinates and returns rounded integer matrix indices. The transformation applies a 3x4 matrix followed by reversing the column order and rounding to nearest integers.
4498	Apply a named transformation to a set of foci, returning them untransformed if the transformation doesn't exist.
4499	Vectorizes an image and masks out invalid voxels. Applies specified mask layers, optionally converts NaN values to 0, and returns a 1D array of masked voxel values. Can return data in either global masked space or full image space based on the in_global_mask parameter.
4500	Set the current mask by taking the conjunction of all specified layers, optionally including the global mask.
4501	Load multiple images from file into a 2D numpy array using a masker.

Args:
  filenames: A single filename or list of filenames pointing to valid images.
  masker: A Masker instance.
  nan_to_num: Optional boolean indicating whether to convert NaNs to zero.

Returns:
  An m x n 2D numpy array, where m = number of voxels in mask and n = number of images passed.
4502	Save a vectorized image to file by unmasking data using the provided masker, setting appropriate header information including data type and calibration min/max values, then writing the image to the specified filename using Nifti1Image format.
4503	Sets neurosynth's logging level either from the provided level parameter or from the NEUROSYNTH_LOGLEVEL environment variable, then returns the effective logging level.
4504	Expand an address into normalized strings with various formatting and transliteration options.
4505	Normalizes a string, tokenizes it, and normalizes each token using string and token-level options. Applies deterministic libpostal normalizations only, without generating multiple string variants. Optionally strips parentheticals and returns tokens with their types.
4506	Parse an address into its components using the specified language and country codes, with the address being decoded from UTF-8 if necessary.
4507	Hashes address components into normalized strings for grouping similar addresses together, acting as a blocking function for record linkage or near-duplicate detection. Takes labels and values of address components, plus optional language and geographic qualifiers, and returns hash values for comparison.
4508	Converts a Python dictionary to a namedtuple object, providing memory-efficient object representation.
4509	Returns the latest End-of-Day composite price for a stock ticker with optional date range filtering and multiple output formats (json, csv, object). Supports daily frequency resampling and handles multiple data sources per ticker.
4510	Return a pandas.DataFrame of historical prices for one or more ticker symbols, with optional start/end dates and metric specification.
4511	Method: `get_bulk_news`

Description: Retrieves bulk news data for institutional clients. If no file ID is provided, returns an array of available file IDs. If a file ID is provided, returns a download URL and metadata for that specific file.

Parameters:
- `file_id` (str, optional): The ID of the bulk news file to download
- `fmt` (str, default='json'): Format of the returned data ('json' or 'object')

Returns: 
- If `file_id` is provided: Dictionary containing download URL and metadata
- If `file_id` is not provided: Array of available file IDs
- If `fmt='object'`: Converts JSON response to object format using `dict_to_object` function

Note: Only available to institutional clients.
4512	Make HTTP request using the specified method and URL, handling errors and returning the response object.
4513	Get the application bearer token from client_id and client_secret by making an async POST request to Spotify's token endpoint with basic authentication.
4514	Make a request to the Spotify API with bearer authentication, handling retries, rate limiting, and various HTTP status codes including 401 (renew token), 429 (rate limit), 502/503 (retry), 403 (Forbidden), and 404 (NotFound).
4515	Get an album's tracks by Spotify ID, with optional limit, offset, and market parameters. Returns the request response containing the album tracks data.
4516	Get a Spotify artist by their ID.

Parameters:
- spotify_id (str): The Spotify ID to search by.

Returns:
- The result of the API request for the specified artist.
4517	Get an artist's albums by their Spotify ID.

Parameters:
- spotify_id (str): The Spotify ID of the artist
- include_groups (INCLUDE_GROUPS_TP, optional): Groups to include
- limit (int, optional): Maximum number of items to return (default: 20, min: 1, max: 50)
- offset (int, optional): Offset for pagination
- market (str, optional): ISO 3166-1 alpha-2 country code (default: 'US')

Returns:
- Response from the Spotify API request containing the artist's albums
4518	Get an artist's top tracks by their Spotify ID and country.
4519	Get related artists for an artist by their Spotify ID.
4520	Get Spotify artists by their IDs.

Parameters
----------
spotify_ids : List[str]
    The Spotify IDs to search with.

Returns
-------
Request response
    The response from the Spotify API request.
4521	Get a single category used to tag items in Spotify.

Parameters:
- category_id (str): The Spotify category ID for the category
- country (COUNTRY_TP): Country code
- locale (LOCALE_TP): Locale code

Returns: Request response for the specified category
4522	Get a list of Spotify playlists tagged with a particular category.

Parameters:
- category_id (str): The Spotify category ID for the category
- limit (int, optional): The maximum number of items to return (default: 20, min: 1, max: 50)
- offset (int, optional): The index of the first item to return (default: 0)
- country (COUNTRY_TP, optional): Country code

Returns:
- Request response containing the playlists for the specified category
4523	Get a list of categories used to tag items in Spotify, with optional pagination and localization parameters.
4524	Get a list of Spotify featured playlists with optional filtering by locale, country, and timestamp, returning up to 50 playlists with specified limit and offset.
4525	Get a list of new album releases featured in Spotify.

Parameters:
- limit : Optional[int] - The maximum number of items to return. Default: 20. Minimum: 1. Maximum: 50.
- offset : Optional[int] - The index of the first item to return. Default: 0
- country : COUNTRY_TP - COUNTRY

Returns:
- Request result containing new album releases data
4526	Get music recommendations based on seed artists, genres, and tracks with optional filtering parameters.
4527	Check if the current user is following one or more artists or Spotify users by their IDs.

Parameters:
- ids (List[str]): Comma-separated list of artist or user Spotify IDs (max 50)
- type (Optional[str]): ID type, either "artist" or "user" (default: "artist")

Returns:
- Response from the Spotify API containing follow status for each ID

The method makes a GET request to the /me/following/contains endpoint to verify following relationships.
4528	Get the albums of a Spotify artist by making an HTTP request and returning a list of Album objects. Supports pagination with limit and offset parameters, and optional filtering by include_groups and market.
4529	Loads all of the artist's albums asynchronously, handling pagination automatically. Returns a list of Album objects for the artist, optionally filtered by market country code. May take a long time depending on the number of albums.
4530	Get the total number of albums for an artist.

Parameters:
- market (Optional[str]): An ISO 3166-1 alpha-2 country code.

Returns:
- int: The total number of albums.
4531	Get Spotify catalog information about artists similar to a given artist based on community listening history. Returns a list of similar artists.
4532	Get the user's currently playing track.

Returns
-------
tuple
    A tuple of the context and track.
4533	Get information about the user's current playback and return a Player object representing the current playback.
4534	Get information about the user's available devices.

Returns
-------
devices : List[Device]
    The devices the user has available.
4535	Get tracks from the current user's recently played tracks.

Returns
-------
playlist_history : List[Dict[str, Union[Track, Context, str]]]
    A list of playlist history objects, where each object contains a timestamp, track, and context field.
4536	Replace all tracks in a playlist with the specified tracks, overwriting existing tracks. Returns the playlist ID.
4537	Reorder tracks in a playlist by specifying the start position, insertion position, and number of tracks to move. Returns the updated playlist's snapshot ID.
4538	Create a playlist for a Spotify user with the specified parameters and return the created playlist object.
4539	Retrieves a list of playlists for a user from Spotify within the specified limit and offset. Returns a list of Playlist objects.
4540	Get the tracks from an album on Spotify.

Parameters:
- limit (Optional[int]): The limit on how many tracks to retrieve for this album (default is 20).
- offset (Optional[int]): The offset from where the api should start from in the tracks.

Returns:
- List[Track]: The tracks of the album.
4541	Loads all tracks from an album with optional market parameter for track relinking, returning a list of Track objects. Uses pagination to handle albums with many tracks by fetching tracks in batches of 50 until all tracks are retrieved.
4542	Generate an OAuth2 URL for user authentication with Spotify, including parameters for redirect URI, scopes, and state.
4543	Retrieves an album from Spotify using the provided album ID and optional market parameter, returning an Album object.
4544	Retrieves an artist object using a Spotify ID by making an HTTP request to the Spotify API and returning an Artist instance populated with the retrieved data.
4545	Retrieves a track object using the provided Spotify ID by making an HTTP request and returning a Track instance.
4546	Retrieves a user by their Spotify ID through an HTTP request and returns a User object.
4547	Retrieves multiple albums from Spotify using a list of album IDs.

Parameters:
- ids: List of Spotify album IDs to look up
- market: ISO 3166-1 alpha-2 country code for market-specific results (defaults to 'US')

Returns:
- List of Album objects populated with album data from Spotify

The method joins the album IDs into a comma-separated string, makes an HTTP request to fetch the album data, and constructs Album objects from the response data.
4548	Retrieves multiple artists from Spotify using a list of IDs and returns them as Artist objects.
4549	Searches Spotify for tracks, playlists, artists, and/or albums using the specified query and parameters, returning a dictionary of the results. Raises TypeError if types is not iterable, or ValueError if an invalid search type is provided. The search results are limited to a maximum of 50 items.
4550	Extracts a Spotify ID from either a URI or open.spotify URL string, returning the ID portion. If the input doesn't match the expected patterns, returns the original string.
4551	A decorator factory that creates a decorator to assert an object has a specific attribute before executing the decorated function. If the attribute is missing, it raises a specified exception with a custom message. Supports both regular and asynchronous functions.
4552	Constructs an OAuth2 object from a spotify.Client instance by extracting the client ID and passing it to the class constructor.
4553	Constructs an OAuth2 authorization URL with the given parameters.

This function builds a complete OAuth2 authorization URL by:
- Requiring client_id and redirect_uri
- Optionally accepting scope, state, and secure parameters
- URL-encoding the redirect_uri and scope
- Formatting the URL using OAuth2._BASE template

Parameters:
- client_id (str): The OAuth2 client identifier
- redirect_uri (str): The URI to redirect to after authentication
- scope (str, optional): The requested permissions
- state (str, optional): A value to prevent CSRF attacks
- secure (bool, default=True): Whether to use HTTPS

Returns:
- str: The complete OAuth2 authorization URL
4554	Returns a dictionary of URL parameters containing client_id, redirect_uri, and optional scope and state values, with redirect_uri and scope properly URL-encoded.
4555	Returns URL parameters as a string in the format "key1=value1&key2=value2&..." by joining key-value pairs from self.attrs.items().
4556	get the track object for each link in the partial tracks data

Returns
-------
tracks : List[Track]
    The tracks
4557	Get all playlist tracks from the playlist, fetching them in batches of 50 if not already loaded, and return them as a list of PlaylistTrack objects.
4558	Resume playback on the user's account, optionally targeting a specific device. If no device is specified, uses the user's currently active device.
4559	Transfer playback to a specified device and control its playback state. If ensure_playback is True, start playing on the new device; otherwise, maintain current playback state.
4560	Get the full object from Spotify using the `href` attribute by making an HTTP GET request and returning a new instance of the class with the retrieved data.
4561	Executes domain expiration date logic and returns the validation status based on domain and IP validity, HTTP status, and IANA database comparison. Handles different cases for domain vs IP validation and returns appropriate status or None if expiration date cannot be determined.
4562	Converts a given month representation into a unified lowercase format. Returns the standardized month name (e.g., "jan", "feb", etc.) if the input matches any of the predefined representations, otherwise returns the original input.
4563	Update code URLs by reading all files in PyFunceble and tests directories, skipping ignored files and __pycache__ directories, then call _update_docs on each valid file path.
4564	Check if the current version is greater than the older version by comparing them using Version.check_versions method, returning True if current version is greater, False otherwise.
4565	Check if the current git branch is named "dev" by executing `git branch` command and parsing its output to detect a line starting with "*" containing "dev".
4566	Check if the current version requires deprecation by comparing version numbers. Returns True if any of the first two version components in current_version are greater than the corresponding components in version_yaml, indicating a newer version that needs to be deprecated. Otherwise returns False.
4567	Backup the current execution state to the autocontinue log file if auto_continue is enabled, saving tested, up, down, and invalid counter states along with existing backup content.
4568	Restore data from backup content when auto_continue is enabled and file exists in backup. Updates counters for up, down, invalid, and tested statuses, with fallback to alternative key names for backward compatibility.
4569	Check if a given line should be ignored based on regex pattern matching. Returns True if the line matches any of the defined ignore patterns, False otherwise.
4570	Handle options data to extract domains, returning a list of domains or True based on aggressive mode.
4571	Extract the base of the given element, handling both single elements and lists of elements. For URLs, use the checker to extract the base. For non-URL strings containing "/", return the part before the first "/". Otherwise, return the element unchanged.
4572	Format extracted adblock lines into a list of valid domains or IPs for testing.
4573	Get the HTTP status code by making a HEAD request to the target URL, returning the status code or None if an exception occurs during the request.
4574	Return the HTTP code status by extracting and validating it against predefined lists of valid status codes, returning the code if valid or "***" if invalid/missing, otherwise return None when status code extraction is inactive.
4575	Check the syntax of a given domain string and return its validity. Returns None for empty or non-string inputs.
4576	Check if the given domain is a subdomain.

:param domain: The domain we are checking.
:type domain: str

:return: The subdomain state.
:rtype: bool

.. warning::
    If an empty or a non-string :code:`domain` is given, we return :code:`None`.

If the domain is valid (non-empty string), it loads the configuration and checks if the domain is a subdomain. Returns None for invalid inputs.
4577	Check the syntax of the given IPv4 address. Returns True if valid, False if invalid, and None if the input is empty or not a string.
4578	Check if a given IP string represents an IPv4 range.

This function validates whether the provided IP parameter is a non-empty string and then checks if it represents an IPv4 range using the Check class. It loads configuration silently before performing the check. Returns True if the IP is a valid IPv4 range, False if it's not a range, and None for invalid inputs (empty, None, or non-string values).

Parameters:
    ip (str): The IP address string to check

Returns:
    bool: True if IP is an IPv4 range, False if not a range, None for invalid inputs

Note: This function is marked as unreachable code (pragma: no cover) and includes a warning about returning None for empty/non-string inputs.
4579	Check the syntax of a given URL and return its validity as a boolean. Returns None if the URL is empty or not a string. Uses the Check class to perform the validation after loading configuration.
4580	Load the PyFunceble configuration, optionally initializing directories and updating with custom configuration values.
4581	Print a friendly message with social media prompts and feedback invitation, shown randomly based on configuration.
4582	Check if the given string is a valid URL and download it if necessary. If the URL is valid and the file doesn't exist locally or no tests have been run yet, download the file and update the test file path. Return True if successful, False otherwise.
4583	Manages the loading of the URL system by checking if the url_file is a valid URL and initiating the file to test accordingly.
4584	**Summary:** The `_print_header` method determines whether to display a header based on configuration settings. It prints a newline and then displays either a "Less" or "Generic" header depending on the `less` configuration flag, but only if quiet mode is disabled and the header hasn't already been printed. Once printed, it marks the header as printed in the configuration.
4585	Manage database, autosave, and autocontinue systems when reading a file, handling status-based logic for up/valid entries, and performing cleanup and backup operations.
4586	Manages domain testing by setting up the domain to test, determining its status through syntax or regular testing, running file decision logic, and returning the domain with its status. If a domain is provided, it formats the domain, gets its status, runs file decision logic, and prints the result in simple mode before returning the domain and status. If no domain is provided, it returns None.
4587	Method: url(self, url_to_test=None, last_url=None)
Summary: Manages URL testing by setting the URL to test, determining the appropriate status check (syntax or URL), executing file decision logic, and returning the test results. If a URL is provided, it performs syntax or URL status checking based on configuration, runs file decision logic, and optionally prints simple output. Returns the tested URL and its status, or None if no URL is provided for testing.
4588	Prints a colored ASCII logo based on test results. Uses yellow for initial display, green if 50% or more tests pass, red otherwise. Respects quiet mode configuration.
4589	Format the extracted domain by removing comments and whitespace, returning the cleaned domain or IP address, or an empty string if the line is a comment.
4590	Extract all non-commented lines from a file for testing purposes, handling potential UTF-8 encoding issues and raising FileNotFoundError if the file doesn't exist.
4591	Method `file()` manages testing of domains from a file path, one domain per line. It filters and processes the domain list, optionally converting domains to IDNA format and applying hierarchical or standard sorting. The method removes already tested domains from the database, then tests the remaining domains and returns the results. If nothing is left to test, it prints a message indicating so.
4592	Method `file_url` manages file URL testing by:
1. Filtering URLs from a file list
2. Removing previously tested URLs from the database
3. Applying hierarchical sorting if enabled
4. Testing each URL and returning results
5. Handling empty lists by printing a "Nothing to test" message

The method processes URLs line-by-line from a file, filters out already tested ones, sorts remaining URLs if requested, and executes tests on each URL, returning the test results.
4593	Switches a PyFunceble configuration variable or custom boolean value to its opposite (True becomes False and vice versa). If the variable is not a boolean, raises an exception. Returns the opposite boolean value.
4594	Get the status while testing for an IP or domain, checking expiration date and returning appropriate status.
4595	Handle the backend of the given status by generating a status file based on whether the caught status is valid or invalid, then return the parsed status.
4596	Get the structure to work with, either from a local file or by downloading it from a link, and update it with configuration names.
4597	Creates a directory and all its parent directories if they don't exist. If the directory already exists, the function does nothing. Handles nested directories by recursively creating parent directories first. Updates file permissions when running under Travis CI.
4598	Delete directories that are not registered in the defined structure, keeping only the directories specified in the structure.
4599	Set the paths to the configuration files and return tuple of (parsed_config_path, default_config_path).
4600	Load the .PyFunceble.yaml configuration file and install required supporting files, with fallback to default configuration file if not found.
4601	Download the production configuration file from GitHub, update the URL based on the current version, and save it to both the default location and the specified config path. Returns the download status.
4602	Download `iana-domains-db.json` if not present, updating the link according to the current version. If the file doesn't exist or the current version is not cloned, download the file from the updated link and return the download status. Otherwise, return None.
4603	Download `public-suffix.json` if not present or if not in a cloned version.
4604	Download the latest version of `dir_structure_production.json` file to the default output directory if the current version is not cloned or if the destination file does not exist, otherwise return None.
4605	Merge older configuration into new one by combining upstream_config with PyFunceble.CONFIGURATION and removing specified keys.
4606	Load and merge configuration by checking environment variable or prompting user input, then save the merged configuration.
4607	Split a version string by dots and return either just the numeric parts or both numeric and non-numeric parts as a tuple.
4608	Compare local and upstream versions and return True if local < upstream, False if local > upstream, None if equal.
4609	Check if the current PyFunceble version is a cloned development version by verifying the existence of specific files and directories typically found only in cloned repositories. Returns True if all required files and directories are present, False otherwise.
4610	Method that handles non-existent configuration indexes by initializing default values for HTTP code and referer if they don't exist in the PyFunceble.INTERN dictionary.
4611	Return the analytic directory path based on the domain status, appending different subdirectories depending on whether the status is potentially up, potentially down, suspicious, or other.
4612	Generate a unified file with consolidated test results instead of separate tables for each status. The method constructs the output path and prints test information in either 'Less' format (with fewer details) or 'Generic_File' format (with comprehensive details including expiration date, source, HTTP code, and timestamp), depending on the configuration settings. The unified file is written to the specified output directory when the unified file generation is enabled and a file to test is defined.
4613	Generate a file according to the domain status, handling both split and unified file outputs based on configuration settings.
4614	Check if file production is allowed based on domain status and test conditions. Returns True if file should not be produced, False if it should be produced.
4615	Extract extension from a line in the public suffix repository, handle IDNA encoding, remove wildcard prefixes, and update the public suffix database with formatted extensions to avoid duplicates.
4616	Load the public suffix database into the system if it hasn't been loaded already, reading from the destination file and converting it to a dictionary format.
4617	Implements standard alphabetical sorting by removing special characters from input elements. Takes a string element, processes it through regex replacement to sanitize special characters, and returns the cleaned string with special characters removed.
4618	This method implements hierarchical sorting for domain names by reversing the typical dot-separated order. Instead of sorting from left to right (e.g., `aaa.bbb.ccc.tdl` as `aaa, bbb, ccc, tdl`), it sorts from right to left (e.g., `tdl, ccc, bbb, aaa`). It handles URL validation, extracts extensions, and processes public suffix lists to correctly identify and reorder domain levels. The method also cleans special characters and returns a formatted string suitable for hierarchical sorting.
4619	Initializes the IANA database if it doesn't exist or is empty by loading the local iana_db into the global PyFunceble.INTERN dictionary.
4620	Return the referer/WHOIS server for a given domain extension by checking IANA records and manual mappings.
4621	Extract extensions from IANA domain database HTML content and yield each extension with its referer URL.
4622	Update the content of the `iana-domains-db` file by iterating through extensions from the IANA website and updating the database when changes are detected, then save the updated database to a JSON file.
4623	Search for domain or URL related to the original URL or domain and return the mined domains or URL.
4624	Retrieve mining information from backup file if mining is activated and backup exists, otherwise initialize empty mined data.
4625	Backup mined information to a JSON file if mining is activated.
4626	Add mined information to the internal database, extending existing entries and removing duplicates.
4627	Remove the currently tested element from the mining data by deleting it from the mined database entries for the current file, then back up the updated data.
4628	Return the list of mined domains or URLs that can be added to the list queue by mining the current file.
4629	**Summary:** Processes and structures mining database logic by loading mined data, adding it to the global database, and backing up the results when mining is activated.
4630	Get and return the content of the given log file as a dictionary, reading from JSON if the file exists, otherwise return an empty dictionary.
4631	Write the given dictionary content to a JSON file if file creation is enabled in the configuration.
4632	Logs WHOIS record information to a file when debug and logs are enabled, including domain, record, and referer details.
4633	Logs the extracted expiration date from a WHOIS record, including domain information and WHOIS server referer, to a timestamped log file. If enabled, it also shares the log data with an API endpoint.
4634	Logs the case when a referer is not found by writing to a log file and optionally sharing with an API.
4635	Method `_before_header` checks if file generation is allowed and the output file doesn't exist, then writes header information including PyFunceble repository link, generation date, and template-specific header to the file. If no header is available, it only writes the link and date.
4636	Constructs a table header with specified separators and column sizes. Takes a list of data and their corresponding sizes, formats them according to the given separators, and returns a list containing the formatted header data and optionally a separator line. The header size is dynamically calculated based on the input data and column widths, using string formatting with %-style placeholders. If a header separator is provided, it also returns a separator line with the same width as the header content.
4637	Method `header` manages and creates column header templates for different status types. It handles various templates including Generic, up, valid, down, invalid, Less, Percentage, and HTTP. The method determines which header to use based on the current template and status configurations, removes unnecessary columns (like Analyze Date or HTTP Code) based on configuration settings, and optionally prints the header to screen and/or writes it to a file. The `do_not_print` parameter controls whether the header is actually outputted.
4638	Constructs a data table with specified string sizes.

This method creates an ordered dictionary mapping data items to their maximum print sizes. It validates that the data and size lists have equal length, raising an exception if they don't. The resulting dictionary contains all data information with corresponding maximum sizes for printing.

Args:
    size (list): The maximal length of each string in the table

Returns:
    OrderedDict: A dictionary mapping data items to their maximum print sizes

Raises:
    Exception: If data and size lists have different lengths

Example:
    >>> result = _data_constructor([10, 20, 30])
    >>> # Returns OrderedDict with data items mapped to size limits [10, 20, 30]
4639	Get the size of each column from the header by extracting values from the header dictionary and returning them as a list.
4640	Method `_colorify` takes a string input and returns a colored string based on the status information stored in `self.data_to_print[1]`. The method applies different background colors (green for up/valid status, red for down status, and cyan for other statuses) when the template is either "Generic" or "Less". The coloring is achieved using PyFunceble's Fore and Back color constants.
4641	Method `_json_print` manages JSON template output by handling file operations and data formatting. It checks if the output path exists and is a file, reads existing JSON content, extends it with new data, applies sorting (standard or hierarchical), and saves back to the file. If the output doesn't exist, it creates a new JSON file with the data. If output is empty or improperly formatted, it raises exceptions.
4642	Method `data` manages and inputs data to the table based on template and configuration settings. It handles different templates including JSON, and processes data accordingly. The method constructs data to be printed, applies formatting and coloring, and outputs to both console and files when configured. It raises an exception if `data_to_print` is not a list. The method supports various templates and handles special cases like headers and alone cases.
4643	Save the current execution time to a log file, tracking start and stop times, and calculate total execution time, with special handling for the final saved state.
4644	Calculate the difference between starting and ending time, returning days, hours, minutes, and seconds as a dictionary with zero-padded string values.
4645	Formats the calculated execution time into a human-readable string format "hours:minutes:seconds" by calling the internal `_calculate` method with optional start and end times.
4646	Return the list of files to delete by walking through the output directory and collecting all files except .gitignore and .keep.
4647	Returns a list of database file paths to be deleted, including dir_structure, iana, public_suffix, inactive_db, mining, and whois_db files located in the current directory.
4648	Delete almost all discovered files, with option to clean everything. Removes files from the deletion list and optionally database files if clean_all flag is True, then reloads the current directory.
4649	Get the hash of the file using the specified algorithm and return its hexdigest.
4650	Get hash of the given data using the specified algorithm.

**Parameters:**
- algo (str): The hashing algorithm to use

**Returns:**
- str: The hexadecimal digest of the hashed data

**Process:**
1. Retrieves the hash algorithm function from hashlib
2. Updates the hash object with the instance's data
3. Returns the hexadecimal representation of the hash
4651	Return the hash of the given file using the specified algorithm or all valid algorithms. If the algorithm is "all", return a dictionary of hashes for all valid algorithms. If only_hash is True and algorithm is not "all", return only the selected hash value. Handle cases where the file path does not exist or data is empty by returning None.
4652	Execute a command and return its output. If the command fails (non-zero return code), return the error output; otherwise, return the standard output.
4653	Remove a given key or list of keys from the main dictionary and return the modified dictionary, or return None if the main dictionary is not actually a dictionary.
4654	Rename keys in a dictionary with optional strict matching. If strict=True, renames exact key matches. If strict=False, renames keys containing the old key as a substring. Returns the modified dictionary or None if inputs are invalid.
4655	Merge the content of to_merge into the main dictionary, handling nested dictionaries and lists recursively. For conflicting keys, dictionaries are merged recursively, lists are merged based on the strict parameter (index-based or content-based), and other types are overwritten by the values from to_merge. Returns the merged dictionary.
4656	Save a dictionary to a JSON file at the specified destination path, handling potential Unicode encoding issues by attempting UTF-8 encoding if needed.
4657	Save a dictionary to a YAML file with specified formatting options.

Parameters:
- destination (str): Path to the output YAML file
- flow_style (bool): Whether to use flow style formatting (default: False)

The method writes the object's main dictionary to the specified destination file using YAML format with UTF-8 encoding, 4-space indentation, and Unicode support. The destination file is overwritten if it already exists.
4658	Fixes and returns a properly formatted path from a list of path components, handling different directory separators and filtering out empty components.
4659	Writes or appends string data to a file based on overwrite parameter. If overwrite is True or file doesn't exist, writes data to file (overwriting existing content). If overwrite is False and file exists, appends data to end of file. Only writes data if it's a non-empty string.
4660	Read a file's content with UTF-8 encoding, falling back to default encoding on UnicodeDecodeError, and return the content as a string.
4661	Method that returns a sorted list with duplicates removed. It converts the main list to a set to eliminate duplicates, then sorts the result using string comparison (case-insensitive). If a TypeError occurs during processing, it returns the original main list unchanged.
4662	Merge a list into the main list either in strict mode (respecting indices) or non-strict mode (allowing duplicates). In strict mode, elements are merged recursively if they are dicts or lists, otherwise the to_merge element is appended. In non-strict mode, only unique elements from to_merge are appended to the main list. Returns the merged result list.
4663	Return a list of strings from self.data that don't match the given regex pattern.
4664	Method `match` executes regex matching on input data and returns results based on configuration flags. It compiles the regex pattern and uses either `re.findall` (when `rematch` flag is True) or `re.search` (otherwise). If `return_data` is True and there's a match, it processes the result to return either the full match data or a specific group. If `return_data` is False, it simply returns a boolean indicating match success. The method returns False if no match is found.
4665	Method `replace` is used to replace matched strings with another string. It takes the regex pattern, replacement string, and data to perform the replacement on. If a replacement string is provided, it uses the `substrings` function to do the replacement, otherwise it returns the original data unchanged. The method returns the modified data after replacement as a string.
4666	Count the number of domains for each status (up, down, invalid) and increment the appropriate counter based on the domain's status.
4667	Calculate the percentage of each status (up, down, invalid) based on their counts compared to the total number of tested items, and update the percentage counters in PyFunceble.INTERN["counter"]["percentage"].
4668	Prints test percentages for each status (up, down, invalid) on screen and file, with optional syntax checking and quiet mode support.
4669	Method `is_url_valid` checks if a given URL is valid by validating its domain or IP address. It supports optional return of the URL base or a formatted version with IDNA conversion. Returns a boolean indicating validity, or the URL base/formatted URL based on parameters.
4670	Check if a given domain is valid, with optional subdomain verification. Returns True if the domain is valid according to regex patterns and database checks, False otherwise.
4671	Check if the given domain is a subdomain by validating it through the is_domain_valid method with subdomain_check=True parameter. Returns a boolean indicating the validity of the subdomain.
4672	Executes the syntax handling logic based on the test type (domain, ip, or url) and returns the appropriate syntax status (valid or invalid). Raises an exception for unknown test types.
4673	Method that reformats historical inactive database files from old format to new format, handling both digit and non-digit keys by adjusting timestamps to ensure automatic retesting, then merges the data into the current database and removes the old file.
4674	Retrieves and returns the current content of the inactive-db.json file by checking if the database subsystem is activated, reformatting historical formatting errors, and merging current database content with existing data if the file exists.
4675	Save the current database into the inactive-db.json file.
4676	Get the timestamp for saving the current list, considering database state and time constraints. Returns current timestamp if database is inactive or conditions aren't met, otherwise returns most recent timestamp or updated timestamp based on time intervals.
4677	Get the content of the database, including inactive entries when the database subsystem is activated and not empty. Returns a list containing the database content.
4678	Check if the currently tested element is present in the database by verifying its existence in either the flattened inactive database or the inactive database structure. Returns True if found, False otherwise.
4679	Retrieve data from database and initialize WHOIS database in PyFunceble.INTEN if it exists or create empty one if it doesn't exist.
4680	Backs up the database to its file if authorization is granted.
4681	Check if the element is in the database by verifying authorization, file path existence in database, and element presence in the database for the given file path. Returns True if all conditions are met, False otherwise.
4682	Check if the current time is older than the time stored in the database by verifying authorization, database presence, and comparing epoch timestamps. Returns True if database time is in the past, False otherwise.
4683	Get the expiration date from the database if authorization is granted, element is in database, and expiration date is in the future. Returns the expiration date if available, otherwise returns None.
4684	Add the currently tested element into the database, updating its epoch, state, and expiration date based on authorization and existing data.
4685	Set Travis CI permissions to avoid issues before committing by changing ownership, group permissions, and git configuration in the Travis build directory.
4686	Method `_travis` handles the autosave logic specifically for Travis CI environments. It checks if Travis CI configuration is enabled, verifies authorization based on time thresholds, and performs git operations including adding files, committing changes, and pushing to the repository. The method supports both regular autosave commits and final commit messages, and can execute custom commands before ending the process. It uses configuration settings for timing, commit messages, and branch names, and exits the program after successful completion.
4687	Method: nslookup
Summary: Implements UNIX-style nslookup functionality to resolve domain names or IP addresses into network address information. The method attempts to retrieve address information using socket operations, handling both domain name resolution and IP address lookups. For domain names, it uses getaddrinfo to obtain address information, while for IP addresses, it uses gethostbyaddr to get hostname and alias information. The method returns True on successful resolution or False when resolution fails due to network errors or DNS issues. The method also supports additional test data collection when 'current_test_data' is present in PyFunceble.INTERN.
4688	Implementation of UNIX whois.

:param whois_server: The WHOIS server to use to get the record.
:type whois_server: str

:param domain: The domain to get the whois record from.
:type domain: str

:param timeout: The timeout to apply to the request.
:type timeout: int

:return: The whois record from the given whois server, if exist.
:rtype: str|None
4689	Execute the logic behind the URL handling and return the status of the URL based on HTTP code validation.
4690	Return the referer/WHOIS server for the current domain extension, or None/False based on configuration and database lookup results.
4691	Get current object behind the proxy. Useful for performance reasons or passing object to different context. Returns the real object by calling the local object with stored args and kwargs, or getattr if local object has __release_local__ attribute. Raises RuntimeError if no object is bound to the proxy.
4692	Yields names of standard library modules by iterating through Python's standard library paths, including both platform-specific and non-platform-specific locations, and their dynamic loadable subdirectories.
4693	Yields standard module names by filtering out names that start with '_' or contain '-', and only including names with valid extensions (.so, .py, .pyc) or no extension.
4694	Yield line numbers of unused imports from pyflakes messages.
4695	Yield line number and module name of unused imports.
4696	Yield line numbers where star imports are used in pyflakes messages.
4697	Yield line number, undefined name, and possible origin module for import star usage messages.
4698	Yields line numbers where unused variables are detected in the given messages.
4699	Function that yields line numbers of duplicate keys in source code by filtering pyflakes messages, creating a key-to-messages mapping, and checking if each duplicate key entry actually has the key in its line of code.
4700	Create a dictionary that maps each message key (first argument of message_args) to a list of messages with that key.
4701	Return messages from pyflakes checker, handling Python 2 unicode encoding and various exceptions during analysis.
4702	Extracts and returns the package name from an import statement line. Returns None for non-import lines or doctests. Assumes the line contains a valid import statement starting with 'import' or 'from'. Splits the line by whitespace and takes the second element (index 1), then splits by '.' to get the base package name. Performs assertions to ensure the line doesn't contain problematic characters and that the extracted package name doesn't contain spaces.
4703	Returns True if an import statement spans multiple lines, False otherwise. Checks for parentheses or doctests, otherwise delegates to multiline_statement function.
4704	Return True if the given line is part of a multiline statement, checking for continuation characters, colons, semicolons, and valid tokenization.
4705	Filter unused imports from a "from module import a, b, c" statement, returning the filtered line or 'pass' if all imports are unused.
4706	Breaks up a line containing multiple imports into separate lines, one import per line, maintaining proper indentation and sorting imports alphabetically.
4707	Filter and yield source code with various elements removed or modified based on specified options like unused imports, variables, duplicate keys, and star imports.
4708	Return dictionary that maps line number to message.
4709	Return line with the star import expanded by replacing '*' with sorted undefined names.
4710	Return '' if first occurrence of the key otherwise return `line`.
4711	Return True if `line` is a dict entry that uses `key`, False otherwise. Handles multiline cases and validates syntax.
4712	Return True if value is a literal or a name.
4713	Yield line numbers of unneeded "pass" statements in Python source code, detecting both leading and trailing pass statements that can be safely removed.
4714	Removes useless "pass" statements from source code by filtering out lines identified by `useless_pass_line_numbers()` function, yielding only the lines that are not marked for removal.
4715	Return the leading whitespace characters from a line, or an empty string if the line is empty or contains only whitespace.
4716	Return the line ending characters from a given line by finding the non-whitespace characters from the right side and returning the trailing whitespace portion.
4717	Returns code with all filtering operations applied iteratively until no more changes occur. Applies various code cleanup operations like removing unused imports, duplicate keys, and unused variables, while handling special cases like 'nonlocal' statements and maintaining source stability through iterative filtering.
4718	Split a comma-separated string into a set of stripped strings, excluding empty strings.
4719	Return True if filename is a Python file by checking for .py extension or detecting Python shebang in the first line.
4720	Return True if file matches exclude pattern, False otherwise. Checks if filename starts with '.' or matches any pattern in exclude list.
4721	Yields filenames that match the given criteria, recursively processing directories if specified and excluding files/directories that match the exclude patterns.
4722	Function `_main` processes command-line arguments to configure and execute autoflake, a tool for removing unused imports and variables from Python code. It supports options like in-place editing, recursive directory traversal, exclusion patterns, and various removal strategies (unused imports, duplicate keys, unused variables). The function validates arguments, processes files using `find_files` and `fix_file`, and returns an exit status indicating success (0) or failure (1).
4723	Read the data encoding the ObtainLease response payload and decode it into its constituent parts, including unique identifier, lease time, and last change date, while validating the KMIP version and handling potential missing data attributes.
4724	Writes the ObtainLease response payload data encoding to a stream, including unique identifier, lease time, and last change date if they exist, then writes the complete encoded data to the output stream.
4725	Writes the Cancel request payload data encoding to a stream, including asynchronous correlation value if present, and handles KMIP version compatibility.
4726	Reads and decodes the Cancel response payload from an input stream, extracting asynchronous correlation value and cancellation result if present, while validating the encoded data against the specified KMIP version.
4727	Creates a Name object with the specified value and type, performing type checking and conversion as needed.
4728	Reads and decodes Digest object data from a stream, parsing hashing algorithm, digest value, and key format type based on the specified KMIP version.
4729	Writes the Digest object data to a stream by encoding its hashing_algorithm, digest_value, and key_format_type fields, then writes the complete encoded data to the output stream.
4730	Creates a Digest object using specified hashing algorithm, digest value, and key format type, with SHA_256 as default hashing algorithm and empty byte string as default digest value.
4731	Reads and decodes ApplicationSpecificInformation object data from a stream, parsing application namespace and data, then validates the parsed information.
4732	Writes the ApplicationSpecificInformation object data to a stream by encoding its application namespace and data, then writes the complete encoded data to the output stream.
4733	Creates an ApplicationSpecificInformation object from application namespace and data strings by constructing ApplicationNamespace and ApplicationData objects and returning a new ApplicationSpecificInformation instance with these components.
4734	Reads and decodes DerivationParameters struct data from an input stream, parsing constituent parts like cryptographic parameters, initialization vector, derivation data, salt, and iteration count based on KMIP version.
4735	Writes the DerivationParameters struct data encoding to a stream, handling optional cryptographic parameters, initialization vector, derivation data, salt, and iteration count based on the specified KMIP version.
4736	Reads and decodes the Get request payload from an input stream, extracting constituent parts like unique identifier, key format type, key compression type, and key wrapping specification based on the KMIP version.
4737	Writes the Get request payload data encoding to a stream, including optional fields like unique identifier, key format type, key compression type, and key wrapping specification, then writes the complete payload to the output stream.
4738	Reads and decodes the Get response payload from an input stream, extracting object type, unique identifier, and secret attributes according to the specified KMIP version. Raises ValueError if required fields are missing.
4739	Writes the Get response payload data to a stream, including object type, unique identifier, and secret attributes with validation checks.
4740	Reads and decodes the SignatureVerify request payload from an input stream, extracting fields like unique identifier, cryptographic parameters, data, digested data, signature data, correlation value, and initialization/finalization indicators based on the KMIP version. Raises ValueError if required data attributes are missing.
4741	Writes the SignatureVerify request payload data encoding to a stream, including all optional components like unique identifier, cryptographic parameters, data, digested data, signature data, correlation value, and processing indicators, then writes the complete encoded data to the output stream.
4742	Reads and decodes the signature verification response payload from an input stream, extracting fields like unique identifier, validity indicator, data, and correlation value based on the specified KMIP version. Raises ValueError if required fields are missing or if the payload is oversized.
4743	Process a KMIP request message by handling its header components (protocol version, timestamp, asynchronous indicator, authentication, batch options) and routing batch items for processing, returning a response with max response size and protocol version.
4744	Build a ResponseMessage with a single error result containing the specified version, reason, and message.
4745	Process a TemplateAttribute object and extract its attribute values into a dictionary format, validating attribute support, multivalued properties, and index constraints while raising appropriate exceptions for unsupported attributes, missing indices, and duplicate single-valued attributes.
4746	Method `_get_attributes_from_managed_object` retrieves attribute values from a managed object based on specified attribute names. It iterates through the attribute names, checks if each attribute is supported and applicable to the object type, and attempts to get the attribute value. If successful, it creates attribute objects using an attribute factory and appends them to a list, handling both single-valued and multi-valued attributes. Returns a list of retrieved attributes.
4747	Returns the attribute value from the kmip.pie managed object based on the given attribute name. Handles various attribute types including Unique Identifier, Name, Object Type, Cryptographic Algorithm, and others, with specific processing for each. Returns None for unrecognized attributes or attributes not currently supported.
4748	Sets attributes on a managed object after validating they are applicable to the object type, raising an exception if not applicable.
4749	Set attribute values on a KMIP pie managed object, handling both single-valued and multi-valued attributes with validation to prevent duplicates and overwrites.
4750	Determine if object access is allowed based on policy settings and session parameters. Returns True if access is granted, False otherwise. Checks policy section, object type, and operation permissions, supporting ALLOW_ALL, ALLOW_OWNER, and DISALLOW_ALL policies.
4751	Writes the Decrypt request payload data encoding to a stream, including unique identifier, cryptographic parameters, data, and IV/counter/nonce if present, raising ValueError if data attribute is missing.
4752	Creates a secret object of the specified type with the given value, returning the newly constructed secret object. Raises TypeError if the secret type is unrecognized. Supports various secret types including certificates, symmetric keys, public/private keys, split keys, templates, secret data, and opaque data.
4753	Sets a specific configuration setting value by calling the appropriate private setter method based on the setting name provided. Raises ConfigurationError if the setting is not supported or invalid.
4754	Load configuration settings from a file, overwriting current settings. Raises ConfigurationError if file doesn't exist or contains invalid settings. Logs the loading process. Uses ConfigParser to read the file and delegates parsing to _parse_settings and parse_auth_settings methods.
4755	Returns the integer bitmask value representing the combined cryptographic usage mask enums for database storage.
4756	Returns a list of enums.CryptographicUsageMask Enums by converting an integer value from the database. Takes an integer value and SQL dialect as arguments, checks each enum value using bitwise operation, and returns matching enums in a list.
4757	Reads the encoding of a LongInteger from an input stream, validates its length, and unpacks the value. Raises InvalidPrimitiveLength if the length is invalid.
4758	Writes the encoding of a LongInteger to the output stream as a signed 64-bit integer in network byte order.
4759	Method `validate` verifies that the value of the LongInteger is valid by checking:
1. Value is not None and is of type int or long (using six.integer_types for compatibility)
2. Value is within the range of signed 64-bit integer (between LongInteger.MIN and LongInteger.MAX)

Raises:
- TypeError: if value is not of type int or long
- ValueError: if value exceeds signed 64-bit integer limits (too large or too small)
4760	Reads the encoding of a BigInteger from an input stream and converts it to an integer value, handling two's complement for negative numbers.
4761	Writes the BigInteger encoding to an output stream using specified KMIP version, handling negative values through two's complement conversion and proper byte packing.
4762	Verify that the BigInteger value is valid, raising TypeError if invalid.
4763	Validates that the Enumeration value is valid by checking:
- The enum is of type EnumMeta
- The value is of the expected Enum subtype
- The value can be represented by an unsigned 32-bit integer
- The value is within accepted min/max bounds

Raises TypeError for invalid enum types or value types, and ValueError for values outside the accepted range.
4764	Reads a boolean value from an input stream and validates it, raising ValueError if the value is not 0 or 1.
4765	Writes the Boolean object's value to the output stream as an unsigned 64-bit integer. Raises an error if writing fails.
4766	Writes the encoding of the Boolean object to the output stream using the specified KMIP version, inheriting from the parent class and writing the value.
4767	Validate that the Boolean object's value is of type bool, raising TypeError if invalid.
4768	Reads the encoding of an Interval from an input stream, validates its length and padding bytes, and decodes the interval value. Raises InvalidPrimitiveLength if the length is invalid, or InvalidPaddingBytes if padding bytes are not zero.
4769	Validate that the Interval's value is valid, raising TypeError for incorrect types and ValueError for values outside the accepted range of unsigned 32-bit integers.
4770	Retrieves all relevant key wrapping data fields and returns them as a dictionary, including encryption key information, MAC signature key information, wrapping method, MAC signature, IV counter nonce, and encoding option. Empty dictionaries are returned for any fields that are not populated.
4771	Sets the key wrapping data attributes using a dictionary, handling nested dictionaries for encryption and MAC signature key information, and their cryptographic parameters. Raises TypeError if the input is not a dictionary.
4772	Validate that the contents of the PublicKey object are valid, checking types of all attributes including value (bytes), cryptographic_algorithm (CryptographicAlgorithm enumeration), cryptographic_length (integer), key_format_type (KeyFormatType enumeration), cryptographic_usage_masks (list of CryptographicUsageMask enumerations), and names (list of strings). Raises TypeError for invalid types and ValueError for invalid key format type.
4773	Validate that the contents of the SecretData object are valid, checking that:
- self.value is bytes
- self.data_type is a SecretDataType enumeration
- self.cryptographic_usage_masks are all CryptographicUsageMask enumerations
- self.names are all strings

Raises TypeError if any attribute has invalid type.
4774	Validate that the OpaqueObject contents are valid by checking:
- self.value is bytes
- self.opaque_type is an OpaqueDataType enumeration
- self.names are all strings

Raises TypeError for any invalid types.
4775	Converts an attribute name string to its corresponding Tags enumeration value. Raises ValueError for non-string inputs or unrecognized attribute names.
4776	Converts an attribute tag enumeration value to its corresponding attribute name string by looking up the tag in the attribute_name_tag_table. Raises ValueError for invalid or unrecognized tags.
4777	A utility function that computes a bit mask from a collection of enumeration values by combining their integer values using bitwise OR operation.
4778	Returns a list of enumeration values that match the given bit mask by checking if the bitwise AND of each enumeration value's bit and the mask equals the enumeration value itself.
4779	Checks if a given value is a valid composite bit mask of enumeration values from specified mask enumeration classes.

Args:
    enumeration (class): A mask enumeration class (CryptographicUsageMask, ProtectionStorageMask, or StorageStatusMask)
    potential_mask (int): A potential bit mask value to validate

Returns:
    bool: True if potential_mask is a valid bit mask of the enumeration, False otherwise

The function validates that all bits set in potential_mask correspond to valid enumeration values, ensuring it's a proper combination of allowed bit flags.
4780	Reads and decodes the CreateKeyPair request payload from an input buffer, handling different KMIP versions by parsing common, private key, and public key template attributes or attributes objects accordingly.
4781	Writes the CreateKeyPair request payload data encoding to a buffer, handling different KMIP versions by appropriately processing template attributes for common, private, and public key components.
4782	Reads and decodes the CreateKeyPair response payload from an input buffer, extracting private and public key unique identifiers and optionally template attributes based on KMIP version. Raises InvalidKmipEncoding if required identifiers are missing.
4783	Writes the CreateKeyPair response payload data encoding to a buffer, including private and public key unique identifiers and their template attributes, raising InvalidField if required fields are missing.
4784	Read the data encoding the GetAttributeList request payload and decode it into its constituent parts, including handling optional unique identifier field and validating buffer size.
4785	Writes the GetAttributeList request payload data encoding to a stream, including the unique identifier if present, and then writes the encoded data to the output buffer.
4786	Reads and decodes the GetAttributeList response payload from an input buffer, extracting the unique identifier and attribute names according to the specified KMIP version. Raises InvalidKmipEncoding if required fields are missing or invalid.
4787	Writes the GetAttributeList response payload data encoding to a stream, including validation of required fields and handling different KMIP versions.
4788	Scan the provided policy directory for all JSON policy files and return a sorted list of their full paths.
4789	Scan policy directory for policy data, load new or modified policy files, remove outdated policies, and update policy cache and mappings.
4790	Starts monitoring operation policy files by initializing tracking structures and either continuously scanning policies in live monitoring mode or performing a single scan when live monitoring is disabled.
4791	Extracts an X.509 certificate from a socket connection by getting the peer certificate in binary format and loading it into a cryptography certificate object, returning None if no certificate is present.
4792	Extracts the extendedKeyUsage extension from an X.509 certificate, returning None if not found.
4793	Extracts all common names from an X.509 certificate's subject field by querying for COMMON_NAME OID attributes and returns them as a list of values.
4794	Extracts client identity from an X.509 certificate's common names. Returns the single common name if present, raises PermissionDenied if multiple identities exist or none are found.
4795	Reads and decodes the Create request payload from an input buffer, extracting the object type and template attribute or attributes based on the KMIP version. Raises InvalidKmipEncoding if required fields are missing.
4796	Writes the Create request payload data encoding to a buffer, validating required fields and handling KMIP version-specific encoding for object type and template attribute.
4797	Reads and decodes the Create response payload from an input buffer, extracting object type, unique identifier, and optionally template attribute based on KMIP version. Raises InvalidKmipEncoding if required fields are missing.
4798	Writes the Create response payload data encoding to a buffer, including object type and unique identifier fields, with optional template attribute for KMIP versions before 2.0.
4799	Convert a Pie object into a core secret object and vice versa, supporting symmetric keys, public keys, private keys, certificates, secret data, and opaque objects. Raises TypeError for unsupported object types.
4800	Reads and decodes the Encrypt response payload from an input stream, extracting required attributes like unique identifier and data, with optional IV/counter/nonce, while validating the presence of required fields and handling KMIP version compatibility.
4801	Reads and decodes the DeriveKey request payload from an input buffer, extracting required fields such as object type, unique identifiers, derivation method, derivation parameters, and template attributes, while validating their presence and correctness according to the specified KMIP version. Raises ValueError if required data is missing or invalid.
4802	Writes the DeriveKey request payload data encoding to a stream, validating required fields and handling different KMIP versions for template attributes.
4803	Check if a given attribute is supported by the current KMIP version by verifying it exists in the attribute rule sets and comparing its version requirement with the current version. Returns True if supported, False otherwise.
4804	Check if the specified attribute is deprecated based on the current KMIP version.

Args:
    attribute (string): The name of the attribute to check (e.g., 'Unique Identifier'). Required.

Returns:
    bool: True if the attribute is deprecated by the current version, False otherwise.
4805	Check if a given attribute is applicable to a specified object type by validating against attribute rule sets. Returns True if the attribute can be used with the object type, False otherwise.
4806	Check if the specified attribute is allowed to have multiple instances.

Args:
    attribute (string): The name of the attribute (e.g., 'State'). Required.

Returns:
    bool: True if multiple instances are permitted, False otherwise.

Note: TODO - Handle multivalue swap between certificate types
4807	Returns a valid value for client or server parameters, prioritizing direct values, then config file values, then defaults. Logs the source of the returned value. Handles special NONE_VALUE conversion to None.
4808	Reads and decodes the Check response payload from an input stream, extracting constituent parts like unique identifier, usage limits count, cryptographic usage mask, and lease time based on the KMIP version. Raises ValueError if the data attribute is missing from the encoded payload.
4809	Writes the Check response payload data encoding to a stream, including optional fields like unique identifier, usage limits count, cryptographic usage mask, and lease time, then writes the complete encoded data to the output stream.
4810	Reads and decodes an AttributeReference structure from a data stream, validating required fields and raising appropriate exceptions for invalid encodings or unsupported KMIP versions.
4811	Writes the AttributeReference structure encoding to the output buffer, validating required fields and handling KMIP version compatibility. Raises InvalidField if required fields are missing or VersionNotSupported if the KMIP version doesn't support AttributeReference.
4812	Read the data stream and decode the Attributes structure into its parts, supporting KMIP versions 2.0 and above. Raises AttributeNotSupported for unsupported attributes and VersionNotSupported for incompatible KMIP versions.
4813	Writes the Attributes structure encoding to the output data stream, validating KMIP version support and attribute compatibility before encoding. Raises AttributeNotSupported for unsupported attributes and VersionNotSupported for incompatible KMIP versions.
4814	Reads and decodes the Nonce struct from an input stream, extracting nonce ID and nonce value fields. Raises ValueError if either field is missing. Supports different KMIP versions with a default of KMIP 1.0.
4815	Writes the Nonce struct data encoding to a stream, validating that both nonce ID and nonce value are defined before encoding.
4816	Reads and decodes a UsernamePasswordCredential struct from an input stream, extracting username and password fields. Raises ValueError if username is missing from the encoding.
4817	Writes the UsernamePasswordCredential struct data encoding to a stream, validating that username is defined and including password if present.
4818	Reads and decodes the DeviceCredential struct from an input stream, extracting constituent parts like device serial number, password, and various identifiers based on KMIP version.
4819	Writes the DeviceCredential struct data to an output stream by encoding its component fields (device serial number, password, device identifier, network identifier, machine identifier, and media identifier) and then writing the encoded data to the output stream.
4820	Reads and decodes Credential struct data from an input stream, validating required fields and constructing appropriate credential value objects based on credential type.
4821	Writes the Credential struct data encoding to a stream, validating that both credential type and value are defined before encoding.
4822	Reads and decodes MACSignatureKeyInformation struct data from an input stream, extracting unique identifier and optional cryptographic parameters based on KMIP version.
4823	Writes the MACSignatureKeyInformation struct data encoding to a stream, including validation of required unique identifier attribute and optional cryptographic parameters, then writes the complete encoded data to the output stream.
4824	Reads and decodes the KeyWrappingData struct from an input stream, extracting its constituent parts including wrapping method, encryption key information, MAC signature key information, MAC signature, IV/counter/nonce, and encoding option, while validating the presence of required attributes and handling optional ones based on the KMIP version specified.
4825	Writes the KeyWrappingData struct to an output stream by encoding its components including wrapping method, encryption key information, MAC signature key information, MAC signature, IV/counter/nonce, and encoding option, then writes the complete encoded data to the output stream.
4826	Reads and decodes the KeyWrappingSpecification struct from an input stream, extracting its constituent parts including wrapping method, encryption key information, MAC signature key information, attribute names, and encoding option, while validating the structure's integrity.
4827	Writes the KeyWrappingSpecification struct data encoding to a stream, including wrapping method and optional encryption/mac/signature key information, attribute names, and encoding option, then writes the complete encoded data to the output stream.
4828	Reads and decodes ExtensionInformation object data from a stream, parsing extension name, optional extension tag and type, and performs validation.
4829	Write the data encoding the ExtensionInformation object to a stream by serializing its components (extension_name, extension_tag, extension_type) into a temporary stream, calculating the length, and then writing the serialized data to the provided output stream.
4830	Creates an ExtensionInformation object by constructing ExtensionName, ExtensionTag, and ExtensionType objects from the provided extension values and returning a new ExtensionInformation instance with these components.
4831	Reads and decodes RevocationReason object data from a stream, parsing the revocation code and optional revocation message based on the specified KMIP version.
4832	Writes the RevocationReason object data to a stream, encoding the revocation code and optional message, then writes the length and value to the output stream.
4833	Validate the RevocationReason object by checking that revocation_code is a RevocationReasonCode instance and revocation_message is a TextString instance (if provided).
4834	Read the data encoding the ObjectDefaults structure and decode it into its constituent parts, including object type and attributes, raising exceptions for missing data or unsupported KMIP versions.
4835	Writes the ObjectDefaults structure encoding to the output data stream, validating KMIP version support (minimum KMIP 2.0) and ensuring both object type and attributes fields are present. Raises InvalidField if required fields are missing or VersionNotSupported for incompatible KMIP versions.
4836	Read the data encoding the DefaultsInformation structure and decode it into its constituent parts, validating that object defaults are present and raising appropriate exceptions if missing or if the KMIP version is not supported.
4837	Writes the DefaultsInformation structure encoding to the output buffer, validating the KMIP version and object defaults field. Raises InvalidField if object defaults is missing, or VersionNotSupported if the KMIP version doesn't support DefaultsInformation.
4838	Reads and decodes the RNGParameters structure from an input buffer, validating the KMIP version and extracting various cryptographic parameters such as RNG algorithm, cryptographic algorithm, cryptographic length, hashing algorithm, DRBG algorithm, recommended curve, FIPS186 variation, and prediction resistance. Raises exceptions for invalid encodings or unsupported KMIP versions.
4839	Writes the RNGParameters structure encoding to the output data stream, validating the KMIP version and ensuring required fields are present. Raises InvalidField if RNG algorithm is missing, and VersionNotSupported for unsupported KMIP versions.
4840	Reads and decodes a ProfileInformation structure from input buffer, supporting KMIP versions 1.3 and above. Parses profile name, server URI, and server port from the encoding, raising exceptions for missing required fields or unsupported versions.
4841	Writes the ProfileInformation structure encoding to the data stream, validating the KMIP version and ensuring required fields are present. Raises InvalidField if profile name is missing, or VersionNotSupported for incompatible KMIP versions.
4842	Writes the ValidationInformation structure encoding to the data stream, validating required fields and supporting different KMIP versions. Raises InvalidField if required fields are missing or VersionNotSupported if the KMIP version doesn't support ValidationInformation.
4843	Reads and decodes the CapabilityInformation structure from an input buffer, supporting KMIP versions 1.3 and above. It parses various capability flags and enumerations such as streaming, asynchronous, attestation, batch operations, unwrap mode, destroy action, shredding algorithm, and RNG mode, raising VersionNotSupported for unsupported KMIP versions.
4844	Writes the CapabilityInformation structure encoding to the output data stream, supporting different KMIP versions from 1.3 onward, with conditional inclusion of various capability attributes based on the specified KMIP version and availability of each capability. Raises VersionNotSupported for versions prior to 1.3.
4845	Stop the server by halting client connections, cleaning up connection threads, shutting down the server socket, and stopping the policy monitor if it exists. Raises NetworkingError if socket shutdown fails, or ShutdownError if policy monitor cleanup fails.
4846	Serve client connections by listening for incoming connections, handling them with KmipSessions, and managing shutdown signals (SIGINT, SIGTERM). Handles socket timeouts and errors gracefully while maintaining a loop that continues until shutdown is signaled.
4847	Reads and decodes the Locate request payload from an input buffer, supporting different KMIP versions. It processes optional fields like maximum items, offset items, storage status mask, and object group member, as well as attributes. For KMIP 2.0+, it requires an attributes structure and raises an exception if missing.
4848	Writes the Locate request payload data encoding to a buffer, handling different KMIP versions and attribute formats, including template attributes for KMIP 2.0+.
4849	Reads and decodes the Locate response payload from an input buffer, extracting located items count and unique identifiers according to the specified KMIP version.
4850	Writes the Locate response payload data encoding to a buffer, handling located items and unique identifiers with specified KMIP version support.
4851	Create a symmetric key using the specified algorithm and length.

Args:
    algorithm (CryptographicAlgorithm): An enumeration specifying the algorithm for the key.
    length (int): The length of the key to be created, must be compliant with the algorithm.

Returns:
    dict: A dictionary containing the key data with 'value' (key bytes) and 'format' (KeyFormatType).

Raises:
    InvalidField: When the algorithm is unsupported or length is incompatible.
    CryptographicFailure: When the key generation process fails.

Example:
    >>> engine = CryptographyEngine()
    >>> key = engine.create_symmetric_key(CryptographicAlgorithm.AES, 256)
4852	Create an asymmetric key pair using the specified algorithm and key length, returning both public and private key data in dictionary format with value and format fields. Raises InvalidField for unsupported algorithms or incompatible lengths, and CryptographicFailure if key generation fails.
4853	Generate message authentication code using specified algorithm, key, and data. Supports hash-based HMAC and cipher-based CMAC algorithms. Returns the MACed data or raises exceptions for invalid algorithms, incompatible lengths, or cryptographic failures.
4854	Encrypts data using either symmetric or asymmetric encryption based on the specified algorithm. For RSA encryption, it calls the asymmetric encryption method; otherwise, it uses symmetric encryption. Returns a dictionary containing the encrypted data and any generated IV/nonce. Raises `InvalidField` for unsupported algorithms and `CryptographicFailure` for failed key generation.
4855	Encrypts data using symmetric encryption with the specified algorithm, key, and parameters. Supports various encryption algorithms, cipher modes, and padding methods. Automatically generates IV/nonce if required and not provided. Returns the encrypted data and generated IV/nonce if applicable. Raises exceptions for unsupported algorithms, invalid keys, or cryptographic failures.
4856	Encrypts data using asymmetric encryption with specified algorithm, key, and padding method. Supports RSA algorithm with OAEP or PKCS1v15 padding. Returns encrypted data as bytes in a dictionary. Raises InvalidField for unsupported algorithms/padding methods and CryptographicFailure for key loading errors.
4857	Decrypts data using asymmetric decryption with specified algorithm, key, and padding method. Supports RSA algorithm with OAEP or PKCS1v15 padding. Handles both DER and PEM formatted private keys. Returns decrypted plaintext bytes. Raises InvalidField for unsupported algorithms/padding methods or CryptographicFailure if key loading fails.
4858	Create an RSA key pair with specified length and public exponent, returning both public and private key data in DER format.
4859	Derive key data using various key derivation functions such as HASH, HMAC, PBKDF2, and NIST800_108_C. The method supports encryption-based derivation and requires specific parameters depending on the derivation method used. It returns the derived key data as bytes and raises InvalidField for unsupported or incompatible cryptographic settings.
4860	Creates an RSA private key from byte strings by attempting PEM deserialization first, then falling back to DER deserialization if PEM fails. Returns a RSAPrivateKey object or raises an exception if both methods fail.
4861	Verify a message signature using the provided signing key, message, and signature parameters. Supports RSA algorithm with PSS or PKCS1v15 padding methods. Returns True for valid signatures, False for invalid ones. Raises InvalidField for invalid parameters and CryptographicFailure for loading key or verification process failures.
4862	Reads and decodes the Sign response payload from an input stream, extracting the unique identifier and signature data attributes. Raises ValueError if either required attribute is missing from the encoded payload.
4863	Writes the Sign response data to an output stream, including unique identifier and signature attributes with validation.
4864	Reads and decodes the GetUsageAllocation request payload from an input stream, extracting unique identifier and usage limits count fields based on the specified KMIP version.
4865	Converts a ProtocolVersion struct to its KMIPVersion enumeration equivalent, returning None for invalid conversions.
4866	Reads and decodes ProtocolVersion struct data from an input stream, extracting major and minor version numbers with validation.
4867	Writes the ProtocolVersion struct data encoding to a stream, validating that both major and minor version numbers are present. Raises ValueError if either version number is missing.
4868	Reads and decodes Authentication struct data from input stream, extracting credentials and validating their presence.
4869	Writes the Authentication struct data to an output stream by encoding its credentials and then writing the complete struct to the stream.
4870	Reads and decodes the Poll request payload from an input stream, extracting the asynchronous correlation value if present, and validates that the stream has been fully consumed.
4871	Reads and decodes Certificate object data from a stream, extracting certificate type and value components.
4872	Writes the Certificate object data to a stream by encoding its certificate type and value, then writes the complete encoded data to the output stream.
4873	Authenticates a client by querying a SLUGS service with provided credentials. Requires a connection certificate containing client identity and validates the user against SLUGS user and groups endpoints. Returns the user ID and associated groups if authentication succeeds, otherwise raises ConfigurationError or PermissionDenied exceptions.
4874	Reads and decodes the Archive response payload from the input stream, extracting the unique identifier if present, and validates that the stream has been fully processed.
4875	Writes the Archive response payload data encoding to a stream, including the unique identifier if present, and handles the serialization according to the specified KMIP version.
4876	Method: run
Summary: The main thread routine that manages client connections by performing TLS handshake, handling messages in a loop until connection closes, then shutting down and closing the connection.
4877	Reads and decodes the Rekey response payload from an input stream, extracting the unique identifier and optional template attribute. Raises ValueError if the unique identifier is missing.
4878	Check if a profile is supported by the client based on conformance clause and authentication suite compatibility.

Args:
    conformance_clause (ConformanceClause): The conformance clause to check
    authentication_suite (AuthenticationSuite): The authentication suite to check

Returns:
    bool: True if both the conformance clause and authentication suite are supported, False otherwise

Example:
    >>> client.is_profile_supported(
    ... ConformanceClause.DISCOVER_VERSIONS,
    ... AuthenticationSuite.BASIC)
    True
4879	Derives a new key or secret data from existing managed objects using specified derivation parameters and returns the result including the unique identifier, template attributes, and operation status.
4880	Send a GetAttributes request to the server and return the results.
4881	GetAttributeList request to server, returns results structure containing retrieved attribute names associated with given managed object ID.
4882	Send a Query request to the server, optionally as part of a batch operation. Returns the query results from the server response.
4883	Signs specified data using a specified signing key, returning the signature and operation results including unique identifier, signature bytes, and status information.
4884	Opens the client connection if it's not already open, raising ClientConnectionFailure if already open or re-raising any exceptions that occur during opening.
4885	Close the client connection if it is open, otherwise do nothing. If an error occurs during closing, log the error and re-raise the exception.
4886	Creates a symmetric key on a KMIP appliance with specified algorithm, length, and optional attributes. Returns the UUID of the newly created key or raises exceptions for connection issues or operation failures.
4887	Create an asymmetric key pair on a KMIP appliance with specified algorithm, length, and optional attributes for public and private keys. Returns the UIDs of the newly created public and private keys. Raises exceptions for connection issues, operation failures, or invalid inputs.
4888	Register a managed object with a KMIP appliance and return its UUID. Extract attributes from the managed object, create a template, and send it to the KMIP proxy for registration. Raise appropriate exceptions if the operation fails or if the input is invalid.
4889	Rekeys an existing symmetric key with optional offset and attributes. Returns the unique ID of the newly rekeyed key. Raises exceptions for connection issues, operation failures, or invalid arguments.
4890	Derive a new key or secret data from existing managed objects using a specified derivation method and parameters. Supports SymmetricKeys and SecretData object types, with optional cryptographic attributes for the derived object. Returns the unique ID of the newly derived object. Raises exceptions for connection issues, operation failures, or invalid inputs.
4891	Search for managed objects based on specified attributes and return their unique identifiers.

This method searches for managed objects in the KMIP server matching the provided criteria. It accepts optional parameters to limit the search results, filter by storage status, specify object group membership, and define required attribute matches. The method validates all input parameters and delegates the actual search to the server proxy. On successful completion, it returns a list of unique identifiers for the located objects. If the operation fails, it raises a KmipOperationFailure exception with detailed error information.

Args:
    maximum_items (integer, optional): Maximum number of object identifiers to return
    storage_status_mask (integer, optional): Bit mask for filtering on-line/archived objects
    object_group_member (ObjectGroupMember, optional): Object group member type filter
    attributes (list, optional): Required attribute matches for candidate objects

Returns:
    list: Unique identifiers of located objects

Raises:
    ClientConnectionNotOpen: If the client connection is unusable
    KmipOperationFailure: If the operation result is a failure
    TypeError: If input arguments are invalid
4892	Check constraints for a managed object with specified parameters and return its unique identifier if successful, otherwise raise an exception.
4893	Get a managed object from a KMIP appliance.

Args:
    uid (string): The unique ID of the managed object to retrieve.
    key_wrapping_specification (dict): A dictionary containing various
        settings to be used when wrapping the key during retrieval.
        See Note below. Optional, defaults to None.

Returns:
    ManagedObject: The retrieved managed object object.

Raises:
    ClientConnectionNotOpen: if the client connection is unusable
    KmipOperationFailure: if the operation result is a failure
    TypeError: if the input argument is invalid

Notes:
    The derivation_parameters argument is a dictionary that can
    contain the following key/value pairs:

    Key                             | Value
    --------------------------------|---------------------------------
    'wrapping_method'               | A WrappingMethod enumeration
                                    | that specifies how the object
                                    | should be wrapped.
    'encryption_key_information'    | A dictionary containing the ID
                                    | of the wrapping key and
                                    | associated cryptographic
                                    | parameters.
    'mac_signature_key_information' | A dictionary containing the ID
                                    | of the wrapping key and
                                    | associated cryptographic
                                    | parameters.
    'attribute_names'               | A list of strings representing
                                    | the names of attributes that
                                    | should be included with the
                                    | wrapped object.
    'encoding_option'               | An EncodingOption enumeration
                                    | that specifies the encoding of
                                    | the object before it is wrapped.
4894	Get attributes associated with a managed object, optionally filtered by UID and attribute names. Returns UUID and attributes on success, raises exception on failure.
4895	Activates a managed object stored by a KMIP appliance. Takes an optional unique ID parameter and returns None. Raises ClientConnectionNotOpen if connection is unusable, KmipOperationFailure if operation fails, or TypeError if input is invalid. Returns successfully if activation operation completes with success status, otherwise raises exception with failure details.
4896	Summary: Revokes a managed object stored by a KMIP appliance with specified revocation reason and optional details. Raises exceptions for connection issues, operation failures, or invalid input arguments.
4897	Get the message authentication code for the provided data using the specified key and algorithm.

Args:
    data (bytes): The data to be MACed
    uid (str, optional): The unique ID of the managed object that is the key to use for the MAC operation
    algorithm (CryptographicAlgorithm, optional): An enumeration defining the algorithm to use to generate the MAC

Returns:
    tuple: A tuple containing (uid, mac_data) where uid is the unique ID of the managed object that is the key to use for the MAC operation, and mac_data is the data MACed

Raises:
    ClientConnectionNotOpen: if the client connection is unusable
    KmipOperationFailure: if the operation result is a failure
    TypeError: if the input arguments are invalid
4898	Build a CryptographicParameters struct from a dictionary by mapping key/value pairs to struct attributes, returning None if input is None, or raising TypeError if input is not a dictionary.
4899	Build an EncryptionKeyInformation struct from a dictionary by processing cryptographic parameters and creating the struct with unique identifier and cryptographic parameters. Returns None if input is None, raises TypeError if input is not a dictionary.
4900	Build a MACSignatureKeyInformation struct from a dictionary by extracting and processing the unique identifier and cryptographic parameters, returning None if input is None or raising TypeError if input is not a dictionary.
4901	Build a KeyWrappingSpecification struct from a dictionary by processing nested encryption and MAC key information, then constructing the specification with all specified parameters.
4902	Build a list of common attributes shared across symmetric and asymmetric objects, optionally including an operation policy name attribute.
4903	Build a name attribute in a list format for easy caller use, returning an empty list if no name is provided.
4904	Reads and decodes QueryRequestPayload object data from input_buffer, extracting query functions and validating the encoding. Raises InvalidKmipEncoding if query functions are missing.
4905	Writes the QueryRequestPayload object data encoding to a stream, including validation of query functions existence and proper KMIP version handling.
4906	Writes the QueryResponsePayload object's data to an output buffer, encoding it according to the specified KMIP version. It handles various payload components like operations, object types, vendor identification, server information, and version-specific extensions, capabilities, and information. The method constructs a local buffer with all encoded components, calculates the total length, and then writes the final encoded data to the provided output buffer.
4907	Reads and decodes the GetAttributes response payload from the input buffer, extracting the unique identifier and attributes according to the specified KMIP version. Raises InvalidKmipEncoding if required fields are missing.
4908	Writes the GetAttributes response payload data encoding to a stream, including the unique identifier and attributes based on KMIP version, raising exceptions for missing fields.
4909	Find a single entry point by searching through configuration files and distributions. Returns an EntryPoint object if found, otherwise raises NoSuchEntryPoint.
4910	Find a group of entry points with unique names and return a dictionary mapping names to EntryPoint objects.
4911	Find all entry points in a specified group.

Returns a list of EntryPoint objects found in the configuration files.
4912	Load the object to which this entry point refers.
4913	Parse an entry point from the syntax in entry_points.txt

Parameters:
    epstr (str): The entry point string (not including 'name =')
    name (str): The name of this entry point
    distro (Distribution): The distribution in which the entry point was found
Returns:
    EntryPoint: The parsed entry point
Raises:
    BadEntryPoint: if epstr can't be parsed as an entry point.
4914	Run a livereload server that watches for changes in pages, macros, and static assets, then serves the application on the specified port.
4915	Generate a new project by copying template files from the project directory to a new destination directory, handling file rewriting for specific extensions and logging the progress.
4916	Generate controller by creating controller file, test file, and assets directory based on templates, with the specified controller name and current working directory.
4917	Generate an action for a given controller by adding action source code to the controller file and creating associated template files (HTML, JS, LESS) if a template is requested. It checks if the controller exists and logs the process.
4918	Generate a form based on the provided form name parameter and log the start and finish of the generation process.
4919	Generate a model file based on a template, with the model name provided in args. The function creates a new Python file in the application/models directory using a template, replacing a placeholder with the model name in title case. It also updates the __init__.py file in the same directory to include the new model. The function logs information about the process and handles cases where the model name is empty.
4920	Generate a macro by creating the necessary HTML, CSS, and JavaScript files in the appropriate directory structure based on the provided macro name and category. The function handles path construction, file creation, and logging of the generation process.
4921	Creates directory path and all parent directories if they don't exist, suppressing errors when the path already exists. Logs a message when a new directory is created.
4922	Replace variables in source file with project name and copy to destination file.
4923	Returns a friendly time description (e.g., "2 hours ago", "3 months ago") comparing a given datetime value to the current time. If the value is in the future, returns "right now". Handles edge cases like None values and non-datetime objects by returning them as-is or empty strings.
4924	Check if a URL field has a valid schema, and if not, prepend "http://" to make it valid.
4925	Encodes the given object using URLSafeSerializer with the application's SECRET_KEY and returns the serialized string.
4926	Decode a serialized string using the application's SECRET_KEY, returning the original data or None if the signature is invalid.
4927	JSON decorator that wraps a function to return JSON responses with proper status codes.
4928	Returns the absolute URL for a given endpoint by combining the site domain with the relative URL generated by url_for.
4929	Load configuration based on MODE environment variable, returning ProductionConfig, TestingConfig, or DevelopmentConfig. Falls back to default Config if import fails.
4930	Signs in a user by setting the session's permanent flag and storing the user's ID in the session.
4931	Get current user from session, return None if not logged in or user doesn't exist.
4932	Creates and configures a Flask application with CSRF protection, debug toolbar in debug mode, Sentry error tracking in production, and registered components.
4933	Register Jinja2 filters, variables, and functions for a Flask application, including custom filters like 'timesince', pagination helper 'url_for_other_page', and URL rules mapping, with different template loaders based on debug/testing mode.
4934	Register Flask routes by importing controller modules and registering their blueprints with the application.
4935	Registers HTTP error handlers for 403, 404, and 500 error codes, returning corresponding HTML templates for each error type.
4936	Register hooks to track render time for admin users. The `before_request` hook sets the current user and stores the request start time for admin users. The `after_request` hook calculates the render time and adds it as an X-Render-Time header to the response.
4937	Serializes a dataframe to CSV format with specified delimiter and header options using UTF-8 encoding.
4938	Returns csv data as a pandas DataFrame object, reading from a reader object with specified delimiter, header options, and space skipping behavior.
4939	Serialize a pandas DataFrame using the specified serialization format and write it to a file-like object.

Parameters:
- writer: file-like object opened in binary mode to write serialized data to
- data_type_id: serialization format identifier (from azureml.DataTypeIds)
- dataframe: pandas DataFrame to serialize

Raises:
- UnsupportedDatasetTypeError: if the data_type_id is not supported
- ValueError: if any required parameter is None or empty

The function uses a serializer registry to select the appropriate serialization method based on data_type_id, then calls the corresponding serializer with the writer and dataframe parameters.
4940	Deserialize a dataframe from a file-like object using the specified serialization format.

Parameters:
- reader: file-like object opened in binary mode to read from
- data_type_id: dict specifying the serialization format (use azureml.DataTypeIds constants)

Returns:
- pandas.DataFrame: The deserialized dataframe object

Raises:
- UnsupportedDatasetTypeError: If the data_type_id format is not supported
- ValueError: If reader or data_type_id is None/empty
4941	Updates the dataset by serializing a DataFrame and replacing the existing dataset with the new data.

Parameters:
- dataframe: pandas.DataFrame - Data to serialize
- data_type_id: str, optional - Format to serialize to (defaults to existing format)
- name: str, optional - Name for the dataset (defaults to existing name)
- description: str, optional - Description for the dataset (defaults to existing description)

The method serializes the provided DataFrame using the specified data type format, then uploads and refreshes the dataset with the new serialized data, preserving existing attributes when parameters are None.
4942	Update dataset with new raw data, replacing existing content while preserving other metadata if not specified.
4943	Full URL to the dataset contents by concatenating the base URI, location, and access credential from the download location.
4944	Summary: Adds a pandas DataFrame as a new dataset by serializing it to the specified format and uploading it with the given name and description. Returns the created SourceDataset object.
4945	Uploads serialized raw data as a new dataset and returns the created SourceDataset object.
4946	Open and return a stream for the dataset contents by calling the workspace's REST interface with the necessary IDs and port information.
4947	Read and return the dataset contents as binary.
4948	Read and return the dataset contents as text by calling the REST API to read intermediate dataset contents.
4949	Read and return the dataset contents as a pandas DataFrame by converting the binary data to a BytesIO stream and deserializing it using the specified data type ID.
4950	Get an intermediate dataset from a module node in the experiment graph.

Parameters:
- node_id (str): Module node id from the experiment graph
- port_name (str): Output port of the module  
- data_type_id (str): Serialization format of the raw data

Returns:
IntermediateDataset object that can be used to access dataset contents as stream, bytes, str, or pandas DataFrame through its open(), read_as_binary(), read_as_text(), or to_dataframe() methods.
4951	Retrieves a list of experiments for a given workspace by sending an HTTP GET request to the formatted API endpoint.
4952	Returns a list of datasets by executing an HTTP GET request to the datasources API endpoint for the specified workspace ID.
4953	Retrieves a single dataset by executing an HTTP GET request to the specified workspace and dataset ID paths.
4954	Publishes a callable function or decorates a function to be published to Azure. Returns a callable, iterable object that invokes the published service when called and provides API URL, API key, and help URL when iterated. Can be used as a decorator or called directly with a function and workspace credentials. Supports publishing additional files along with the function.
4955	Marks a function as published and routes all invocations to a remote operationalized service.
4956	A decorator that adds type annotations to a function. It takes keyword arguments representing parameter names and their types, then attaches these as annotations to the decorated function. The decorator can be used with the @types decorator syntax to specify the expected types for function parameters.
4957	A decorator factory that specifies the return type annotation for a function. It takes a type parameter and returns a decorator that adds or updates the 'return' key in the function's annotations dictionary with the specified type.
4958	Attaches a file to a function's payload for uploading. If contents is provided, it uses those contents; otherwise, reads from disk. If name is a tuple, it specifies both the source and destination filenames. Returns a decorator that adds attachment information to functions.
4959	This function analyzes bytecode to identify global variables referenced in a Python function. It walks through the bytecode instructions, looking for LOAD_GLOBAL operations, and collects the names of variables being loaded from the global namespace. The function returns a set of global variable names found in the code object.
4960	Create a copy of this pen by duplicating all attributes from the current pen instance to a new Pen object.
4961	Lookup RGBA color values from X11 colors or brewer color schemes. Returns RGBA tuple (r, g, b, a) or None if color is unknown.
4962	Draws this shape using the provided cairo context, with optional highlighting and bounding box intersection checking.
4963	Find extremas of a cubic Bernstein polynomial by solving its derivative. Returns tuple of critical points, or empty tuple if constant or no real solutions.
4964	Evaluate a cubic Bernstein polynomial using de Casteljau's algorithm with given control points and parameter t.
4965	Builds a choices list runtime using the 'sitetree_tree' template tag by creating a context, rendering the tree, and parsing the results into tuple choices with ID and title pairs.
4966	A compatibility function that replaces optparse for Django management commands post-Django 1.10, returning a closure that generates command options for Django commands.
4967	Registers a hook callable to process tree items before they are passed to templates. The callable must handle ``tree_items`` and ``tree_sender`` parameters and return a list of TreeItem objects. The hook is useful for modifying tree items based on navigation type (e.g., 'menu', 'sitetree', 'breadcrumbs'). Raises SiteTreeError if the provided function doesn't have 2 or 3 arguments.
4968	Returns a structure describing a dynamic sitetree configuration. Can build structure from app names or iterable of tree definitions, with optional filtering and tree attachment settings. Handles ImportError gracefully in DEBUG mode.
4969	Initializes local cache from Django cache by retrieving cached sitetrees data and dropping reset flag if set.
4970	Empties cached sitetree data by deleting 'sitetrees' and 'sitetrees_reset' cache keys, then initializes the sitetree if the 'init' keyword argument is True (default behavior).
4971	Returns the value of a specified key from a cache entry, or False if the key doesn't exist.
4972	Updates a cache entry parameter with new data by adding or updating key-value pairs in the specified cache entry.
4973	Replaces entire cache entry parameter data by its name with new data.

**Parameters:**
- `entry_name` (str|unicode): The name of the cache entry to modify
- `key`: The key within the cache entry to update
- `value`: The new value to set for the specified key

**Example:**
```python
# Replace the 'max_size' parameter of cache entry 'config1' with value 1000
set_entry('config1', 'max_size', 1000)
```
4974	Initializes sitetree to handle new request. Sets up cache, retrieves current page context and request, determines current language, and initializes various internal attributes including admin app flag, user permissions, and URL/item caches.
4975	Resolves internationalized tree alias by checking if a language-specific sitetree exists for the current active language. If available, returns the i18n alias; otherwise returns the original alias. Uses caching to optimize database queries for tree alias lookups.
4976	Returns a boolean indicating whether the current application is the Admin contrib module by checking the app_name from request resolver_match or context against ADMIN_APP_NAME.
4977	Calculates the depth of an item in a tree structure by recursively traversing up to the root node, using the item's parent references to determine hierarchical depth. Returns the calculated depth as an integer.
4978	Method `get_tree_current_item` resolves and returns the current tree item for a given tree alias by matching the current request path against URL patterns. It first checks if a current item is already cached, and if not, it iterates through stored URL patterns to find a match. If a match is found and it belongs to the specified tree alias, it marks the item as current and caches it for future use. The method handles URL encoding for non-ASCII characters and special handling for admin applications. Returns the matching TreeItemBase object or None if no match is found.
4979	Resolves an item's URL by either returning a cached result or dynamically resolving it as a URL pattern. If the item's URL is marked as a pattern, it processes the URL using Django's URL resolution system. Otherwise, it returns the URL as-is. The resolved URL is cached for future requests.
4980	Initializes sitetree in memory by resolving the tree alias from context and retrieving associated items. Returns a tuple of (resolved_tree_alias, items) on success, or (None, None) on failure. Raises SiteTreeError if the request context processor is not enabled.
4981	Returns an arbitrary attribute of the sitetree item that is resolved as current for the current page. If no current item is found and in debug mode with error raising enabled, it raises a SiteTreeError. Otherwise, it returns an empty string.
4982	Returns the ancestor of the specified depth recursively. If depth is 1 or less, returns the direct parent. If the current item has no parent, returns the current item itself.
4983	Builds and returns menu structure for 'sitetree_menu' tag based on tree alias, branches, and context, filtering items by access rights and parent relationships.
4984	Checks whether a current user has access to a certain item based on authentication status and permissions. Returns True if access is granted, False otherwise.
4985	Builds and returns breadcrumb trail structure for 'sitetree_breadcrumbs' tag by traversing the site tree from current item upward, filtering based on breadcrumb visibility and access rights, then applying hooks and updating children information.
4986	Builds and returns tree structure for 'sitetree_tree' tag by initializing the tree, filtering and processing items, and updating children status.
4987	Builds and returns site tree item children structure for 'sitetree_children' tag, resolving parent item, getting children items, filtering them by navigation type, applying hooks, updating children status, and rendering with specified template.
4988	Returns item's children from cache, with optional i18n resolution for non-admin applications.
4989	Updates the 'has_children' attribute for tree items in place by checking if each item has children based on the specified navigation type.
4990	Filters sitetree items by hiding hidden items, access permissions, and navigation type visibility. Returns filtered list of items, unless in admin app where no filtering is applied.
4991	Climbs up the site tree to find the root item for a given base item by recursively traversing parent references until reaching the topmost ancestor. Returns the root TreeItemBase object.
4992	Climbs up the site tree to mark items in the current branch by recursively traversing parent nodes and setting `in_current_branch` flag to True on each item.
4993	Resolves a variable name within a given context, returning the resolved value or the original name if resolution fails.
4994	Parses the sitetree tag parameters to render site trees with optional custom templates. Supports two notation types: `{% sitetree_tree from "mytree" %}` for default template rendering, or `{% sitetree_tree from "mytree" template "sitetree/mytree.html" %}` for custom template rendering. Raises TemplateSyntaxError if incorrect number of arguments provided.
4995	Parses the sitetree_children template tag to render child items of a site tree using specified navigation type and template. The tag requires six arguments in the format: `{% sitetree_children of tree_item for navigation_type template "template_path" %}` where navigation_type can be either 'menu' or 'sitetree'. Returns a sitetree_childrenNode for processing, or raises TemplateSyntaxError if arguments are invalid.
4996	Parses the sitetree_breadcrumbs template tag to generate breadcrumb navigation paths. Supports two notation types: basic usage with tree alias only, or extended usage with both tree alias and custom template. Returns a sitetree_breadcrumbsNode for rendering.
4997	Parses the sitetree_menu template tag to render site tree elements as a menu. Supports specifying a tree alias, included branches (with reserved aliases like 'trunk', 'this-children', 'this-siblings', 'this-ancestor-children'), and an optional custom template. Raises TemplateSyntaxError if the tag doesn't have the required four arguments in the correct format.
4998	Render helper function that processes template nodes by pushing context, setting tree items, resolving templates, rendering content, and popping context.
4999	Creates a node constructor for template tags that parses a token containing a preposition and tree alias, returning a class instance with the parsed arguments or raising a syntax error if the format is incorrect.
5000	Returns a URL name for a given Tree admin page type by combining namespace prefix, model information, and page type, all in lowercase.
5001	Forces unregistration of tree admin class with following re-registration.
5002	Fixes Admin contrib redirects compatibility problems introduced in Django 1.4 by adjusting redirect paths based on the request path, adding appropriate "../" shifts for delete and history operations to ensure proper navigation between admin pages.
5003	Generic redirect handler for item editor with three possible actions: add another (redirects to item_add page), save (redirects to parent page), continue editing (returns current response), or default redirect (empty string).
5004	Redirects to the appropriate items' 'continue' page on item add, with special handling for tree items within tree itself.
5005	Redirects to the appropriate items' 'add' page on item change, modifying the standard redirection process for tree items administered within the tree itself.
5006	Returns a modified form for the TreeItem model with a customized 'Parent' field and registered URL pattern hints. The parent field choices are built by the sitetree itself, and the form includes validation for URL patterns.
5007	Fetches and returns the Tree object for the current or given TreeItem, setting verbose_name_plural and urls attributes on the tree.
5008	Moves an item up or down within a tree by swapping the 'sort_order' field values of the item and its neighbor. The direction parameter determines whether to move the item up or down. Returns an HTTP redirect to the parent page after the move operation.
5009	Saves a TreeItem model instance under a specific tree, handling cases where an item attempts to become its own parent by preserving the previous parent relationship and issuing a warning message to the user.
5010	Returns a list of URL patterns for TreeAdmin and TreeItemAdmin, including routes for changing, adding, editing, deleting, viewing history, and moving tree items, with conditional URLs based on Django version and smuggler installation.
5011	Dumps sitetrees with items using django-smuggler, returning a response with serialized data prefixed as 'sitetrees'.
5012	Creates and returns a dynamic sitetree with the given alias, title, and items. The tree object is initialized with the provided parameters, marked as dynamic, and populated with items and their children recursively. Returns the constructed tree object.
5013	Creates and returns a sitetree item object with specified properties and optional children, handling URL patterns, access permissions, and display settings.
5014	Imports sitetree module from a given app, returning the module if found or None if not available.
5015	Returns a sitetree model class as defined in project settings, raising ImproperlyConfigured if the model is not installed.
5016	Create a configuration object from a mapping or keyword arguments, setting attributes on the config instance while gracefully handling invalid attributes.
5017	Create a configuration instance from a Python file by loading it as a module and converting it to a Config object using the from_object method.
5018	Load configuration values from a TOML formatted file and return a Config instance.
5019	Create a configuration from a Python object by importing and extracting attributes from the object or module specified by the input. Supports both string paths (e.g., 'module', 'module.attribute') and direct object references. Extracts all non-module attributes from the object and uses them to construct a new Config instance.
5020	Creates a set of Zipkin attributes for a span with optional trace and span IDs, and determines sampling based on the provided sample rate.
5021	Generate HTTP headers for a new Zipkin span, including trace ID, span ID, parent span ID, flags, and sampled status. Returns an empty dict if not called within a Zipkin trace context.
5022	Returns the current ZipkinAttrs and generates new ones if needed. For root spans, it handles sampling logic and trace context generation based on sample_rate and zipkin_attrs_override. For child spans, it retrieves existing trace context from the tracer or creates new one with parent context. Returns a tuple of (report_root_timestamp, zipkin_attrs).
5023	**Summary:**

The `start` method enters a new span context, attributing annotations and child spans to this span. It handles both sampled and unsampled cases, ensuring proper span ID generation and thread-local stack management. In the unsampled case, it still generates span IDs but skips logging. For local root spans, it configures logging and transport if not already configured, creating a `ZipkinLoggingContext` for span reporting. The method returns `self` to allow method chaining.
5024	Exit the span context by popping zipkin attributes, handling exceptions, and logging spans based on sampling and transport configuration. If a logging context exists, it stops it and performs cleanup; otherwise, it creates and adds a span to the tracer with appropriate timing and annotations.
5025	Updates the binary annotations for the current span by either adding them to the span's binary annotations (for non-root spans) or directly to the logging context tags (for root spans).
5026	Adds a 'sa' (server address) binary annotation to the current span for client spans, setting the destination endpoint information when the destination doesn't support Zipkin instrumentation. The method validates that the span is a client span and raises ValueError if an SA annotation was already set.
5027	Overrides the current span name with a new name and updates the logging context if it exists.
5028	Creates a zipkin Endpoint object with specified parameters, using defaults for unspecified values. It handles IPv4/IPv6 address validation and sets default values for port (0), service_name ('unknown'), and host (current host IP). The function returns an Endpoint object with ipv4, ipv6, port, and service_name attributes.
5029	Creates a copy of an endpoint with a new service name while preserving other endpoint properties like IP addresses and port.
5030	Builds and returns a V1 Span by creating full annotations with cs=sr and ss=cr, removing annotations based on span kind, adding user-defined annotations, and returning a _V1Span with all the constructed parameters.
5031	Encodes a list of protobuf Spans into binary format.

Args:
    pb_spans: list of protobuf Spans (zipkin_pb2.Span)
Returns:
    bytes: serialized binary representation of the spans list
5032	Converts a py_zipkin Span object into a protobuf Span object, handling all relevant fields including trace ID, parent ID, span ID, kind, name, timestamp, duration, local and remote endpoints, annotations, tags, debug flag, and shared flag.
5033	Converts a hexadecimal string ID to big-endian binary representation. For IDs with 16 characters or less, directly converts to 8-byte binary. For longer IDs, splits into two 64-bit segments and concatenates their binary representations. Returns bytes object containing the big-endian binary encoding.
5034	Converts py_zipkin's Kind to Protobuf's Kind.

:param kind: py_zipkin's Kind
:type kind: py_zipkin.Kind
:return: corresponding protobuf's kind value
:rtype: zipkin_pb2.Span.Kind
5035	Converts py_zipkin's Endpoint to Protobuf's Endpoint by mapping service name, port, IPv4, and IPv6 addresses, handling address conversion with socket.inet_pton for network addresses.
5036	Converts py_zipkin's annotations dict to protobuf format by mapping each annotation value and timestamp to a protobuf Annotation message with timestamp converted to microseconds.
5037	Create a zipkin annotation object with the specified timestamp, annotation value, and host endpoint.
5038	Creates a Zipkin binary annotation object with the specified key, value, type, and host endpoint.
5039	Create a zipkin Endpoint object with the specified network information including port, service name, and IP addresses. The function handles both IPv4 and IPv6 addresses by converting them to network byte order and ensures proper unsigned to signed integer conversion for Thrift compatibility. Returns a thrift Endpoint object.
5040	Copies a zipkin_core.Endpoint object with a new service name while preserving the ipv4 address and port from the original endpoint. Returns a new Endpoint object with the specified service name.
5041	Returns a list of zipkin_core Annotation objects by converting timestamp from seconds to microseconds and associating each annotation with the given host endpoint.
5042	Builds a list of zipkin_core binary annotation objects from a dictionary of binary annotations, converting all values to strings and using a fixed STRING annotation type.
5043	Creates a Thrift span object from span attributes, handling 128-bit trace IDs by separating high and low parts, converting timestamps from seconds to microseconds, and optionally setting parent span ID.
5044	Returns a TBinaryProtocol encoded Thrift span as bytes.
5045	Encodes a list of Thrift objects into a binary format using TBinaryProtocol.

Parameters:
    binary_thrift_obj_list (list): List of TBinaryProtocol objects to encode

Returns:
    bytes: Binary representation of the encoded list
5046	Detects the span version and encoding for a given message by checking its format and content. Returns the appropriate Encoding type (V1_THRIFT, V2_PROTO3, V1_JSON, or V2_JSON) based on the message structure. Handles both byte arrays and string inputs, with specific logic for binary formats, JSON lists, and individual JSON spans. Raises ZipkinError for invalid or unsupported formats.
5047	Converts encoded spans from one encoding to another encoding. Takes input spans as byte array and optional input encoding, detects encoding if not specified, then decodes spans using input encoding and re-encodes them using output encoding. Returns converted spans as byte array.
5048	Stores zipkin attributes to thread local storage. This function is deprecated and will be removed in version 1.0 - use the Tracer interface instead. Takes a zipkin attributes tuple and pushes it onto the thread local stack.
5049	Encodes a v2 span to thrift format by converting span components to thrift objects, adding remote endpoint annotations if present, and serializing the final span to bytes.
5050	Converts an Endpoint object to a JSON endpoint dictionary, handling v1 serialization rules where serviceName defaults to empty string when not set.
5051	Encodes a single span to protobuf format. Raises ZipkinError if protobuf requirements are not installed. Uses protobuf library to create and encode the span.
5052	Decodes an encoded list of spans into a list of Span objects by reading from a transport buffer and processing each span through the Thrift protocol.
5053	Converts a Thrift-encoded endpoint to an Endpoint object by decoding the IP address and port information from the Thrift endpoint structure.
5054	Method `_decode_thrift_annotations` converts Thrift annotations to v1 annotations by:

1. Processing a list of Thrift annotations to extract timestamp information
2. Determining the span kind (CLIENT, SERVER, or LOCAL) based on annotation presence
3. Converting timestamp values to seconds
4. Returning a tuple containing: annotations dictionary, local endpoint, kind, timestamp, and duration

The method identifies CLIENT spans when 'cs' annotation exists without 'sr', and SERVER spans when 'sr' exists without 'cs'. It drops certain annotations specified in `_DROP_ANNOTATIONS` and converts Thrift endpoint information to the v1 format.
5055	Converts Thrift binary annotations to v1 binary annotations, extracting tags, local endpoint, and remote endpoint from the Thrift data structure. Returns a tuple of (tags_dict, local_endpoint, remote_endpoint).
5056	Decodes a Thrift span object into a Span builder by extracting and converting trace ID, span ID, parent ID, annotations, tags, and endpoint information from the Thrift span's attributes.
5057	Converts a trace ID (with optional high bits) from integer format to a hexadecimal string representation. If trace_id_high is provided, the result will be a 32-character string combining both high and low bits. Otherwise, it returns a 16-character string for the trace ID alone. Uses bytearray and _write_hex_long helper method for efficient hex conversion before decoding to UTF-8 string.
5058	Converts an unsigned long value to a hexadecimal string representation. Takes an unsigned long parameter and returns its hex string equivalent.
5059	Writes an unsigned long value to a byte array at the specified position by breaking it into 8 bytes and writing them at positions 0, 2, 4, 6, 8, 10, 12, and 14 relative to the starting position.
5060	Replace illegal February 29, 30 dates with the last day of February for German bank date processing.
5061	Sets transaction code from tag dictionary by extracting the first part of the split tag value.
5062	Sets iph_id in tag_dict by extracting it from tag_dict using regex pattern, for mBank transactions with ID IPH to distinguish virtual accounts.
5063	Sets the TNR (Transaction Number) in the tag dictionary from transaction details if a match is found, using a regular expression pattern. Returns the updated tag dictionary.
5064	Parses MT940 data into a list of Transaction objects. It processes the input string by stripping whitespace, identifying valid tags using regex, sanitizing matches, and then parsing each tag according to its type. The method handles different tag types (like Statement, Transaction, and Transactions) and applies pre- and post-processing steps as defined in processors. Transactions are created or updated based on tag data, particularly for :20: and :61: tags. Returns a list of Transaction objects.
5065	Parses MT940 data from various sources (file handler, filename, or raw string) and returns a collection of transactions. Handles multiple encodings automatically and raises appropriate exceptions for encoding errors.
5066	Join strings together and strip whitespace from left/right sides based on the strip parameter flags.
5067	Returns a properly formatted JSON object or text from an asynchronous response, parsing JSON when the content type matches 'application/json; charset=utf-8', otherwise returning the text as-is.
5068	Handles ratelimit quota exhaustion by calculating retry duration and logging a warning message with both seconds and minutes formatted for clarity.
5069	Handles API requests with rate limiting, retry logic, and proper error handling for various HTTP status codes including 429 (rate limited), 400, 401, 403, and 404. Uses a rate limiter to prevent exceeding API limits and implements exponential backoff for retries.
5070	Gets information for a given bot ID, parses the date field from ISO format, and converts empty string values to None.
5071	Gets a batch of bots from DBL with specified limit and offset, capped at 500 items with default fallback to 50 if limit exceeds 500.
5072	Reads incoming message by unpacking packet header to determine message length, then reads complete message including terminating character using buffer and lock synchronization.
5073	Write outgoing message by encoding it, packing the length, and writing to output descriptor with proper error handling.
5074	Close the input and output file descriptors associated with the port.
5075	Decodes an Erlang external term from bytes, handling both uncompressed and compressed formats. Raises `IncompleteData` for insufficient data or `ValueError` for invalid protocol versions or compressed data. Returns the decoded term and unused data for compressed terms.
5076	Encodes an Erlang external term with optional compression. Returns the encoded term as bytes, prefixed with the Erlang external term format identifier (0x83). If compression is enabled and beneficial, the term is compressed using zlib with the specified compression level (default 6) and prefixed with a compression header (0x50). Compression levels must be between 0-9, where 0 means no compression.
5077	Adds a source address for multicast communication by joining the multicast group and creating an outbound socket for the specified address.
5078	Method that sends pending messages from queue, sleeping briefly when queue is empty. For each message, if it can be sent, it sends the message and re-queues it if not finished. If message cannot be sent, it re-queues the message and sleeps briefly.
5079	Sets a callback function to be invoked when remote services become online and send Hello messages. The callback can be filtered by service types and scopes. Passing None disables the callback.
5080	Stops the discovery server by cleaning up remote and local services, stopping threads, and marking the server as not started.
5081	Clears all local services by sending Bye messages and removing them from the registry.
5082	Search for services by sending a probe with specified types and scopes, then filter and return the results after a timeout period. Raises an exception if the server is not started.
5083	Creates a raw SOAP XML string from a prepared SoapEnvelope object based on the action type, returning different message types for PROBE, PROBE_MATCH, RESOLVE, RESOLVE_MATCH, HELLO, and BYE actions.
5084	**Summary:**

The `discover` function performs system discovery using WS-Discovery. It accepts three parameters: `scope` (determines the discovery scope), `loglevel` (sets the logging level for output), and `capture` (controls whether to capture discovered systems). 

The function first validates and sets the logging level if provided. If an invalid log level is specified, it prints an error message and exits. Then it calls the `run` function with the provided scope and capture parameters to execute the actual discovery process.
5085	Return the manager that handles the relation from this instance to the tagged_item class. If content_object is defined as a ParentalKey, return a DeferringRelatedManager which allows writing related objects without committing them to the database.
5086	Return a list of RelatedObject records for child relations of the given model, including ones attached to ancestors of the model.
5087	Return a list of ParentalManyToManyFields on the given model, including ones attached to ancestors of the model.
5088	Save the model and commit all child relations, handling both regular relations and many-to-many fields separately when using update_fields.
5089	Builds a model instance from JSON-like data, recursively processing related objects. Handles foreign key validation and manages dangling references according to on_delete settings. Returns the constructed object or None if validation fails with strict_fks enabled.
5090	This method validates uniqueness constraints across multiple forms in a formset. It collects unique check conditions from all valid forms, then iterates through each unique constraint to ensure no duplicate combinations exist across the forms. If duplicates are found, it adds error messages to the appropriate forms and raises a ValidationError containing all uniqueness errors. The method handles both regular unique constraints and unique_together constraints by checking if the same set of field values appears more than once across the valid forms.
5091	Return True if form data differs from initial data, checking nested formsets recursively.
5092	Returns the address with a valid checksum attached by generating and appending a checksum to the address, while preserving all ancillary attributes like balance, key_index, and security_level.
5093	Generates the correct checksum for the address by absorbing the address trits into a Kerl sponge and squeezing out the checksum trits, then returns the checksum using the last checksum_length trits.
5094	Parses command line arguments and returns a dictionary of parsed arguments with API object initialized. If seed is required, it processes seed from file or prompts user. The URI argument is used to create an Iota API instance which is stored in the returned dictionary under the 'api' key.
5095	Creates and returns an ArgumentParser instance for interpreting command-line arguments, including URI, seed file, and testnet options.
5096	Prompts user to enter a seed via stdin, with hidden typing, and returns a Seed object. If no seed is provided, generates a random seed.
5097	Validates whether a sequence of signature fragments is valid by reconstructing a public key from the fragments and comparing it with the provided public key. Uses a cryptographic sponge (Kerl by default) to process the fragments and hash values. Returns True if the reconstructed public key matches the provided public key, otherwise False.
5098	Generates a single private key at the specified index with the given number of transform iterations for security.
5099	Returns the key associated with the specified address by using the address's key index and security level to generate the appropriate key.
5100	Creates a KeyIterator generator for progressively generating new keys with specified starting index, step size, and security level.
5101	Creates a hash sponge for the generator by absorbing a seed value with an index, squeezing trits out, resetting the sponge, and re-absorbing the results.
5102	Absorbs a sequence of trits into the sponge function by copying them in hash-sized chunks into the internal state and applying the compression transformation after each chunk. Handles padding to ensure the input length is a multiple of the hash length, and includes validation for the length parameter. The absorption process occurs in fixed-size blocks (HASH_LENGTH) until all specified trits have been processed.
5103	Squeeze trits from the sponge state into a provided sequence. Copies trits from the internal state to the given trits parameter in hash-sized chunks, transforming the internal state between each copy. Validates that the length is a multiple of HASH_LENGTH and that the offset and length parameters are within valid bounds. The trits sequence is modified in-place with the squeezed values.
5104	Transforms the internal state by applying a series of transformations based on a truth table and state transitions. The method optimizes performance by minimizing global and dot lookups through local variable copies and operates on state copies to avoid modifying the original state during computation. The transformation involves iterating through rounds and positions while applying index-based state changes according to a predefined truth table.
5105	Generates one or more key digests from the seed for secure multisig address creation. Returns a dictionary containing a list of digests. Supports specifying starting index, number of digests to generate, and security level (1-3) for signature security.
5106	Generates one or more private keys from the seed for secure signature creation, with options to specify starting index, key count, and security level. Returns a dictionary containing a list of PrivateKey objects.
5107	Prepares a bundle that authorizes the spending of IOTAs from a multisig address, requiring manual signing of input transactions with generated private keys before proof of work and broadcasting.
5108	Adds two sequences of trits together, returning a list of trits with length equal to the longer input sequence. Handles carry propagation during addition and supports overflow (e.g., add_trits([1], [1]) returns [-1]).
5109	Converts an integer to its balanced ternary (trit) representation, where each trit can be -1, 0, or 1. Handles negative numbers by using "lending" logic when remainder is 2, and pads the result to ensure minimum length.
5110	Adds two individual trits together, returning a single trit. If the sum is between -2 and 2 (exclusive), returns the sum directly. Otherwise, returns -1 if sum is negative or 1 if sum is positive.
5111	Adds two trits together with carry support, returning the sum trit and carry-out trit.
5112	Outputs the user's seed to stdout with security warnings about seed safety and shoulder surfing prevention.
5113	Finds transactions matching specified criteria (bundles, addresses, tags, approvees) and returns them in a dictionary format. Uses the IOTA API's FindTransactionsCommand to query the network.
5114	Returns all possible inputs of a seed along with their total balance, either deterministically or within a specified key range. It can stop based on a threshold balance or iterate through all addresses. The method supports optional parameters for start index, stop index, balance threshold, and security level for address generation. Returns a dictionary containing the inputs (addresses with nonzero balances) and the total balance. Raises BadApiResponse if threshold is not met when specified.
5115	Generates one or more new addresses from the seed using the specified parameters. Returns a dictionary containing the generated addresses. Supports optional checksum generation and allows specifying the number of addresses to generate, starting index, and security level for address generation.
5116	Returns all transfers associated with the seed, with options to specify index range and inclusion states.
5117	Promotes a transaction by adding spam on top of it with specified depth and minimum weight magnitude, returning the newly-published bundle.
5118	Replays a bundle by attaching it to the Tangle using the provided tail transaction hash. Takes optional parameters for depth and min weight magnitude, with defaults applied when not specified. Returns the raw trytes that were published to the Tangle.
5119	Sends a transfer by preparing transfers, creating a bundle, attaching it to the Tangle, and broadcasting the transactions. Returns the published bundle.
5120	Sends transaction trytes to the Tangle by attaching, broadcasting, and storing them. Takes transaction trytes, attachment depth, and minimum weight magnitude as parameters, returning the published trytes. Uses a default minimum weight magnitude if not provided.
5121	Given a URI, returns a properly-configured adapter instance by parsing the URI, validating its scheme, looking up the appropriate adapter type in the registry, and configuring it with the parsed URI components. Raises InvalidUri exceptions for malformed URIs or unrecognized protocols.
5122	Method that sends an API request to the node with the given payload and additional kwargs, returning the decoded response. Raises BadApiResponse for non-success responses. Not implemented in the base class and must be overridden by subclasses.
5123	Logs a message to the instance's logger if configured, with optional context data.
5124	Sends an HTTP request with the specified URL, payload, and method, with optional authentication and timeout settings. Logs the request and response details at the DEBUG level. Supports mocking for unit testing purposes. Returns the HTTP response object.
5125	Interprets an HTTP response from a node, validating the response format and status code. Raises exceptions for empty, non-JSON, or malformed responses, and for unexpected status codes. Returns the decoded response body if the status code is expected.
5126	Sets a response for a given command in a FIFO queue structure, allowing multiple responses per command. Returns the adapter instance for chaining.
5127	Absorbs a digest into the sponge by adding it to the internal sponge state and digest list, while preventing further modifications once an address has been extracted.
5128	Returns the multisig address generated from the accumulated digests. Raises ValueError if no digests have been added. Creates the address using a sponge function if it hasn't been created yet, and stores it for future use.
5129	Creates an iterator that generates addresses progressively using a key generator, starting from a specified index with a given step size.
5130	Generates an address from a private key digest by absorbing the digest's trits into a Kerl sponge state and squeezing out the address trits. Returns an Address object constructed from the computed trits along with the digest's key index and security level.
5131	Generates a new address for cache miss events, optionally adding checksum validation based on checksum configuration.
5132	Finds transactions matching specified criteria, fetches their trytes, and converts them into Transaction objects. Returns a list of Transaction objects or empty list if no transactions found.
5133	Iterates through addresses starting from a given index to find those with transaction history.

This function generates addresses using a seed and security level, then checks each address for associated transactions on the Tangle. It yields tuples of (address, transaction_hashes) for addresses that have transactions, stopping when it encounters an address with no transactions. The iteration uses a FindTransactionsCommand to query the Tangle for each address, and resets the command between queries to avoid state conflicts.

Args:
    adapter: BaseAdapter instance for Tangle communication
    seed: Seed object for address generation
    start: Starting index for address generation
    security_level: Security level for address generation (defaults to 2)

Yields:
    Tuple of (Address, List[TransactionHash]) for addresses with transaction history

Returns:
    Generator that yields address-transaction pairs until no more used addresses are found
5134	Returns the bundles corresponding to the given transaction hashes, sorted by tail transaction timestamp. Optionally attaches inclusion states to the bundles.
5135	Determines which codec to use for the specified encoding, returning AsciiTrytesCodec.get_codec_info() for either the standard or deprecated codec name, with a deprecation warning for the old codec name, or None if the encoding is not recognized.
5136	Returns codec information dictionary containing encode/decode methods for the codecs library configuration, with additional text encoding flag for Python 3.
5137	Encodes a byte string into trytes by converting each byte into two tryte characters from the alphabet using base-27 encoding. Takes a byte string input and optional error handling, returns the encoded trytes and the length of original input. Raises TypeError for non-byte string inputs.
5138	Decodes a tryte string into bytes, handling invalid input according to the specified error handling scheme ('strict' or 'replace'). Returns a tuple of the decoded bytes and the length of the input.
5139	Find addresses matching the command parameters by either iterating through addresses until one with no transactions is found (when count is None) or by generating a specific number of addresses using the AddressGenerator.
5140	Adds a route to the wrapper.

Args:
    command: The name of the command to route (e.g., "attachToTangle").
    adapter: The adapter object or URI to route requests to.

Returns:
    The wrapper instance.
5141	Creates a Transaction object from a sequence of trytes by parsing the tryte string into transaction components and optionally computing the transaction hash if not provided.
5142	Returns a JSON-compatible dictionary representation of the transaction object, containing all its attributes like hash, signature message fragment, address, value, and various transaction metadata including timestamps, indexes, and hashes.
5143	Returns the concatenated tryte string containing address, value, tag, timestamp, and index values needed to validate the transaction's signature message fragment.
5144	Sets the `is_confirmed` status for the bundle and propagates this status to all transactions within the bundle.
5145	Extracts and decodes messages from transaction bundles by concatenating signature message fragments from positive value transactions, handling decoding errors according to the specified error policy ('drop', 'strict', 'replace', or 'ignore').
5146	Returns TryteString representations of the transactions in this bundle, with optional ordering control (head-to-tail or tail-to-head).
5147	Groups transactions in the bundle by address, returning a list of transaction groups where each group contains transactions from the same address.
5148	Automatically discovers commands in a specified package by dynamically importing modules and registering command classes that inherit from CommandMeta. Returns a dictionary of discovered commands indexed by their command names. Supports recursive discovery of sub-packages and handles both package paths (as strings) and package references (as ModuleType objects). Uses walk_packages to iterate through modules and get_members to identify command classes. The function leverages the CommandMeta metaclass to ensure proper registration of commands during module import.
5149	Sends a request through the adapter after injecting the command name, returning the response.
5150	Applies a filter to a value and raises a ValueError with contextual information if the filter validation fails. If no filter is provided, returns the original value unchanged.
5151	Returns the URL to check job status for a given job ID by constructing a path relative to the current URI.
5152	Returns all errors found with the bundle by extending the internal errors list with the validator results and catching any StopIteration exceptions during the process.
5153	Returns whether the bundle is valid by checking if there are any errors in the validation process. If no errors exist, it attempts to validate the bundle and returns True if validation passes (no errors) or False if validation fails (errors present).
5154	Creates a generator that validates bundle transactions by checking bundle hashes, indices, balance, and signatures, yielding error messages for any invalid transactions.
5155	Validates signature fragments in a bundle using supported and legacy algorithms, returning error messages for invalid signatures.
5156	Validates signature fragments for a group of transactions using specified sponge type. Returns None if valid, otherwise returns error message indicating invalid signature.
5157	Recursively traverses the Tangle to collect all transactions belonging to a bundle, starting from a given transaction hash. Stops when encountering a transaction from a different bundle or when reaching the end of the bundle. Returns a list of Transaction objects in the bundle, ordered from tail to head. Raises BadApiResponse if the starting transaction is not a tail transaction or if transactions are not visible.
5158	Starts a REPL (Read-Eval-Print Loop) session with the IOTA API client. The function creates a banner message showing the API URI and network type (testnet/mainnet), then attempts to start an IPython REPL if available. If IPython is not installed, it falls back to the standard Python REPL. The API client is made available in the REPL scope as the variable `api`.
5159	Generates a random seed using a CSPRNG with specified length (default 81 trytes) for maximum security.
5160	Generates a constant-length digest from a signing key by processing it through multiple PBKDF iterations using Kerl sponge hashing, returning a Digest object with the computed hash and key index.
5161	Signs the input transactions in a bundle starting at the specified index, splitting the signature across multiple transactions if necessary. Raises exceptions with detailed context if the bundle hash is missing, transactions are invalid, or attempts are made to sign non-input transactions or already signed transactions.
5162	This method provides pretty-printing support for IPython's display system by implementing the `_repr_pretty_` protocol. It formats JSON-serializable objects in a readable way, handling circular references and different data types (mapping vs iterable) with appropriate prefixes. The method uses IPython's pretty printer to format the object's JSON-compatible representation within parentheses, making objects display nicely in Jupyter notebooks and IPython consoles.

**Key aspects:**
- Implements IPython's `_repr_pretty_` protocol for enhanced display
- Handles circular references with cycle detection
- Formats data with proper prefix markers (** for mappings, * for iterables)
- Uses IPython's group formatting for clean output structure
- Works with JSON-compatible representations of objects
5163	Absorbs trits into the sponge from a buffer, padding the input if necessary to ensure it can be evenly divided into hash chunks. The method processes the trits in chunks of TRIT_HASH_LENGTH, zeroing the last trit of each full chunk before converting and updating the internal state with the unsigned byte representation. Raises a ValueError if an invalid length is provided.
5164	Squeeze trits from the sponge into a buffer, padding the input if necessary and handling hash-length constraints. If the buffer is too small, it will be extended. The method defaults to squeezing one hash length (TRIT_HASH_LENGTH) of trits unless a specific length is provided. It processes the sponge's digest, converts it to trits, and updates the internal state by flipping bytes and resetting the sponge.
5165	Attaches a context dictionary to an Exception object by adding/updating the 'context' attribute, then returns the modified exception. If the exception doesn't have a context attribute, it initializes it as an empty dictionary before updating it with the provided context data.
5166	Generates a filter chain that validates security levels as integers between 1 and 3, with an optional default value of 2.
5167	Increments the transaction's legacy tag by adding 1 to its trit representation, used for fixing insecure bundle hashes during bundle finalization.
5168	Returns the most relevant tag for the bundle by checking transactions in reverse order, returning the first transaction's tag found or an empty Tag if none exist.
5169	Adds a transaction to the bundle, automatically splitting long messages into multiple transactions while maintaining the original transaction's properties. Raises RuntimeError if the bundle is already finalized, or ValueError if attempting to add a negative value transaction.
5170	Finalizes the bundle by validating transactions, handling balance adjustments, generating a secure bundle hash, and assigning the hash to individual transactions. Raises errors for invalid states or unbalanced inputs.
5171	Sign inputs in a finalized bundle using the provided key generator, skipping transactions that don't require signing and handling security levels for signed transactions.
5172	Signs the input transaction at the specified index using the provided private key. Raises RuntimeError if the bundle is not finalized. Handles automatic splitting of signatures across multiple transactions when necessary.
5173	Creates input transactions for a specified address by adding a main transaction that spends the entire balance and additional zero-value transactions for signatures, based on the address security level.
5174	Converts a given value with its unit symbol to a specified standard unit of iota and returns the converted value as a float.
5175	Decompresses a G1 compressed point into its uncompressed form by recovering x and y coordinates from the compressed representation, handling special cases like the infinity point and ensuring the correct y coordinate is chosen based on the compression flags.
5176	Returns the modular multiplicative inverse of a modulo n using the extended Euclidean algorithm. For input a and n, computes integer x such that (a * x)  1 (mod n). Handles edge case when a = 0 by returning 0. Uses iterative approach with variable tracking to efficiently find the inverse.
5177	Loads a lexicon from a JSON file by opening the file and parsing its contents into a new instance of the class.
5178	Finds and combines words into groups based on their proximity in the text. Takes a string and a category of words, uses regex to identify matching words, then groups nearby words (within the specified proximity) together. Returns a list of combined strings. For example, with color categories and text "GREYISH-GREEN limestone", it returns ['greyish green'].
5179	Method that finds the preferred synonym for a given word using a reverse lookup table, case insensitive, and returns the input word if no synonym is found.
5180	Method: `expand_abbreviations(self, text)`

Summary: Replaces abbreviations in the input text with their full word equivalents using a lexicon dictionary. The method processes abbreviations in chunks to handle regex group limitations, with special case handling for 'w/' which is replaced with 'wi'. Returns the text with abbreviations expanded.

Input: 
- text (str): The text to parse and expand abbreviations in

Output: 
- str: The text with abbreviations replaced by their full word equivalents

Raises:
- LexiconError: If no abbreviations exist in the lexicon

Processing:
1. Validates that abbreviations exist in the lexicon
2. Defines helper functions for chunking abbreviation data and regex callbacks
3. Handles special case 'w/'  'wi' replacement
4. Processes abbreviations in chunks of 25 to avoid regex group limits
5. Builds regex pattern for each chunk and applies replacement callback
6. Returns the processed text with all abbreviations expanded
5181	Split a description text into component parts using specified delimiters, while protecting special sequences like "in." and "ft." measurements and handling percentage indicators as separators.
5182	Returns a list of category names from the lexicon, excluding special/optional categories.
5183	Returns a minimal Decor with a random color by generating three random values between 0-255 for RGB components.
5184	Creates a simple plot of the Decor component with specified formatting. Returns the figure or axis object based on input parameters, displaying a colored rectangle with hatch pattern and component summary text.
5185	Generate a default legend based on the specified name parameter by looking up the corresponding legend data in defaults.py and returning it as a Legend object.
5186	Generate a default timescale legend from predefined names. Returns a Legend object based on the specified timescale name.
5187	Generate a random legend for a given list of components, with optional width and color settings.
5188	Creates a legend from an image by extracting colors from the top of the image and mapping them to components. The method reads an image file, identifies color changes, reduces to unique colors while ignoring specified colors, and creates Decor objects mapping each unique color to a component. The resulting list of Decors is used to initialize and return a new instance of the class.
5189	Creates a Legend object from CSV text or file by parsing rows into Decor and Component objects, handling component properties prefixed with 'comp' or 'component', and managing duplicates with warnings.
5190	Renders a legend as a CSV string by collecting all properties from legend rows and their components, creating a header with combined properties and then appending each row's data with proper formatting. Returns the complete CSV content as a string.
5191	Returns the maximum width among all Decors in the Legend, needed for scaling legends when plotting with widths enabled. Returns 0 if no valid widths are found.
5192	Get the decor for a component by matching component attributes or curve mnemonic, returning the matching Decor from the Legend or a default Decor if not found.
5193	Get the attribute of a component by first finding the matching Decor and then retrieving the specified attribute, returning a default value if the attribute doesn't exist.
5194	Get the component corresponding to a display colour, with optional tolerance for colour matching. Returns the best matching component or a default value if no match is found within the specified tolerance. Raises LegendError if tolerance is out of valid range.
5195	Plots the legend by calling the plot method on all its member objects. Simply invokes Decor.plot() on each element in the internal list. Returns None.
5196	Create a Component instance from text using a lexicon, with optional required attribute checking.
5197	Returns a formatted summary description of a component based on its attributes and a given format string. If no format is provided, it returns a comma-separated list of non-empty attributes with the first letter capitalized. If an empty string is provided as format, it returns a default value. Raises ComponentError if there's an issue with the formatting.
5198	Summary: The `Rock` function serves as a graceful deprecation wrapper that alerts users when they attempt to use the old class name 'Rock' instead of the new 'Component' class. It issues a deprecation warning with a clear message instructing users to update their code, then seamlessly forwards the call to the new `Component` class with the same arguments.
5199	Processes a single row from a file by parsing text according to column specifications and returning a dictionary mapping field names to their extracted values.
5200	Parse CANSTRAT text data into a dictionary structure, where each card type is a key and its corresponding processed data is the value. The function splits the input text into rows, processes each row based on its card type using predefined column mappings, and flattens single-item lists into individual values. Returns a dictionary with card types as keys and either single items or lists of items as values.
5201	Checks if the striplog is monotonically increasing in depth by examining boundaries and returning a boolean result.
5202	Property. Summarize a Striplog with some statistics.

Returns:
    List. A list of (Component, total thickness) tuples sorted by thickness in descending order.
5203	Private method that converts a sequence of tops into a list of intervals for striplog creation. Takes tops, values, basis, and components as input, scales tops to actual depths, and creates Interval objects with corresponding data and components. Handles NaN values based on ignore_nan parameter and supports optional field specification. Returns a list of Interval objects representing the intervals between tops.
5204	Private function to clean longitudinal data for striplog creation by renaming depth/MD to 'top', sorting by top values, handling missing values, and returning cleaned data dictionary.
5205	Creates a striplog from a Petrel text file by reading the data, cleaning it, building intervals, and returning a striplog object if intervals exist.
5206	Builds a list of Interval objects from a data dictionary by reconstructing intervals with optional filtering, sorting, and component handling.
5207	Load data from a CSV file or text string, parse it into a structured format, and return a new instance of the class containing the parsed intervals. Supports various options for handling delimiters, field names, data cleaning, and interval building.
5208	Create a Striplog object from an image by extracting color-based intervals. Reads an image file, processes pixel data to identify color changes, maps colors to components using a legend, and generates intervals with corresponding values and components. Supports configurable column/row offsets and color tolerance for matching.
5209	Creates a striplog object from a 1D array-like log using specified cutoffs and components. Supports optional legend mapping, field specification, and basis alignment. Raises StriplogError for insufficient components or missing basis. Returns a Striplog instance.
5210	Creates a Striplog object from a LAS3 lithology section string by extracting the data portion using regex pattern matching, updating the source if specified, and then converting the descriptions to a Striplog using the class's from_descriptions method. Handles multiple data sections and supports custom lexicon, delimiter, and abbreviation expansion options.
5211	Creates a striplog from a Canstrat DAT file by parsing lithology data and constructing Interval objects with lithology and color components.
5212	Returns a shallow copy of the Striplog object.
5213	Returns a CSV string built from the summaries of the Intervals, with options for custom delimiter, header, and using descriptions instead of summaries.
5214	Returns an LAS 3.0 Lithology section string by converting the object data to CSV format and embedding it in a formatted template with specified delimiter and source parameters.
5215	Plots rectangular patches on a given matplotlib axis based on the data in `self.__list`. It supports optional width scaling, coloring based on data fields, legends, and custom styling. Returns the modified matplotlib axis object.
5216	Get data from the striplog by extracting a specified field from each item, optionally applying a function to transform the data, and returning a numpy array of the results with NaN as default for missing values.
5217	Extracts log data into striplog components by grouping samples at the same index and storing processed values in the specified attribute name. Takes log data, basis values, and an optional processing function to determine what gets stored in each component's data dictionary.
5218	Method: find
Purpose: Search for a regex expression or Component within striplog intervals
Parameters: 
- search_term (string or Component): Text to search for (treated as regex when string)
- index (bool): If True, returns indices instead of Interval objects
Returns: 
- Striplog containing matching intervals, or list of indices if index=True
- None if no matches found
Behavior: 
- Searches descriptions first, then summaries if no description exists
- For Component searches, checks against components directly
- Case insensitive matching
- Handles TypeError exceptions for Component searches
- Returns empty result when no matches found
5219	Find overlaps in a striplog by identifying intervals where the next interval starts before the current one ends, returning a Striplog of all overlapping intervals. If index=True, returns indices of intervals with gaps after them instead.
5220	Finds gaps in a striplog by identifying incongruities where intervals are less than expected. Returns a Striplog containing all gaps, with an option to return indices of intervals with gaps after them.
5221	Remove intervals below a certain limit thickness. In place.

Args:
    limit (float): Anything thinner than this will be pruned.
    n (int): The n thinnest beds will be pruned.
    percentile (float): The thinnest specified percentile will be pruned.
    keep_ends (bool): Whether to keep the first and last, regardless of whether they meet the pruning criteria.
5222	Method `anneal` fills empty intervals by growing from top and base in-place, destroying Position information. It finds gaps, then for each gap adjusts the top and base values of adjacent intervals to fill the gap based on the order (depth or not depth). Returns the modified strip with filled gaps.
5223	Fill gaps in the intervals with the provided component, returning a new object with filled gaps. If no component is provided, uses an empty list. Returns a deep copy of the object with gaps filled.
5224	Union two striplogs by combining overlapping intervals and returning a new striplog with all unioned intervals.
5225	Method: `intersect`

Summary: Creates a new striplog containing all overlapping intervals between this striplog and another striplog. Returns a Striplog instance with the intersected intervals.

Parameters: 
- `other`: A Striplog instance to intersect with

Returns: 
- Striplog: A new Striplog containing intersected intervals

Raises:
- StriplogError: If the other object is not of the same class
- IntervalError: If intervals don't overlap (handled silently)
5226	Merges overlapping intervals in a striplog by combining overlapping Intervals and updating the striplog in place. Returns None. Note: this function has limitations and will not work if any interval overlaps more than one other interval at either its base or top.
5227	Plots a histogram of interval data and returns the histogram data. Supports optional grouping by component attributes, sorting by thickness, plotting with optional custom axis and legend, and returns either component summaries or full components as bins. The method can return counts, entities, and optionally the plot axis object.
5228	Inverts the striplog by reversing its order and contents. If copy=True, returns a new inverted copy; otherwise, operates in-place and returns None.
5229	Crops a striplog to a new depth range specified by the extent tuple. Takes a start and stop depth value, validates they are within existing striplog bounds, and returns a new cropped striplog or modifies the existing one in place. Supports optional copying via the copy parameter.
5230	Run a series of tests and return the corresponding results.

Args:
    tests (list): a list of functions.
    alias (dict): a dictionary of aliases for striplog tests.

Returns:
    dict. The test results with test names as keys and test outcomes as values.
5231	Converts a hexadecimal color code to its corresponding color name using matplotlib's color names. Returns the color name if found, otherwise returns None.
5232	Extracts RGB pixel values from a specified column of a PNG image as a log-likelihood stream. The column is determined by an offset that can be specified as either a proportion (0-1) of image width or absolute pixels. Returns a 2D array containing RGB triples from the selected column.
5233	Return an underscore if the attribute is absent. Not all components have the same attributes. If the field is missing due to KeyError or IndexError, return ("_", field_name) as a fallback.
5234	Lists all jobs registered with Nomad, optionally filtered by a prefix string. Returns a list of jobs. Raises BaseNomadException or URLNotFoundNomadException on error.
5235	Parse a HCL Job file and return a dictionary with the JSON formatted job. Supported from Nomad version 0.8.3. Raises BaseNomadException or URLNotFoundNomadException.
5236	Update ACL token by ID.

https://www.nomadproject.io/api/acl-tokens.html

Arguments:
- id (str): Accessor ID of the token
- token (dict): Token data to update

Returns:
- dict: API response containing updated token information

Raises:
- nomad.api.exceptions.BaseNomadException
- nomad.api.exceptions.URLNotFoundNomadException
5237	Lists all allocations with optional prefix filtering, returns JSON response containing allocation data.
5238	Marks a deployment as failed to stop allocation creation or trigger a rollback to a previous job version.

**Arguments:**
- `id` (str): The deployment ID to mark as failed

**Returns:**
- `dict`: API response containing deployment information

**Raises:**
- `nomad.api.exceptions.BaseNomadException`: For general Nomad API errors
- `nomad.api.exceptions.URLNotFoundNomadException`: When deployment ID is not found

**HTTP Request:** POST /v1/deployment/fail/{id}
5239	This endpoint pauses or resumes a deployment, allowing control over rolling upgrades. It requires a deployment ID and a pause boolean flag, returning a dictionary with the deployment status. It may raise BaseNomadException or URLNotFoundNomadException.
5240	Sets the health status of allocations in a deployment manually. Used when automatic health detection is disabled (health_check = "manual" upgrade policy). Marks allocations as healthy to allow rolling upgrades or unhealthy to fail the deployment. Requires deployment ID and lists of healthy/unhealthy allocation IDs. Returns JSON response from the Nomad API.
5241	Toggle the drain mode of a node. When enabled, no further allocations will be assigned and existing allocations will be migrated. Returns the JSON response from the API call. Raises BaseNomadException or URLNotFoundNomadException on error.
5242	This method toggles the drain mode of a Nomad node, controlling whether allocations are assigned to or migrated from the node. It accepts a node ID, drain specification, and optional eligibility flag to configure draining behavior. When drain_spec is provided, it enables draining with the specified settings. When an empty dictionary is passed, it disables draining. The method constructs a payload based on the provided parameters and makes a POST request to the Nomad API endpoint for node draining, returning the JSON response.
5243	Toggle the eligibility of a node by setting it to eligible or ineligible based on the provided parameters. The method requires either `eligible` or `ineligible` parameter to be specified, and raises InvalidParameters exception if both or neither are provided. It returns a dictionary with the response from the Nomad API.
5244	List files in an allocation directory. If an allocation ID is provided, it lists files in the specified allocation's directory; otherwise, it lists files in the default directory. Returns a list of files and directories at the specified path. Raises BaseNomadException or URLNotFoundNomadException on error.
5245	Streams the contents of a file in an allocation directory from the Nomad client API, returning the file contents as text.
5246	Stats a file in an allocation directory.

**Arguments:**
- `id` (str, optional): Allocation ID
- `path` (str): Path to the file/directory to stat (default: "/")

**Returns:**
- dict: File statistics information

**Raises:**
- `nomad.api.exceptions.BaseNomadException`: For general Nomad API errors
- `nomad.api.exceptions.URLNotFoundNomadException`: When the specified path is not found

**API Reference:** https://www.nomadproject.io/docs/http/client-fs-stat.html
5247	Initiates a join between the agent and target peers by sending a POST request to the join endpoint with the specified addresses. Returns a dictionary response from theNomad API. Raises exceptions for base Nomad errors or URL not found scenarios.
5248	Updates the list of known servers with the provided addresses, replacing all previous server addresses. Returns HTTP 200 status code on success. Raises BaseNomadException or URLNotFoundNomadException on failure.
5249	Force a failed gossip member into the left state and return the HTTP status code.
5250	Lists all client nodes registered with Nomad, optionally filtered by a prefix string. Returns a list of nodes and may raise BaseNomadException or URLNotFoundNomadException.
5251	Lists all evaluations with optional prefix filtering, returns JSON response containing evaluation data.
5252	Lists all namespaces registered with Nomad, optionally filtered by a prefix. Returns a list of namespaces as JSON. Raises BaseNomadException or URLNotFoundNomadException on error.
5253	Registers a new job or updates an existing job in Nomad.

Registers a new job or updates an existing job in Nomad.

Arguments:
- id (str): The job ID
- job (dict): The job definition

Returns:
- dict: The JSON response from the Nomad API

Raises:
- nomad.api.exceptions.BaseNomadException: Base exception for Nomad API errors
- nomad.api.exceptions.URLNotFoundNomadException: Exception raised when the Nomad API endpoint is not found

This method sends a POST request to the Nomad HTTP API job endpoint to register or update a job with the specified ID using the provided job definition. The job definition should be a dictionary containing the job configuration. The method returns the JSON response from the Nomad API, which typically contains the job status and other relevant information.

The method follows the Nomad HTTP API specification for job registration and can be used to both register new jobs and update existing ones by providing the same job ID for an existing job.
5254	Plans a job by invoking a dry-run of the scheduler for the specified job.

**Parameters:**
- `id` (str): The job ID
- `job` (dict): The job definition
- `diff` (bool, optional): Whether to return a diff showing changes. Defaults to False
- `policy_override` (bool, optional): Whether to override policy checks. Defaults to False

**Returns:**
- dict: The JSON response from the Nomad API containing the job plan

**Raises:**
- nomad.api.exceptions.BaseNomadException: If the request fails
- nomad.api.exceptions.URLNotFoundNomadException: If the job URL is not found
5255	Dispatches a new instance of a parameterized job to Nomad.

This method creates and submits a new job dispatch request to the Nomad API. It takes a job ID along with optional payload and metadata parameters, constructs a dispatch request with these parameters, and sends it to Nomad's dispatch endpoint. The method returns the JSON response from Nomad containing details about the dispatched job.

Arguments:
- id (str): The job ID to dispatch
- payload (str, optional): Additional payload data for the job dispatch
- meta (dict, optional): Metadata to include with the job dispatch

Returns:
- dict: JSON response from Nomad API containing dispatch information

Raises:
- nomad.api.exceptions.BaseNomadException: For general Nomad API errors
- nomad.api.exceptions.URLNotFoundNomadException: When the job dispatch endpoint is not found
5256	This endpoint reverts a job to a specified older version. It takes a job ID and version number as required parameters, with an optional enforce_prior_version parameter for check-and-set operations. The method makes a POST request to the Nomad API's revert endpoint and returns the JSON response containing the revert operation results. It can raise BaseNomadException or URLNotFoundNomadException if the operation fails.
5257	Sets a job's stability status to stable or unstable by specifying the job ID, version, and desired stability state. Returns the JSON response from the Nomad API after marking the job as stable/unstable.
5258	Deregisters a job and stops all its allocations. Optionally purges the job immediately or defers purging to the Nomad garbage collector. Returns a dictionary response from the Nomad API. Raises exceptions for base Nomad errors, URL not found, and invalid parameters.
5259	Queries the raft configuration status of a client node registered with Nomad, with an optional stale parameter to allow responses without an active leader. Returns a dictionary containing the configuration data.
5260	Delete a Nomad server peer from the Raft configuration by address. Returns True if successful, False otherwise. Supports optional stale query parameter for cluster responses without active leader. Raises BaseNomadException or URLNotFoundNomadException on error.
5261	Method: `get_deployments`

Summary: Retrieves all deployments from the Nomad API, optionally filtered by a prefix string. 

Parameters:
- `prefix` (str, optional): Specifies a string to filter deployments on based on an index prefix. Defaults to empty string.

Returns: List of dictionaries containing deployment information

Raises:
- `nomad.api.exceptions.BaseNomadException`
- `nomad.api.exceptions.URLNotFoundNomadException`

HTTP Endpoint: `GET /deployments` (via `self.request` call with query parameters)
5262	Get a random mutator from a list of mutators based on the specified object type and configuration level.
5263	Get a random mutator for the given type, converting unicode to str if necessary, then apply the random mutator to the object.
5264	Return a polyglot attack string containing the original object using a randomly selected technique from the configuration.
5265	Perform fuzzing on an object by randomly modifying its contents through a series of random actions, returning the result as a Unicode string.
5266	Safely returns a Unicode encoded string by joining and concatenating characters from the input buffer.
5267	Start the HTTP and HTTPS servers, set up routing for serving files and handling requests, and begin fuzzing if enabled.
5268	Stop the HTTP and HTTPS servers by sending SIGKILL signals, terminate the client queue, join the request checker if fuzzing is enabled, and log the completion message.
5269	Serve a custom HTML page from the specified filepath with CORS headers and proper content-type, handling exceptions by raising a PJFBaseException.
5270	Serve fuzzed JSON object with CORS headers and optional testcase notification.
5271	Generic fuzz mutator that applies a mutate_object_decorator to the given object and returns the decorated result.
5272	Spawn a new process using subprocess with the given command and parameters, handling various input types and exceptions during process execution.
5273	Method: `get_output(self, stdin_content, stdin)`
Summary: Attempts to retrieve output from a subprocess in a separate thread. Writes input to the process stdin if provided, then calls communicate() to get the output. If an error occurs during the process, it falls back to using the input content as output.
5274	Wait for process output with timeout, handling timeouts by closing the process and setting return code to SIGHUP signal.
5275	Terminate the process and close all file descriptors, logging completion status.
5276	Parse command line arguments and start PyJFuzz based on specified options, handling various fuzzing modes including web fuzzer, external fuzzing, command line fuzzing, HTTP server start, file fuzzing, and process monitoring.
5277	Execute external fuzzing by spawning a process with the configured command and input object, handling both stdin and file-based input methods with appropriate error handling and logging.
5278	A decorator that converts return values from PJFFactory.fuzzed into a printable JSON structure, handling both hexadecimal and Unicode encoding/decoding for proper serialization.
5279	Build the String instance with optional prerequisites and shortest reference-chain option, returning either a valued string or randomly generated data based on charset and length.
5280	Builds the ``And`` instance by processing values with optional prerequisites and shortest reference-chain generation. Returns the joined result string. Handles `OptGram` exceptions by continuing and `FlushGrams` exceptions by flushing previous results to scope stack.
5281	Build the ``Quote`` instance with optional prerequisites and shortest reference-chain flag, returning the appropriately formatted quoted string based on escape settings.
5282	Build the ``Or`` instance with optional prerequisites and shortest reference-chain generation.

**Parameters:**
- `pre` (list): The prerequisites list (default: None, which becomes empty list)
- `shortest` (bool): Whether to generate the shortest reference-chain version (default: False)

**Returns:**
- A value generated using `utils.val()` with randomly selected values from either `self.shortest_vals` (when shortest=True and available) or `self.values`

**Behavior:**
- If `shortest=True` and `self.shortest_vals` is available, uses the minimal reference chain values
- Otherwise, uses the standard values from `self.values`
- Both cases call `utils.val()` with the randomly chosen value and provided parameters
5283	Build the current ``Opt`` instance with optional prerequisites and shortest reference-chain generation.
5284	Builds the ``Ref`` instance by fetching the rule from the GramFuzzer instance and building it.

Args:
    pre (list): The prerequisites list
    shortest (bool): Whether or not the shortest reference-chain (most minimal) version of the field should be generated.

Returns:
    The built reference instance.

Raises:
    None explicitly mentioned.

Note:
    This method modifies the global ``REF_LEVEL`` variable, incrementing it before execution and decrementing it in the finally block to ensure proper cleanup. The ``shortest`` parameter affects the building process, and if ``REF_LEVEL`` exceeds ``self.max_recursion``, the ``shortest`` flag is forced to ``True``.
5285	Build the STAR field with optional prerequisites and shortest reference-chain generation, raising OptGram errors for certain conditions.
5286	Shutdown the running process and the monitor, wait for process completion, close process streams, mark as finished, send testcase, and log completion. Raises PJFBaseException on error.
5287	Run command once and check exit code, handling SIGINT signal and monitoring for SIGSEGV exit code.
5288	Starts a monitoring loop for a process, restarting it when needed and handling crashes with SIGSEGV by waiting for testcases and saving them.
5289	Generate a random float number within specified range. If only one argument is provided, generates a float between 0.0 (inclusive) and the given value (exclusive). If two arguments are provided, generates a float between the first value (inclusive) and the second value (exclusive).
5290	Add a new rule definition to a specified category with optional pruning control and staging support.
5291	Associate a rule definition name with a category group by appending the definition name to a deque stored under the specified category and group.
5292	Generate `num` rules from a specified category, with optional preferred category groups and recursion limits. The method supports automatic rule processing and handles error cases during rule generation. It returns a deque of generated rules.
5293	Fuzz all elements inside the object recursively, applying mutation to dictionary values and list elements based on configuration parameters.
5294	Get a printable fuzzed object with optional URL encoding and strong fuzzing based on configuration settings.
5295	Return the fuzzed object by processing JSON elements, handling both array and non-array cases with error handling.
5296	**Summary:**

The `mutate_object_decorate` method is a decorator that creates a mutation function for generic objects based on their type. It takes a function `func` as input, executes it to get an object, and then applies the appropriate mutator from `self.Mutators` based on the object's type. The method returns a closure that encapsulates this mutation behavior.

**Key aspects:**
- Decorator pattern for object mutation
- Type-based mutator selection
- Encapsulated mutation logic
- Generic object handling through type inspection
5297	Handles SIGTERM signal by stopping the ioloop, sending the signal to a child process if running, and exiting gracefully based on current state (WAITING, RUNNING, or PAUSED).
5298	kills the child process and exits the CLI command loop
5299	Pause the running child process if exists, otherwise just set the state to paused. Useful when deploying code and wanting to prevent the child from spawning randomly. Returns 'killed' if a process was terminated.
5300	Sets the state to waiting to resume spawning children when the current state is paused.
5301	Stops the running child process if it's active, sets the state to PAUSED, sends a kill signal to the process, and returns 'killed'. The process will respawn automatically in a single-beat node after a timeout.
5302	Method: `cli_command_restart`

Summary: Restarts the subprocess by setting the state to RESTARTING, killing the current process, and preparing to start a new one. Returns 'killed' if successful, otherwise returns empty string. The method only executes when the current state is RUNNING and a subprocess exists.

Parameters:
- `msg`: Message parameter (not used in implementation)

Returns: String indicating success ('killed') or empty string

Side effects: 
- Changes internal state to RESTARTING
- Kills the subprocess process
- Sets exit callback for process restart handling
5303	Retrieve a list of events since the last poll by fetching from the connection endpoint and converting raw JSON data into SkypeEvent objects. Returns a list of SkypeEvent objects, which may be empty if no events occur within the 30-second timeout period.
5304	Update the current user's mood message by sending a POST request to the Skype API and updating the local user object with the new mood value.
5305	Update the profile picture for the current user by uploading an image file.
5306	Retrieve various metadata associated with a URL, as seen by Skype. Args: url (str): address to ping for info Returns: dict: metadata for the website queried
5307	Retrieve all details for a specific contact by ID, including birthday and mood information. Returns a SkypeContact object or None if the user is not a contact or access is forbidden.
5308	Retrieves public information about a user by their ID and returns a SkypeUser object, or None if the user is not found or an error occurs.
5309	Retrieve a list of all known bots.

Returns:
    SkypeBotUser list: resulting bot user objects
5310	Retrieve a single bot by UUID or username, returning a SkypeBotUser object or None if not found.
5311	Search the Skype Directory for a user by name and return a list of matching SkypeUser objects.
5312	Retrieve any pending contact requests.

Returns:
    :class:`SkypeRequest` list: collection of requests
5313	Create a new instance based on raw API response properties, allowing for subclass instantiation based on raw content. Takes a parent Skype instance and raw dictionary object, returns a new class instance.
5314	Merges properties from another object into self, skipping None values, and updates raw data dictionaries.
5315	Merge a given object into the cache, updating existing entries or creating new ones.
5316	Method `syncStateCall` handles API pagination by tracking sync state URLs returned by API endpoints. It makes HTTP requests using the provided method and URL, and if a `syncState` link is found in the JSON response metadata, it stores this state for subsequent requests to the same endpoint. The method maintains a registry of sync states per (method, url) tuple and automatically uses the latest sync state URL for follow-up calls, eliminating the need for explicit pagination handling by the caller. The method returns the response object from the final API call made.
5317	Reads and validates authentication tokens from a file to establish a Skype connection, handling token expiration and registration token re-registration when necessary.
5318	Store details of the current connection in the named file for later re-authentication.
5319	Verifies that the authentication token for a given auth method is still valid. For SkypeToken and Authorize methods, checks if the Skype token has expired and attempts to renew it if a getSkypeToken method exists. For RegToken method, checks if the registration token has expired and refreshes it. Raises SkypeAuthException if Skype token expired and no password is specified for renewal.
5320	Refreshes the existing Skype token to extend its expiry time without requiring additional credentials. Updates the Skype token and its expiry time in the tokens and tokenExpiry dictionaries respectively, and retrieves a new registration token. Raises SkypeAuthException if the login request is rejected, and SkypeApiException if the login form can't be processed.
5321	Get the authenticated user's Skype identifier and store it on the connection object.
5322	Acquire a new registration token by verifying the Skype token, obtaining a new registration token from the provider, updating token storage with the new token and its expiry time, configuring message host and endpoint if available, synchronizing endpoints, and writing tokens to file if token file is specified.
5323	Retrieves all current endpoints for the connected user by making a GET request to the messaging service presence docs endpoint, extracts endpoint IDs from the JSON response, and creates SkypeEndpoint objects for each endpoint which are stored in the self.endpoints["all"] list.
5324	Check if a Microsoft account exists by querying a username or email address. Returns True if the account exists, False otherwise.
5325	Authenticates and refreshes an existing Skype token to extend its expiry time. Takes a Skype token as input, sends it to be validated and refreshed, then retrieves the updated token and its expiry time. Returns a tuple containing the new token and expiry datetime. Raises SkypeAuthException if authentication fails or SkypeApiException if the login form processing fails.
5326	Authenticates a user with a Skype token and returns a registration token along with associated metadata including expiry time, endpoint hostname, and endpoint information. The method handles token validation, endpoint registration, and redirects as needed, raising appropriate exceptions on failure.
5327	Configures this endpoint to allow setting presence with the specified display name. Sends a PUT request to update the messaging service presence document with endpoint information including the display name, capabilities, and version details.
5328	Send a keep-alive request to maintain endpoint activity with specified timeout duration.
5329	Retrieve recent conversations with most recent activity, store them in cache, and return as SkypeChat list. Each conversation is retrieved only once, with subsequent calls getting older conversations. Handles both single and group chats.
5330	Get a single conversation by identifier, returning either a single or group chat object based on the conversation type.
5331	Creates a new group chat with specified members and admins, automatically adding the current user as an admin. Returns a chat object for the newly created conversation.
5332	Extracts a username from a Skype API URL by matching patterns containing "users/<user>" or "users/ME/contacts/<user>" and returns the identifier portion.
5333	Extracts a conversation ID from a Skype API URL by matching the pattern "conversations/<chat>" and returns the extracted identifier, or None if no match is found.
5334	Generator function that repeatedly calls a given function until it returns a falsy value, yielding items from each call. Optional transform function can convert results into iterables for processing. Useful for retrieving all results from state-synced functions.
5335	Converts binary text to unicode, handling encoding and line endings consistently.
5336	Detects the appropriate handler based on text patterns. Takes unicode text and a dictionary of patterns-to-handlers, returning the matching handler instance or None if no pattern matches.
5337	Parse text with frontmatter, returning metadata dictionary and content. Uses optional handler for format detection and supports metadata defaults. Returns empty metadata dictionary if no frontmatter found.
5338	Method `to_dict` creates a dictionary representation of the object by copying metadata and adding the content field, useful for serialization purposes.
5339	Method: load
Parameters: self, fm, **kwargs
Returns: Parsed YAML front matter using yaml.SafeLoader by default
Description: Parses YAML front matter with SafeLoader as the default loader, allowing for custom loader specification through kwargs.
5340	Export metadata as YAML using yaml.SafeDumper by default, with default settings for flow style and unicode support.
5341	Convert metadata dictionary to a JSON-formatted unicode string with default indentation of 4 spaces.
5342	Return the match object for the current list, using cached results when possible to avoid redundant pattern matching operations.
5343	Return items as a list of strings, excluding sub-items and the start pattern.
5344	Return the Lists inside the item with the given index, optionally filtered by a pattern. If no index is provided, returns all sublists; otherwise, returns only sublists within the specified item. The pattern parameter can improve performance by limiting the search to specific list types.
5345	Converts the current list to another list type by replacing the starting pattern with a new start string, updating the pattern attribute with an escaped version of the new start string.
5346	Parse template content and create self.name and self.arguments, returning a list of Argument objects.
5347	Return all lists from all arguments, optionally filtered by a pattern. For better performance, consider getting a specific argument first and calling its `lists` method instead.
5348	Creates a Trie data structure from a list of strings and returns the root node of the Trie. Each node in the Trie represents a character, with nested dictionaries representing the character relationships. An empty string key ('') is added to mark the end of each word in the Trie. This structure is optimized for fast regex pattern matching by avoiding simple regex unions.
5349	Convert a trie data structure to a regular expression pattern, handling optional empty strings and grouping characters with shared subpatterns into character classes.
5350	Return adjusted start and stop index as tuple for __setitem__ and __delitem__ methods, handling both integer indices and slices with proper bounds checking and negative index adjustment.
5351	Inserts a string before the specified index in the span, updating spans and type mappings accordingly.
5352	Partition the string into three parts based on the first occurrence of a character: before the character, the character itself, and after the character, considering atomic sub-spans.
5353	Return all sub-spans including the current span for the specified type.
5354	Update self._type_to_spans according to the removed span, adjusting span coordinates and removing completely overlapped spans. Warning: This function can cause data loss and should be used carefully in combination with _insert_update.
5355	Update span boundaries in self._type_to_spans based on inserted length, adjusting both start and end positions when the insertion index affects existing spans.
5356	Return the nesting level of self, where the minimum level is 0. The nesting level increases by 1 for each Template or ParserFunction that contains self.
5357	Return a copy of self.string with specific sub-spans replaced by spaces (for comments) or underscores (for other spans), using cached results when available.
5358	Replace invalid characters in external links with underscores, handling different types of spans differently - all characters replaced for comments, only invalid chars replaced for Template, ParserFunction, and Parameter types.
5359	Create arguments for parse function used in pformat method, returning sub-spans adjusted to fit the new scope (self.string).
5360	Method `pprint` is deprecated and should be replaced with `pformat`. It takes an optional indent string (defaulting to 4 spaces) and a remove_comments boolean flag, issues a deprecation warning, and delegates to `pformat` with the same arguments.
5361	Return a list of parameter objects by creating Parameter instances from subspans.
5362	Return a list of parser function objects by creating ParserFunction instances for each subspan of type 'ParserFunction'.
5363	Return a list of template objects by creating Template instances from subspans of type 'Template'.
5364	Return a list of wikilink objects by creating WikiLink instances from subspans of type 'WikiLink'.
5365	Return a list of comment objects by creating Comment instances from subspans of type 'Comment'.
5366	Return a list of found external link objects, including adjacent templates as part of the link. Handles both new and existing external link spans, with templates within links being considered part of the link URL.
5367	Return a list of section objects in the current wikitext, including the lead section. If sections already exist, reuse their spans; otherwise, create new spans for sections.
5368	Return a list of found table objects by processing spans and creating Table instances.
5369	Return a list of WikiList objects based on the specified pattern. If no pattern is provided, returns all types of lists (ordered, unordered, and definition lists). The method uses regex matching to identify list items and creates WikiList objects for each match. Performance can be improved by specifying a pattern.
5370	Return all tags with the given name, including extension tags. If no name is provided, return all extension tags. Tags are constructed with their spans and type, and the result is sorted by span.
5371	Yield all sub-span indices of a given type that are completely contained within the current span, excluding the span itself. Uses binary search to efficiently find relevant spans and filters results to only include spans that are properly nested within the current span.
5372	Return the ancestors of the current node, optionally filtered by type. If no type is specified, returns all ancestors of any supported type. The supported types are Template, ParserFunction, WikiLink, Comment, Parameter, and ExtensionTag. Ancestors are sorted by their position relative to the current node.
5373	Return the parent node of the current object.

:param type_: the type of the desired parent object.
    Currently the following types are supported: {Template,
    ParserFunction, WikiLink, Comment, Parameter, ExtensionTag}.
    The default is None and means the first parent, of any type above.
:return: parent WikiText object or None if no parent with the desired
    `type_` is found.
5374	Return the most common item in the list, raising ValueError for empty lists.
5375	Return the first argument with the specified name from an iterable of arguments, or None if not found. Uses stripped name comparison for matching.
5376	Return the normalized form of the template name by removing comments, language codes, namespaces, replacing underscores with spaces, capitalizing the first letter if specified, and removing anchors. Supports deprecated parameters for backward compatibility.
5377	Remove duplicate arguments by deleting the first occurrences of arguments with duplicate names, preserving the last occurrence of each argument name in the rendered wikitext.
5378	Remove duplicate arguments in a safe manner, keeping only one instance when arguments have the same name and value, or removing empty arguments when duplicates exist. If a tag is provided, it will be appended to the value of the remaining duplicate arguments.
5379	Sets the value of an existing argument by name, or adds a new argument if it doesn't exist. Supports positioning options (`before`, `after`) and handles both positional and named arguments. When adding a new argument, it respects spacing and formatting rules based on the `preserve_spacing` flag. If `positional` is True, the argument is added as a positional argument, ignoring spacing rules. If neither `before` nor `after` is specified, the new argument is appended to the end. The method updates or appends argument strings in the template according to the provided parameters and spacing logic.
5380	Return the last argument with the given name, or None if not found.
5381	Return True if an argument named `name` exists. If `value` is provided, also check if the argument's value matches. Supports both positional and non-positional argument comparison.
5382	Delete all arguments with the given name from the reversed argument list.
5383	Lookup CRS code on spatialreference.org and return in specified format.

**Arguments:**
- *codetype*: "epsg", "esri", or "sr-org"
- *code*: The code to lookup
- *format*: The CRS format of the returned string (e.g., "ogcwkt", "esriwkt", "proj4")

**Returns:**
- CRS string in the specified format

**Example usage:**
```python
crs_string = crscode_to_string("epsg", "4326", "proj4")
```
5384	Search for an ellipsoid by name using specified CRS naming convention, with optional strict matching mode. Returns the matching ellipsoid object or None if not found.
5385	Returns a CRS object from a coordinate reference system string read from a URL. The string can be parsed as a specific format (ogc wkt, esri wkt, or proj4) or auto-detected if no format is specified. Reads the string from the URL and returns the corresponding CRS object.
5386	Returns a CRS object from a file, determining the format from the filename extension. Supports .prj files with WKT format and .geojson/.json files with CRS information. For GeoJSON files without CRS, defaults to WGS84 (EPSG:4326).
5387	Loads a CRS (Coordinate Reference System) object from an EPSG code by fetching the proj4 representation from spatialreference.org and converting it to a CS instance.
5388	Load a CRS object from an ESRI code by fetching its PROJ4 representation from spatialreference.org and converting it using from_proj4().
5389	Load a CRS object from an SR-ORG code by fetching its proj4 representation from spatialreference.org and parsing it.
5390	Detects the CRS string format and parses it into a CRS object using the appropriate parsing function based on the format prefix (+, PROJCS[, GEOGCS[, EPSG:, ESRI:, SR-ORG:). Raises FormatError if the format cannot be auto-detected.
5391	Write the raw header content to the specified output stream by writing the header bytes and record data sequentially.
5392	Method: `read_from`

Summary: A class method that instantiates a RawVLR object by reading data from a given data stream. It reads the header first, then reads the specified amount of record data based on the header's record length, and returns the constructed RawVLR object.

Parameters:
- `data_stream`: A file object containing the raw VLR data to be read

Returns:
- `RawVLR`: An instantiated RawVLR object with header and record data populated from the stream
5393	Extracts and parses GeoTiff keys from VLRs in a LAS file by retrieving the required VLRs (GeoKeyDirectory, GeoDoubleParams, GeoAsciiParams) and converting them into a structured format. Raises IndexError if any required VLR is missing. Returns a list of parsed GeoTiff keys.
5394	Parses GeoTiff VLRs (Virtual List Records) information into structured GeoTiffKey objects by handling different TIFF tag locations (0, 34736, 34737) and extracting values from corresponding VLRs, with appropriate error handling for unknown tag locations.
5395	Returns the signedness for the given type index by checking the dimension style string for 'uint', 'int', or other values, raising UnknownExtraType for invalid indices.
5396	Returns the index of the extra dimension type as defined in the LAS Specification. Looks up the type in two style dictionaries and raises UnknownExtraType error if not found.
5397	Constructs a new PackedPointRecord from an existing one while allowing conversion to a different point format. Creates a new array with the target format's dtype, initializes a new record, and copies all fields from the original record.
5398	Method copies dimension field values from another record, handling ValueError exceptions during assignment.
5399	Appends zeros to the internal array when the input value is larger than the current array size, ensuring the arrays are compatible for further processing.
5400	Returns a frozenset containing all dimension names including array dtype names and sub_fields dictionary keys.
5401	Creates a new point record with all dimensions initialized to zero given a point format and point count.
5402	Constructs a point record by reading points from a stream using the specified point format and count, handling cases where insufficient bytes are read or the actual count differs from expected count.
5403	Constructs a point record by reading and decompressing points data from an input buffer using the specified point format, count, and LASzip VLR information.
5404	Returns the scaled x positions of the points as doubles using the x_scale and x_offset from the header.
5405	Returns the scaled y positions of the points as doubles using the y_scale and y_offset from the header.
5406	Returns the scaled z positions of the points as doubles using the z_scale and z_offset from the header.
5407	Adds a new extra dimension to the point record with specified name, type, and optional description, storing it as an ExtraBytesVlr structure.
5408	Writes the LAS data to a given stream, with optional compression. If compression is enabled, it creates a LasZipVLR, updates header information, and compresses the point data. Otherwise, it writes the data uncompressed. The method handles VLRs and updates header offsets accordingly before writing all components to the output stream.
5409	Writes LAS data to a file with optional compression based on filename extension or explicit flag.
5410	Writes data to a stream or file destination. If destination is a string, it's treated as a file path where the data will be written. Compression is automatically guessed from the file extension (.laz = compressed, .las = uncompressed) when do_compress is None. If destination is a file object, compression must be explicitly specified. The method calls either write_to_file() for string destinations or write_to() for file objects.
5411	Builds a dictionary mapping point format IDs to numpy dtypes, where bit fields remain packed and need unpacking for access.
5412	Builds a dictionary mapping point format IDs to numpy dtypes where bit fields are unpacked and directly accessible. For each point format, it combines composed fields and regular dimensions into a single dtype structure.
5413	Function `np_dtype_to_point_format` maps a NumPy dtype to a compatible point format ID by comparing it against predefined point format dtypes. It iterates through either packed or unpacked point format dtypes based on the `unpacked` parameter, returning the first matching format ID. If no match is found, it raises an `IncompatibleDataFormat` error with details about the incompatible dtype.
5414	Returns the minimum file version that supports the given point format ID by iterating through sorted version mappings and raising PointFormatNotSupported error if not found.
5415	Returns True if the given point format ID is supported by the specified file version, False otherwise. Raises FileVersionNotSupported error if the file version is not recognized.
5416	Returns a list of VLRs matching the specified type. Always returns a list, even if there's only one VLR of that type. If no VLRs of the specified type are found, returns an empty list.
5417	Returns a list of VLRs of the specified type and removes them from the original list.
5418	Reads VLRS from a stream and parses them, returning a VLRList object containing the parsed VLRS.
5419	Returns True if all LAS files have the same point format ID, False otherwise.
5420	Returns True if all files have the same numpy datatype, False otherwise.
5421	Reads the first 4 bytes from the stream to verify that the file signature matches the expected LAS file signature, and raises a PylasError if they don't match.
5422	Reads the header of the LAS file from the current stream position and returns it using the HeaderFactory.
5423	Method `read_vlrs` seeks to the position after the header in the file stream and reads the specified number of VLRs (Variable Length Records) using `VLRList.read_from`, returning the list of VLRs found in the file.
5424	Private function to read points record data from a LAS file, handling both compressed and uncompressed point data based on the file header, with support for extra dimensions from VLRs.
5425	Reads compressed point record data from the stream, including handling chunk table offset and decompressing point data using PackedPointRecord.
5426	Reads and returns the waveform VLR header and waveform record from the stream, including logging the size of the waveform data read.
5427	Reads the EVLRs from the file starting at the position specified in the header, returning an EVLRList object containing the EVLR data. Raises an exception if the file version does not support EVLRs.
5428	Helper function that warns when there are unexpected bytes between specified positions in a file stream.
5429	Opens and reads the header of LAS content from a file or stream, returning a LasReader object. Takes a source parameter (filename string or file object) and closefd flag to control whether the stream should be closed when used in a with statement. Raises ValueError if closefd is used with a filename source.
5430	Summary: Reads LAS file data into memory and returns a LasBase object for accessing points and VLRs. Supports both file paths and stream sources, with optional automatic closing of file descriptors.
5431	Creates a File from an existing header by allocating an array of points according to the header, copying the input header. Returns a LasBase object (either LasData from las12 or las14 module depending on header version).
5432	Creates a new empty LAS data object with specified point format and file version. If only point_format_id is provided, file_version is automatically selected (1.2 for point formats 0-5, 1.4 for point formats 6+). If both parameters are provided, they must be compatible or an exception is raised. Returns a LasBase object initialized with the specified header.
5433	Converts a LAS file from one point format to another, automatically upgrading the file version when necessary for compatibility. If a newer point format is specified, the file version is upgraded to support it, but never downgraded. An exception is raised if the requested point format is incompatible with the specified file version. Returns a new LAS data object with the converted point format and version.
5434	Merges multiple LAS files into a single LAS file by combining their point data while preserving the header information and point format. The function takes either multiple LAS file arguments or a single iterable of LAS files, validates that all files have the same point format, and creates a new merged LAS file with combined points. Extra dimensions from the first file are preserved in the merged result, and each point is assigned a source ID indicating which input file it came from. The merged file maintains proper coordinate scaling and offsets based on the input files.
5435	Writes a LAS file to memory using BytesIO and reads it back again, primarily for testing purposes without disk I/O.
5436	Returns the creation date by converting year and day-of-year values to a datetime.date object, or None if invalid.
5437	Sets the file creation date and extracts the year and day of year from a date object.
5438	Returns the minimum values of x, y, z coordinates as a numpy array.
5439	Sets the minimum values of x, y, z as a numpy array.
5440	Returns the maximum values of x, y, z as a numpy array.
5441	Sets the maximum values of x, y, z as a numpy array.
5442	Returns the scaling values of x, y, z as a numpy array.
5443	Returns the offsets values of x, y, z as a numpy array.
5444	Method `peek_file_version` reads the file version from a stream by seeking to a specific offset, extracting major and minor version numbers, and returning them as a formatted string. It preserves the original stream position by saving and restoring it before and after the operation. The method takes a stream parameter of type `io.BytesIO` and returns a string containing the version in "major.minor" format.
5445	Converts a header instance to a specified version by creating a new header of the target version and copying data from the old header. The method handles both float and string version inputs, ensuring proper byte alignment and version string assignment. Returns a new header instance with the requested version.
5446	Unpacks a sub-field from a source array using bitwise operations with the provided mask, returning the extracted sub-field as a numpy array of specified dtype.
5447	Packs a sub field's array into another array using a mask, with optional in-place operation. Raises OverflowError if sub field values exceed the mask's capacity. Returns the packed array or modifies the input array in place.
5448	Returns a list of dimension names that will be lost when converting from point_fmt_in to point_fmt_out by comparing the field names of their respective PointFormat dtypes.
5449	Returns a dictionary mapping sub field names to their composed dimensions with additional information.
5450	Returns the total number of extra bytes calculated by summing the itemsize of each extra dimension's data type.
5451	Returns True if the point format includes all waveform packet dimensions, checks by verifying that all required waveform field names exist in the current dimension names.
5452	Main function for satel_integra console script that sets up logging and runs demo command. Takes port, ip, command, and loglevel parameters, validates the log level, configures basic logging, and executes demo functionality when command is "demo".
5453	Function to calculate checksum using CRC algorithm with bit rotation and XOR operations.
5454	Debugging method to print frame data in hexadecimal format. Takes input data and converts each byte to a \xHH format string, then logs it at debug level.
5455	Verify checksum and strip header and footer of received frame, raising exceptions for wrong headers, footers, or checksums, and return the stripped frame data.
5456	Return list of positions of bits set to one in given data.

This method is used to read e.g. violated zones. They are marked by ones
on respective bit positions - as per Satel manual.
5457	The `generate_query` function adds a header, checksum, and footer to command data. It takes a command byte sequence, calculates a checksum, appends the checksum bytes (high byte then low byte), escapes any `0xFE` bytes by replacing them with `0xFE 0xF0`, and wraps the result with a header (`FEFE`) and footer (`FE0D`). The function returns the complete formatted data as a bytearray.
5458	This function demonstrates the monitoring capabilities of an AsyncSatel security system by connecting to a device at the specified host and port, then performing a sequence of operations including arming, disarming, keeping the connection alive, and monitoring the system status in an infinite event loop.
5459	Make a TCP connection to the alarm system. Returns True if successful, False if connection fails.
5460	Start monitoring for interesting events by sending a query and handling the response.
5461	Send disarm command with code and partition list, padding code to 16 characters with 'F' if necessary, then transmit the formatted data.
5462	Send command to clear the alarm by generating a query with the provided code and partition list, then sending the data asynchronously.
5463	Send output turn on/off command to the alarm system with specified code and output ID, handling code padding and byte conversion.
5464	Keeps the Satel Integra connection alive by periodically sending status queries every 25 seconds to prevent disconnection, while ignoring the responses.
5465	Start monitoring of the alarm status by sending commands to the Satel Integra device to begin sending updates. The method continuously reads updates in a loop and calls registered callbacks when specific events occur (alarm status changes, zone changes, or output changes). It handles reconnection attempts if the connection is lost and continues monitoring until the connection is closed. The monitoring process includes connecting to the device, starting the monitoring mode, and periodically updating the status while maintaining the connection.
5466	Close the connection and stop monitoring by setting closed flag and closing the writer if connected.
5467	Clears all database records matching the instance's user_id by executing a purging operation within a database transaction.
5468	Guess the type of a file, returning 'notebook', 'directory', or 'file' based on the path extension and existence.
5469	Get the database ID of a file given its path, raising NoSuchFile if the file doesn't exist.
5470	Get a notebook from the database by path, handling the case where the file doesn't exist.
5471	Build a notebook model from a database record, including path, type, timestamps, and optional content with validation.
5472	Get a directory from the database by path, handling cases where directory doesn't exist or has wrong type, and return directory model.
5473	Convert file records to appropriate models based on their type, yielding notebook models for notebooks, file models for files, or raising a 500 error for unknown types.
5474	Builds a directory model from a database record, optionally including file content and subdirectory structures.
5475	Builds a file model from a database record, including path, type, timestamps, and optional content with format detection.
5476	Save a notebook by converting the model content to a notebook object, validating and signing it, then persisting it to storage. Updates the model with validation results and returns any validation message.
5477	Save a non-notebook file by encoding its content and storing it in the database.
5478	Rename a file or directory from old_path to path, handling both files and directories with appropriate error handling for existence conflicts and root renaming restrictions.
5479	Delete the file or directory at the specified path by checking if it exists and calling the appropriate deletion method, or raise an exception if it doesn't exist.
5480	Add a new user to the database if they don't already exist, ignoring unique constraint violations.
5481	Delete a user and all of their associated files and directories from the database.
5482	Creates a directory in the database with the specified user ID and API path, setting appropriate parent directory information.
5483	Return a WHERE clause that matches entries in a directory, parameterized on table because this clause is re-used between files and directories.
5484	Delete a directory from the database based on user ID and API path. Raises DirectoryNotEmpty if the directory contains files, or NoSuchDirectory if the directory doesn't exist. Returns the number of deleted rows.
5485	Checks if a directory exists for a given user in the database by querying the directories table with user_id and directory name conditions. Returns True if directory exists, False otherwise.
5486	Return a list of file records from the specified directory for a given user, including default file fields and ordered by user_id, parent_name, name, and created_at.
5487	Return subdirectories of a specified directory for a given user by querying the database and converting results to dictionaries without content fields.
5488	Return a WHERE clause that matches a file by its API path and user_id, checking the file name, user ID, and parent directory name.
5489	Return a SELECT statement that returns the latest N versions of a file.
5490	Default fields returned by a file query. Returns a list containing the name, creation timestamp, and parent name of files.
5491	Gets file data for a given user_id, path, and query_fields, raising NoSuchFile if not found. Returns file data with or without content based on query_fields.
5492	Get file data for a given user and path, optionally including file content.
5493	Get the file ID from the database for a given user and API path by querying the 'id' column from the files table.
5494	Check if a file exists by attempting to retrieve it without content. Returns True if file exists, False if it doesn't.
5495	Rename a directory in the database from an old API path to a new API path, including updating all descendant directories. Raises RenameRoot if attempting to rename root directory, or DirectoryExists if the new path already exists. Uses deferred foreign key constraints to handle updates properly.
5496	Save a file to the database, updating existing files or inserting new ones. Handles content preprocessing, path splitting, and manages database transactions with savepoints. If a file already exists (unique constraint violation), it overwrites the content with the new version while updating the timestamp. Returns the result of the database operation.
5497	Generate a sequence of decrypted notebook files from a database, yielding them in chronological order based on their creation timestamps, with optional date range filtering.
5498	Delete all remote checkpoint records for the specified user ID from the database.
5499	Generate a generator of decrypted remote checkpoints by selecting notebook checkpoints within an optional datetime range, decrypting them using a crypto factory, and yielding dictionaries containing decoded notebooks with metadata including user, filepath, and timestamp in ascending order of timestamp.
5500	Generates notebooks from a database table by filtering based on timestamp conditions, decrypting content using a provided crypto factory, and yielding structured notebook data with path, last modified time, and decoded content. Handles corrupted files gracefully by logging warnings.
5501	Re-encrypts a row's content in a database table by decrypting the current content and then re-encrypting it using provided functions. Takes a database connection, table, row ID, and decryption/encryption functions as inputs, and logs the process.
5502	Re-encrypts all files and checkpoints for a single user using old and new encryption functions, processing each file and checkpoint in a database transaction while logging the progress.
5503	Convert a password and user ID into a Fernet encryption key using PBKDF2HMAC with SHA-256 hashing.
5504	Derive a list of per-user Fernet keys from a list of master keys and a username, preserving None values. Each non-None password is used with the user_id as salt to derive a Fernet key, which is then decoded to ASCII format. The function validates that passwords is a list or tuple and returns a list of derived keys.
5505	Creates a password-based cryptography factory that returns a FernetEncryption instance with a key derived from the given password and user_id salt.
5506	Decorator that memoizes a single-argument function by caching its results in a dictionary to avoid redundant computations.
5507	Get the name from a column-like SQLAlchemy expression, handling both Column and Cast types.
5508	Converts a SQLAlchemy row (without 'content' field) to a dictionary mapping field names to row values. Raises AssertionError if 'content' field exists or if fields/row lengths don't match. Returns None if row is None.
5509	Converts a SQLAlchemy row with a 'content' field to a dictionary, applying a decryption function to the content field. Returns None if row is None. Raises AssertionError if 'content' field is missing or if fields/row length mismatch.
5510	Creates a checkpoint of a notebook's current state and returns the checkpoint ID.
5511	Creates a file checkpoint by encoding content in base64 and saving it to the database, returning a checkpoint ID. Handles value errors during encoding by returning a 400 error.
5512	Delete a checkpoint for a file by removing the checkpoint with the specified ID from the remote storage path.
5513	Get the content of a checkpoint by ID and path from the remote checkpoint storage.
5514	Return a list of checkpoints for a given file by querying the database through the engine connection.
5515	Rename all checkpoints from old_path to new_path for the current user.
5516	Delete all checkpoints for the given path by executing a database transaction that calls delete_remote_checkpoints with the database connection, user ID, and path parameters.
5517	Method: `purge_db`

Summary: Removes all database records associated with the current user by deleting their remote checkpoints.

Parameters: None

Returns: None

Side effects: Deletes database records permanently
5518	Resolve a path based on a dictionary of manager prefixes, returning a triple of (prefix, manager, manager_relative_path).
5519	Prefix all path entries in model with the given prefix.
5520	A decorator that wraps methods expecting a path argument, resolves the path to a manager and path, delegates the call to the manager's method, and optionally applies a prefix to the result if needed.
5521	A parameterized decorator that creates methods accepting a path argument, resolves the path to a manager, calls the specified method on that manager, and optionally applies a prefix to the result based on the manager prefix and returns_model flag.
5522	Decorator for methods that accept old_path and new_path parameters, handling path resolution and validation to ensure both paths belong to the same backend manager before performing the operation.
5523	Strip slashes from directory names in managers dictionary and validate that no keys contain slashes.
5524	Method `get` handles retrieval of directory or file content with special case for root directory listing. It normalizes the path and delegates to internal `__get` method for non-root paths. For root directory (empty path), it returns base directory model with optional extra content from `root_manager` or `_extra_root_dirs()`. Supports optional parameters for content type, format, and filtering by type.
5525	Normalize API paths by resolving '..' references and ensuring they remain within root boundaries.
5526	Split an API file path into directory and name components, handling cases where the path may not contain a directory separator. Returns a tuple of (processed_directory, filename) where the directory is processed through `from_api_dirname()` function.
5527	Writes a notebook as base64-encoded string.
5528	Reads a notebook from base64 format by decoding the base64 content and parsing it into a notebook object, raising CorruptedFile exception if decoding or parsing fails.
5529	Decode base64 data of unknown format by first trying utf-8 decoding, falling back to ascii decoding on failure, and returning the decoded content along with its detected type ('text' or 'base64').
5530	Decode base64 content for a file based on specified format, with automatic fallback handling and mimetype detection.
5531	Return an iterable of all prefix directories of path, descending from root.
5532	Decorator for converting PathOutsideRoot errors to 404s.
5533	Creates a user by initializing a PostgresCheckpoints object with the specified database URL and user ID, triggering user creation on startup.
5534	Split an iterable of models into a list of file paths and a list of directory paths.
5535	Recursive helper function for walking directory structures that yields directory paths along with their subdirectories and files, supporting nested directory traversal.
5536	The `walk_files` function is a generator that iterates over all files visible to the provided manager object (`mgr`). It uses a recursive directory traversal approach to visit all directories and subdirectories, yielding each file path one by one. However, there appears to be a recursive call to `walk_files(mgr)` within the function itself, which would cause infinite recursion and likely result in a stack overflow error. The function seems to be intended to walk through a directory structure and yield file paths, but the implementation contains a critical bug that prevents it from working correctly.
5537	Iterates over the contents of all files visible to the given manager, yielding each file's content.
5538	Re-encrypts data for all users in a database using old and new crypto factories. This function is idempotent, meaning it can be run multiple times without side effects by attempting decryption with old crypto first, then falling back to new crypto. It iterates through all user IDs and applies single-user re-encryption. The process handles initial encryption when old crypto is `NoEncryption` but does not support decrypting existing encrypted data - use `unencrypt_all_users` for that purpose. Requires SQLAlchemy engine, crypto factories for old and new encryption methods, and a logger for tracking progress.
5539	Re-encrypts all files and checkpoints for a single user by using a FallbackCrypto instance to ensure re-entrant behavior during the re-encryption process.
5540	Unencrypts data for all users by iterating through each user ID and applying single user unencryption using the provided crypto factory and logger.
5541	Unencrypts all files and checkpoints for a single user by decrypting content with old crypto and leaving it unencrypted.
5542	Creates a temporary alembic.ini file with specified alembic directory location and SQLAlchemy URL, yields the filename, then cleans up the temporary directory.
5543	Upgrade a database to a specific revision using alembic migration tool.
5544	Sanitizes block data by converting it to internal value format using the appropriate serializer if one exists for the block's type. Returns the modified block with sanitized data, or the original block if no matching serializer is found.
5545	Queue an instance to be fetched from the database by storing its ID in the appropriate list based on the serializer type.
5546	Fetch queued instances of specified type and save to self.instances using corresponding serializer.
5547	Inserts a fetched instance into an embed block by serializing the instance using the appropriate serializer based on the block type, and updates the block's data with the serialized instance or None if serialization fails.
5548	Load data in bulk for each embed block by iterating through available embed types and calling load_instances for each one.
5549	Validate widget data by checking required fields and field-specific validation rules, raising ValidationError with any errors found.
5550	Render HTML entry point for manager app with API URL and versioned asset bundle names in the context.
5551	Return JSON representation for this template by converting each field to JSON format and combining them into a result dictionary.
5552	Hides authenticated fields from the form if the user is not authenticated. Specifically, it removes all fields listed in the Meta.authenticated_fields attribute from self.fields when is_authenticated() returns False.
5553	Method that excludes fields from the serializer based on 'exclude' query parameter. Gets the exclude parameter from request query parameters, splits it by commas to get individual field names, and removes those fields from the serializer's fields dictionary. If no exclude parameter is present, the method returns early without making any changes.
5554	Get the latest article with the given primary key, handling version and preview_id query parameters, or fall back to the published version.
5555	Returns a queryset of articles with optional filtering by topic, section, tags, and author, plus optimized database queries with prefetching and ordering by update time.
5556	Returns the base queryset ordered by updated_at in descending order, optionally filtered by a query parameter 'q' if present.
5557	Overrides the default get_attribute method to convert None values to False. Returns True if attribute value is truthy, False if falsy or None.
5558	Validates that a widget contains all required fields including a valid ID, valid name, valid template, and at least one zone compatibility. Raises InvalidWidget exception with descriptive messages if any validation fails.
5559	Validates that a zone contains required fields by checking for valid 'id' and 'name' attributes, raising InvalidZone exception if validations fail.
5560	Return True if id is a valid UUID, False otherwise.
5561	Returns the user's permissions, specifically 'admin' if the user belongs to the 'Admin' group or is a superuser, otherwise returns an empty string.
5562	Modify a user's permissions by adding or removing them from the 'Admin' group based on the permissions parameter.
5563	Validates that author data conforms to the required format, ensuring each author has a 'person' field and that 'type' (if present) is a string. Raises ValidationError for invalid formats.
5564	Save widget data for a zone, handling nested widgets and calling before-save hooks before persisting the data.
5565	Returns a dictionary containing data from each field, where keys are field names and values are the corresponding data values.
5566	Prepare widget data for template by iterating through fields and calling prepare_data on each field with corresponding data.
5567	Renders the widget as HTML using a template, with optional data and additional context parameters.
5568	Retrieves integration settings as a dictionary, optionally removing hidden fields based on the show_hidden parameter.
5569	Handles OAuth callback from Facebook by authenticating the user and fetching their pages. Returns a dictionary containing the user's Facebook pages. Raises IntegrationCallbackError if Facebook API authentication fails.
5570	Return settings for given integration as a dictionary, or empty dict if integration doesn't exist or settings are invalid.
5571	Updates settings for a given integration by merging new settings with existing ones and saving the combined result back to the integration record.
5572	Handles user signup requests, validates invite expiration, processes signup forms, assigns admin permissions if needed, and redirects to admin dashboard upon successful registration.
5573	Returns HTML string by enclosing each item in contents within a tag of specified tagname.
5574	Renders the contents of a zone specified by zone_id, returning empty string if zone or widget is not found.
5575	Handles saving the featured image by creating, updating, or removing an ImageAttachment based on the provided data dictionary. If data is None or contains None image_id, the existing featured image is removed. Otherwise, it updates or creates an attachment with the provided image_id, caption, and credit, then associates it with the current instance.
5576	Save the subsection to the parent article by updating the subsection_id in Article objects that match the parent's id.
5577	Returns the file extension of the image file, removing the leading period if present.
5578	Returns the medium size image URL, or the absolute URL if the image is a GIF. For non-GIF images, constructs the URL using the media URL, image name, and 'medium' suffix.
5579	Custom save method that processes thumbnails and saves image dimensions, handling new images by making filenames lowercase, reading image data to get dimensions, and creating thumbnails for predefined sizes.
5580	Processes and saves a resized thumbnail version of an image with specified size, name, label, and file type, handling image resizing, filename formatting, and storage.
5581	Attempts to establish a connection to the MySQL server and returns a bound MySQL connection object if successful, or None if unsuccessful. Uses Flask's application context stack to cache and reuse the connection within the same request context.
5582	Wraps a file-like object in a bandwidth-limited stream wrapper that can be optionally disabled. Returns the wrapped stream object.
5583	Reads data from a file object with optional bandwidth throttling. If bandwidth limiting is disabled, reads directly from the underlying file object. Otherwise, it uses a leaky bucket algorithm to control read rates, only consuming from the bucket after accumulating a certain number of bytes to minimize overhead.
5584	Consume a requested amount of bandwidth, checking against maximum allocated rate and handling scheduled requests or exceptions. Returns the actual amount consumed.
5585	Schedules a consumption request with specified amount and time, tracking wait durations and returning the total accumulated wait time for the given request.
5586	Processes a completed scheduled consumption request by removing the token from scheduled consumption tracking and decrementing the total wait time.
5587	Get the projected rate using a provided amount and time by calculating the exponential moving average rate based on the last known time and the given parameters. Returns 0.0 if no previous time is recorded.
5588	Records the consumption rate based on amount and time point, calculating an exponential moving average rate when not at the first consumption event.
5589	Downloads an object from S3 to a local file using the transfer manager.

This method initiates a download transfer from an S3 bucket to a specified local filename. It accepts optional parameters for extra arguments to pass to the S3 client operation and an expected file size to optimize multipart download decisions. The method validates input arguments, notifies the transfer monitor of a new transfer, creates a download request, and returns a TransferFuture object representing the ongoing download operation.

Args:
    bucket (str): The name of the S3 bucket to download from
    key (str): The S3 object key to download
    filename (str): The local file path where the downloaded content will be saved
    extra_args (dict, optional): Additional arguments for the S3 client operation
    expected_size (int, optional): Expected file size in bytes to bypass HeadObject call

Returns:
    s3transfer.futures.TransferFuture: Future object representing the download transfer
```
5590	Polls for the result of a transfer by waiting for it to complete, then checks if the transfer succeeded or failed. If the transfer failed, it raises the associated exception; otherwise, it returns None.
5591	Retrieves a list of callbacks of a specified type from subscribers associated with a transfer future. The callbacks are preinjected with the transfer future and can be one of three types: 'queued', 'progress', or 'done'. Returns an empty list if no callbacks of the specified type are found.
5592	Gets a dictionary filtered by whitelisted keys.

:param original_dict: The original dictionary of arguments to source keys and values.
:param whitelisted_keys: A list of keys to include in the filtered dictionary.

:returns: A dictionary containing key/values from the original dictionary whose key was included in the whitelist
5593	Decrement the counter by one, raising RuntimeError if count is already zero. If the counter is finalized and reaches zero, execute the callback function.
5594	Finalizes the counter by setting a flag and invoking the callback if count is zero.
5595	Checks if a file is a special UNIX file (character device, block device, FIFO, or socket). Returns True if special file, False otherwise.
5596	Acquires a semaphore resource with optional blocking behavior. Returns a token for releasing the semaphore or raises NoResourcesAvailable if acquisition fails and blocking is False. The tag parameter is used for API compatibility but not required for basic functionality.
5597	Releases the semaphore, decrementing the internal counter and logging the release operation with the provided tag and acquire token for debugging purposes.
5598	Adjusts the chunksize to fit within S3 limits based on file size and configured constraints.
5599	Queue IO write task for submission to the IO executor, deferring submission if necessary.
5600	Returns an IOWriteTask object configured with the specified file object, data, and offset for writing data to a file-like object.
5601	Returns the appropriate DownloadOutputManager class for handling download output based on file object compatibility. Iterates through a resolver chain of manager classes and returns the first one that is compatible with the given file object and OS utilities. Raises RuntimeError if no compatible manager is found.
5602	Downloads an object from S3 and writes its content to a file object, with support for retries, progress callbacks, and bandwidth limiting. Handles streaming of the object body in chunks and manages transfer coordination for cancellation or error cases. Raises RetriesExceededError if max attempts are exceeded due to retryable download errors.
5603	Writes data to a file at the specified offset position using seek and write operations.
5604	Request writes by providing new data and its offset, returning any contiguous writes that can now be submitted. Handles duplicate requests and retries by checking offset conditions and maintaining pending offsets. Uses a heap to manage writes and processes them in order of increasing offsets.
5605	Summary: The `seekable` function determines if a file-like object is seekable by checking for a `seekable()` method first, then falling back to checking if the object has `seek` and `tell` methods by attempting to seek to the current position. It returns `True` if the object is seekable, `False` otherwise.
5606	Uploads a file to S3 with optional extra arguments and subscribers, returning a TransferFuture representing the upload operation.
5607	Downloads a file from S3 with optional extra arguments and subscribers, returning a TransferFuture representing the download operation.
5608	Copies a file in S3 from a source location to a destination bucket and key. Supports optional version ID, extra arguments, subscribers for event handling, and custom source client. Returns a TransferFuture representing the copy operation.
5609	Delete an S3 object by submitting a deletion transfer request with optional extra arguments and subscribers, returning a TransferFuture representing the deletion operation.
5610	Shutdown the TransferManager, waiting for all transfers to complete before shutting down. If cancel=True, it will cancel all in-progress transfers to expedite shutdown.
5611	Cancels all in-progress transfers by calling cancel() on all tracked transfer coordinators, passing along an optional message and exception type.
5612	Wait until all in-progress transfers complete, ignoring failures but allowing KeyboardInterrupt interruption.
5613	Reads a specific amount of data from a stream, prioritizing data from initial_data if available. Returns a generator that yields parts of the data. If initial_data is empty, reads directly from fileobj. If amount is less than or equal to initial_data length, returns data from initial_data. Otherwise, combines remaining initial_data with data read from fileobj. Truncates initial_data after reading if specified.
5614	Wraps input data with interrupt reader and file chunk reader, returning the fully wrapped data by creating a BytesIO object and using the OS utility to create a chunk reader with specified parameters.
5615	Retrieves the appropriate input manager class for upload operations based on the file object type from the transfer future. Checks a resolver chain of upload manager classes to find the first one compatible with the file object, raising a RuntimeError if no compatible manager is found.
5616	Sets an exception on the future's coordinator if the transfer is complete, raising TransferNotDoneError otherwise.
5617	Sets a result for the TransferFuture, indicating that the transfer succeeded. This method is called on the final task of a transfer process and always sets a result, even if the transfer was canceled later. It clears any existing exception, stores the provided result, and marks the status as 'success'.
5618	Sets an exception for the TransferFuture, marking it as failed. If override is True, it will set the exception even if the future is already done.
5619	Waits for the TransferFuture to complete and returns its result. If the transfer failed, raises the associated exception. Uses a maximum timeout value to ensure the wait can be interrupted properly.
5620	Cancels the TransferFuture by setting its status to 'cancelled' and raising a specified exception. If the transfer hasn't started, it announces the completion. The method is thread-safe and uses a lock to ensure atomic operations.
5621	Submits a task to the provided executor and returns a Future representing the submitted task. The task is logged for debugging purposes, added to the list of associated futures for cleanup, and a callback is registered to remove it from the associated futures list when the task completes.
5622	Add a done callback function to be invoked when the transfer is complete, with optional arguments that will be passed to the callback when executed.
5623	Adds a callback function to be executed upon failure, with arguments and keyword arguments, in a thread-safe manner using a lock.
5624	Method `announce_done` signals that a transfer future has completed, executes failure cleanups if needed, unblocks result() calls by setting a completion event, and runs any registered done callbacks.
5625	Submit a task to complete by acquiring a semaphore token, submitting the task to an executor, and returning a future that releases the semaphore when the task completes.
5626	Adds a callback function that will be executed when the future is completed. The callback takes no arguments, unlike concurrent.futures.Future which passes the future object as an argument. The method creates a wrapper that adapts the callback signature and registers it with the underlying future object.
5627	Upload a file to an S3 object using either multipart upload or single put object based on file size threshold. Registers callback disable/enable event handlers during the upload process.
5628	Downloads an S3 object to a local file with temporary file handling and validation.

This method downloads an S3 object to a local file using a temporary file for safety. It:
- Validates extra arguments against allowed download arguments
- Determines the object size via head_object request
- Downloads to a temporary file first
- Handles exceptions by removing partial files
- Renames temporary file to final filename on success
- Supports callback functions for download progress tracking

The method includes error handling to clean up partial downloads and validation of input arguments.
5629	Find functions with step decorator in parsed file and yield them along with their decorators.
5630	Get the arguments passed to step decorators converted to Python objects, handling single string or list arguments with error logging for invalid inputs.
5631	Refactors a step by replacing old_text with new_text and adjusting function parameters based on move_param_from_idx. Returns a list of diffs representing the changes made to the step text and parameter list.
5632	Find functions with step decorator in parsed file.
5633	Get arguments passed to step decorators converted to python objects. Returns a string or list of strings if valid, otherwise logs error messages.
5634	Refactors a step by replacing its text and updating function parameters based on the provided index mappings. Returns a list of diffs representing the changes made to the step text and parameters.
5635	Selects the default Python parser for loading and refactoring steps. Uses Parso parser by default (supports Python 3 syntax) but can revert to the old Redbaron parser (from v0.3.3) by passing 'redbaron' as argument or setting GETGAUGE_USE_0_3_3_PARSER=true in python.properties file. The Redbaron parser and corresponding property will be removed in future releases.
5636	**Summary:**

The `list` method retrieves all team memberships for a specified team ID from the Webex Teams service. It supports pagination through RFC5988 Web Linking, returning a generator container that lazily fetches and yields team membership objects. The method accepts optional parameters to limit the number of results per request and allows additional request parameters. It includes type checking for inputs and handles API errors appropriately. The generator is safe for reuse, automatically making new API calls when iterated multiple times with the same initial parameters.
5637	Adds a person to a team by Person ID or email address, with optional moderator status. Returns a TeamMembership object with the details of the created team membership.
5638	Update a team membership by ID, optionally setting moderator status. Returns an updated TeamMembership object. Raises TypeError for incorrect parameter types or ApiError if the API returns an error.
5639	Delete a team membership by ID.

Args:
    membershipId (basestring): The team membership ID.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

Deletes the team membership specified by membershipId from the Webex Teams cloud.
5640	Get a cat fact from catfact.ninja API and return it as a string.
5641	This method handles inbound webhook POST requests from Webex Teams by:
1. Parsing JSON data and printing received information
2. Creating webhook, room, message, and person objects from the data
3. Printing message details including room title, sender name, and message text
4. Implementing loop prevention to avoid responding to bot's own messages
5. Processing messages containing "/CAT" by fetching and sending a cat fact to the same room
6. Returning 'OK' to acknowledge successful processing
5642	**Summary:**

The `list` method retrieves room memberships from the Webex Teams API, with optional filtering by room ID, person ID, or person email. It supports pagination through RFC5988 Web Linking and returns a generator container that yields membership objects. The method accepts various query parameters and handles API requests automatically, iterating through all results as needed. It includes type checking for parameters and raises appropriate exceptions for invalid types or API errors.
5643	Delete a membership by ID.

Args:
    membershipId (basestring): The membership ID.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

API request: DELETE request to the membership endpoint with the specified membership ID.
5644	Validates that a base URL contains both a protocol scheme and network location. Returns the parsed URL if valid, otherwise raises a ValueError with a descriptive error message.
5645	Check if a string is a validly-formatted web URL with http or https scheme.
5646	Open a local file and return an EncodableFile tuple containing the file name, file object, and content type.
5647	Function `check_type` validates if an object is an instance of acceptable types or None. It takes an object `o`, acceptable types (which can be a single type or tuple of types), and a boolean `may_be_none` indicating if None is acceptable. It raises TypeError if object is None when `may_be_none=False` or if object is not an instance of acceptable types. The function provides detailed error messages showing expected types and actual object information.
5648	Creates a dictionary from multiple dictionaries and keyword arguments, excluding any key-value pairs where the value is None. Returns a new dictionary containing only items with non-None values.
5649	Check response code against the expected code; raise ApiError.

Checks the requests.response.status_code against the provided expected response code, and raises a ApiError if they do not match.

Args:
    response(requests.response): The response object returned by a request using the requests package.
    expected_response_code(int): The expected response code (HTTP response code).

Raises:
    ApiError: If the requests.response.status_code does not match the provided expected response code.
5650	Given a dictionary or JSON string, return a dictionary.

Args:
    json_data(dict, str): Input JSON object.

Returns:
    A Python dictionary with the contents of the JSON object.

Raises:
    TypeError: If the input object is not a dictionary or string.
5651	Creates a datetime object from a string using Webex Teams DateTime format with Zulu timezone awareness.
5652	List rooms with pagination support, optionally filtered by team ID, type, sorting criteria, and maximum results. Returns a generator container yielding room objects. Supports RFC5988 Web Linking for automatic pagination.
5653	Creates a new room with the specified title and optional team ID. The authenticated user is automatically added as a member. Returns a Room object with the created room's details. Raises TypeError if parameter types are incorrect or ApiError if the Webex Teams cloud returns an error.
5654	Updates a room's details by ID, supporting optional title parameter and additional request parameters. Returns an updated Room object. Raises TypeError for incorrect parameter types or ApiError if the Webex Teams cloud returns an error.
5655	Delete a room by ID.

Args:
    roomId (basestring): The ID of the room to be deleted.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

Deletes the specified room from the Webex Teams service.
5656	**Summary:**

The `list` method retrieves all licenses for a specified organization. If no organization ID is provided, it defaults to the authenticated user's organization. The method accepts an optional `orgId` parameter and additional request parameters. It returns a generator container that yields license objects created from the API response. The method includes type checking and handles potential API errors.
5657	Returns the creation date and time in ISO8601 format as a WebexTeamsDateTime object, or None if not available.
5658	Get access token from environment variables, checking both current and legacy variables with deprecation warning for legacy usage.
5659	Creates a webhook with the specified parameters and returns a Webhook object with the details of the created webhook. The method validates parameter types, constructs a POST request with the provided data, and handles API responses to return the created webhook. Supports additional request parameters for future compatibility. Raises TypeError for incorrect parameter types and ApiError for API-related errors.
5660	Updates a webhook by ID with the provided parameters and returns the updated webhook object.
5661	Delete a webhook by its ID.

Args:
    webhookId (basestring): The ID of the webhook to be deleted.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

The method validates the webhookId parameter type and sends a DELETE request to the API endpoint with the webhook ID to remove the specified webhook.
5662	Remove max=null parameter from URL.

Patch for Webex Teams Defect: 'next' URL returned in the Link headers of
the responses contain an errant 'max=null' parameter, which  causes the
next request (to this URL) to fail if the URL is requested as-is.

This patch parses the next_url to remove the max=null parameter.

Args:
    next_url(basestring): The 'next' URL to be parsed and cleaned.

Returns:
    basestring: The clean URL to be used for the 'next' request.

Raises:
    AssertionError: If the parameter types are incorrect.
    ValueError: If 'next_url' does not contain a valid API endpoint URL
        (scheme, netloc and path).
5663	Enable or disable automatic rate-limit handling by setting the _wait_on_rate_limit attribute to the provided boolean value.
5664	Updates the HTTP headers for this session by merging the provided dictionary with existing headers, adding new key-value pairs or updating existing ones, without replacing the entire header set.
5665	Given a relative or absolute URL, returns an absolute URL by combining relative URLs with the instance's base_url or returning absolute URLs as-is.
5666	Abstract base method for making requests to the Webex Teams APIs that expands URLs to absolute URLs, handles rate-limiting, and inspects response codes to raise appropriate exceptions.
5667	Sends a GET request to the specified URL with optional parameters and returns the parsed JSON response. Raises ApiError if the response code doesn't match the expected code.
5668	Return a generator that GETs and yields pages of data with native support for RFC5988 Web Linking.
5669	Return a generator that GETs and yields individual JSON `items` from Webex Teams API endpoint, handling pagination automatically and raising appropriate exceptions for malformed responses or unexpected HTTP status codes.
5670	Sends a PUT request to the specified URL with optional JSON or form data, validates the response against an expected status code, and returns the parsed JSON response.
5671	Deletes a resource at the specified URL by sending a DELETE request to the API endpoint, with optional expected response code validation.
5672	Creates a new guest issuer with API access token using provided parameters including subject, display name, issuer token, expiration time, and secret. Returns a GuestIssuerToken object with valid access token. Raises TypeError for incorrect parameter types or ApiError if webex teams cloud returns an error.
5673	Lists messages in a Webex Teams room with pagination support, returning a generator of message objects sorted in descending order by creation date. Supports filtering by room ID, mentioned people, date/time, and maximum results. Uses RFC5988 Web Linking for pagination and includes error handling for invalid parameters or API errors.
5674	Create a message in a room or send a private 1:1 message, with optional file attachment.
5675	Delete a message with the specified message ID.

Args:
    messageId (basestring): The ID of the message to be deleted.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

The method validates the input type using `check_type` and then sends a DELETE request to the API endpoint with the message ID appended to the endpoint URL.
5676	Create a new user account for a given organization with the specified details.

Args:
    emails (list): Email address(es) of the person.
    displayName (str): Full name of the person.
    firstName (str): First name of the person.
    lastName (str): Last name of the person.
    avatar (str): URL to the person's avatar in PNG format.
    orgId (str): ID of the organization to which this person belongs.
    roles (list): Roles of the person.
    licenses (list): Licenses allocated to the person.
    **request_parameters: Additional request parameters.

Returns:
    Person: A Person object with the details of the created person.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.
5677	Get a person's details by ID.

Args:
    personId(basestring): The ID of the person to be retrieved.

Returns:
    Person: A Person object with the details of the requested person.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.
5678	Update details for a person by ID, requiring admin privileges. Email addresses cannot be changed via the API. All user details must be included in the request, typically by first GETting the person's details, making changes, then PUTting both changed and unchanged values. Returns a Person object with updated details. Raises TypeError if parameter types are incorrect or ApiError if the Webex Teams cloud returns an error.
5679	Remove a person from the system.

Only an admin can remove a person.

Args:
    personId(basestring): The ID of the person to be deleted.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.
5680	Get the details of the person accessing the API.

Raises:
    ApiError: If the Webex Teams cloud returns an error.

Returns:
    A person object created from the response JSON data.
5681	Method: list
Summary: Retrieves all roles from the Webex Teams API and returns them as a generator container of role objects. The method accepts additional request parameters and handles potential type errors or API errors during the request process. It uses the session's get_items method to fetch data and creates role objects from the returned JSON using an object factory.
5682	Lists teams to which the authenticated user belongs, supporting pagination through a generator container that automatically handles additional API requests as needed.
5683	Creates a new team with the specified name and additional request parameters. The authenticated user is automatically added as a team member. Returns a Team object representing the created team. Raises TypeError if parameter types are incorrect or ApiError if the Webex Teams cloud returns an error.
5684	Updates details for a team identified by teamId. Optional name parameter can be provided to update the team's user-friendly name. Additional request parameters are supported. Returns a Team object with the updated team details. Raises TypeError if parameter types are incorrect or ApiError if the Webex Teams cloud returns an error.
5685	Delete a team by its ID.

Args:
    teamId (basestring): The ID of the team to be deleted.

Raises:
    TypeError: If the parameter types are incorrect.
    ApiError: If the Webex Teams cloud returns an error.

The method validates the teamId parameter type and sends a DELETE request to the API endpoint with the team ID to remove the team.
5686	Lists events in the organization with optional filtering by resource type, event type, actor ID, and date range. Supports pagination through a generator container. Returns event objects from the Webex Teams API based on the specified parameters.
5687	Serializes data into an immutable frozen tuple format. Returns data directly if already hashable, converts lists to tuples recursively, processes dictionaries by sorting key-value pairs and converting to tuples, or raises TypeError for unhandled data types.
5688	Exchange an Authorization Code for an Access Token by making a POST request to the OAuth endpoint with the provided credentials and code, then return an AccessToken object created from the response.
5689	Returns the date and time of the person's last activity as a WebexTeamsDateTime object, or None if no last activity data is available.
5690	This function handles inbound webhook POST requests from Webex Teams, processes incoming messages, and responds with cat facts when the message contains "/CAT". It includes loop prevention to avoid responding to its own messages, logs relevant information about the incoming message and sender, and sends the cat fact back to the same room where the message was received.
5691	Get the ngrok public HTTP URL from the local client API by making a GET request to the tunnels endpoint and parsing the response for the first tunnel with a public URL starting with "http://". Returns the URL if found, otherwise returns None if connection fails or no HTTP tunnel is found.
5692	Delete webhooks with a specific name by finding them through the API and removing each matching webhook.
5693	Creates a Webex Teams webhook that points to a specified ngrok public URL with predefined webhook configuration settings.
5694	Deletes existing webhooks with a specific name, then creates a new webhook if a public ngrok URL is available.
5695	```python
def console():
    """Output DSMR data to console."""
```
5696	Reads DSMR telegram data from serial interface, parses into CosemObject's and MbusObject's, and yields parsed results while handling checksum and parsing errors.
5697	Reads DSMR telegram data from serial interface, parses it into CosemObject's and MbusObject's, and pushes parsed telegrams to provided queue for asynchronous processing.
5698	Creates a DSMR asyncio protocol with the specified version, telegram callback, and optional loop. Returns a protocol factory and serial settings based on the DSMR version. Supports versions 2.2, 4, and 5. Raises NotImplementedError for unsupported versions.
5699	Creates a DSMR asyncio protocol coroutine using serial port by establishing a serial connection with the specified parameters and returning the connection object.
5700	Creates a DSMR asyncio protocol coroutine using TCP connection. Returns a connection object.
5701	Adds incoming ASCII-decoded data to buffer and processes all telegrams in the buffer.
5702	**Summary:** Handles connection loss by logging the disconnection reason (either due to exception or graceful close) and signals that the connection is closed.
5703	Handle incoming telegram by parsing it and sending to callback, with error handling for checksum and parsing failures.
5704	Parse telegram string data into a dictionary mapping regex signatures to parsed objects, validating checksum if enabled. Returns a dictionary where keys are regex patterns and values are parsed CosemObject or MBusObject instances. Raises ParseError or InvalidChecksumError on parsing failures.
5705	Get the version of a package from a given file by executing it and extracting the specified version variable.
5706	Summary: The `ensure_python` function checks if the current Python version is compatible with a given list of version specifications. It takes a list or tuple of version range specifiers, compares the current Python version (in format "major.minor") against each specifier, and raises a ValueError if no match is found. The function supports exact version matching and comparison operations through eval(), though it gracefully handles syntax errors during evaluation.
5707	Find all packages by walking through directories and identifying those containing `__init__.py` files, returning them as dot-separated package names relative to the specified top directory.
5708	Creates a command class dictionary for setup.py with optional prerelease command and file handling specifications. Returns a dictionary mapping command names to their wrapped implementations, including build_py, bdist_egg, sdist, handle_files, and develop commands, with optional bdist_wheel support.
5709	Creates a command class that executes a given function and updates package data when run.
5710	Runs a command after echoing it to log, using repository as working directory by default, and handles command execution with proper path resolution and shell settings.
5711	Returns a Command class that checks for the existence of specified files and raises a ValueError if any are missing, unless the `--skip-npm` flag is used.
5712	Wrap a setup command with pre-commands execution and package data update functionality.
5713	Returns a FileHandler class that processes package_data and data_files specifications during the build process. The handler populates package_data with matched files based on patterns and updates data_files with specified file mappings.
5714	Expand data file specs into valid data files metadata by processing existing files and adding new files based on patterns, then construct and return a valid list of data_files items.
5715	Expand file patterns to a list of `package_data` paths, ignoring files in `node_modules`. If no patterns are provided, defaults to including all files.
5716	Compiles a glob pattern into a regular expression matcher function. Translates the glob pattern to regex syntax and compiles it with optional case-insensitive flag. Handles both string and bytes patterns by decoding/encoding with ISO-8859-1 encoding. Returns a match function that can be used to match strings against the compiled pattern.
5717	Iterates over all parts of a path by recursively splitting it using os.path.split(), yielding each component from root to leaf.
5718	Translates a glob pattern to a regular expression by converting each path part and joining them with OS-specific separators, then appending a end-of-string anchor.
5719	Join translated glob pattern parts, handling ** special cases to match zero or more directories, and following stdlib/git conventions for matching sub files/directories.
5720	Translates a glob pattern part to a regular expression, handling special characters like *, ?, and []. Returns a regex pattern that matches the glob pattern, where ** becomes .* and * matches any characters except path separators.
5721	Truncates the specified table by executing DDL commands, including handling serial key resets. Returns None.
5722	Send DDL to create the specified table by executing the generated SQL statements, including any serial key SQL.
5723	Writes database indexes for a given table by executing DDL statements through the parent class implementation.
5724	Send DDL to create the specified `table` triggers by executing the SQL statements returned by the parent class method.
5725	Writes table constraints to PostgreSQL database by executing constraint SQL statements generated from the table definition.
5726	Writes the contents of a table by creating a FileObjFaker object and copying data from it to the target table using the copy_from method.
5727	Processes a row of MySQL data for compatibility with PostgreSQL copy command, handling type conversions, null values, and special character escaping.
5728	Write DDL statements for table indexes to the output file by calling the parent class's write_indexes method and writing the results to the file.
5729	Write DDL constraints of a table to the output file by calling the parent class method and writing the joined constraint lines to the file.
5730	Writes the triggers associated with the given table to the output file by joining and writing the trigger definitions returned by the parent class's write_triggers method.
5731	Return an approximate number of queued tasks in the queue by counting the items with an optional extra predicate filter.
5732	Enqueues a task with the specified data by converting it to JSON format and inserting it into a database table with a timestamp. Returns the result of the database insertion operation.
5733	Retrieves a task handler from the queue, with optional blocking behavior and retry logic. If block is True, it will continue attempting to retrieve a task until successful or until the specified timeout is reached. The method uses exponential backoff with a random jitter for retry intervals. An optional extra predicate can be provided to filter tasks based on additional criteria.
5734	Builds an SQL predicate string by escaping query parameters and wrapping them in AND condition. Handles special cases where the predicate value is not a sequence type by wrapping it in a tuple before escaping. Returns empty string if no extra predicate is provided.
5735	Summary: A serializer function that converts datetime objects to ISO format strings for JSON serialization, raising a TypeError for non-serializable objects.
5736	Closes the existing database connection and re-opens it using the saved database arguments.
5737	Returns the first row from a database query, raising exceptions for invalid queries or multiple rows.
5738	Returns a new connection to the database using the specified parameters.
5739	This function runs a benchmark by launching multiple InsertWorker threads to insert data into a database, then measures and reports the performance. It creates a specified number of worker threads, starts them, waits for a set time period, stops them, and calculates the total rows inserted and insertion rate per second.
5740	Returns an aggregator connection by attempting to connect to available aggregators in random order, falling back to the primary aggregator if needed, and handling connection failures appropriately.
5741	Function to look up error number names by their numeric value, printing the corresponding variable name from global scope.
5742	Returns the total number of connections cached by the pool by summing up the sizes of all connection queues and adding the number of fairies.
5743	Method `__potential_connection_failure` handles MySQL connection errors by first attempting a simple query to verify if the connection is actually broken. If the query fails with IOError or OperationalError, it treats this as a real connection issue and handles it appropriately. If the query succeeds, it raises a DatabaseError suggesting the error is likely due to programmer error rather than connection issues.
5744	Builds a simple expression string and parameters dictionary from keyword arguments, useful for constructing SQL queries. Returns a tuple of (expression_string, params_dict) where expression_string contains field comparisons joined by the specified joiner, and params_dict maps placeholder keys to their corresponding values.
5745	Builds an UPDATE SQL query string and parameter dictionary from the given table name and field-value pairs.

Args:
    table_name (str): The name of the table to update
    **fields: Keyword arguments representing column names and their new values

Returns:
    tuple: A tuple containing (SQL query string, parameter dictionary)

Example:
    >>> update('foo_table', a=5, b=2)
    ("UPDATE `foo_table` SET `a`=%(_QB_a)s, `b`=%(_QB_b)s", { '_QB_a': 5, '_QB_b': 2 })
5746	Connect to the specified database with given connection parameters and validate the connection by executing a simple query. Raises RequiresDatabase exception if no database is specified. Returns the instance for method chaining.
5747	Initialize the required tables in the database by executing table definitions against the database connection.
5748	Destroy the SQLStepQueue tables in the database by dropping each table if it exists.
5749	Start a step by adding it to the steps collection with a start timestamp, raising appropriate exceptions if the workflow is already finished or if the step is already started or finished.
5750	Stop a step by recording its end time and duration, raising appropriate exceptions if the step is not started, already finished, or the process is already finished.
5751	Load steps by converting datetime ISO formats into datetime objects for start and stop fields.
5752	disconnect(): Disconnects from the websocket connection and joins the Thread.
5753	**Summary:** The `reconnect` method initiates a reconnection sequence by setting the `reconnect_required` event, clearing the `connected` event, and closing the socket if it exists. It logs a debug message indicating the reconnect sequence has been initialized.
5754	Creates a websocket connection with SSL options and handles reconnection logic. Initializes WebSocketApp with callback handlers, sets default SSL certificate path if needed, and runs the connection forever. Implements retry logic with exponential backoff when reconnection is required, stopping timers and managing socket state during reconnection attempts.
5755	Handles incoming WebSocket messages by parsing JSON data and routing it to appropriate handlers (system message handler, heartbeat handler, or data handler) while managing timers.
5756	Stops the ping, pong, and connection timers if they exist, and logs a debug message confirming the timers have been stopped.
5757	Sends a ping message to the API and initiates a pong timeout timer.
5758	Checks if a Pong message was received within the timeout period. If received, resets the pong flag and logs debug message. If not received, cancels the pong timer, logs debug message, and initiates reconnection.
5759	Sends a payload to the API via websocket connection, with optional authentication. Supports three payload types: authenticated requests, list data, or keyword argument data. Logs the payload being sent and handles connection closed exceptions.
5760	**Method Summary:**

`_unpause()` resumes a paused connection by clearing the paused flag and performing a soft re-subscription to all channels.

**Details:**
- Clears the `paused` flag using `self.paused.clear()`
- Logs debug message "Clearing paused() Flag!"
- Initiates soft re-subscription via `self._resubscribe(soft=True)`
- Logs debug message "Re-subscribing softly.."
- Sends re-subscription message to client

**Purpose:** 
Restores normal operation after a connection pause by re-establishing channel subscriptions without full reconnection.
5761	Distributes system messages to appropriate handlers based on event type. Handles 'pong', 'info', 'error', and response events ('subscribed', 'unsubscribed', 'conf', 'auth', 'unauth'), with unhandled events logged as errors.
5762	Handle INFO messages from the API and trigger relevant actions based on the message code. Logs API version information and executes specific methods like reconnect, pause, or unpause based on the code. Raises ValueError for invalid users and unknown codes.
5763	Handle error messages by looking up error codes in a predefined dictionary and logging appropriate error messages. If an unknown error code is encountered, log a generic error message indicating reconnection is needed.
5764	Handles data messages by passing them up to the client with debug logging.
5765	Resubscribes to all channels in self.channel_configs. If soft=True, unsubscribes first then resubscribes in reverse order. Sends configuration messages via self.send() for each channel, handling 'auth' channels specially. Restores Bitfinex websocket configuration if present.
5766	Handles authentication responses by processing auth/unauth data, extracting channel and user IDs, and setting up channel handlers and directory mappings for authenticated channels.
5767	Handles configuration messages by logging the configuration data and returning.
5768	Updates the timestamp for a given channel ID, logging a warning if the channel is no longer present.
5769	Reset the client by reconnecting the connection, waiting for the connection to be established, and then sending channel configuration data.
5770	Return a queue containing all received candles data for the specified symbol pair and timeframe.
5771	Configures the websocket connection to the Bitfinex server by setting various flags and sending configuration parameters.

Sets up configuration for websocket connection with options for:
- decimals_as_strings: Convert decimals to strings (flag 8)
- ts_as_dates: Request timestamps as dates (flag 32)  
- sequencing: Enable sequencing (flag 65536)
- ts: Append timestamp to arrays (flag 32768)

Combines all flags into a single configuration object and sends it to the server.
5772	Subscribes to the ticker channel for a specified symbol pair by creating an identifier tuple and calling the internal _subscribe method with 'ticker' as the channel type.
5773	Unsubscribes from a symbol pair's ticker channel by creating an identifier tuple and calling the internal _unsubscribe method with the appropriate parameters.
5774	Subscribe to the specified symbol pair's order book channel by creating a subscription identifier and calling the internal subscribe method with 'book' type, pair identifier, and additional keyword arguments.
5775	Unsubscribes from the order book channel for a specified trading pair by sending an unsubscribe request using the internal _unsubscribe method with 'book' as the channel type and the pair as identifier.
5776	Subscribe to a symbol pair's raw order book channel with optional precision parameter.
5777	Unsubscribes from a symbol pair's raw order book channel by creating an identifier tuple and calling the internal unsubscribe method with appropriate parameters.
5778	Subscribe to a symbol pair's trades channel.
5779	Unsubscribes from the specified symbol pair's trades channel by creating an identifier and calling the internal unsubscribe method with the appropriate parameters.
5780	Subscribe to OHLC data channel for a given symbol pair and timeframe. Validates timeframe against accepted values and constructs appropriate subscription key.
5781	Unsubscribes from a pair's OHLC data channel by removing the subscription for the specified timeframe. Raises a ValueError if the timeframe is invalid. The pair identifier is prefixed with 't' if not already present. Removes the subscription using the internal _unsubscribe method with appropriate identifier and key construction.
5782	Authenticate with the Bitfinex API using provided key and secret, configure authentication channel, and send authentication request through connection. Raises ValueError if either key or secret is missing.
5783	Cancel one or multiple orders via WebSocket using the provided order identifiers. If multi is True, cancels multiple orders; otherwise cancels a single order.
5784	Internal callback for handling device command messages. Parses command from MQTT message topic and forwards it to the registered command callback after validation. Logs command receipt at debug level and critical errors at critical level.
5785	Internal callback for handling gateway command messages. Parses the source device from the topic string and forwards the parsed command information to the registered device command callback. Logs critical errors if command parsing fails, and debug information when commands are successfully received.
5786	Internal callback for handling gateway notification messages. Parses source device from topic string and forwards the information to the registered device command callback. Logs critical errors for invalid events and debug information for received notifications.
5787	Creates new device types by registering them through an API call, returning a DeviceType object on successful creation (HTTP 201) or raising an ApiException for other status codes.
5788	Publish an event to Watson IoT Platform by constructing a MQTT topic string and delegating the actual publishing to `_publishEvent` method. The topic follows the format "iot-2/evt/{event}/fmt/{msg_format}" where {event} and {msg_format} are replaced with the event name and message format parameters respectively. The method supports optional QoS (Quality of Service) levels (0, 1, or 2) and an on_publish callback function that is triggered upon delivery confirmation for QoS 1 and 2. For QoS 0, the callback is called when the client begins sending the event asynchronously.
5789	Update an existing device with the specified device UID, metadata, device info, and status. The method constructs the device URL using the device type ID and device ID from the device UID, prepares the update data, and sends a PUT request to the API. If the update is successful (status code 200), it returns a Device object populated with the response data; otherwise, it raises an ApiException.
5790	Find and iterate through all connectors with optional status and connection time filters, returning an IterableClientStatusList.
5791	List all device management extension packages by making a GET request to the API endpoint "api/v0002/mgmt/custom/bundle" and return the JSON response if successful, otherwise raise an ApiException.
5792	Create a new device management extension package by sending POST request to "api/v0002/mgmt/custom/bundle" endpoint. Returns the created package data if successful (status code 201), otherwise raises an ApiException.
5793	Update a schema with the given schema ID and definition. Throws APIException on failure. Sends a PUT request to the API endpoint with the schema definition in the request body. Returns the JSON response if successful, otherwise raises an APIException with the HTTP status code and error message.
5794	Disconnects the client from IBM Watson IoT Platform by calling disconnect() and loop_stop() on the client, then logs the connection closure.
5795	**Summary:** 

The `_onConnect` method is called when the MQTT client successfully connects to or fails to connect to a broker. It handles different connection result codes (rc) to determine the outcome:

- **rc == 0**: Connection successful. Sets a connection event, logs the success, and restores previous subscriptions.
- **rc == 1-5**: Connection refused due to specific issues (protocol version, invalid client ID, server unavailable, bad credentials, not authorized). Raises appropriate exceptions.
- **Other rc values**: Unexpected connection failure, also raises an exception.

The method manages subscriptions carefully using a lock to avoid concurrency issues during restoration.
5796	Subscribe to device event messages on a specified topic with optional wildcards for type, device, event, and format, using the specified QoS level. Returns the message ID if successful, or 0 if the subscription fails. Raises a warning and returns 0 if using QuickStart mode with a wildcard device ID.
5797	Subscribe to device status messages on the specified topic with optional type and device ID wildcards. Returns the message ID if successful, or 0 if the subscription fails. QuickStart applications cannot subscribe to wildcard device status messages.
5798	Subscribe to device command messages using MQTT topic subscription with optional filtering by type, device, command, and format. Returns message ID if successful, 0 if failed or quickstart mode is active.
5799	Publish a command to a specific device by constructing the appropriate MQTT topic and encoding the payload using the specified message format. The method handles quality of service levels and optional callback functions for publish confirmation. It first checks if the application is in quickstart mode or if client is connected, then creates the topic string using the provided type ID, device ID, command ID, and message format. It validates that a codec exists for the message format, encodes the data, and publishes the message. The method manages callback execution for publish confirmation based on the QoS level and returns a boolean indicating success or failure of the publish operation.
5800	Internal callback that handles unsupported messages by logging a warning about received messages on unsupported topics, without passing them to user-defined callbacks.
5801	Internal callback for handling device event messages. Parses event data from MQTT messages, logs the received event, and invokes the registered device event callback if one exists. Handles invalid events by logging critical error messages.
5802	Internal callback for handling device status messages. Parses the source device from the topic string and forwards the information to the registered device status callback. Logs received actions and handles invalid events with critical logging.
5803	Internal callback for handling application command messages. Parses status information from MQTT messages and invokes the registered application status callback. Logs received actions and handles invalid events with critical logging.
5804	Retrieves the last cached message for a specified event from a specific device by making an API call to the device's event endpoint. If the request is successful (status code 200), it returns a `LastEvent` object initialized with the response data. Otherwise, it raises an `ApiException` with the response details. The `deviceUid` parameter can be either a `DeviceUid` object or a dictionary that will be converted to a `DeviceUid` object.
5805	Retrieves a list of the last cached messages for all events from a specific device by making an API call to the device events endpoint and returns a list of LastEvent objects. Raises ApiException if the API request fails.
5806	Method `_makeApiCall` performs a GET request to a specified URL using the API client with optional parameters. It returns the JSON response if the status code is 200, otherwise it raises an exception with the HTTP status code and response text.
5807	Initiates a device management request (like reboot) by sending a POST request to the management requests URL. Returns the JSON response if successful (status code 202), otherwise raises an ApiException.
5808	Get device management request statuses. If no typeId or deviceId is provided, returns a list of all statuses for the given requestId. If both typeId and deviceId are provided, returns the status for a specific device within the request.
5809	Force a flush of the index to storage and render it inaccessible by destroying the handle. Raises IOError if the index is unclosable.
5810	Return the number of objects that intersect the given coordinates by querying the index with the provided bounds.
5811	Returns the k-nearest objects to the given coordinates using the R-tree index. Takes coordinates defining a query window, number of results to return, and an objects parameter to control return format. Uses the R-tree's nearest neighbor search algorithm to find the closest index entries. Returns either just the IDs of matching entries, or the actual objects depending on the objects parameter. The method handles equidistant entries by returning both when they exist.
5812	Returns the bounds of the index, optionally formatting coordinates as interleaved or non-interleaved arrays based on the coordinate_interleaved parameter or the index's default interleaved setting.
5813	Deletes items from the index with the given ID within the specified coordinates. Takes a long integer ID and coordinate pairs representing min/max bounds of the item to delete. Uses core.rt.Index_DeleteData to perform the deletion operation.
5814	Creates an index from an iterable data stream by processing each item through a callback function that fills pointers for spatial coordinates and data objects, handling interleaved coordinates and serialization.
5815	Method `loadByteArray` must be overridden by subclasses to return a string with loaded data. Currently raises `NotImplementedError` with message "You must override this method." and sets `returnError.contents.value` to `self.IllegalStateError`.
5816	Deletes an object from the container within specified coordinates. Raises IndexError if object is not found. Returns the result of the parent delete operation.
5817	Error checking function for RTREE operations that raises RTreeError with detailed error messages when operations fail.
5818	Loads and returns the application by importing it if it's a string, otherwise returns it directly.
5819	Initializes the Flask application with Common by setting up extensions, configuring WhiteNoise for static files, initializing cache, and adding request callbacks for timing and headers, along with a favicon redirect route.
5820	Serves the Flask application by running either a development server in debug mode or a Gunicorn server in production mode with specified workers and configuration options.
5821	Returns a versatile image field URL set for Django REST framework versions <=2.3.14 by building URLs with specified sizes and optional request context.
5822	Crops a PIL image to a specified aspect ratio centered on a primary point of interest (PPOI). The method adjusts the image by trimming excess pixels from either the sides (left/right) or top/bottom based on the aspect ratio comparison between the original image and the target dimensions. The PPOI determines the center point for cropping, ensuring that the resulting image matches the specified width and height while maintaining the correct aspect ratio. The final cropped image is resized to exactly the target dimensions.
5823	Method `process_image` returns a BytesIO instance of a given image cropped to specified dimensions. The cropping process first resizes the image down to its longest side, then crops inwards centered on the primary point of interest. For GIF images, it preserves the original palette to avoid display issues. The method uses `crop_on_centerpoint` for the actual cropping operation and saves the result using provided save keyword arguments.
5824	Return a BytesIO instance of `image` that fits in a bounding box of `width`x`height` dimensions.
5825	Return a BytesIO instance of `image` with inverted colors.
5826	Ensures data is properly prepared before being processed by ImageField by opening file handles when necessary.
5827	Process the field's placeholder image by ensuring it's saved to the same storage class as the field in a dedicated placeholder directory. If the placeholder image already exists, return immediately. Otherwise, save the placeholder image to the storage with a name based on the settings configuration.
5828	Return field's value just before saving, and update the PPOI field.
5829	Updates the ppoi field of a model instance before saving, if the field has a ppoi dimension field defined. Retrieves the ppoi from the file attribute if available and sets it on the associated ppoi field.
5830	Handles form data for MultiValueField forms that set ppoi values, managing file uploads and ppoi updates while preserving existing file data when only ppoi changes.
5831	Return a formfield for the VersatileImageField, using SizedImageCenterpointClickDjangoAdminField as the form class when ppoi_field is set, and handling admin widget overrides to prevent default AdminFileWidget usage in favor of the custom PPOI click widget.
5832	Prepare field for serialization by getting the prepared value from object.
5833	Discover versatileimagefield.py modules by iterating over Django app configurations and attempting to import their versatileimagefield modules, with proper error handling and registry management.
5834	Unregister a SizedImage subclass from the specified attribute name. Raises NotRegistered if no subclass is registered to the given attribute name. Removes the registration entry from the internal registry.
5835	Unregisters a FilteredImage subclass from the specified attribute name by removing it from the filter registry. Raises `NotRegistered` exception if no FilteredImage subclass is currently registered to the given attribute name.
5836	Return the appropriate URL based on field conditions: if the field is empty and a placeholder is defined, return the placeholder URL; otherwise, default to vanilla ImageFieldFile behavior.
5837	Build filters and sizers for a field including setting up FilterLibrary and SizedImage objects based on the registry.
5838	Return the path to the filtered images directory by joining the folder path with VERSATILEIMAGEFIELD_FILTERED_DIRNAME.
5839	Return the location where sized images are stored by joining the VERSATILEIMAGEFIELD_SIZED_DIRNAME with the folder path from self.name.
5840	Return the location where filtered + sized images are stored by joining the sized root folder path with the filtered directory name.
5841	Delete files in a storage folder that match a regex pattern before file extension, removing files that share the same base name and extension as the current instance but have matching tags.
5842	Preprocess an image by handling EXIF orientation and ICC profile, then apply format-specific preprocessing if available. Returns the processed image and save keyword arguments.
5843	Method `preprocess_GIF` takes a PIL Image instance of a GIF and returns a 2-tuple containing the original image and a dictionary with transparency information. If the GIF has transparency information in its metadata, it includes that transparency value in the returned dictionary; otherwise, it returns an empty dictionary.
5844	Preprocesses a PIL JPEG image by converting it to RGB format and preparing save parameters including progressive JPEG setting and quality. Returns a tuple containing the RGB image and a dictionary with save parameters.
5845	Retrieves and returns a PIL Image instance along with its file extension, image format, and MIME type from the specified path.
5846	Save an image to storage by creating an InMemoryUploadedFile instance and storing it at the specified path.
5847	Return PPOI value as a string in format "value1-value2" where dots are replaced with hyphens.
5848	Create a resized image by processing an input image file with specified dimensions and save it to the given storage path.
5849	Renders the widget as an HTML string, with support for Django versions prior to 1.11 by conditionally using either the parent class's render method or a template-based rendering approach.
5850	Get the context to render this widget with, including additional image preview and clear checkbox information.
5851	Build an attribute dictionary by copying base attributes and updating with extra attributes if provided.
5852	Returns the storage path for a resized image based on the original path, dimensions, and filename key.
5853	Returns the filtered path for an image by constructing a new path with the filtered filename in the VERSATILEIMAGEFIELD_FILTERED_DIRNAME directory, with spaces removed to make it memcached key friendly.
5854	Validate a list of size keys where each size key must be either 'url' or follow the format 'segment__segment__...__dimension' with 'x' in the last segment. Raises InvalidSizeKey for invalid formats and InvalidSizeKeySet for non-2-tuple iterables. Returns a list of unique size key tuples.
5855	Builds a URL from an image key by splitting the key, handling size specifications, and traversing the image instance attributes to retrieve the final URL.
5856	Retrieves and validates a rendition key set from IMAGE_SETS dictionary using the provided key, raising an ImproperlyConfigured exception if the key doesn't exist, otherwise returns the validated rendition key set.
5857	Formats an Instruction object into a human-readable text representation using its mnemonic and immediate values. Returns the instruction mnemonic followed by formatted immediate arguments separated by commas, or just the mnemonic if no immediate values exist.
5858	Formats a function body into a formatted string representation with optional type information, local variable declarations, and indented bytecode instructions.
5859	Decodes raw bytecode into a sequence of Instruction objects by iterating through the bytecode, extracting opcodes and their immediate values using the opcode mapping, and yielding each instruction with its corresponding opcode, immediate value, and length.
5860	Decodes raw WASM modules into `ModuleFragment`s, yielding module headers and sections. If enabled, it also decodes name subsections when encountered.
5861	A decorator that deprecates a function by printing a warning on its first usage, then calls the original function. Uses a mutable container to track first usage since Python 2 lacks the `nonlocal` keyword. The warning is issued as a `DeprecationWarning` and includes the function name.
5862	Connect to the server using asyncio, creating a connection task with the specified protocol factory, host, port, and SSL configuration, then add a callback for when the connection is made.
5863	Close the connection by canceling the pinger if it exists and closing the protocol if it exists.
5864	Reads a response from the AGI, decodes it using the specified encoding, and parses it into a dictionary using parse_agi_result function. Returns the parsed response as a dictionary.
5865	AsyncIO coroutine handler that listens for FastAGI socket connections, parses AGI headers from incoming requests, routes requests based on the agi_network_script header to registered routes, handles exceptions during route execution, and properly closes client connections. It supports asynchronous reading of client data, header parsing, and route dispatching for FastAGI applications.
5866	Parse AGI results using regular expressions, handling various result formats including hangup cases and different return codes.
5867	Function to check AGI code and return error handling information. Takes code, response, and line parameters, converts code to integer, and returns a dictionary with status_code, result, and msg. Handles different code cases (100, 200, 510, 520) with specific error handling and returns appropriate error messages and codes for AGI execution results.
5868	Reset method for unit testing that allows setting a static UUID and resetting all counters by regenerating generators for all instances.
5869	Returns a list of string representations of instances with class name, prefix, and uid for debugging purposes.
5870	Returns metadata from a package directory by running setup.py and collecting distribution information, with error handling for missing or broken setup.py files.
5871	Get primary key properties for a SQLAlchemy model by extracting column information from the model's mapper and returning the corresponding property objects.
5872	Deserialize a serialized value to a model instance, creating a new transient instance if the parent schema is transient, or attempting to find an existing instance in the database otherwise. If the value is not a dict and there's more than one related key, raise an invalid error. If no existing instance is found, create a new one.
5873	Retrieve the related object from an existing database instance using either filter_by() for multiple columns or get() for primary key only, raising NoResultFound if no matching record exists.
5874	Updates declared fields with fields converted from a SQLAlchemy model, combining them with existing declared fields and returning the merged result.
5875	Deserialize data to internal representation.

Parameters:
- session: Optional SQLAlchemy session
- instance: Optional existing instance to modify  
- transient: Optional switch to allow transient instantiation

Validates that a session is available for deserialization, sets up session and transient state, then delegates to parent load method. Clears instance reference in finally block.
5876	Split serialized attributes into regular kwargs and association proxy attributes for proper SQLAlchemy processing, separating them to ensure correct order of operations when dealing with association proxies.
5877	Deletes old stellar tables that are not used anymore by getting the app, upgrading from old version, and deleting orphan snapshots with a callback echo message.
5878	Creates a database snapshot with the specified name, checking for existing snapshots and providing progress feedback during the process.
5879	Returns a formatted list of snapshots with their names and relative timestamps using humanized time formatting.
5880	Restores a database from a snapshot by first checking if a snapshot exists (using the latest one if none specified), then ensuring slaves are ready for the restore process. If slaves aren't ready and a background process is running, it waits for the process to complete. If no background process is running, it performs a slow restore inline. Finally, it executes the restore operation and reports completion.
5881	Removes a snapshot with the given name by retrieving it from the application, displaying a deletion message, removing it from the application, and confirming the deletion. If the snapshot is not found, it outputs an error message and exits with code 1.
5882	Renames a snapshot from old_name to new_name, with validation checks to ensure the old snapshot exists and the new name doesn't already exist. Outputs appropriate success or error messages using click.
5883	Replaces a snapshot with a new one by first removing the existing snapshot and then creating a new snapshot with the same name. If the snapshot doesn't exist, it outputs an error message and exits with status code 1.
5884	Updates indexes after each epoch for shuffling.
5885	Clean text using default preprocessing settings, including unicode fixing, lowercasing, transliteration, and removing URLs, emails, phone numbers, numbers, currency symbols, punctuation, and accents.
5886	Apply a function to a list of elements in parallel using multiple CPU cores. Automatically determines chunk size and number of cores to use. Returns the transformed data as a list.
5887	Generate a function that cleans and tokenizes text by applying a cleaner function followed by a tokenizer, with optional start and end token indicators.
5888	Combines text cleaning and tokenization processes using a constructed processor function that applies the instance's cleaner, tokenizer, and formatting indicators to the input text list.
5889	Applies text cleaning and tokenization in parallel to a list of text strings using the specified cleaner and tokenizer, returning a list of tokenized text lists.
5890	Generate document length statistics and determine padding strategy based on a heuristic percentile threshold, setting the maximum document length and logging the result.
5891	Returns token frequencies as a pandas DataFrame sorted by count in descending order.
5892	Maps parameter types to their corresponding Python types, handling special cases like lists/arrays and nested types. If a type doesn't match known mappings, defaults to string type. Supports recursive type resolution for complex nested types.
5893	Parse conduit.query JSON response to convert non-standard params dict into a format that Resource can understand, organizing methods by app and function with default assumptions for formats and method type, while categorizing parameters as required or optional based on type information parsing.
5894	Returns the inverse bidict, creating it if necessary. Uses cached strong or weak references, or initializes a new inverse if needed.
5895	Update items with rollback capability, logging each successful write operation. If a duplication error occurs, roll back all previously successful writes before raising the error. Returns log of (dedup_result, write_result) tuples for successful operations.
5896	A shallow copy method that creates a new instance using `__new__` to bypass `__init__` for efficiency, then copies the backing mappings directly instead of copying items one at a time.
5897	A shallow copy of this ordered bidict is created by bypassing __init__ for performance. It replicates the internal structure including forward and inverse mappings, and initializes the copy with the same key-value pairs in the same order.
5898	Order-sensitive equality check that compares two mappings for equality while preserving order. Returns False if the other object is not a Mapping or if lengths differ. Otherwise, returns True if all key-value pairs match in order, using zipped iteration of both mappings' items.
5899	Return an iterator that yields inverted key-value pairs from the input object. If the object has an `__inverted__` method, call it and return its result. Otherwise, iterate through the object's items and swap each key-value pair.
5900	Clear all items from the data structure by clearing forward and inverse mappings, then reinitializing the sentinel node's next and previous pointers to point to itself.
5901	Move an existing key to the beginning or end of the ordered bidict. If `last` is True, moves the key to the end; otherwise moves it to the beginning. Raises KeyError if the key does not exist.
5902	Creates a temporary file with .yml extension, writes provided text to it, and returns the file name.
5903	Get a list of contacts from one or more address books based on a search query, with options to specify search method, sorting, grouping, and ordering.
5904	Merges command line arguments into a configuration object by setting various configuration parameters based on provided arguments, including display options, grouping, sorting criteria, vcard version, and address book settings.
5905	Load address books by names from config, validate names exist, and yield loaded address books with search queries applied.
5906	Prepare search queries from command line arguments for filtering vCards in address books, creating regex patterns for source and target queries based on provided search terms, contacts, and UIDs, and return a dictionary mapping address book names to their respective query strings.
5907	Create a new contact in a selected address book, either from stdin input or by opening an editor. If input is provided, parse it as YAML and create the contact; otherwise, initiate the creation process through a new contact assistant. Optionally open the new contact in an editor after creation.
5908	Prints a formatted table of contact birthdays from a list of vcards, optionally in a machine-readable parsable format sorted by date.
5909	Prints a phone application friendly contact table based on search terms, using vcards and optional parsable output format.
5910	Prints a user friendly contacts table from a list of vcards, either in human-readable format or machine-readable tab-separated format based on the parsable parameter. If no contacts are found, prints "Found no contacts" and exits with error code 1. For parsable output, displays UID, name, and address book name for each vcard. For human-readable output, uses the list_contacts function.
5911	Modify a contact in an external editor, with optional data input from stdin/file. Validates vcard version compatibility, prompts user for confirmation, and either updates the contact or opens it in an editor.
5912	Remove a contact from the address book with optional confirmation prompt.
5913	Opens a vcard file in an external editor using the specified editor command and waits for the editor to close.
5914	Merge two contacts into one by selecting a source contact and a target contact from provided address books, ensuring unique identification by UID or search terms, and then performing the merge operation.
5915	Copy or move a contact from a source address book to a target address book, handling cases where the contact already exists in the target book by offering options to overwrite, merge, or cancel the operation.
5916	Find the name of the action for the supplied alias. If no action is associated with the given alias, None is returned.

Parameters:
- alias (str): the alias to look up

Returns:
- str or NoneType: the name of the corresponding action or None
5917	Convert a boolean configuration value from string ("yes"/"no") to boolean (True/False) in a config object.

The function takes a config section, option name, and default boolean value. If the option doesn't exist, it sets it to the default. If it exists with value "yes", it converts to True. If it exists with value "no", it converts to False. Any other value raises a ValueError with a descriptive error message.

Parameters:
- config: configobj.ConfigObj - the configuration section
- name: str - the name of the option to convert  
- default: bool - default value if option not present

Returns: None

Raises:
- ValueError: when the option value is neither "yes" nor "no"
5918	Creates a new empty contact by instantiating the class with a None contact_id parameter.
5919	Creates a new contact from an existing .vcf file by calling the class constructor with the specified parameters.
5920	Creates a new contact from user input by initializing a contact object and processing the user input.
5921	Creates a new contact by cloning an existing contact and replacing its data with new user input in one step.
5922	Get a specific part of the vCard name entry as a list, returning empty list if the part doesn't exist or contains only empty strings.
5923	Adds category information to a vCard object by converting a list of categories into vCard format and attaching it to the vCard's categories property.
5924	Parse type value of phone numbers, email and post addresses.

Args:
    types (list(str)): list of type values
    value (str): the corresponding label, required for more verbose exceptions
    supported_types (list(str)): all allowed standard types

Returns:
    tuple(list(str), list(str), int): tuple of standard and custom types and pref integer
5925	converts list to string recursively so that nested lists are supported

**Parameters:**
- input: a list of strings and lists of strings (and so on recursive)
- delimiter: the delimiter to use when joining the items

**Returns:**
- the recursively joined list

**Return type:**
- str
5926	Convert string to date object by trying multiple date and datetime formats including --mmdd, --mm-dd, yyyymmdd, yyyy-mm-dd, and various datetime formats with and without timezone information. Raises ValueError if no format matches.
5927	Calculate the minimum length of initial substrings of uid1 and uid2 for them to be different. Returns the length of the shortest unequal initial substrings.
5928	Searches for contacts matching a query across all fields, including phone numbers with special characters. Returns a generator yielding matching contacts.
5929	Search for contacts by name using a regex query, yielding matching contacts.
5930	Search for contacts with a matching uid, first trying exact match then prefix matching.
5931	Searches contacts in the address book matching the query using specified search method.

This method searches through contacts in the address book based on the provided query string. It supports three search methods: "all" (searches all fields), "name" (searches only names), and "uid" (searches only unique identifiers). The address book is automatically loaded if not already loaded. Returns a list of matching CarddavObject instances.

Parameters:
- query (str): The search term to look for
- method (str): Search method to use ("all", "name", or "uid", default: "all")

Returns:
- list(carddav_object.CarddavObject): List of contact objects matching the query

Raises:
- ValueError: If an unsupported search method is specified
5932	Create a dictionary mapping shortened unique prefixes of UIDs to their corresponding contacts. Initializes the address book if needed and handles edge cases for empty or single-contact lists. For multiple contacts, it computes the shortest unique prefix for each UID by comparing adjacent items in sorted order and stores the results in self._short_uids for reuse.
5933	Get the shortened UID for a given UID by checking against a dictionary of short UIDs, returning the longest matching prefix or empty string if no match found.
5934	Find all vcard files in the address book, optionally filtering by a search string applied either to file contents or all files.

**Parameters:**
- `search` (str): Regular expression to filter results (optional)
- `search_in_source_files` (bool): Apply search regexp directly on .vcf files for speed (less accurate)

**Returns:** Generator yielding paths of matching vcard files

**Behavior:**
- Returns all *.vcf files in the address book directory by default
- When search is provided and search_in_source_files is True, filters files by searching within their content
- When search is provided but search_in_source_files is False, returns all files (search parameter ignored)
- Uses case-insensitive, multi-line matching for content searches
5935	Load all vcard files from this address book directory. If a query is provided, only matching files are loaded. Returns tuple of (successful_loads, errors). Raises AddressBookParseError if parsing fails and skip_unparsable is False.
5936	Get one of the backing address books by its name.

Parameters:
- name (str): the name of the address book to get

Returns:
- AddressBook or NoneType: the matching address book or None
5937	Initialize the dictionary of architectures for assembling via keystone, returning a mapping of architecture constants to their corresponding keystone architecture and mode tuples.
5938	Initialize the dictionary of architectures for disassembling via capstone
5939	Returns the argument specification of a function with relaxed checks to support Cython-compiled functions. Unlike the standard `inspect.getargspec()`, this version accepts functions that have `func_code` and `func_defaults` attributes even if they are not instances of Python's `types.FunctionType`. It extracts the argument names, *args, **kwargs, and default values from the function's code object.
5940	Parses command line arguments using the provided parser, executes the appropriate function, and outputs the result. Supports help command conversion, shell completion, custom output/error files, raw output formatting, and skipping unknown arguments. Returns output as string if output_file is None, otherwise writes to the specified file. Handles command execution errors and displays usage information when no commands are found.
5941	Handles user input with proper encoding support for both Python 2 and 3, converting between unicode and bytes as needed.
5942	Encodes a given value for writing to a file object, handling differences between Python 2 and Python 3. In Python 3, returns the value as Unicode text. In Python 2, handles encoding of Unicode and binary data based on the output file's encoding or defaults to UTF-8 encoding.
5943	Adds types, actions, etc. to given argument specification based on default values and choices. For example, ``default=3`` implies ``type=int``. Infers action as 'store_false' or 'store_true' from boolean default values, and infers type from default values or first choice item when not explicitly provided.
5944	Adds given functions as commands to a parser, with optional namespace grouping. Supports deprecated title, description, and help parameters via namespace_kwargs. Creates subparsers for each function, inferring command names from function names (underscores replaced with hyphens). Handles function metadata extraction and command setup through helper functions. Modifies the parser object directly and raises AssemblingError if default command already exists.
5945	Sets a given string as the command name for a function, replacing the function's original name. The string is used exactly as provided. Useful for creating commands with different names than their function names.
5946	**Summary:**

The `arg` function is a decorator that adds argument specifications to a function without modifying the function itself. It collects argument declarations in a list stored in the function's `ATTR_ARGS` attribute, preserving the order of decorators. The decorator accepts both positional and keyword arguments that match `argparse.ArgumentParser.add_argument`, and automatically infers some argument properties (like type or action) when default values are provided. It's intended for extending function signatures with details that can't be expressed through ordinary Python function parameters, such as help messages or choices. The decorator follows the principle of minimizing repetition and maximizing readability, recommending against its use unless necessary.
5947	A confirmation prompt function that asks user to confirm an action with 'yes' or 'no' choices. Supports default behavior when user hits Enter, skip mode for batch processing, and handles KeyboardInterrupt. Returns True for "yes", False for "no", and the default value or None for invalid input.
5948	Creates a copy of the Query object with optional replacements for filters, order_by, or limit information.
5949	Method `like` filters entities based on pattern matching using wildcard characters (*, ?, +, !). It accepts keyword arguments where keys are column names and values are patterns to match. The method requires prefix=True option in column definition and returns a new instance with added filters. Patterns match at the beginning of strings by default, with wildcards allowing flexible pattern matching.
5950	The `cached_result` method executes a query and returns a key for accessing cached results stored in a ZSET, with an expiration time specified by the timeout parameter. It validates that filtering or ordering criteria are present and that the timeout is a positive integer. The method ignores limit clauses and is designed for pagination and cached result management, with a note that results will be automatically deleted after the timeout unless explicitly persisted.
5951	Returns only the first result from the query, if any.
5952	Deletes entities that match a query in chunks to avoid memory issues, raising an error for models with foreign key relationships.
5953	This function handles the cascade delete operation for OneToMany relationships by traversing referenced models and applying specified deletion actions (cascade, restrict, set null, set default) to maintain referential integrity. It collects entities to delete, processes their references according to on_delete rules, and performs the actual deletion and saving operations.
5954	Function `redis_prefix_lua` performs prefix, suffix, and pattern match operations using Redis. It generates a temporary key, determines start/end positions from a prefix, and calls `_redis_prefix_lua` with destination, temporary key, index, start/end positions, pattern information, and first-operation flag. Returns the result of the Redis operation.
5955	Estimates the total work necessary to calculate the prefix match over the given index with the provided prefix. Handles different index types (':idx' and ':geo') with specific argument processing and delegates to `_estimate_work_lua` for the actual calculation.
5956	Search for model IDs matching given filters, with optional ordering, offset, and count parameters. Returns either a temporary key or the actual search results.
5957	Returns the count of items matching the provided filters by using a pipeline to get the cardinality of a temporary set and then deleting the set.
5958	tries to get the _conn attribute from a model, falling back to global default connection
5959	A full-text index key generation function that processes input values by converting them to strings, lowercasing words, removing punctuation, splitting by whitespace, and creating a sorted list of unique terms for inverted index creation. Handles various input types including floats, None, empty strings, and different string types across Python versions. Returns None for invalid inputs and encoded byte strings for Unicode input in Python 2.
5960	This utility function refreshes database indices for all entities of a given model by iterating through them in blocks. It connects to the database, determines the maximum ID, then processes entities in batches (default 100) using blocks of the specified size. For each block, it fetches entities, commits them to trigger index updates, and yields progress information. The function is useful after adding new indexes to ensure all existing data is properly indexed. It uses session commits to handle index refresh and will commit any outstanding entities in the session.
5961	This function cleans up old index data that may have been left behind during item deletion in ROM versions <= 0.27.0. It should be run after upgrading clients to version 0.28.0 or later. The function works by scanning through index entries and removing any stale references that no longer correspond to existing entities. It supports both Redis HSCAN (for versions >= 2.8) and fallback methods for older versions, yielding progress updates throughout the cleanup process. The function handles both regular indexes and unique indexes, providing warnings when cleanup cannot be performed due to Redis version limitations or disabled HSCAN functionality.
5962	Adds an entity to the session, storing it in known and wknown dictionaries if it has a valid primary key.
5963	Fetches an entity from the session based on primary key by checking both known and wknown collections.
5964	Writes data to Redis using Lua scripting, handling unique key violations and data race conditions. Processes input data into JSON format and executes Redis operations through a pipeline or direct connection, raising appropriate exceptions for conflicts or violations.
5965	Saves the current entity to Redis, only updating changed data by default unless `full=True` or `force=True` is specified. Executes pre-commit hooks before saving and post-commit hooks after saving. Returns the result of the save operation.
5966	Deletes the entity immediately, handling pre/post-delete hooks and foreign key cascade operations specified in column definitions.
5967	Method `get(cls, ids)` fetches one or more entities of a given type from either the session or Redis. It accepts a single ID or a collection of IDs and returns the corresponding entities, preserving the order of IDs. If an entity is not found in the session, it attempts to load it from Redis. For a single ID, it returns the entity directly or None if not found. For multiple IDs, it returns a list of entities (or None for missing ones) in the same order as the input IDs.
5968	Register a reducer function to a given type in the dispatch table, with special handling for Python 2 where a closure workaround is needed for customizable pickler dispatching.
5969	Construct or retrieve a semaphore with the given name. If value is None, try to retrieve an existing named semaphore. Else create a new semaphore with the given value. Raises FileExistsError if semaphore already exists, FileNotFoundError if semaphore cannot be found, NotImplementedError if no semaphore implementation exists on the system, or raisesFromErrno() for other errors. Returns the semaphore handle.
5970	Return the number of CPUs the current process can use, accounting for system CPU count, CPU affinity settings, CFS scheduler limits, and LOKY_MAX_CPU_COUNT environment variable, with a minimum value of 1.
5971	Sends a result or exception back through a queue in a safe manner, handling potential serialization errors by wrapping exceptions with traceback information.
5972	**Summary:**

The `_process_worker` function is a worker process that continuously retrieves tasks from a queue, executes them, and returns results. It handles initialization, timeout management, memory monitoring (using psutil if available), and proper cleanup. The worker supports nested parallelism via `current_depth`, and manages exceptions and memory leaks to ensure stable operation. It shuts down gracefully when signaled or when timeouts occur, and notifies the parent process of its exit.
5973	Fills a call queue with work items from pending work items while managing running work items and handling queue full/empty conditions. The function processes work IDs from a queue, converts corresponding work items to call items, and adds them to the call queue if they can be set to running state. It returns early if the call queue is full or no more work IDs are available.
5974	Ensures all worker processes and management thread are running by adjusting process count if necessary and starting the queue management thread.
5975	Wrapper for non-picklable object to use cloudpickle to serialize them. Note that this wrapper tends to slow down the serialization process as it is done with cloudpickle which is typically slower compared to pickle. The proper way to solve serialization issues is to avoid defining functions and objects in the main scripts and to implement __reduce__ functions for complex classes.
5976	Start a server process for this manager object by spawning a new process that runs the server, setting up communication pipes to retrieve the server address, and registering a finalizer for clean shutdown.
5977	Returns a wrapper for an fd that can be pickled and passed to a new process. Uses the appropriate duplication method based on the platform and Python version, raising TypeError if pickling is not supported.
5978	Return the current ReusableExecutor instance, creating a new one if necessary. Reusing the executor avoids the overhead of starting new worker processes and importing packages. The function handles dynamic resizing of workers, manages executor lifecycle (creation, reuse, shutdown), and supports customization through various parameters like max_workers, timeout, job/result reducers, and initializer functions.
5979	Wait for pending jobs to complete before resizing the executor pool, issuing warnings if jobs are running during resize operation.
5980	Return information about the parent process needed by the child to unpickle process objects, including logging settings, system path, and main module initialization details.
5981	Summary: Initializes and configures the current process with various settings from the input data dictionary, including process name, authentication key, logging configuration, Python path, command line arguments, working directory, semaphore tracker PID, and main module initialization.
5982	Close all file descriptors except those specified in keep_fds, with special handling to keep stdout (1) and stderr (2) open for logging purposes. Uses /proc/self/fd to list open file descriptors on Linux systems, with a fallback to resource.getrlimit for other systems. Ignores errors during close operations.
5983	Terminate a process and its descendants recursively, with fallback to classic terminate if psutil is not available.
5984	Recursively terminates a process and all its descendants by sending SIGTERM signals, with platform-specific handling for Windows (using taskkill) and Unix-like systems (using pgrep and os.kill). On Windows, it attempts to terminate the process and its children together, falling back to terminating just the process if permission is denied. On Unix-like systems, it first identifies child processes using pgrep and recursively terminates them before killing the parent process. Error handling ensures that non-existent processes don't cause failures and that permission errors are appropriately managed.
5985	Return a formatted string with the exit codes of terminated workers, waiting up to 0.25s for exit codes to be available if necessary.
5986	Format a list of exit codes with their corresponding signal names into a formatted string representation.
5987	Run semaphore tracker that monitors semaphore registration/unregistration, handles process signals, and cleans up leaked semaphores at shutdown.
5988	Ensures the semaphore tracker process is running by checking if it's alive and restarting it if necessary. If the tracker is dead, it closes old file descriptors, cleans up any dangling processes, and launches a new semaphore tracker process using a subprocess. The new process is created with specific file descriptors passed to it and inherits signal masks to prevent race conditions during startup. If any errors occur during this process, it cleans up and re-raises the exception. The method uses locks to ensure thread safety when managing the semaphore tracker state.
5989	A simple event processor that prints or writes debugging events with file location information. It takes a frame, event type, and optional argument, then outputs the event name along with the filename and line number. If an output stream is available, it writes to that stream; otherwise, it prints to standard output. The argument is also included in the output if present. Returns the event processor method itself.
5990	This method implements a program counter functionality that displays the current execution position in a running Python program. When the program is running, it shows the current bytecode offset and disassembles the nearby code instructions. When the program is not running, it displays information about the program status and execution state. The method returns False to indicate it doesn't handle the command itself.
5991	Function `interact` creates an interactive Python interpreter session similar to `code.interact`, but with customizations. It initializes an `InteractiveConsole` with local and global namespaces, replaces the default code execution with a custom `runcode` function, and optionally sets up readline for better input handling. The function allows customization through parameters like `banner` for display, `readfunc` for custom input handling, and `my_locals`/`my_globals` for namespace control.
5992	Split a command line's arguments in a shell-like manner returned as a list of lists, using ';;' to indicate separate commands. Uses modified shlex.split() with posix=False by default to respect quotes.
5993	Returns a stack of frames for debugging backtraces and frame switching, with optional filtering based on debugger settings and traceback frames.
5994	Run each function in `hooks` with the given arguments, returning True if any hook returns True, otherwise returning False.
5995	Remove memory of state variables set in the command processor by clearing stack, resetting index and frame pointers, and clearing thread names.
5996	Returns the integer value of evaluating the given argument in the current frame's context, or None if the evaluation fails or the result is not an integer.
5997	Method `get_int` converts an argument to an integer with validation. It returns a default value if the argument is None. It validates that the integer is within specified bounds (min_value to at_most) and reports errors if validation fails. The method supports optional command name context for error messages and handles edge cases where conversion to integer fails or values are out of range.
5998	Handle debugger commands by setting up and locating the debugger, then entering a loop to process commands until a leave condition is met, managing hooks and handling EOF errors by either popping stacked interfaces or quitting the debugger.
5999	Queue a debugger command file to be read in the process-command loop. Expands the user path and checks if the file is readable before adding it to the command queue. Reports errors if the file doesn't exist or isn't readable.
6000	Find the next token in a string from a given position, returning the token and the position after the token. Tokens are sequences of non-whitespace characters delimited by whitespace. Returns [next_blank_pos, token] where next_blank_pos is the position after the token, or string length if it's the last token.
6001	Common routine for reporting debugger error messages with optional location information and abort functionality.
6002	Method: read_command

Summary: Reads a command line from input for script execution, increments the input line number, and optionally logs the command with location information when verbose mode is enabled. The prompt parameter is accepted for compatibility but ignored. Returns the readline result.
6003	Closes both input and output connections, sets state to 'closing' then 'disconnected', and returns None.
6004	Disassembles a code object into human-readable bytecode representation, providing detailed information about the compiled Python code including line numbers, variable names, constants, and other code metadata.
6005	Disassembles a byte string of Python code into human-readable assembly-like instructions, showing line numbers, opcodes, arguments, and labels. It supports optional filtering by line range, offset range, and highlighting. The function processes instructions sequentially, handling labels, line starts, and formatting for display. Returns the code and final offset processed.
6006	Return a count of the number of frames in the current call stack, starting from a given offset.
6007	Returns the name of the function being called at the given frame, or None if the frame is not at a function call.
6008	Prints the stack trace entries of a process object up to a specified count, with optional coloring and formatting options.
6009	Find subcmd in self.subcmds that starts with subcmd_prefix and meets the minimum abbreviation length requirement.
6010	Show short help for a subcommand, optionally prefixed with the command name. If the subcommand exists and has short_help attribute, display it with optional prefix; otherwise show undefined subcommand error.
6011	Adds a subcommand to the available subcommands for this object, storing it with its name as key and maintaining a command list for completion assistance.
6012	Run a subcommand with given arguments using the object as environment. Look up the subcommand entry, execute its callback if found, otherwise handle undefined command. Returns nothing.
6013	Enters the debugger at the point where it is called, with options to control debugging behavior such as stack frame skipping, line event ignoring, and post-mortem debugging. It initializes a debugger instance if one doesn't exist and allows for custom debugger and startup options.
6014	Show short help for all commands in a specified category, or list all commands if '*' is specified as argument.
6015	Returns the current line number in the source file with file path and instruction information.
6016	Find the first debugged frame in a traceback by looking for the first frame where f_trace is set, skipping debugger frames that don't have f_trace set. If a tracer_func_frame is found in the frame's locals and matches the current frame, move back one frame. Returns the determined debugged frame or the original frame if no debugged frame is found.
6017	Create a mapping from thread names to thread IDs by inverting threading._active dictionary, where each thread name is associated with its corresponding thread ID.
6018	Function `get_int` attempts to convert an argument to an integer, using a default value if conversion fails. It handles arithmetic expressions and variables through `eval()`, and raises a `ValueError` with an error message if the conversion is unsuccessful. The error message can include command name context if provided.
6019	Function `get_onoff` converts string or numeric arguments to boolean values, returning True for 'on'/'1' and False for 'off'/'0'. It raises ValueError for invalid inputs and supports optional default values and error message handling.
6020	Sets a Boolean-valued debugger setting to either "on" or "off" based on the provided arguments, defaulting to "on" if no arguments are given. If the argument is invalid, the function silently ignores the error and returns.
6021	Sets an integer-valued debugger setting with optional min/max value validation. Returns the assigned value.
6022	Displays a boolean-valued debugger setting by retrieving the setting value, converting it to "on"/"off" format, and returning a formatted message showing the setting name and its value.
6023	Generic subcommand for displaying integer values from debugger settings. Takes an object and optional parameter name, retrieves the integer setting value, and returns a formatted message string showing the value. If no parameter name is provided, uses the object's name as the display key. Returns a formatted message in the form "param_name is [value]."
6024	Generic subcommand value display that retrieves a setting value from the debugger and displays it formatted as "setting_name is value." Returns False to indicate no further processing is needed.
6025	Return True if the given line represents a function definition statement by checking for 'def' pattern match, 'LOAD_CONST' opcode at the frame, and 'MAKE_FUNCTION' opcode presence in the statement.
6026	Return True if the given line represents a class definition statement by matching against a class regex pattern and verifying that the corresponding bytecode contains a BUILD_CLASS operation.
6027	**Summary:** The `threaded_quit` method terminates all threads except the current one by sending a `DebuggerQuit` exception to each threaded process, then raises the same exception in the current thread to exit the debugger.
6028	Sets default background based on TERM environment variable. Returns False for xterm, eterm, and dtterm terminals, True otherwise.
6029	Function `is_dark_rgb(r, g, b)` determines if a given RGB color is dark by comparing the color's brightness against a calculated midpoint threshold. It accepts R, G, B values in hex and returns a boolean indicating if the color is considered dark. The midpoint is configurable via the `TERMINAL_COLOR_MIDPOINT` environment variable, with a default value of 383 for 'xterm-256color' terminals or 117963 for others. The brightness calculation uses the formula (16*5 + 16*g + 16*b) and compares it to the midpoint to determine darkness.
6030	Returns a frame signature tuple containing (function name, filename, first line number) for keying display expressions, or None if frame is falsy.
6031	List all display items; return 0 if none. Returns a formatted string list of all display items with a header "Auto-display expressions now in effect:" followed by "Num Enb Expression" and each display item formatted via display.format().
6032	Displays active items in a frame by filtering based on signature match and enabled status, returning their string representations.
6033	Formats a display item with optional enabled status, format string, and argument, returning a formatted string with the item number.
6034	Reads one message unit from the connection, handling buffering for multiple messages and raising EOFError on end-of-file. Raises IOError if called in invalid state.
6035	Sets a breakpoint at the current location or specified frame using RemoteCeleryTrepan debugger with a banner message.
6036	Error message when subcommand is undefined, displays helpful message with available commands.
6037	Run a frame command with support for multiple parameter variations including frame position, thread specification, and combined thread-position arguments.
6038	Pretty prints a simple (non-nested) list by formatting its elements into columns. Returns True if successful, False otherwise. Handles numeric and non-numeric elements differently, using columnar arrangement for better readability.
6039	Lookup the signal name for a given signal number. Returns the corresponding signal name if found, otherwise returns None.
6040	Lookup the signal number for a given signal name. Returns None if the signal name is invalid. The function handles both uppercase and lowercase signal names, and works with or without the 'SIG' prefix.
6041	Return a canonical signal name for a signal name or signal number. If name_num is an invalid signal number, return None. If name_num is not a number, return False. Otherwise, return the canonical signal name.
6042	Sets a signal handler that chains behind the debugger's handler. Returns True if successful, False otherwise.
6043	Check and adjust signal handlers for interested signals, returning early if any handler fails to be properly set.
6044	Print information about a signal, showing all signal handlers when no arguments are provided or displaying information for a specific signal when given a signal name or number.
6045	This method delegates signal action handling based on command arguments. It processes signal names and their associated attributes (like stop, print, pass, ignore, stack) to configure signal handlers. The method supports:
- Displaying signal information when no arguments are provided
- Handling signal actions for various signal types
- Preventing modification of fatal signals
- Supporting multiple attributes in a single command
- Returning validation status after signal handler adjustments

The method splits the input argument string, validates signal names, and delegates to specific handler methods based on the attributes specified.
6046	Sets whether to print a message when a signal is caught. If set_print is True, assigns the debugger's message interface method to the signal's print_method. If set_print is False, sets the signal's print_method to None. Returns the set_print value.
6047	This method handles signals by:
1. Printing signal information if a print method is defined
2. Optionally printing the stack trace if enabled
3. Handling the signal in the debugger if stopping is enabled
4. Passing the signal along to the original handler if configured to do so

The method manages signal interception and propagation for debugging purposes, providing flexibility in how signals are processed during program execution.
6048	Given a filename, extract the most likely module name by returning the basename without the file extension. If there is no extension, return the basename as-is.
6049	Search for a file in specified directories and return its full pathname if found, otherwise return None.
6050	Function `whence_file` performs a shell-like path lookup for a Python script file. It takes a script name and optional directory list, searches for the script in those directories, and returns the full path if found. If the script contains a path separator or isn't found, it returns the original script name.

**Parameters:**
- `py_script` (str): The name of the Python script to search for
- `dirnames` (list, optional): List of directories to search in

**Returns:**
- str: Full path to the script if found, otherwise returns the original script name

**Logic:**
1. If `py_script` contains path separators, return it unchanged
2. If `dirnames` is None, use PATH environment variable split by path separator
3. Search each directory for the script file using `os.path.join`
4. Return first match found, or original script name if not found
6051	Returns a list of Python module names (without .py extension) from the directory of the caller's file, excluding __init__.py files.
6052	Writes a message to an attached debugger with a newline character added.
6053	Summary of the `run` method:

This method displays the execution status of a Python program. It checks if the program is running or stopped, and provides detailed information accordingly. When the program is running, it shows:
- The main file name and stop status
- Event information (via event type)
- Current program counter offset
- Return values or exception details if applicable
- Stop reason and additional notes about stopping conditions

When the program is not running, it displays:
- Whether a Python program is running or not
- Execution status information

The method returns `False` indicating it doesn't handle command-line arguments directly.
6054	Formats and displays a sorted list of commands in aligned columns with specified width formatting.
6055	Enter debugger read loop after program has crashed, using exception information from sys.last_traceback or sys.exc_info() if available. Sets up debugger context including main file and execution status, then processes the exception event to start debugging. Handles debugger restart and quit exceptions during debugging session.
6056	Closes both socket and server connection by setting state to 'closing', closing the inout connection if it exists, then setting state to 'closing connection', closing the conn if it exists, and finally setting state to 'disconnected'.
6057	Writes a message to the debugger connection without adding a newline. Handles connection state and splits large messages into packets for transmission.
6058	Complete an arbitrary expression by collecting globals and locals (excluding builtins), handling dotted attribute access for nested completions, or completing simple names using Mcomplete.
6059	Invoke a debugger command from inside a python shell called inside the debugger.
6060	Add one or more frames or functions to the ignore list for debugging.
6061	Returns the canonical representation of a filename by resolving it to an absolute path, handling relative paths and cached lookups. If the filename is in `<...>` format (like `<string>`), it returns as-is. For other filenames, it resolves relative paths against the main directory, searches through the search path if needed, and normalizes the path case and resolution before caching and returning the result.
6062	Return the filename or its basename depending on the basename setting. If no filename is provided, use the debugger's mainpyfile or return None. If basename setting is True, return only the basename of the filename.
6063	Return True if debugging is in progress by checking if tracer is started, trace hook is not suspended, and trace dispatch hook is properly set.
6064	This method determines whether the debugger should stop at the current execution point and run a command processor. It checks multiple stopping conditions including:

- Whether the debugger is stepping (next/finish) and if the current frame depth matches stopping criteria
- Whether a breakpoint was encountered  
- Whether we're in a different line (for next/finish commands)
- Whether stepping commands should trigger a stop

The method returns True and sets stop_reason when a stop condition is met, False otherwise. It also tracks line numbers and filenames to handle line-based stepping logic, and manages frame-level stopping for 'next' and 'finish' commands by comparing stack depth against stop_level.
6065	Sets the debugger to stop on the next event that occurs in the specified frame, ignoring a certain number of steps if specified.
6066	A mini stack trace routine for threads that iterates through the frame stack, formats and displays each frame while applying filters, and returns after processing all frames.
6067	Get file information including cache status, canonical name, and optional details like size, SHA1, and breakpoint line numbers.
6068	Check whether we should break at the current frame based on the breakpoint's function name and line number constraints. Returns True if the breakpoint condition is met, False otherwise.
6069	Remove breakpoint `bp` from the breakpoint list, clean up associated data structures, and return True if successful.
6070	Delete a breakpoint by its breakpoint number. Returns a tuple of (success: bool, message: str) where message is empty on success.
6071	Enable or disable all breakpoints. Returns a message indicating which breakpoints were enabled/disabled.
6072	Enable or disable a breakpoint given its breakpoint number. Returns a tuple of (success, message) where success is a boolean indicating if the operation was successful, and message is an empty string on success or an error message on failure. If the breakpoint already has the requested enable state, returns False with a message indicating it was previously enabled/disabled.
6073	Removes all breakpoints at a given filename and line number, returning a list of the deleted breakpoint numbers.
6074	Summary: The `open` method sets the input source for reading. It accepts either a file object (io.TextIOWrapper) or a file path string. If a file object is provided, it's used directly. If a string is provided, the file is opened in read mode and stored. Raises IOError for invalid input types.
6075	Read a line of input from stdin, removing the trailing newline character. Raises EOFError if end-of-file is encountered. The prompt and use_raw parameters are ignored for compatibility with other input routines.
6076	Method `confirm(self, prompt, default)` prompts the user for confirmation before proceeding with a potentially dangerous action. It displays the given prompt and accepts user input, returning `True` for affirmative responses ('y', 'yes'), `False` for negative responses ('n', 'no'), and the specified default value if an EOFError occurs. The method continues prompting until a valid response is received.
6077	Handles whitespace characters by recognizing one or more whitespace characters, adding a 'SPACE' token to the token list, and advancing the position pointer by the length of the matched whitespace string.
6078	Method `t_number` is a token recognition function that matches one or more digits (`\d+`) from the input string `s`. It creates a token of type 'NUMBER' with the integer value of the matched digits, updates the current position in the parsing process, and advances the position by the length of the matched string. The function returns the matched string for further processing.
6079	Wrap a SQLAlchemy query object into a tornado concurrent Future so that it can be awaited/yielded. Uses a thread pool executor to run the query asynchronously and chains the old-style concurrent.futures.Future with a new tornado.concurrent.Future for compatibility. Returns the new Future object that can be awaited in tornado applications.
6080	Restore original login session by checking signed session, reverting to original user if valid, displaying info message, and cleaning up session flag.
6081	Loads a module and returns a specific attribute from it, with error handling for import and attribute errors.
6082	Generator function that yields documents from a Luminoso project, with options for expanded fields and progress tracking. Returns documents in batches with configurable field sets ('title', 'text', 'metadata' or with additional analysis fields like 'terms' and 'vector'). Includes optional progress bar visualization.
6083	Handles command-line arguments for the 'lumi-download' command, including API URL, authentication token, and project ID, then downloads document data from the Luminoso API.
6084	Reads a JSON or CSV file and converts it into a JSON stream saved in a temporary file.
6085	Function `open_json_or_csv_somehow` deduces the format of a given file (CSV, JSON, or JSON stream) based on filename extensions and content analysis, then loads and normalizes the data accordingly.
6086	Normalizes data from a stream for Luminoso Analytics upload by converting dates to a standardized format. Takes a stream of documents and an optional date format, then yields each document with its date field converted if present and the format is specified. If the date doesn't match the expected format, the original document is yielded unchanged and the error is logged.
6087	Convert a date string in specified format to epoch time, or return the float value if format is 'epoch'.
6088	Detects the encoding of a file using ftfy library by analyzing a sample from its first megabyte, returning one of the supported encodings: UTF-8, CESU-8, UTF-16, Windows-1252, or MacRoman.
6089	Load a JSON stream and return a generator, yielding one object at a time.
6090	Converts a file from a specified encoding to UTF-8 encoding and returns it as a temporary file object.
6091	Open a CSV file using Python 2's CSV module, handling UTF-16 encoding by transcoding to UTF-8, and return a reader with decoded headers and data.
6092	Reads CSV rows as dictionaries, handling encoding, empty rows, text normalization, and special field processing like title, date, and subset handling.
6093	Handle command line arguments to convert a file to a JSON stream as a script.
6094	Returns an authenticated API client object that makes requests to the Luminoso API using a specified or saved token. The method supports different authentication sources including explicit tokens, token files, and default token storage. It automatically handles URL construction and provides appropriate error handling for missing authentication credentials.
6095	Save a long-lived API token to a local file for later use, creating the file and directory structure if needed.
6096	Make a request via the `requests` module and convert HTTP error status codes to Python exceptions. Logs the request type and URL at debug level. Raises specific LuminosoError subclasses based on HTTP status codes (401/403 for auth errors, 400/404/405 for client errors, >=500 for server errors, and other status codes for general errors). Returns the successful response object.
6097	Delete an object at the specified path by making a DELETE request with optional URL parameters, returning the JSON-decoded response.
6098	Waits for a project build to complete by polling the API at specified intervals. Returns the build information if successful, or raises a LuminosoError if the build fails. Logs status updates every 120 seconds. Raises ValueError if no build is currently running.
6099	Extracts the root URL for a given URL by ensuring it's a complete URL and appending '/api/v4' to the scheme and network location, issuing a warning if the original URL's path doesn't already start with '/api/v4'.
6100	Save a user's long-lived API token to a local file, creating one if needed. Returns the saved token.
6101	Make a JSON request of the specified type and return the result, raising an error if the response contains an 'error' value.
6102	Make a POST request to the specified path with the given data and content type, converting keyword parameters to URL parameters and returning JSON-decoded response. Used for uploading documents in JSON format to the Luminoso API.
6103	Creates a new LuminosoClient instance for a subpath of the current client's URL, allowing navigation to related API endpoints while maintaining the same session and authentication.
6104	Get the ID of an account that can be used to access projects. Returns the default account ID if available, otherwise returns the first valid non-public account ID, or raises an error if no valid accounts exist.
6105	Get the documentation that the server sends for the API by creating a new client instance and making a raw GET request to the root URL.
6106	Wait for an asynchronous task to finish by polling the Luminoso API endpoint specified by job_id. Polls every 5 seconds (or specified interval) until the job completes or fails. Returns the job result upon completion or raises LuminosoError if the job fails. Logs progress every 120 seconds. The base API endpoint defaults to 'jobs/id/' under the current URL but can be customized via base_path parameter.
6107	Get the raw text response from a given URL path by making a GET request with optional parameters.
6108	Print a JSON list of JSON objects in CSV format. Raises TypeError if result is not a list. Writes CSV header from first object's keys and rows from each object.
6109	Read parameters from input file, -j, and -p arguments, in that order, and return them as a dictionary. Raises ValueError for invalid JSON or improperly formatted --param arguments.
6110	Limit a document to just the three fields we should upload (text, metadata, and title). Raises ValueError if the document has no text field. Returns a new dictionary with only these three fields, filling in default values for metadata (empty list) and title (empty string) if they're missing.
6111	Creates a Luminoso project and uploads documents to it, with optional progress tracking. Uploads documents in batches, builds the project, and returns project status upon successful completion.
6112	Uploads documents from a JSON lines file to create a project using the Luminoso API client.
6113	Handles command-line arguments for the 'lumi-upload' command, including API URL, authentication token, and input file details. Sets up a Luminoso client, prompts for a project name if not provided, uploads documents from a JSON-lines file, and prints the created project ID and document count.
6114	Uploads a JSON stream to a Luminoso project, creating a new project or appending to an existing one, and optionally calculates the documents.
6115	Uploads a file to Luminoso by converting it to JSON stream format and sending it to the specified server with given account and project details. Supports JSON, JSON stream, and CSV data formats with optional language specification, authentication, append/stage operations, and date formatting.
6116	This function handles command line arguments for uploading a file to a Luminoso project. It accepts parameters like filename, account, and project name, plus optional flags for appending to existing projects, staging without recalculation, specifying API URL, language code, username, password, and date format. The function processes human-readable date format shortcuts (like 'iso', 'epoch', 'us-standard') into standard format strings and then calls `upload_file` with all the parsed arguments.
6117	Creates an authentication object using username and password credentials by obtaining a short-lived token from the login endpoint. Raises LuminosoLoginError if authentication fails.
6118	Method `login` initializes an HTTP session if one doesn't exist, sets a random user-agent header, and returns the result of posting to the login page.
6119	Method `_post_login_page` handles the login process to enedis by submitting login credentials through a POST request. It constructs a data dictionary containing the username, password, and other required parameters, then sends the request using the session object. If the request fails due to OS errors, it raises a `PyLinkyError` with a connection error message. After the request, it checks if the login was successful by verifying the presence of the 'iPlanetDirectoryPro' cookie in the session. If the cookie is missing, it raises a `PyLinkyError` indicating incorrect login credentials. The method returns `True` upon successful login.
6120	Get data from Enedis.fr API by sending a POST request with specified parameters and date range, handling various error cases including maintenance mode, empty responses, and JSON decoding errors, then returning the graph data from the response.
6121	Fetch the latest data from Enedis for hourly, daily, monthly, and yearly periods by calling get_data_per_period for each time period.
6122	Loads and initializes a view class from a dotted view name on first call, setting up view properties with site, page, and request parameters.
6123	Initialize the view by loading it on first load, setting handler and request properties, or creating a new View instance with company, request, and handler properties.
6124	Method that handles GET requests by routing them differently based on connection type - uses parent class handling for websockets and renders a view for regular HTTP requests.
6125	Handles messages received from enaml.js by decoding JSON data, finding the corresponding view node by reference, and triggering events or updating properties based on the message type and content.
6126	When pages change, update the menus by collecting all links from pages and explicit links, organizing them into their respective menus based on link.menus attribute, and then updating the corresponding menu attributes on the object.
6127	Generate the URL handlers for the site, including static file handling and page-specific handlers.
6128	Handles JavaScript messages by looking up Enaml nodes and triggering events or updates based on the message content.
6129	When a DOM modification event occurs from enaml, this method sends the update through a websocket to the client's browser for real-time UI synchronization.
6130	Create the toolkit widget for the proxy object during top-down pass, assigning it to the 'widget' attribute by creating a SubElement of the parent widget with the declaration's tag.
6131	Initializes the toolkit widget state during top-down pass, setting various properties like text, tail, style, class, attributes, and ID from the declaration, while also handling member attributes and events.
6132	A reimplemented destructor that clears the reference to the toolkit widget, removes it from its parent container, and cleans up cached references before calling the parent destructor.
6133	Handle the child added event from the declaration by inserting the child toolkit widget in the correct position. Inserts the child widget at the appropriate index in the parent widget's children list, maintaining proper ordering.
6134	Handle the child removed event from the declaration by unparenting the child toolkit widget and removing it from the widget list.
6135	Get the child toolkit widgets for this object.

Returns
-------
result : iterable of QObject
    The child widgets defined for this object.
6136	Sets a widget attribute with appropriate value handling: True becomes a self-referential attribute, False removes the attribute, and other values are converted to strings.
6137	Updates the proxy widget when widget data changes by calling appropriate handler or setting attribute directly.
6138	Method `_notify_modified` sends websocket notifications when changes occur. It checks if the root object is an Html instance, then constructs a standardized change notification containing reference, type, name, and value, and calls the modified method on the root object to propagate the change.
6139	Find nodes matching the given xpath query and return their declarations.
6140	Method that prepares the object for rendering by setting attributes from keyword arguments, and initializing or activating proxy if needed.
6141	Initialize the widget with the source, setting it if available otherwise falling back to parent initialization.
6142	Sets the source by parsing it and inserting into the component's widget, then reinitializes the widget.
6143	When the mode changes, refresh the items by removing old children from the block and clearing the parent references, then call refresh_items to update the display. Raises NotImplementedError if the old value is 'replace'.
6144	Method `_observe_block` handles changes to the 'objects' list in an Include component. When the component is initialized and an update occurs, it removes old objects from their parent containers, clears their parent references, and refreshes the item display. The method specifically processes child objects by removing them from the old block's children list and setting their parent to None, then calls `refresh_items()` to update the display.
6145	When the children of the block change, update the referenced block by destroying removed children and inserting new children into the block or its parent, depending on whether the block exists or is a placeholder.
6146	Read the contents of a file located relative to setup.py
6147	Print error message to stderr with help text and exit with specified exit code.
6148	Prints a parsing error message to stderr and exits with status -1.
6149	Returns an Item object from the Menu by case-insensitive name match. Raises StopIteration if no matching item is found.
6150	Clears the current remote session and sets up a new one with updated headers, returning the response from the session expiration request.
6151	Clears the current store, gets a cookie, sets the cross site request forgery token for subsequent requests, and returns the response.
6152	Search for Dominos pizza stores using a search term and return a list of nearby stores matching the search term.
6153	Sets up the delivery system by initializing it with store ID, postcode, and fulfilment method, then returns the initialization response.
6154	Retrieve the menu from the selected store by making an API call with store-specific parameters and return a Menu object.
6155	Adds an item to the current basket, routing to appropriate method based on item type (Pizza or Side).
6156	Add a pizza to the current basket with specified item, variant, and quantity, then return the response from the API call.
6157	Add a side item to the current basket with specified quantity and return the response.
6158	Remove an item from the current basket.

**Parameters:**
- `idx` (int): Basket item id.

**Returns:**
- `requests.Response`: A response having removed an item from the current basket.
6159	Sets the payment method for a purchase transaction by sending a POST request to the payment options endpoint with the specified payment method ID.

**Parameters:**
- `method` (int, optional): Payment method ID. Defaults to `PAYMENT_METHOD.CASH_ON_DELIVERY`.

**Returns:**
- `requests.Response`: Response object containing the result of setting the payment method.

**Example usage:**
```python
response = obj.set_payment_method(PAYMENT_METHOD.CREDIT_CARD)
```
6160	Process payment using selected method and return the payment response.
6161	Make a HTTP GET request to the Dominos UK API with the given parameters for the current session.

Parameters:
- path (string): The API endpoint path
- kargs (list): A list of arguments

Returns:
- response.Response: A response from the Dominos UK API
6162	Make a HTTP POST request to the Dominos UK API with the given parameters for the current session.

Parameters:
- path (string): The API endpoint path.
- kargs (list): A list of arguments.

Returns:
- response.Response: A response from the Dominos UK API.
6163	Make an HTTP request to the Dominos UK API with the given parameters for the current session.

**Parameters:**
- `verb` (func): HTTP method on the session
- `path` (string): The API endpoint path  
- `kargs` (list): A list of arguments

**Returns:**
- A response from the Dominos UK API

**Raises:**
- `ApiError`: If the response status code is not 200
6164	Add an item to the end of the menu before the exit item, update the menu structure, and resize/redraw the screen if necessary.
6165	Add the exit item if necessary. Used to make sure there aren't multiple exit items

Returns True if item needed to be added, False otherwise
6166	Redraws the menu and refreshes the screen, updating the display based on current menu state including title, subtitle, items, and highlighting. Handles scrolling when menu items exceed screen height and refreshes the display with proper styling.
6167	Process user input by interpreting single character input to navigate or select items in a list. Handles numeric input (1-9) for direct item selection, arrow key navigation, and newline for selection. Returns the processed input character.
6168	Selects the current item, executes its setup, action, and cleanup methods, captures the return value, and determines whether to exit based on the item's exit flag. Redraws the interface if exit flag is false.
6169	Parses old-style menu data dictionary and returns a CursesMenu object with appropriate menu items based on the data structure provided.
6170	Return the top or flop N results based on a column value for each specified group. If no group is specified, apply the operation to the entire dataframe. The `limit` parameter determines how many results to retrieve (positive for top, negative for bottom), and the `order` parameter specifies ascending or descending order. The `group` parameter allows grouping by one or more columns before applying the operation.
6171	Returns the top or bottom N groups based on an aggregated value, preserving all original rows for those groups. The function aggregates data by specified columns, ranks the groups by a given function and value, selects the top/bottom N groups, and merges back to return all rows belonging to those selected groups. Supports ascending/descending order and various aggregation functions.
6172	Convert a string column to datetime format using pandas' to_datetime function with specified format.
6173	Convert a datetime column to string format using specified formatting rules.

**Parameters:**
- `column` (str): Name of the datetime column to convert
- `format` (str): Format string for the output (based on strftime behavior)
- `new_column` (str, optional): Name of output column. Defaults to overwriting the input column

**Returns:**
- DataFrame with datetime column converted to string format

**Example:**
```python
# Convert date column to string format
df = convert_datetime_to_str(df, column='date', format='%Y-%m-%d')
```
6174	Convert the format of a date column in a DataFrame.

This function transforms the date format of a specified column using pandas' datetime parsing and formatting capabilities. It can optionally handle time zone conversion and create a new column instead of overwriting the existing one.

Parameters:
- `df`: DataFrame containing the data
- `column` (str): Name of the column to change the format
- `output_format` (str): Format of the output values (using strftime format codes)
- `input_format` (str, optional): Format of the input values (if None, parser detects automatically)
- `new_column` (str, optional): Name of the output column (defaults to overwriting the input column)
- `new_time_zone` (str, optional): Name of new time zone for conversion (defaults to no conversion)

Returns:
- DataFrame with the date column formatted according to the specified output format

Example:
```cson
change_date_format:
  column: 'date'
  input_format: '%Y-%m-%d'
  output_format: '%Y-%m'
```

This transforms dates from '2017-03-22' to '2017-03' format.
6175	Converts a column's data type in a DataFrame.

This function takes a specified column and converts its data type to the target type (int, float, or str). The conversion can be performed in-place or create a new column with the converted values.

Parameters:
- `df`: DataFrame containing the data
- `column` (str): Name of the column to convert
- `type` (str): Target data type ('int', 'float', or 'str')
- `new_column` (str, optional): Name of the output column. If not provided, the original column is modified

Returns:
- DataFrame with the column converted to the specified type

The function handles type conversion for numeric and string data, converting strings to numeric types where possible and ensuring proper data types for further analysis.
6176	Creates rank columns based on numeric values, with optional grouping and ranking methods. Supports multiple ranking methods (min, max, average, first, dense) and ascending/descending order. Returns the dataframe with added rank columns.
6177	Creates a waterfall chart dataset by computing value variations and rates between two time periods, organized by hierarchical groups. Takes a DataFrame and parameters defining date, value, grouping structures, and optional filters to return a formatted dataframe suitable for waterfall chart visualization.
6178	Creates a new column in a DataFrame by applying a basic mathematical operation between two columns or values. Takes two columns/values, applies the specified operator, and stores the result in a new column. Validates input types and supports both column names (strings) and numeric values.
6179	Round each value of a specified column to a given number of decimal places, optionally creating a new column for the rounded values.
6180	Get the absolute numeric value of each element in a specified column. Creates a new column with the results or replaces the existing column if no new column name is provided.
6181	Pivot a DataFrame by reshaping it based on specified index, column, and value parameters. The function aggregates values using a specified aggregation function (default is 'mean') and returns a pivoted DataFrame with the specified column values as new column headers. If the value column contains object data types, it joins the values with a space separator. The resulting DataFrame is reset to have a standard integer index.
6182	Pivot a dataframe by group of variables based on specified mapping.

This function transforms a long-format dataframe into a wide-format dataframe by grouping specified variables and mapping them to new column names. It takes a dataframe and restructures it so that each group becomes a column, with values from the 'value' column filling the pivoted cells. The function supports keeping additional identifier columns and uses a mapping dictionary to define how variables should be grouped.

Parameters:
- variable (str): Column name used to create groups
- value (str): Column name containing values to fill the pivoted dataframe
- new_columns (list of str): Names of the new columns in the output
- groups (dict): Dictionary mapping group names to their corresponding variables
- id_cols (list of str, optional): Additional columns to keep in the output

Returns:
- DataFrame: Pivoted dataframe with groups as columns and specified values in the cells

The function works by creating temporary columns to track group mappings, then using pandas pivot operation to reshape the data according to the specified grouping rules.
6183	Group data by specified columns and apply aggregation functions to other columns. The function takes a DataFrame, group columns, and a dictionary of column-to-aggregation function mappings. It returns a new DataFrame with grouped data and computed aggregates. When multiple aggregations are performed on the same column, it flattens the multi-indexed columns back to single-level headers.
6184	**Summary:**

The `cumsum` function calculates cumulative sums for a specified column in a DataFrame, grouped by index columns and ordered by a date column. It's deprecated and users should use `compute_cumsum` instead. The function takes a DataFrame, creates a temporary date column, groups by index and date columns, computes the cumulative sum within each group, and returns the updated DataFrame with the new cumulative column. The temporary date column is removed from the result.

**Parameters:**
- `df`: Input DataFrame
- `new_column`: Name of the new column to store cumulative sums
- `column`: Column name to calculate cumulative sum on
- `index`: Grouping columns (string or list of strings)
- `date_column`: Column name containing dates for ordering
- `date_format`: Format string for parsing dates

**Returns:** DataFrame with cumulative sum column added
6185	Add missing rows to a DataFrame based on a reference column, with options to specify a complete index, filtering methods, and additional columns to keep. Supports methods like 'between', 'between_and_after', and 'between_and_before' for conditional row addition.
6186	A decorator factory that creates a decorator to catch exceptions in decorated functions, log them with a warning, and prevent exceptions from being raised. The decorator uses a logger to record when exceptions occur in the decorated functions, ensuring that logging failures don't themselves raise exceptions. The wrapper function executes the original function within a try-except block and logs any caught exceptions with the function name.
6187	A decorator that logs a message before executing a function, using a provided logger and optional message string.
6188	A decorator that logs the execution time of a function using a provided logger. It measures the time taken by the decorated function and logs the function name along with the execution duration.
6189	A decorator that logs the shapes of input and output dataframes for a function. It captures shapes from all dataframe arguments and return values, then logs this information using the provided logger.
6190	Function `rename` replaces data values and column names in a DataFrame according to specified locale translations. It takes optional dictionaries for value translations and column name translations, along with a locale string. The function modifies the DataFrame by replacing values based on the `values` dictionary and renaming columns based on the `columns` dictionary using the specified locale. Returns the modified DataFrame.
6191	Compute cumulative sum for specified columns within grouped data.

This function calculates the cumulative sum of specified value columns within groups defined by ID columns and reference columns. It groups the data by the specified columns, sums duplicate rows, and then computes the cumulative sum for each group. The function supports optional parameters to specify which columns to keep in the final output and which new column names to use for the cumulative sum results.

**Parameters:**
- `id_cols` (list): Columns to group by
- `reference_cols` (list): Columns to order the cumulative sum
- `value_cols` (list): Columns to calculate cumulative sum for
- `new_value_cols` (list, optional): New column names for cumulative sum results (defaults to value_cols)
- `cols_to_keep` (list, optional): Additional columns to retain in output

**Returns:**
- DataFrame with cumulative sums computed for specified columns, grouped and ordered as specified
6192	**Summary:**

The `combine_columns_aggregation` function aggregates data from a DataFrame to create an "All" category for requesters by grouping data based on specified ID columns and combinations of filter columns. It applies aggregation functions to the grouped data and returns a concatenated result containing all possible combinations of the filter columns with their default values.

**Key features:**
- Groups DataFrame by `id_cols` and combinations of `cols_for_combination` keys
- Applies aggregation functions (sum by default) to the grouped data
- Creates all possible combinations of filter columns
- Returns a combined DataFrame with all combinations and their default values

**Parameters:**
- `id_cols`: Columns to group by
- `cols_for_combination`: Dictionary mapping filter columns to their default values
- `agg_func`: Aggregation function(s) to apply (default: 'sum')

**Returns:**
- DataFrame with aggregated data including all combinations of filter columns
6193	Get the value of a function parameter by analyzing the function signature and provided arguments.

This function determines what value will be assigned to a specific parameter when calling a function with given positional and keyword arguments. It uses Python's inspect module to analyze the function signature and bind the provided arguments, then returns the resolved value for the specified parameter name.

Example:
```python
def foo(a, b, c=3, d=4):
    pass

# What would be the value of "c" when calling foo(1, b=2, c=33)?
get_param_value_from_func_call('c', foo, [1], {'b': 2, 'c': 33})  # Returns 33
```
6194	Remove old cache entries from the specified directory, keeping only the most recently accessed entries up to the given limit. Returns the number of entries removed.
6195	Creates aggregated values following a hierarchical structure by rolling up data through specified levels, allowing for custom aggregation functions and column names. It returns a DataFrame with aggregated results for each level of the hierarchy, including optional filtering of levels to exclude from the output.
6196	Keep the row corresponding to the maximal value in a specified column, optionally grouped by one or more columns. If no groups are specified, returns the row with the maximum value in the specified column. If groups are specified, returns the row with the maximum value within each group.
6197	Keep the row corresponding to the minimal value in a specified column, with optional grouping support.
6198	Fill NaN values in a specified column with either a given value or values from another column. Raises an error if both replacement parameters are set or if the referenced column doesn't exist. Returns the modified DataFrame.
6199	Add a human-readable offset to a date object, supporting standard pandas Timedelta syntax plus custom shortcuts for weeks, months, and years. The function handles positive/negative offsets and falls back to custom parsing for unsupported formats.
6200	Function that adds a specified number of months to a date object, handling cases where the target month doesn't have the same day number (e.g., Jan 31 -> Feb 28) by returning the last day of the target month.
6201	Function that adds a specified number of years to a date object, handling edge cases like leap year February 29th by returning the last day of the target month when the resulting date doesn't exist.
6202	Parses a date string according to a specified format, supporting additional offset operations. The function handles standard date strings matching the format, as well as date strings with offsets using syntax like "(date) + offset" or "(date) - offset". Supported offset formats include pandas.Timedelta-compatible strings and custom keywords like 'w', 'week', 'month', 'year'. Symbolic names 'TODAY', 'YESTERDAY', and 'TOMORROW' are also supported. Returns a datetime.date object, raising ValueError if parsing fails.
6203	Filter a dataframe by date using specified date column and range parameters. Supports filtering by exact date (`atdate`), start date (`start`), stop date (`stop`), or date range (`start` and `stop`). Accepts date formats and symbolic values like 'TODAY', 'YESTERDAY', 'TOMORROW'. Also supports offset syntax like "(date) + offset" using pandas.Timedelta. Returns filtered dataframe with temporary date column removed. Raises TypeError for invalid parameter combinations.
6204	Add a column to the dataframe with percentages calculated either across the entire dataframe or within groups defined by `group_cols`.

**Parameters:**
- `column` (*str*): Name of the column to calculate percentages for.
- `group_cols` (*str* or *list*, optional): Column(s) to group by. If None, calculates percentages across the entire dataframe.
- `new_column` (*str*, optional): Name of the output column. If None, the original column is overwritten.

**Example:**
```python
percentage(df, column='number', group_cols=['sport'], new_column='number_percentage')
```
This computes the percentage of each value in the 'number' column relative to the sum of values within each 'sport' group.
6205	Optimizes parameters using SGD, AdaGrad, or AdaDelta methods with optional regularization and momentum. Supports different update rules based on the specified method, maintains running sums for adaptive learning rates, and returns parameter updates along with free parameters for AdaDelta and AdaGrad. Includes special handling for fine-tuning with AdaGrad and supports momentum through beta parameter.
6206	Return updates in the training by computing gradients and applying optimization updates.
6207	Get parameters to be optimized, with optional parameter freezing based on configuration.
6208	Returns optimization updates and manages free parameters for the network.
6209	Compute first glimpse position using down-sampled image by taking max pooling, flattening the result, and applying a dot product with weights W_f. Optionally sample from a Gaussian distribution or use random glimpse based on configuration flags.
6210	This method prepares the model architecture by:
1. Setting output dimension to 10
2. Creating an encoder network with one dense layer using tanh activation
3. Creating a decoder network with one dense layer
4. Creating a classifier network with two dense layers and softmax activation
5. Registering all inner layers with the model
6. Creating a target input tensor for classification
7. Registering the external inputs with the model

The method follows the pattern where parameter creation happens in setup functions, though the actual setup is performed in this prepare method.
6211	This method builds a computation graph that processes input data through an encoder, decoder, and classifier. It computes reconstruction and classification costs, combines them into a final cost with a weighting factor, calculates error rate, registers monitoring metrics, and returns the final cost. The method implements a multi-task learning approach combining autoencoding and classification objectives.
6212	Process all data in train, validation, and test sets with the given function, where the function schema is x,y -> x,y.
6213	Converts target labels into one-hot vector representation for training, validation, and test datasets.
6214	Print dataset statistics showing the count of train, validation, and test sets.
6215	Trains the model over mini-batches with periodic evaluation and testing. Returns training messages yield by `train_func`. Handles keyboard interrupts gracefully and implements early stopping based on validation performance. Restores best parameters if validation is used, and performs final test evaluation.
6216	Sample outputs from LM by generating sequences step-by-step, where each new token is sampled based on the model's current predictions and appended to the input sequence.
6217	Compute alignment weights from previous state and precomputed values using attention mechanism with optional masking.
6218	Compute the context vector with soft attention by calculating alignment weights and applying them to the inputs.
6219	A utility function that concatenates variables along a specified axis, handling both NeuralVariable objects and raw tensors with appropriate dimension management for the last axis.
6220	Pad sequences to given length in the left or right side for train, validation, and test datasets.
6221	RMSPROP optimization core that updates parameters using adaptive learning rates based on centered RMS of gradients. For each parameter and gradient pair, it maintains a moving average of squared gradients (RMS) and updates parameters using the formula: `param - learning_rate * grad / sqrt(rms + 1e-8)`, where RMS is computed as `momentum * rms_ + (1 - momentum) * grad * grad`.
6222	Method: report
Summary: Reports the elapsed time in minutes since the timer was started. If the timer hasn't been ended yet, it ends the timer first, then calculates and prints the duration in minutes.
6223	Runs the model with validation data and returns the computed costs by first computing the output variables and then extracting costs from those variables.
6224	This method is called after each training iteration to monitor and evaluate performance. It increments an internal counter and triggers monitoring every specified frequency. When triggered, it processes data from the trainer, runs evaluation on each data point, accumulates results, calculates averages, compares against current best, reports results, and saves checkpoints when better performance is achieved.
6225	Build inner loop variables for scan operation by creating dummy tensors and mapping them to NeuralVariables.
6226	Internal scan method that processes loop variables with dummy input tensors. Takes a dictionary of variables, validates loop initialization, creates tensor replacements for dummy nodes, clones loop variable tensors with replacements, and returns cloned NeuralVariables. Raises exception if loop is uninitialized or variable not found in loop vars.
6227	Momentum SGD optimization core that implements momentum-based gradient descent. Takes parameters and gradients as input, computes velocity updates using momentum factor (default 0.9) and learning rate (default 0.01), and returns parameter updates along with velocity tensors for free parameters. The function uses Theano shared variables to maintain velocity states between optimization steps.
6228	Execute `then_branch` when training, otherwise execute `else_branch`.
6229	Skip N batches in the training by setting the number of epochs and batches to skip.
6230	Load training parameters from a file, optionally excluding free parameters, and resume training progress if available.
6231	Trains the model for multiple epochs, performing validation and testing at specified frequencies. During training, it handles keyboard interrupts, checks for NaN in costs, and rolls back to checkpoint parameters if needed. The method yields training costs at each step and saves the best parameters if validation is performed. Returns the trained model with final parameters.
6232	Run one training iteration, record training costs, and report results periodically based on monitor frequency.
6233	Run validation iteration, track best cost and parameters, save checkpoints, report results, and determine if training should continue based on patience criterion.
6234	Report scores and record them in the log, including type, epoch, and performance metrics with optional new best indicator.
6235	Get specified split of data. Returns training, validation, or test data based on the data_split parameter, or None if invalid split specified.
6236	Apply a function to tensors and return a new NeuralVariable with the transformed tensor and specified output dimension.
6237	Report usage of training parameters by logging accessed parameters and their undefined status.
6238	Returns the variance of a tensor along the last dimension, with optional test shape parameter. This is an alias for deepy.tensor.var.
6239	Create neural variables from dataset data with specified split, setting test values and appropriate tensor types based on numpy array properties.
6240	Create a shared theano scalar value with automatic dtype conversion based on the input type (int/float) or use provided value directly.
6241	Stack encoding layers and extend the encoding_layers list with the provided layers.
6242	Stack decoding layers by extending the decoding_layers list with the provided layers.
6243	Encode given input using the encoding network, constructing it if it doesn't exist yet.
6244	Decode given representation using the decoding network.

This method takes a representation tensor 'x' and decodes it using a neural network. It first checks if the representation dimension ('rep_dim') is set, raising an exception if not. Then it initializes the decoding network if it doesn't exist yet, setting up the decoding layers. Finally, it computes and returns the decoded output using the decoding network.

Args:
    x: The input representation tensor to decode

Returns:
    The decoded representation tensor

Raises:
    Exception: If rep_dim is not set before calling this method
6245	Creates a 2D Gaussian kernel with specified dimension and standard deviation. The kernel is normalized so that all elements sum to 1. Raises ValueError if dimension is even. Returns a numpy 2D array representing the Gaussian kernel.
6246	Register a layer by incorporating its parameters and monitoring/callbacks into the training process while fixing Block layers and preventing their outputs from being stacked.
6247	Monitor layer outputs by calculating and storing the mean absolute value of hidden outputs for each layer, useful for troubleshooting convergence issues.
6248	Return all parameters by combining both regular parameters and free parameters into a single list.
6249	Set up input variables for the model, creating a symbolic variable x from input_tensor or default matrix, and store it in input_variables along with output references.
6250	Return network output by compiling and computing the input, then formatting the output as a MapDict if output keys are defined, otherwise returning the raw output.
6251	Save model parameters to file either in current thread or new thread.
6252	Load model parameters from a file, supporting .gz, .npz, and .uncompressed.gz formats. Optionally exclude free parameters during loading. Parameters are loaded into model tensors and training logger is updated.
6253	Print network statistics including inputs, targets, parameters, and parameter count.
6254	Register parameters by updating the parameter count with the product of each parameter's shape dimensions and adding the parameters to the parameters list.
6255	Register updates that will be executed in each iteration by adding them to the updates list if they haven't been registered yet.
6256	Register training updates that will only be executed during training phase by adding them to training_updates list if they haven't been registered yet.
6257	Register monitors by adding them to training and testing monitor lists, ensuring each monitor key is unique.
6258	Get the L2 norm of multiple tensors by flattening all tensors, joining them, and computing the square root of the sum of squares.
6259	Dumps a single picklable element to a file object, followed by a blank line separator.
6260	Loads contents from file_obj and yields one unpickled element at a time, where elements are separated by blank lines.
6261	Load parameters from a file path into the block, with optional exclusion of free parameters.
6262	Creates OAuth 2.0 request elements based on the specified request type, including user authorization, access token, refresh token, and protected resource requests, with proper parameter and header handling.
6263	Decode a state parameter from a provider and return the specified parameter value (either 'csrf' or 'user_state'). If the state is present and user state is supported, it decodes the base64-encoded state, parses it as JSON, and returns the requested parameter. Otherwise, it returns the original state if requesting 'csrf', or an empty string if requesting 'user_state'.
6264	Method `_x_credentials_parser` overrides the default credentials parsing to handle Facebook's naming deviation where "expires" is returned instead of "expires_in". It also hardcodes the token type to 'Bearer' for bearer tokens. Returns the modified credentials object.
6265	Method `_x_request_elements_filter` filters out client ID and secret from request parameters for access token requests to comply with Google's authorization requirements, removing these credentials from the parameters when they are already present in the basic authorization header.
6266	Login handler that accepts both GET and POST requests for OpenID authentication, using WerkzeugAdapter to handle the login process with the specified provider, updates user information if login is successful, and renders a login template with the result, while returning the appropriate response object.
6267	Normalizes a dictionary by replacing single-item iterables (except strings) with their first element. Returns a new dictionary with these replacements made.
6268	Converts a list of tuples into a dictionary, where duplicate keys are grouped into lists, and returns a normalized dictionary.
6269	Parses response body from JSON, XML or query string formats and returns appropriate Python data structures. First attempts to parse as JSON, then XML, and finally as query string if the previous attempts fail. Returns dict or list for JSON/query string, or xml.etree.ElementTree.Element for XML.
6270	Returns a provider class either by importing it from the authomatic.providers module using a string name, or by returning the class directly if it's already a class object.
6271	Creates the value for ``Set-Cookie`` HTTP header, handling both regular cookie values and deletion cases with appropriate formatting including domain, path, security flags, and expiration dates.
6272	Save method that adds session cookie to headers, checks cookie size limit, sets the cookie header, and resets session data.
6273	Extracts session data from cookie by getting the cookie value using the session name and deserializing it, returning an empty dict if no cookie exists.
6274	Gets session data lazily, initializing it if necessary and ensuring a dictionary is always returned.
6275	Creates an HMAC-SHA1 signature for a session by hashing the joined parts with the session secret.
6276	Serializes a value by pickling it, percent-encoding the result, and concatenating it with a timestamp and signature separated by '|'. The serialized output includes the pickled data, current timestamp, and a signature for verification.
6277	Returns ``True`` if credentials are valid (not expired), ``False`` if expired. Checks expiration_time against current time.
6278	Returns ``True`` if credentials expire sooner than specified number of seconds, else ``False``. Checks if expiration_time is set and if the credentials will expire before the given time threshold.
6279	Serializes credentials to a percent-encoded string for storage, including provider ID and type ID as the first two items followed by provider-type-specific data. Raises ConfigError if provider_id is None. All items are converted to strings, joined with newlines, and then percent-encoded.
6280	Return true if string is binary data.
6281	Returns the complete response content, decoding binary content from UTF-8 if necessary. Reads content from httplib_response if not already cached in _content.
6282	Creates OAuth1 request elements including signature for different request types (user authorization, request token, access token, protected resource) by assembling parameters, headers, and body based on provided credentials and request type, then returns filtered request elements.
6283	Method `_access_user_info` extends the parent class implementation to additionally fetch and set the user's email address. It first calls the parent's method to get basic user info, then makes a separate request to access the user's email URL. If email data is returned, it searches for the primary email address and updates the response data with it. The method ensures email is always set in the response data, defaulting to None if not found.
6284	A Flask view function decorator that handles authentication by creating a response adapter, setting default session parameters, and calling the parent class's login method with the provided arguments.
6285	Method: login

Summary: Launches the OpenID authentication procedure. In Phase 1, if an identifier parameter is present, redirects the user to the OpenID login URL. In Phase 2, after redirection, verifies the authentication result and creates a user object if successful, otherwise raises a FailureError.
6286	Generates a session key string by combining the settings prefix, session name, and provided key using colon separation.
6287	Saves a value to the session with the specified key.
6288	Generates a CSRF token by creating a hash from a random string plus salt, then returns a random portion of the hash as a random unguessable string.
6289	Logs a message with a pre-formatted prefix using the class's logger or a default logger, with the message formatted as 'authomatic:ClassName:msg'.
6290	Checks whether a HTTP status code belongs to a specific category based on its hundreds digit. Returns True if the status code falls within the range of the specified category (0-9), False otherwise. Validates that the category is a single digit between 0 and 9.
6291	Splits a URL into its base components and query parameters. Returns a tuple containing the base URL (without query string) and a list of parameter tuples derived from the query string.
6292	A decorator function that adds CORS (Cross-Origin Resource Sharing) support to Sanic routes, allowing configuration of allowed origins, methods, headers, and other CORS-related settings with extensive customization options including credentials support, caching, and security considerations.
6293	Sets CORS headers on a response based on Sanic-CORS options, handling request context evaluation and response modifications while providing fallback error handling for header operations.
6294	Returns a dictionary of CORS-specific application configurations by filtering and transforming configuration options from the app instance's config attribute.
6295	A more flexible string conversion function that handles None, iterables (sorting them lexographically for consistency), and other objects uniformly.
6296	Wraps scalars or string types as a list, or returns the iterable instance as-is.
6297	This function implements a close comparison between two numbers, similar to Python 3.4's `math.isclose()`. It handles both relative and absolute tolerance comparisons, with error checking for negative tolerances and special cases like NaN and infinity values. The function falls back to a custom implementation for older Python versions that don't have `math.isclose()`.
6298	A decorator that marks functions as deprecated by issuing a DeprecationWarning when the function is called, while preserving the original function's behavior and metadata through functools.wraps.
6299	Deserializes a bytestring into an AudioSegment object by unpickling the serialized data and reconstructing the audio segment with its name metadata.
6300	Returns an AudioSegment object from a file based on its extension, throwing an error if the extension is invalid. Takes a file path as input and returns an AudioSegment instance.
6301	Creates an AudioSegment from a numpy array by interleaving channels and converting to audio bytes. Raises ValueError for invalid array dimensions or unsupported bit depths (8, 16, or 32 bits). Handles both 1D arrays (single channel) and 2D arrays (multiple channels) by reshaping and interleaving the audio data before constructing the AudioSegment.
6302	Executes a Sox command in a platform-independent manner by creating temporary files for input/output, running the command via subprocess, and returning a new AudioSegment with the processed audio data.
6303	Removes silence from an AudioSegment using the sox command-line tool. Returns a copy of the audio segment with silence intervals shorter than the specified duration removed. Sileness is determined by a threshold percentage relative to the maximum sample value. Handles decoding errors by issuing a warning and returning a copy of the original segment. Requires the sox program to be installed.
6304	Transforms a slice of the AudioSegment into the frequency domain using FFT and returns frequency bins and their corresponding values. Supports slicing by time or sample indices with optional zero-padding. Raises ValueError for invalid parameter combinations or out-of-bounds slices. Returns numpy arrays of frequencies (in Hz) and FFT magnitude values.
6305	Generates audio frames of specified duration from an AudioSegment object. Yields Frame namedtuples containing audio bytes, timestamp, and duration. If zero_pad=True, pads the final frame with zeros to ensure complete frame duration. Uses the frame rate and sample width to calculate appropriate byte offsets for frame boundaries.
6306	Normalizes the AudioSegment's SPL (Sound Pressure Level) to a specified decibel value by adjusting the audio data using successive approximation to match the desired RMS (Root Mean Square) level. Returns a new AudioSegment with normalized values. Raises ValueError if the AudioSegment is empty. Note: This method is currently broken and may be removed in the future.
6307	Reduces other AudioSegment objects into this one by concatenating all segments and returning the result without modifying the original.
6308	Returns a new AudioSegment with resampled audio data based on specified characteristics. Parameters left as None will remain unchanged. Requires 'sox' program installation. Uses sox command-line tool for resampling operations.
6309	Serializes the object into a bytestring containing the name and serialized segment data using pickle protocol -1 for both the outer dictionary and the segment data.
6310	Creates a spectrogram by computing FFTs on a slice of the audio segment. Takes optional start time/duration or sample indices, window length (in seconds or samples), overlap ratio, and window type. Returns frequency values, time values, and amplitude spectrogram as 2D array in dB. Raises ValueError for invalid parameter combinations or out-of-bounds segments.
6311	Returns the offset front ID that has the maximum overlap with the given onset front's corresponding offsets.
6312	Returns the offset_front_id corresponding to the offset front that occurs first entirely after the given onset sample index. For each offset front, it checks if all its sample indices are greater than the onset index, and keeps track of the offset front with the minimum such sample index. The function assumes offset_front_id values are greater than 1, or -1 if no valid offset front is found.
6313	Get the ID of the offset front that occurs first after the given onset front, where "first" means the offset front contains the closest offset to the latest point in the onset front, and "after" means all offsets in the offset front occur after the latest onset in the onset front. Returns -1 if no appropriate offset front exists.
6314	Find the best matching offset front ID for a given onset front ID by:
1. Getting the onsets that make up the onset front
2. Finding corresponding offsets for those onsets
3. Identifying candidate offset fronts that contain at least one matching offset
4. Selecting the offset front that contains the most matching offsets, or returning the next offset front if none match
5. Returns -1 if no matching offset fronts are found
6315	Returns overlapping portions of an onset front and offset front that share frequency channels. Iterates through consecutive portions of the onset front to find the first overlap with the offset front, then returns the overlapping segments from both fronts. If no overlap is found, returns two empty lists.
6316	Updates a segmentation mask by segmenting between specified onset and offset fronts, and removes processed fronts from the front matrices. Returns a boolean indicating if the entire onset front was processed.
6317	Returns the front ID from the given front array at the specified index position, or -1 if no valid ID is found.
6318	Yields onset front IDs one at a time in order, processing all fronts from each frequency channel before moving to the next channel, skipping zero IDs and avoiding duplicates.
6319	Gets the offsets that occur as close as possible to the onsets in the given onset-front by mapping each onset index to its corresponding offset indices.
6320	Removes overlapping points between segmentation mask and fronts by setting overlapping front points to zero.
6321	Removes fronts from the `fronts` array that are smaller than the specified `size` in length, setting their values to 0. Skips fronts with id 0 or -1. Uses `_get_front_idxs_from_id` to identify front indices and filters based on length comparison.
6322	Breaks poorly matched onset fronts between frequency channels based on signal similarity, and removes fronts that are too small.
6323	Merges adjacent segments in a mask by iterating through unique segment IDs and checking if segments are adjacent using a brute force O(N^2) approach. When adjacent segments are found, the overlapping segments are merged by updating their mask values to match the primary segment ID.
6324	Separates a segmentation mask into individual segment masks using multiprocessing. Returns a list of masks where each contains exactly one segment with all other pixels set to zero. Only includes segments larger than the specified threshold relative to the total mask size. Uses all available CPU cores for parallel processing.
6325	Takes a mask and STFT matrix (both with shape frequencies x times) and downsamples one of them to match the time dimension of the other, while preserving the frequency dimension. Returns the adjusted mask, mask_indexes, stft, and stft_indexes.
6326	Summary: Worker function for ASA algorithm multiprocessing that converts masks to binary, multiplies them with STFT data, performs inverse STFT reconstruction, and puts results in a queue.
6327	Function `bandpass_filter` applies a bandpass filter to input data using a Butterworth filter design. It takes input data, low and high frequency cutoffs, sampling frequency, and filter order parameters. The function normalizes the cutoff frequencies relative to the Nyquist frequency, designs a Butterworth bandpass filter of the specified order, and applies it to the data using linear filtering. The result is the filtered data array.
6328	Creates a lowpass filter for the given data using a Butterworth filter design. Takes raw data, cutoff frequency, sample rate, and filter order as inputs, and returns the filtered data with frequencies above the cutoff removed. The filter uses the scipy.signal.butter and scipy.signal.lfilter functions to design and apply the filter.
6329	Separates outcome feature from input data and creates one-hot encoded vectors for each row. Takes input data, response index, and number of outcomes, returns matrix with outcome feature removed and one-hot encoded outcomes.
6330	Expands categorical features into binary columns and standardizes continuous features using provided standardizers, while ignoring specified features and mapping outcome values according to a transformation dictionary. Returns the modified dataset and updated headers.
6331	Function to check if two lists contain the same elements regardless of order by comparing their counts. Returns True if lists are equal ignoring order, False otherwise.
6332	Groups audit files by feature similarity across repair levels using a provided measurer. Features are clustered into groups where intra-group similarity (measured by the difference in scores) stays within a specified bound. The function returns a list of feature groups, where each group contains features that show similar performance across repair levels.
6333	Loads confusion matrices from an audit file, parses them into nested dictionaries, and returns them sorted by repair level. Skips the first line of the file, extracts repair levels and confusion matrix data from each subsequent line, converts JSON strings to dictionaries (handling boolean values as strings), and sorts the resulting list of (repair_level, confusion_matrix) tuples by repair level.
6334	Separates outcome feature from input data by creating a feature matrix excluding the outcome column and an outcomes array containing only the outcome values.
6335	Updates the index URL by checking for alternative index-url settings in pip configuration files, including virtual environment configs, site config files, and environment variables, with priority given to environment variables and then configuration files in order of precedence.
6336	Method `autodetect_files` attempts to detect requirements files in the current working directory by:

1. Checking for 'requirements.txt' file and adding it to filenames if valid
2. Checking for 'requirements.pip' file and adding it to filenames if valid (covered by pragma: nocover)
3. Searching recursively in 'requirements' directory for valid requirements files and adding them to filenames
4. Calling `_check_inclusions_recursively()` to handle any additional inclusion checks

The method populates the `self.filenames` list with detected valid requirements files found in the current directory or requirements subdirectory.
6337	Resolve all streams on the network by searching for available outlets within a specified time limit, returning a list of StreamInfo objects that can be used to open inlets.
6338	Resolves streams by filtering them based on a specific property-value pair. Returns a list of matching StreamInfo objects that can be used to open inlets. The method allows specifying a minimum number of streams to return and an optional timeout for the operation. This is more efficient than resolving all streams and then filtering them manually.
6339	Resolve streams matching a given XPath 1.0 predicate with optional minimum count and timeout constraints, returning a list of matching StreamInfo objects.
6340	Error handler function that converts error codes into appropriate exceptions, raising specific exception types based on the error code value, with special handling for timeout, lost stream, invalid arguments, and internal errors, and a generic runtime error for unknown negative error codes.
6341	Push a sample into the outlet with optional timestamp and pushthrough behavior. Validates that the sample length matches the channel count, encodes strings to UTF-8 if needed, and calls the underlying C function to push the sample. Raises ValueError if sample length doesn't match channel count.
6342	Push a list of samples into the outlet with optional timestamp and pushthrough behavior. Handles both list of lists and multiplexed value formats, with proper error handling for channel count mismatches.
6343	Retrieve complete information about a stream including extended description. Can be called at any time during the stream's lifetime. Uses the underlying C library's lsl_get_fullinfo function with specified timeout. Throws TimeoutError if timeout expires or LostError if stream source is lost. Returns a StreamInfo object containing all stream information.
6344	Opens a connection to the data stream with an optional timeout, allowing samples to be queued for subsequent retrieval via pull_sample() or pull_chunk() calls. Returns immediately if called multiple times. Throws TimeoutError if timeout expires or LostError if stream source is lost.
6345	Retrieve an estimated time correction offset for the stream. The first call takes several milliseconds to obtain a reliable estimate, while subsequent calls are instantaneous. Returns the time correction value that needs to be added to remotely generated timestamps to map them to the local clock domain. Throws TimeoutError if timeout expires, or LostError if the stream source is lost.
6346	Get a child element with the specified name from the current XML element.
6347	Get the next sibling element in the parent's children list. If a name is provided, returns the next sibling with that specific name. Returns an XMLElement object.
6348	Get the previous sibling element in the parent's children list. If a name is provided, returns the previous sibling with that specific name. Returns an XMLElement object.
6349	Set the element's name. Returns False if the node is empty.
6350	Sets the element's value and returns True if successful, False if the node is empty.
6351	Append a child element with the specified name to the current element.
6352	Prepend a child element with the specified name to the current element.
6353	Appends a copy of the specified element as a child and returns a new XMLElement object.
6354	Prepend a copy of the specified element as a child and return it as an XMLElement.
6355	Removes a child element from the current element, either by passing the child element directly or by passing the child's name as a string.
6356	Returns a list of StreamInfo objects representing currently present streams on the network. Each StreamInfo object can be used to open an inlet. The method queries the network resolver and returns up to 1024 matching streams as StreamInfo objects with empty description fields.
6357	The `pair` function displays all tokens associated with a given token by retrieving them from a Redis set. It preprocesses the input word, generates a key using `pair_key`, fetches the associated tokens from the database, sorts them, and prints them in white color along with the total count in magenta.
6358	Shows autocomplete results for a given token by retrieving matching keys from the database and displaying them in white color along with the total count in magenta.
6359	Compute edge ngrams of a token from a minimum length, excluding the token itself. If no minimum is specified, uses a default configuration value. The resulting ngrams are truncated to a maximum length defined in configuration.
6360	A generator function that processes an input pipe through a sequence of processors, yielding items one by one. If the input is a string, it's converted to a list containing that string. Each processor in the processors list is applied to the pipe sequentially, and the final result is yielded item by item. This allows for flexible processing of both single items and iterators of items.
6361	Customized version of imap_unordered that sends chunks directly to func instead of iterating in each process. Uses Pool._get_tasks to create task batches and IMapUnorderedIterator to handle results. Avoids loading all data into RAM like map_async and doesn't require manual chunking like apply_async.
6362	The `make_fuzzy` function generates a list of "fuzzy" or similar words to the input word by creating various types of neighbor words within a specified maximum edit distance (default 1). It produces neighbors through four operations: swapping adjacent characters (inversions), replacing each character with every letter of the alphabet (substitutions), inserting every letter of the alphabet at every position (insertions), and removing each character (removals), but only for words longer than 3 characters. The function returns all these generated neighbor words as a list.
6363	Compute fuzzy extensions of a word using fuzzy matching algorithm.
FUZZY lilas
Processes the input word through preprocessing and applies fuzzy matching to generate potential variations.
6364	Computes fuzzy extensions of a given word that exist in the index, showing matches sorted by frequency in descending order.
6365	Try to extract larger groups of interlinked tokens by finding many-to-many relations between meaningful and common tokens, adding them to the bucket if they exist, and only proceeding if the bucket is dry (empty).
6366	Display help information for commands. If a specific command is provided, shows its detailed documentation. If no command is specified, lists all available commands with their brief descriptions.
6367	Print useful information from Redis database including keyspace statistics, memory usage, command processing counts, connection information, and key counts for each database.
6368	Prints the raw content of a DB key by determining its type and retrieving the appropriate data. Supports 'set' and 'string' types, with unsupported types showing an error message.
6369	Compute a geohash from latitude and longitude coordinates using the geohash library with specified precision. Takes a string input containing space-separated latitude and longitude values, converts them to floats, and outputs the geohash encoding. Handles invalid input values by printing an error message.
6370	Get document from index by ID and print its fields, skipping housenumbers field. If housenumbers exist, sort and print them. Return error if ID not found.
6371	Get index details for a document by its id. Returns error if document not found, otherwise prints field index details for each field in config.FIELDS.
6372	Return document linked to word with higher score by querying the database for the top 20 scored entries associated with the word's token key, then prints the result details including the document, score, and ID.
6373	Method: do_STRDISTANCE
Parameters: self, s
Description: Calculates and prints the distance score between two strings using '|' as a separator. The method splits the input string on '|' into two parts, validates that exactly two strings were provided, and then computes and displays the similarity score between them. If the input format is incorrect, it prints an error message.
Input format: String with two parts separated by '|'
Output: Prints the distance score between the two strings or an error message for malformed input
6374	Sends a request using its send method and returns the response.
6375	Concurrently converts a list of Requests to Responses using parallel processing with a specified number of workers. Returns a list of Response objects or results from exception handler for requests that encountered errors.
6376	Extracts a range of bits from an array of words and returns them as a BitsVal instance.
6377	Reinterprets an HArray signal or value as a Bits signal or value by concatenating its elements and casting to the target type, with size validation.
6378	Converts a Python slice object to an SLICE HDL type value, handling start and stop indices with proper value conversion and update time management. Raises NotImplementedError for slices with steps.
6379	Find files by pattern in directory, optionally recursively. Raises IOError if directory doesn't exist or is not a directory. Uses fnmatch for pattern matching and yields full file paths.
6380	Hdl convertible in operator that checks if any item in an iterable equals a given value, returning a bitwise OR of equality comparisons.
6381	Generate a for loop for static items with counter logic, handling zero, one, or multiple items cases by either returning empty list, executing single iteration, or creating indexed loop with acknowledgment signaling.
6382	Logical left shift operation that shifts a signal left by 'howMany' bits, filling the vacated rightmost bits with zeros.
6383	Returns the number of bits required to store x-1, where x=8 returns 3. For x=0 or x=1, returns 1; otherwise returns the ceiling of log2(x). The result is converted to an integer type using hInt().
6384	Check if a number is a power of two using bitwise operation. Returns True if the number is a power of two, False otherwise. The function first converts the input to an integer if it isn't already, then uses the bit manipulation trick where a power of two minus one flips all bits after the single set bit, making the AND operation equal to zero.
6385	Creates a case statement for a switch operation, validating the case value and registering it with the switch statement.
6386	Method: Default
Description: Implements the default case for a switch statement with C-like syntax
Parameters: *statements - variable number of statements to include in the default case
Returns: self - allows for method chaining
Side effects: Asserts that parentStm is None, increments rank by 1, initializes default list, registers statements to the default list
Validation: Raises AssertionError if self.parentStm is not None
6387	Registers signals from interfaces for Interface or Unit instances by creating VCD variable scopes and adding variables to the VCD writer, handling both interface hierarchies and unit sub-units recursively.
6388	This method is called before the simulation starts and performs the following operations:
1. Sets VCD date and timescale
2. Registers interfaces and remaining signals for VCD writing
3. Ends VCD definitions

The method prepares the VCD (Value Change Dump) file for simulation output by initializing the header information and registering all necessary signals and interfaces before the simulation begins.
6389	Logs a value change for a signal at a given time, ignoring signals that are not registered.
6390	Serializes a HWProcess instance by processing its statements and rendering them with proper indentation and naming scope to prevent collisions.
6391	Walk all interfaces on unit and instantiate agent for every interface.

:return: all monitor/driver functions which should be added to simulation as processes
6392	Returns the associated clock signal for this interface by checking its own clock reference, then recursively searching parent units if needed.
6393	Returns unique elements from an iterable based on a key function, yielding only the first occurrence of each unique key value.
6394	Groups items from a collection by a key function, returning key-value pairs where values are lists of items with the same key. Unlike itertools.groupby, it doesn't require pre-sorting and yields items in non-deterministic order.
6395	Flatten nested lists, tuples, generators and maps up to a specified depth level. If the input is an iterable (list, tuple, GeneratorType, map, zip) and the current depth level is greater than or equal to 0, recursively flattens the elements. Otherwise, yields the input as-is. The recursion stops when the maximum depth (level) is reached or when the input is not an iterable.
6396	Merge nested IfContainer from else branch into this IfContainer as elif and else branches by appending the nested if condition and body to elif list, extending additional elif branches, and copying the else branch.
6397	Removes unconnected signals from a netlist by identifying signals that have no endpoints and are not interfaces, then cleans up their drivers and associated operations. Returns the modified netlist with orphaned signals removed.
6398	Checks if a process consists only of unconditional assignments and is therefore too simple to be merged. Returns True if the process has exactly one assignment statement, False otherwise.
6399	Try to merge procB into procA. Raise IncompatibleStructure if merge is not possible. If merge succeeds, procA is modified to contain the merged result and is returned. The merge combines statements, outputs, inputs, and sensitivity lists from both processes.
6400	Summary: The `reduceProcesses` function merges similar processes to minimize the total number of processes. It first sorts processes deterministically by name and maximum statement ID, then groups them by rank. For each rank group, it attempts to merge processes with similar structures using `tryToMerge`, skipping incompatible structures. Merged processes are marked as None and the remaining non-None processes are yielded as the final result.
6401	Method: onWriteReq
Description: Handles write request received in monitor mode
Parameters: sim (simulation), addr (address), data (write data)
Behavior: Appends a write request tuple (WRITE, addr, data) to the requests list
6402	Converts a unit or unit class to RTL (Register Transfer Level) hardware description code using a specified serializer. Supports optional name overriding, target platform metadata, and file output. If saveTo is provided, writes generated code to files in the specified directory; otherwise, returns the generated RTL as a string. Handles entity and architecture serialization, and can copy HDL source files. Returns either a list of generated file paths or the RTL string depending on the saveTo parameter.
6403	Function `name_for_process_and_mark_outputs` takes a list of HdlStatement objects, extracts output signal names from each statement, and returns the lexicographically smallest name among them. If no output names are found, it returns an empty string.
6404	Summary: The `cut_off_drivers_of` function removes drivers from a list of statements that are connected to a specified destination signal. It processes each statement by cleaning its signal metadata and cutting off drivers of the specified signal. The function returns a filtered list of statements (excluding those that were modified) and a list of the cut-off driver statements.
6405	Creates a new signal in the current context with optional clock and reset functionality. Returns either a synchronous signal (RtlSyncSignal) if clk is provided, or a regular signal (RtlSignal) otherwise. Handles default values, type casting, and proper signal initialization with error checking for synchronous signals.
6406	Synthesize netlist representation into Entity and Architecture instances for hardware description generation, including generics, ports, signals, processes, and sub-units while applying platform-specific preprocessing hooks.
6407	Get maximum _instId from all assignments in statement. For Assignment nodes, returns the node's _instId. For WaitStm nodes, returns 0. For other nodes, recursively checks all sub-statements and returns the maximum _instId found.
6408	Returns the maximum statement ID from all statements in a process, used for sorting processes in architecture.
6409	Writes data to the interface using the simulation object's write method.
6410	Sets the interface direction to the opposite of the master direction and returns self. Raises an assertion error if interfaces have already been set up.
6411	Load declarations from _declr method, collect interfaces and parameters, set read-only on parameters, and handle external interface directions.
6412	Generate signals for each interface that has no subinterface, returning existing signals if they already exist. Creates new signals using the provided context, prefix, and optional type transformation, and handles connection to bounded entity ports.
6413	Get the physical name in HDL by returning the bounded entity port name if available, otherwise return the full name with dots replaced by the name separator.
6414	Returns the total bit length by summing up the bit lengths of all interfaces in this interface. If interfaces are not loaded, it loads them first before calculating the total bit length. If no interfaces exist, it returns the bit length of the interface's data type.
6415	Returns the sensitivity type for a given operator, where RISING_EDGE maps to RISING sensitivity, FALLING_EDGE maps to FALLING sensitivity, and any other operator raises a TypeError.
6416	Evaluates an operator by loading all operands and processing them through `_evalFn`. It handles value resolution, adds simulation time for event-dependent operations, and includes data type information for integer-to-bits operations.
6417	Convert signed-unsigned bit representation, or cast to int or bool type.
6418	Reinterprets a Bits signal as an HStruct by casting each field of the HStruct type to the corresponding slice of the input signal, starting from offset 0 and proceeding through each field's width.
6419	Count of complete words between two addresses.
6420	Groups transaction parts split on words into words by their word index, yielding tuples of (wordIndex, list of transaction parts in that word).
6421	Pretty prints an interface with optional indentation and prefix, handling both HObjList objects and regular interfaces by recursively printing nested interfaces.
6422	Converts a transaction template into frames based on specified constraints like frame length and padding limits. It yields FrameTmpl objects with appropriate start and end addresses, handling padding trimming and frame splitting as needed. Supports trimming padding from start or end of frames and ensures frames do not exceed maximum length.
6423	Generator that yields tuples of (wordIndex, list of TransParts in this word) by walking through enumerated words in the frame, optionally including padding TransParts.
6424	Packs data into a list of BitsVal objects representing word values. Takes a dictionary of field values and converts them into bit-level representations according to the struct's field layout and word width, handling padding and validation masks during the packing process.
6425	Clean enclosure information and sensitivity settings for outputs, and recursively clean signal metadata for all statements in the current scope.
6426	Discover enclosure for a list of statements by identifying which outputs have drivers in the statement list. Returns a set of signals that are always driven (enclosed) within the given statements.
6427	Discovers sensitivity for a list of signals by walking through their sensitivity and extending the context with casual sensitivity, but stops early if event dependencies are found.
6428	Returns the RtlNetlist context from signals by iterating through inputs and outputs, returning the first signal context found, or raising HwtSyntaxError if no context is found.
6429	Update signal IO after reduce attempt, handling case where object was reduced or not reduced. When reduced, disconnects from signals and updates drivers/endpoints. When not reduced but IO changed, collects new IO signals.
6430	Method `_on_merge(self, other)` handles post-merge updates for statements by:
1. Combining inputs and outputs from both statements
2. Merging sensitivity lists if they exist
3. Merging enclosed for contexts if they exist
4. Moving the other statement from its parent context to this statement
5. Updating endpoint and driver relationships for inputs and outputs

The method preserves the rank but updates IO, sensitivity, and context relationships between statements.
6431	Method `_is_mergable_statement_list` checks if two lists of statements (`stmsA` and `stmsB`) can be merged into a single statement list by comparing each corresponding pair of statements for mergeability. It handles cases where one or both lists are None, iterates through both lists simultaneously, and returns True only if all corresponding statements are mergable. The method uses helper functions `_get_stm_with_branches` to retrieve statements and the `_is_mergable` method to check individual statement mergeability. Returns False if any mismatch is found or if lists have different lengths.
6432	Merge statements in a list to remove duplicated if-then-else trees, returning the merged statements and the total rank decrease from merging. For each rank group, if there's only one statement or the statements are not mergable, they are added as-is. If statements are mergable, they are combined and the rank of the second statement is added to the rank decrease counter. The final list is sorted according to the original order and returned along with the rank decrease.
6433	Merge two lists of HdlStatement objects into one, handling complex statements that require merging while simple statements are appended directly. Returns the merged list of statements.
6434	This function attempts to simplify a list of HDL statements by recursively reducing each statement and merging adjacent statements. It returns the reduced statements, a flag indicating if the statement rank decreased, and a flag indicating if any I/O changes occurred during the reduction process.
6435	Method `_on_parent_event_dependent` propagates event dependency flag to child statements when a parent statement becomes event dependent. It sets the `_is_completly_event_dependent` flag to True and recursively calls the same method on all child statements.
6436	Sets the parent statement and propagates dependency flags. Assigns parent statement and if necessary propagates event dependency flags. Traverses up to the top statement and appends inputs and outputs to the parent statement's collections. If the statement was previously top-level, updates endpoint and driver relationships and removes from current context. Finally, adds the statement's rank to the parent statement's rank.
6437	Appends a list of statements to a target list after performing parent statement assignment and flattening, while ensuring each statement has no existing parent.
6438	Disconnect this statement from signals and delete it from RtlNetlist context, altering signal endpoints/drivers so they can not be used for iteration.
6439	Creates a register in the unit with optional clock and reset signals. Supports default values, structured data types, and proper signal handling with inheritance from parent unit when signals are not specified. Returns the created register or container for structured types.
6440	Create a signal in this unit with the given name, data type, and default value. If the data type is an HStruct, recursively create signals for each field in the struct. Otherwise, delegate signal creation to the context's sig method.
6441	Method that disconnects internal signals and cleans interfaces to allow unit reuse by parent unit.
6442	Generator function that recursively traverses HStruct and HArray objects to yield all simple (Bits) values, skipping padding fields when specified. It handles nested structures by walking through fields of HStruct, elements of HArray, and the underlying value of HUnion, while properly managing padding fields based on the skipPadding parameter.
6443	Unpacks serialized data into a structured object by parsing bits according to the structure's field definitions, handling padding and data width constraints.
6444	Converts the sign representation of a value between signed, unsigned, and vector formats. Returns the value with the specified sign type (signed=True, unsigned=False, or no sign specification=None). Uses appropriate conversion operations based on the target sign type.
6445	Registers sensitivity for a hardware process, allowing it to be triggered by signal changes. Supports different sensitivity types (ANY, RISING, FALLING) and can handle both simple signals and tuples specifying sensitivity types.
6446	Evaluates a list of values as conditions and returns a tuple of (condition_result, validity_flag). For each value in the input conditions, it checks if the value is valid (vldMask == 1) and boolean true. If any invalid value is found, it returns (False, True). If any value has incomplete validity, it returns (False, False). Otherwise, it returns the logical AND of all values and validity flags.
6447	Connect ports of simulation models by name, handling both outgoing and incoming directions by swapping port references and removing the original port from signals.
6448	Creates a value updater function for simulation that compares current and next values, and returns a tuple indicating if the value changed and the updated value. If the invalidate flag is True, the updated value's validity mask is set to 0.
6449	Creates an array value updater for simulation that assigns a new value to a specified index in an array. Returns a function that takes the current array value and returns a tuple of (change_flag, updated_array). Supports invalidating the value by setting vldMask to 0. Currently only supports single index operations.
6450	Creates an HDL vector value from a Python value with specified width and signedness properties.
6451	This method processes hardware statements to analyze and register resource usage based on signal dependencies and types. It examines each statement's outputs to determine whether they represent RAM write ports, flip-flops, latches, or multiplexers, depending on their event dependency status and data types. For each output signal, it checks if it's been seen before, and if not, categorizes it based on whether it's an HArray (RAM), event-dependent, or not. It also handles case equations in switch containers and processes hidden signals through operator analysis. The method updates the resource context with appropriate registrations for each identified resource type.
6452	Get the value of a parameter by recursively evaluating Param objects until a base value is reached, then convert to hardware value format.
6453	Sets the value of this parameter, performing validation checks to ensure the parameter is not read-only and not replaced, then converts and stores the value with its data type.
6454	Generate flattened register map for HStruct from interface map, returning a structured representation with type, name, and BusFieldInfo for each field.
6455	Resolve ports of discovered memories and update resource counts accordingly. Remove registers on read ports that will be merged into RAM.
6456	Find indexed signal and return the signal it is indexed on with the index operand. Returns None if signal is not indexed.
6457	Constructs a value of this type by delegating to the value class's fromPy method.
6458	Method `auto_cast` casts a signal or value to another compatible type. It first checks if the source signal/value's dtype matches the target type, returning it directly if so. Otherwise, it retrieves or creates an auto-cast function and uses it to perform the conversion. The method handles potential AttributeError when accessing the cast function and stores it as an instance attribute for future use.
6459	Reinterprets a signal or value of one type as another type of the same size, with automatic casting as fallback. Returns the cast result or raises an exception if casting fails.
6460	Generator function that recursively walks parameter instances on an interface and its sub-interfaces, yielding unique parameters that haven't been discovered yet.
6461	Connects a 1D vector signal to a structuralized interface by iterating through physical interfaces in reverse order, extracting appropriate signal segments based on data type (BIT or other), and creating signal connections. Skips excluded interfaces and returns a list of signal connections.
6462	Concatenates all signals from an interface into one big signal recursively, considering direction constraints and exclusions. Returns None if no matching signals are found.
6463	This method converts ROM memory contents into hardware processes to work around Verilog limitations with array constants. It creates process-based implementations of ROM read operations by:

1. Analyzing ROM endpoints to identify index operations on the ROM
2. Generating signals to represent ROM output values
3. Creating switch-case processes that map index values to ROM content
4. Replacing original ROM index operations with references to the generated signals
5. Returning the created processes and signals for hardware synthesis

The method handles the constraint that Verilog doesn't support array literals by explicitly generating process blocks that implement ROM behavior through conditional statements based on index values.
6464	Synthesize all subunits, make connections between them, build entity and component for this unit.
6465	Register interface in implementation phase by registering the interface, loading it, and setting up its signals for the current context.
6466	Reduces a signal and value by the bitwise AND operator when possible, returning either the reduced signal or value, or None if static reduction is not possible. Specifically, if the value is fully valid, it checks if the value equals the mask (returns the signal) or zero (returns the value).
6467	Function `tryReduceXor` attempts to statically reduce XOR operations between a signal (`sig`) and a value (`val`) using the `^` operator. It returns the reduced signal or None if reduction is not possible. The function handles cases where the value is fully valid and equals all-ones (returns bitwise NOT of signal) or zero (returns signal unchanged). If the value has no valid bits, it returns the original value.
6468	Get the root of the name space by creating a new NameScope instance with level 1 and updating it with the class's keywords dictionary.
6469	Method `serializationDecision` determines whether an object should be serialized based on its type and serialization rules. It handles Entity and Architecture objects by checking their associated Unit's serialization decision. For other object types, it returns True (serialize). The method tracks already serialized classes in `serializedClasses` and updates the serialization state, returning a boolean indicating whether serialization should occur.
6470	Serializes an HdlType instance by dispatching to type-specific serialization functions based on the type of the input parameter. Raises NotImplementedError for unimplemented types.
6471	Serialize IfContainer instance by generating HDL code with proper conditional handling and error management for unsupported operations.
6472	Returns the base condition and a negation flag. If the condition is negated (wrapped in a NOT operator), it extracts the original condition and sets the negation flag to True. Otherwise, it returns the condition as-is with the negation flag set to False.
6473	Constructs a SimBitsT instance with caching support based on width and signed parameters. Returns cached instance if exists, otherwise creates new instance and stores it in cache before returning.
6474	Get constant name for a value, reusing names for duplicate values. Returns cached name if available, otherwise generates new name using nameCheckFn.
6475	Cut off statements which are drivers of specified signal. If the destination signal matches the input signal, set parent statement to None and return the statement; otherwise return None.
6476	Load array from array type to transaction template instance and return the end address.
6477	Load data from HStruct type to transaction template instance, return end address.
6478	Loads an HDL type into this transaction template instance by dispatching to type-specific loading methods based on the HdlType subclass.
6479	Returns the width of an item in the original HArray by calculating the bit difference divided by item count. Raises TypeError if the dtype is not an HArray instance.
6480	Walks through fields in a TransTmpl instance, yielding tuples of bit address ranges and TransTmpl instances. Handles different data types (Bits, HStruct, HArray, HUnion, HStream) with appropriate traversal and yielding logic based on provided functions and context.
6481	Converts a signed integer to its equivalent positive representation with the same bit pattern by adjusting for two's complement form when the most significant bit is set.
6482	Merges another IfContainer's statements with this statement by combining corresponding cases and default cases using a merge function, then calls _on_merge callback.
6483	Cached indent getter function that returns a string of spaces based on the indent number, using a cache to avoid repeated string operations.
6484	Check if a property already exists on an object before redefining it, raising an IntfLvlConfErr if the property exists with different value.
6485	Register a parameter object on the interface level by performing name availability checks, setting/verifying the parameter name, registering the scope, updating generic name if applicable, setting parent relationship if needed, and appending to the parameters list.
6486	Updates all parameters defined on self from otherObj using the provided updater function, while optionally excluding specified parameters and applying a prefix to parameter names during matching.
6487	Register a unit object on the interface level by performing name availability checking, setting parent and name attributes, and adding the unit to the internal units list.
6488	Register an interface object on the interface level object, setting up parent-child relationships and categorizing it as private or external based on the isPrivate flag.
6489	Register an array of items on the interface level object by setting parent and name attributes, then dynamically creating numbered attributes on the object for each item in the array.
6490	Returns the single driver from a signal if exactly one driver exists, otherwise raises appropriate exceptions (NoDriverErr if no drivers, MultipleDriversErr if more than one driver).
6491	Recursively evaluates operators and updates result value using evaluation function.
6492	Create operator with result signal, setting up the operator with given operands and result type, establishing signal relationships and constancy tracking.
6493	Creates a copy of this context with increased indentation level.
6494	Try to connect src to a specific interface named intfName on unit. If the interface doesn't exist or already has a driver, ignore the connection attempt.
6495	Propagates the "clk" clock signal from the main object to all its subcomponents by connecting the clock signal to each unit's clk port.
6496	Propagates the clock signal ("clk") and negative reset signal ("rst_n") to all subcomponents, along with the inverted reset signal ("rst") to each unit in the object's units list.
6497	Propagates clock ("clk") and reset ("rst") signals to all subcomponents. Connects the clock signal directly and the inverted reset signal as "rst_n" to each unit in the object's _units list.
6498	Propagates the negative reset signal "rst_n" to all subcomponents by connecting it to both "rst_n" and "rst" ports of each unit.
6499	Propagates the reset signal "rst" to all subcomponents by connecting it to both 'rst_n' (inverted) and 'rst' (direct) ports of each unit in the object's _units collection.
6500	Iterates over bits in a signal or value, yielding parts of specified bit width. Takes a signal/value, number of bits per part, and flags for padding handling. Returns generator that yields bit chunks until all bits are processed.
6501	Always decides not to serialize the given object. Prepares an entity for non-serialization if it's a declaration, and returns a tuple indicating false serialization status along with the private data.
6502	Serialize only the first object of each class, tracking the first object instance in private data to determine serialization eligibility.
6503	Serialize objects with unique parameters and class, tracking previously seen parameter combinations in private data to avoid duplicate serialization.
6504	Get full name hierarchy separated by '.' by traversing up the parent chain from InterfaceBase and HObjList objects.
6505	Method `_make_association` delegates the association making process to all items in the collection by calling their respective `_make_association` methods with the provided arguments.
6506	Creates a simulation model for a unit, connects it with the unit's interfaces, and decorates it with agents. Generates or uses a simulation model class, optionally dumps it to a folder, reconnects unit signals to the model, instantiates the model, and automatically adds agents to simulation processes. Returns the unit, model, and agent processes.
6507	Create a simulation model for a unit by converting it to RTL code with simulation-specific serialization, then dynamically imports or executes the generated code to return the simulation module.
6508	Reconnect model signals to unit interfaces for simulation while preserving original unit interfaces for communication. Recursively processes unit interfaces, replacing signal references with corresponding signals from the simulation model class.
6509	Creates a VCD (Value Change Dump) simulation output file for a given simulator model and stimulus functions. Handles both file path strings and file objects as output destinations, automatically creating directories when needed. Returns the HDL simulator object.
6510	Initializes the callback by registering write callbacks for input and output signals with the simulator.
6511	Connects a signal to a port item on a subunit based on the port's direction (IN/OUT). For IN ports, associates the signal as source and adds port to signal's endpoints. For OUT ports, associates the signal as destination and adds port to signal's drivers. Raises HwtSyntaxError if port is already connected or NotImplementedError for unsupported directions. Marks signal as not hidden and adds unit to signal's context subunits.
6512	Connects internal signal to port item for simulation use, only connecting output port items. Raises HwtSyntaxError if port is already associated with a signal, or NotImplementedError if port direction is not supported.
6513	Connects internal signals to component ports based on direction: adds to endpoints for OUT, drivers for IN/INOUT, raises NotImplementedError for unsupported directions.
6514	Return the signal inside the unit that contains this port, based on the port's direction. For input ports, returns the destination signal; for output ports, returns the source signal. Raises NotImplementedError for other directions.
6515	Check if an HDL process has event dependency on a signal by verifying if the process is present in either the signal's falling sensitivity processes or rising sensitivity processes.
6516	Schedule a process to run at the current time with the specified priority by adding it to the events queue.
6517	Add an HDL process to the execution queue based on its dependency on the trigger signal. Processes are categorized as sequential or combinational and scheduled accordingly. Sequential processes dependent on events are added to `_seqProcsToRun`, while combinational processes go to `_combProcsToRun`. If no value application is planned for the current time, one is scheduled first. Processes dependent on startup events are skipped when the current time is 0.
6518	Schedule combUpdateDoneEv event to notify agents that the current delta step is ending and combinational logic values are stable. Returns the created event.
6519	Schedule application of stashed values to signals, and if not already scheduled, also schedule sequential processes execution.
6520	This method resolves write conflicts for signals by determining the appropriate update strategy based on the value type. It returns a tuple containing a callback function for performing updates and a boolean indicating if the update is event-dependent. For 3-element values (array updates), it creates an array updater with indexes; for 2-element values (simple signals), it creates a regular updater. The invalidate parameter is always set to False in both cases.
6521	Delta step for combinational processes that executes registered combinational processes, applies conflict resolution to signal updates, and prepares values for application while clearing the list of processes to run.
6522	Summary: Executes sequential processes in delta steps, handling process outputs and signal updates while managing process scheduling and conflict resolution.
6523	Apply stacked values to signals by processing value updates and running combinatorial processes, while handling event-dependent processes and scheduling additional value applications if needed.
6524	Reads a value from a signal or interface by accessing its internal value, with fallback to an internal signal if direct access fails, and returns a cloned copy of the value.
6525	Writes a value to a simulation signal or interface, handling signal proxies and value type casting, while scheduling value application when necessary.
6526	Add a process to events with normal priority at current time.
6527	Run simulation for a Unit instance with optional pre-simulation hook, extra processes, and signal initialization.
6528	Creates a variadic operator function that applies a binary operation across multiple operands, optionally transforming each operand with a key function before processing.
6529	Convert ternary operators in assignments to IfContainer structures, preserving other statements unchanged. For each assignment statement, if it contains a ternary operator (identified by TERNARY operator type), replace it with an IfContainer that has the ternary's condition as the if condition and the two ternary operands as the true/false branches. If the assignment doesn't contain a ternary operator or has other issues (multiple drivers, no driver, etc.), append the original statement unchanged to the result list.
6530	Serialize HWProcess objects as VHDL, handling process body serialization, sensitivity list generation, and temporary variable creation while managing indentation and scope to prevent name collisions.
6531	Computes the Hamming distance between two hashes by comparing corresponding characters and counting mismatches. Raises ValueError if the hashes have different lengths. Returns the total count of differing positions.
6532	Compute the average hash of a given image by resizing it to specified hash size, converting to grayscale, calculating pixel average, and generating a hexadecimal hash based on pixels compared to the average value.
6533	Computes the Hamming distance between two images by first generating their average hashes and then calculating the distance between these hashes.
6534	Sets up the Vizio media player platform with given configuration and adds the device entity to Home Assistant. Validates device setup and handles authentication requirements based on device type. Optionally suppresses insecure request warnings.
6535	Update the device state by retrieving latest power state, volume, input settings, and available inputs from the device. Sets appropriate state constants and handles both on and off states with proper None value handling for incomplete data.
6536	Mute or unmute the device volume based on the mute parameter. When mute is True, calls mute_on() on the device; when False, calls mute_off().
6537	Method that increases the device volume by incrementing the volume level and calling the device's volume up function with a specified step number.
6538	Decreases the device volume by reducing the volume level and sending a volume down command to the device.
6539	Set the volume level on the device. If the new volume is higher than current volume, increase volume by the difference multiplied by max volume. If the new volume is lower than current volume, decrease volume by the difference multiplied by max volume.
6540	Resets the board to its starting position by initializing piece bitboards, piece counters, occupied square tracking, king positions, and game state variables.
6541	Returns the piece at the specified square, including its type and color, or None if the square is empty.
6542	Removes a piece from the specified square and updates the board state accordingly. If `into_hand` is True, the piece is added to the appropriate player's hand. The method updates bitboards, piece lists, and the incremental Zobrist hash, handling both standard piece removal and piece collection into hand scenarios.
6543	Sets a piece at the given square, replacing any existing piece. Handles pieces coming from or going to hand, updates piece bitboards, king position tracking, occupied squares tracking, and incremental Zobrist hash calculation.
6544	Checks if a given move would leave the king in check or put it into check by either causing a suicide move or creating a check through pawn dropping.
6545	Checks if the opponent's king is under attack, returning True if the position is invalid due to illegal move.
6546	Checks if the game is over due to checkmate, stalemate, or fourfold repetition. Returns True if game is over, False otherwise.
6547	Checks if the current position is a checkmate by first verifying the king is in check, then attempting to generate legal moves. Returns True if no legal moves exist (checkmate), False otherwise.
6548	Method that checks if a game has ended due to fourfold repetition, where a position occurs four times on consecutive alternating moves. Returns True if the current position has appeared at least four times in the transpositions table, False otherwise.
6549	Restores the previous position by popping the last move from the stack and reverting all board state changes, including updating the transposition table, decrementing move number, restoring captured pieces, handling null moves, and swapping turns. Returns the restored move.
6550	Returns the SFEN (Shogi Fen) representation of the current position as a string, including board layout, side to move, pieces in hand, and move number.
6551	Parses a move in USI notation, makes the move, adds it to the move stack, and returns the move. Raises ValueError for illegal or invalid moves.
6552	Returns a Zobrist hash of the current position by combining board setup hash, turn information, and pieces in hand patterns using bitwise XOR operations with random array values.
6553	Gets the piece symbol in uppercase for black pieces or lowercase for white pieces using the piece type and color.
6554	Creates a piece instance from a piece symbol, determining piece type from symbol index and color (white if lowercase, black if uppercase). Raises ValueError for invalid symbols.
6555	Gets the USI string representation of the move. For example, a move from 7A to 8A would be '7a8a' or '7a8a+' if promoted. Returns '0000' for invalid moves.
6556	Parses a USI (Universal Shogi Interface) string representation of a move. Supports several formats:
- '0000' returns a null move
- 4-character strings like '7g7f' for regular moves
- 4-character strings with '*' like 'P*7h' for drop moves
- 5-character strings ending with '+' like '7g7f+' for promotions

Raises ValueError for invalid USI string formats. Returns a new instance of the class representing the parsed move.
6557	Function `parse_commits` accepts a string input and parses it into individual commit dictionaries using regex patterns. It's a generator that finds all commit blocks with `RE_COMMIT.finditer`, extracts each commit's content, parses its components using `RE_COMMIT.match` and `parse_commit`, and yields each parsed commit dictionary one at a time. The function processes multi-line commit data and returns structured commit information for each commit found in the input string.

The function structure:
1. Uses `RE_COMMIT.finditer` to find all commit blocks in the input data
2. For each commit block, extracts the full commit content
3. Uses `RE_COMMIT.match` to parse commit components into a dictionary
4. Calls `parse_commit` to further process the commit parts
5. Yields each parsed commit dictionary

This is a generator function that efficiently processes large commit logs by yielding results one at a time rather than storing all parsed commits in memory simultaneously.
6558	Parses a commit by processing its various components including parents, author, committer, message, and changes. Splits and processes multi-line fields, applies specific parsing functions to each component, and returns a dictionary with the completely parsed commit information.
6559	Loads configuration from CLI arguments, temporarily patches Django's command parser to include config arguments, parses known arguments to load config file, and yields remaining default arguments while ensuring the original parser is restored.
6560	Loads configuration from command line arguments and executes Django management commands with the loaded configuration.
6561	Adds a configuration file argument to an existing argparse parser with optional environment variable and default file support.
6562	Load configuration by finding a config file and setting values from it, falling back to environment variables if no file is specified.
6563	Generates YAML configuration string from class initial config with documentation comments and help text annotations.
6564	Documents values in markdown format by generating a structured document with class documentation, required flags, help text, data types, and default values for each value in the class's _values dictionary.
6565	Converts a string value to the type specified by `cast_as` attribute by calling the appropriate casting method.
6566	Returns a list of all dates from first_date to last_date inclusive, generating each date by adding incremental days to the first date.
6567	Function to parse date strings in either 'YYYY-MM-DD' format or 'DD Month YYYY' format into datetime.date objects.
6568	Loads currency data from a file or URL, handling both local files and remote URLs, and processes the content whether it's plain text or ZIP compressed data.
6569	Fill missing rates of a currency with the closest available ones by setting missing dates to None and reporting missing rates if verbose mode is enabled.
6570	Fill missing rates of a currency by linear interpolation of the two closest available rates.
6571	Get a currency rate for a given date, with fallback behavior when the date is outside the valid range. Returns 1.0 for the reference currency. Raises RateNotFoundError for invalid currencies or dates outside bounds when fallback is disabled.
6572	Convert an amount from one currency to another using the specified date's exchange rate. If no date is provided, uses the most recent available rate. Raises ValueError for unsupported currencies and RateNotFoundError when a rate is not available for the specified date. Returns the converted amount as a float.
6573	Groups elements of an iterable into tuples of size n, padding with fillvalue if necessary.
6574	Animate given frames for a set number of iterations with specified interval and name, displaying each frame with a clear line and flush output.
6575	Return record `n` as 1,024 bytes by seeking to the appropriate position and reading K bytes.
6576	Write `data` to file record `n` (records indexed from 1) by seeking to the appropriate position and returning the result of the write operation.
6577	Return a memory-map of elements from index `start` to `end` (inclusive) as 8-byte double-precision floats, with proper handling of file access and memory mapping with page boundary alignment.
6578	Return the text inside the comment area of the file by reading records and extracting ASCII text until EOT byte.
6579	Add a new array to the DAF file by writing the array data and updating the file's summary records with the array's start and end word positions.
6580	Close this SPK file by closing the underlying DAF file, cleaning up segment data, and clearing internal arrays and maps.
6581	Computes the component values for the specified time by generating positions and returning the first one.
6582	Close this file and clean up segment data by deleting _data attribute from each segment that has it.
6583	Load coefficients into memory as a NumPy array, returning initial epoch, interval length, and coefficients data.
6584	Generate angles and derivatives for given time values using Chebyshev polynomials. Returns angles and their derivatives when derivative=True, otherwise returns only angles. Handles scalar and array inputs, performs precision-enhanced computation, and includes error checking for out-of-range time values.
6585	Visits a function call node to analyze logging statements and string formatting. Handles three main cases: logging statements (with level detection and violation checking), string format calls within logging arguments (flagging as violations), and general statements. Detects logging levels, checks for exc_info usage, validates exception arguments, and tracks logging call context including extra keyword arguments. Appends violations for warn-level logging and string formatting issues, and properly manages visitor state for nested calls.
6586	Visits binary operations to detect percent format and string concatenation violations within logging statements, adding appropriate violations to the list and continuing with generic node traversal.
6587	Process dictionary arguments by checking whitelist violations and extra exception handling, then continue with generic node traversal.
6588	Process f-string arguments and detect logging violations in Python 3.6+ environments.
6589	Process keyword arguments by checking whitelist compliance and extra exception handling, then continue with generic node traversal.
6590	Process except blocks by extracting the exception handler name, tracking it in the current exception names list, and then visiting the node's children.
6591	Method to detect if an AST Call node represents a logging call by checking if the function attribute is in LOGGING_LEVELS and not a warnings call. Returns the logging level name if detected, None otherwise.
6592	Helper method to extract exception name from an ExceptHandler node, handling both Python 2 and Python 3 compatibility by checking the version_info and returning the appropriate name attribute (either `name.id` for Python 2 or `name` for Python 3). Returns None if no exception name is present.
6593	Check if value has id attribute and return it, handling cases where the id might be nested within a value attribute.
6594	Checks if the given node is a bare exception name from an except block by verifying it's a Name node with an id present in the current except names.
6595	Checks if `exc_info` keyword is used with `logging.error` or `logging.exception` and reports violations. Returns early if current logging level is not 'error' or 'exception'. For each keyword argument in the node, if the argument is 'exc_info', it appends an appropriate violation to the violations list based on the current logging level.
6596	Delete file from database only if needed when editing an instance. If the filefield is being replaced, the old file is deleted from the database.
6597	A decorator that modifies a Django widget class to customize the display of download links by extracting and formatting the filename from the URL, handling both Python 2 and 3 compatibility, and updating the widget's template substitution values and context with the formatted display name.
6598	Returns the freshly rendered content for the PDF template and context, rendering a PDF response without setting the final content.
6599	Returns a PDF response with a template rendered with the given context, handling filename and command options for PDF generation while falling back to standard response for non-PDF responses.
6600	Function `http_quote` takes a unicode string and converts it to a valid ASCII string suitable for HTTP headers. It first attempts to transliterate unicode characters using `unidecode`, then encodes to ASCII with replacement for non-ASCII characters. It escapes backslashes and double quotes, and wraps the result in double quotes for safe HTTP usage.
6601	Sets defaults for ``class Meta`` declarations by configuring MongoDB options either from a module's attributes (starting with a specified prefix) or directly from keyword arguments. Supports configuration via module inspection or explicit keyword arguments, but is not thread-safe.
6602	Converts a given string from CamelCase to under_score.

>>> to_underscore('FooBar')
'foo_bar'
6603	Builds all indices listed in the model's Meta class by calling ensure_index on the collection for each index.
6604	Parse a .csv file into a list of PriceModel objects with specified currency.
6605	Loads the content of a text file and returns it as a list of strings.
6606	Parse a CSV line into a price element containing symbol, value, and datetime.
6607	Method `translate_symbol` translates an incoming symbol into a locally-used symbol by looking up the symbol in a pre-loaded mapping dictionary. If the symbol exists in the mapping, it returns the mapped value; otherwise, it returns the original symbol. The method ensures symbol mappings are loaded from the database before translation if they haven't been loaded yet.
6608	Loads all symbol maps from database into a dictionary mapping input symbols to output symbols.
6609	Returns the default database session, creating it if it doesn't exist yet.
6610	Adds an individual price entry to the database with the specified symbol, date, value, and currency. The symbol and currency are converted to uppercase, the date is parsed from ISO format, and the price is saved to the database. Outputs a confirmation message upon successful addition.
6611	Imports prices from a CSV file and converts the currency to uppercase before processing.
6612	Displays the last price for a given symbol or all available securities if no symbol is provided. If a symbol is specified, it converts it to uppercase, parses the security symbol, and retrieves the latest price. If no symbol is provided, it retrieves and displays the latest prices for all securities.
6613	Display all prices for a given date and currency, or show the latest prices if the 'last' parameter is True. The function fetches prices from a database application and prints each price followed by the total count of records found.
6614	Download the latest prices for securities, with optional filtering by currency, agent, symbol, and namespace. If help flag is set, display help text and exit. Supports currency normalization to uppercase and uses PriceDbApplication for price download operations.
6615	Deletes old price entries, keeping only the most recent ones for a specified symbol or all symbols, and prints the count of removed entries.
6616	Return the default session by reading the database path from configuration and creating a session with get_session(). Raises ValueError if the price database path is not set in the configuration.
6617	Creates a symbol mapping by adding a new SymbolMap record with incoming and outgoing symbols to the database session and commits the transaction.
6618	Displays all symbol maps by querying the price database and printing each SymbolMap item using click.echo().
6619	Finds and returns a SymbolMap object by its in-symbol value.
6620	Read text lines from a file and return them as a list of strings.
6621	Maps a price entity to a price model by converting currency, date/time, symbol, and value properties.
6622	Maps a PriceModel entity to a Price entity with formatted date, time, symbol, value, and currency information.
6623	Reads a configuration file and validates its existence, raising FileNotFoundError if the file is not found.
6624	Gets the default config path from resources by constructing the full path using resource_filename with the package name and template path.
6625	Creates a user configuration file by copying a template to the user's directory, with error handling for missing templates and copy failures.
6626	Returns the full path to the active config file by combining the user's profile folder path with the config filename.
6627	Reads and returns the contents of the config file by writing the in-memory configuration data to a string buffer and returning its content.
6628	Sets a configuration value for the specified option key within the default section and saves the changes.
6629	Retrieves a configuration value for the specified option key from the single section in the config.
6630	Save the configuration file by writing the current contents to the file path returned by get_config_path().
6631	Splits a symbol into namespace and mnemonic components based on colon delimiter, returning a tuple of (namespace, mnemonic) and storing these values as instance attributes.
6632	Adds a new price record by mapping a PriceModel to an entity and persisting it through the mapper. Raises ValueError if the price model is null.
6633	Adds a price entity to the database, updating existing records if they match by namespace, symbol, date, and time. Raises ValueError if currency differs between existing and new price. Returns nothing.
6634	Downloads and saves price data online for a given symbol and currency, then returns the price model.
6635	Returns the current db session, creating a new one using dal.get_default_session() if none exists.
6636	Fetches all prices for the given date and currency, filters by date and currency if provided, sorts by symbol, and returns a list of PriceModel objects.
6637	Returns the latest price for a given date, namespace, and symbol by querying the price repository and ordering by time in descending order to get the most recent record.
6638	Prune historical prices for all symbols, leaving only the latest. Returns the number of items removed.
6639	Deletes all price records for a given security symbol except the latest one, returning whether any records were removed.
6640	Downloads and parses stock price information for a given symbol using the specified currency and agent source. Returns the parsed price data or raises ValueError if download/parsing fails.
6641	Fetches securities matching the specified filters (currency, agent, symbol, namespace) and returns them sorted by namespace and symbol.
6642	Return partial application of the original function with bound arguments, excluding the first argument which is typically 'self' or 'cls'.
6643	Replaces child nodes in the original function call with their partials and marks the object as updated.
6644	Generator function that performs depth-first descent into all child nodes, optionally including the current node. Yields nodes in depth-first order.
6645	Decorator that removes nodes from root node before executing a function, then updates child calls for those nodes.
6646	Verify that a part that is zoomed in on has equal length between student and solution code.

This function checks if the length of a specified part (such as arguments, body, etc.) in the student code matches the length of the corresponding part in the solution code. If the lengths don't match, it reports a feedback message with the provided error message and length information.

Arguments:
- state: The state object containing student and solution parts
- name: Name of the part to check (e.g., 'args', 'body')
- unequal_msg: Message to display when lengths don't match

Returns the state object after performing the length comparison check.

Typically used in the context of check_function_def() to verify structural consistency between student and solution code.
6647	Test whether the abstract syntax trees (ASTs) of student and solution code match. Can be used to verify exact AST equality or check if the solution AST is contained within the student AST. Supports custom code matching and provides configurable error messages.
6648	Test if student code contains specified text or pattern, with optional custom feedback message. Uses StringContainsTest to perform the check and returns the updated state.
6649	Checks whether a student has correctly imported a package or function, with optional strict aliasing verification.
6650	Search student output for a pattern using string matching or regular expressions, with customizable feedback messages.
6651	Check if the specified printout from the solution code appears in the student's output. It reruns the print call from the solution and verifies its output against the student's print statements, making it robust for checking specific printouts regardless of how many print statements the student uses. Can be used to verify exact print outputs or patterns, with options to customize messages, execute pre-code, and handle object copying.
6652	Check whether the submission did not generate a runtime error. If the student code contains an error, report the error and provide an incorrect message. This function is automatically called before marking a submission as correct, but can be used explicitly to ensure code runs without errors before performing other verifications.
6653	Test a multiple choice exercise by comparing the student's selected option with the correct answer, and provide appropriate feedback messages. Raises InstructorError if arguments are invalid or if the selected option is not available in the student process.
6654	Check whether a particular function is called in the student's code, verifying its arguments and signature against the solution. It supports custom error messages, argument validation, and result equality checks.
6655	Get a value from process, return tuple of value and result if successful, otherwise return the result and its string representation.
6656	Override the solution code with arbitrary code for temporary alternative solutions. Takes a solution string and state, parses the new solution, handles different AST node types, and returns a child state with the overridden code. Used when you want to temporarily override the solution code to allow alternative ways of solving an exercise. The remainder of the SCT chain will run as if the specified solution code is the only code that was in the solution.
6657	Check whether an object is an instance of a certain class, typically used when chained from `check_object()` to verify the class of an object in the student's code against the solution code.
6658	Return a copy of the instance with EMPTY entries omitted.
6659	Creates a child state by diving into a nested tree structure, typically used for testing control flow statements like if statements or for loops. It sets up the current state as a parent with subtree information for both student and solution trees, handling message passing, context updates, and AST token generation while managing optional parameters and context updates for both student and solution code.
6660	Returns the value of an extension attribute from a parser's output, using caching to avoid reprocessing the same parser-tree combination. If the parser output is already cached, it returns the cached result; otherwise, it creates and runs the parser on the tree, caches the result, and returns the requested attribute.
6661	Returns a test result for context loop validation with target variables.
6662	Summary: The `has_context_with` function processes each context manager within a with statement by iterating through the solution parts labeled "context". For each context manager, it creates a state object using `check_part_index` and then calls `_has_context` to verify the context, using either a provided error message or a default one. The function returns the updated state after processing all context managers.
6663	Check if a part exists in the state and return a child state with the part's AST tree. Validates that the part is defined and correctly specified, then converts the part to a child state for further processing.
6664	Function `check_part_index` retrieves and validates a specific part from student and solution parts based on given index, then returns a child state with that part's AST tree. It supports integer, string, or list indices, and includes error handling with customizable messages for missing or incorrectly specified parts.
6665	Check whether a function argument is specified in the student's code, either by name or position. Can be used to verify that required arguments are present and to proceed with further checks using `has_equal_value()` or `has_equal_ast()`. Supports both named and positional arguments, and can handle variable length arguments.
6666	Summary: `check_call` prepares a function call for verification in SCT (Submission Correctness Test) by replacing the function name with the targeted function/lambda, building call strings for both student and solution code, and creating a child node for further checking of function behavior. It supports custom argument strings and expand messages for detailed feedback.
6667	Return the true anomaly at each time by calling the _getf function from _rsky module with the provided orbital parameters and time values.
6668	Initializes the LDAP3 login manager with a Flask application by registering a teardown callback and configuring the extension with application settings.
6669	Initializes and configures the extension with a given configuration dictionary, setting default values for various LDAP-related parameters including connection settings, search scopes, object filters, and authentication types. It also optionally adds an LDAP server based on the configuration.
6670	Add an additional server to the server pool and return the freshly created server.

Args:
    hostname (str): Hostname of the server
    port (int): Port of the server
    use_ssl (bool): True if SSL is to be used when connecting.
    tls_ctx (ldap3.Tls): An optional TLS context object to use when connecting.

Returns:
    ldap3.Server: The freshly created server object.

Raises:
    ValueError: If a TLS context is specified but SSL is not used.
6671	Remove a connection from the appcontext's ldap3 manager connections list if it exists.
6672	Cleans up resources after a request by closing all open LDAP connections and unbinding the main connection if they exist in the current context.
6673	Authenticates a user using either direct credentials, direct bind, or search bind methods based on LDAP configuration settings. Returns an AuthenticationResponse object.
6674	Authenticates a user through direct LDAP bind by constructing a distinguished name from the username and attempting to bind with the provided password. Returns an AuthenticationResponse indicating success or failure, along with user information if authentication succeeds.
6675	Performs LDAP authentication using search bind method when login attribute differs from RDN. Searches for user by username, then attempts to bind with provided credentials. Returns AuthenticationResponse indicating success or failure, along with user information if authentication succeeds.
6676	Gets a list of LDAP groups that a user identified by dn is a member of, using an optional existing connection or creating a temporary one for the search.
6677	Gets information about a user specified by distinguished name from LDAP directory using the configured user object filter and attributes.
6678	Gets user information from LDAP by searching for a specific username within the Users DN using the configured user login attribute and object filter, returning a dictionary of the user's LDAP attributes.
6679	Gets an LDAP object by DN using the specified search filter and attributes. Creates a temporary connection if none provided, searches for the object, and returns its attributes plus DN. Cleans up the temporary connection if created.
6680	Returns an authenticated LDAP connection from the Flask app context, creating one if needed. Raises LDAPException if bind fails.
6681	Make a connection to the LDAP Directory using optional bind credentials and additional connection arguments, returning an unbound ldap3.Connection object.
6682	Creates and returns an unbound ldap3.Connection object with specified authentication parameters. Supports anonymous authentication or authentication based on configuration settings, and can optionally contextualize the connection for automatic cleanup. Returns the connection object for further use.
6683	Method: destroy_connection
Description: Destroys a connection by removing it from the appcontext and unbinding it.
Parameters: connection (ldap3.Connection) - The connection to destroy
Side effects: Removes connection from appcontext and unbinds the connection
Logging: Outputs debug message with connection memory address
Returns: None
6684	Method `search` queries an S3 endpoint for images based on a string query. If a query is provided, it performs a container search using `_container_search()`, otherwise it searches all collections across all fields using `_search_all()`. Supports empty query to list all container collections or specific container names like "vsoch/dinosaur".
6685	Searches across labels with optional key and value filters. Returns formatted label information with containers details. If no filters provided, shows all labels with container counts. Uses GET request to /labels/search endpoint and displays results in table format.
6686	Method: `search(self, query=None, args=None)`

Summary: Queries a GitLab artifacts folder for a list of images based on the provided query parameter. If no query is specified, it exits with an error message requiring a collection query in the format `<collection>/<repo>`. When a query is provided, it delegates to the internal `_search_all` method to perform the actual search operation.
6687	Searches all jobs in a collection for successful artifacts and returns browsable URLs for zip files found in the artifacts. The function fetches jobs from the specified collection, filters for successful jobs with zip artifact files, and constructs browse URLs for each artifact. If no zip artifacts are found, it exits with an info message. Otherwise, it displays a table of artifact browsers with job IDs and URLs, and returns the results list.
6688	A method for client announcement that logs client and database information to info level when quiet is False, then calls the private _speak method.
6689	Method `announce` announces the client itself unless the command is in a predefined list or quiet mode is enabled. If a command is provided and it's not 'get', and quiet mode is disabled, the client will speak.
6690	Updates Google Drive client secrets and base directory from environment variables, exiting with error if secrets are not found.
6691	Update headers with a token and other fields, resetting headers if necessary, then debug log the available headers.
6692	**Summary:**
The `require_secrets` method validates that a client has access to a secrets file and optionally verifies that specific parameters exist and are non-empty within the secrets. It performs two checks: first, ensuring the secrets file exists and the client is defined in it; second, if parameter names are provided, confirming each parameter exists in the secrets and is not None or empty. If any check fails, the method logs an error and exits the program.
6693	Downloads a file from a URL to a local file name by streaming to a temporary file first, then renaming it on successful completion. Supports optional headers and progress indication. If SSL verification is disabled, a warning is issued. Returns the final file name.
6694	Streams a file from a URL to a local file with progress tracking. Takes a URL, headers, and output file path as input. Handles authentication errors by retrying with updated tokens. Displays progress bar during download. Returns the path to the downloaded file upon success. Exits with error if streaming fails.
6695	update_token updates HTTP headers with a new AWS ECR authorization token using basic authentication. It creates an AWS CLI driver to retrieve authorization credentials and adds them to the provided headers dictionary with "Authorization" key. The function handles potential import errors and authentication failures appropriately.
6696	Creates a folder at the drive root if it doesn't exist, otherwise returns the existing folder. Uses a query to search for folders with the specified name and MIME type, and creates one if none is found.
6697	Method `_read_response` attempts to extract a specified field from a JSON response body. If the field cannot be extracted (due to JSON parsing error or missing field), it falls back to using the response's reason phrase. Returns the extracted message or fallback reason.
6698	Get or create an S3 bucket by name using the initialized client. Returns the bucket object, creating it if it doesn't exist. Exits if required attributes (bucket_name, s3) are missing.
6699	Updates client secrets from a credentials file and updates the API base URL if present in the secrets.
6700	Initializes clients by obtaining transfer and access tokens, then creates a transfer client using the loaded secrets.
6701	Load secrets credentials file with Globus OAuthTokenResponse, prioritizing cache loading for authentication and transfer credentials.
6702	Returns logs for a particular container by name or the most recent log if no name provided. If name is specified, searches through available logs and returns the content of the first matching log (either by name match in storage path or metadata). If no name is provided, returns the content of the most recently created log file. Returns None if no logs are available.
6703	Return a list of log files from the bucket by filtering blobs that end with '.log' extension. If no log files are found, log an info message.
6704	Creates an endpoint folder with error handling for existing folders. Takes an endpoint ID and folder path as parameters, attempts to create the directory, and logs either the successful creation message or informs if the folder already exists.
6705	Initializes and returns a transfer client for the user by creating a RefreshTokenAuthorizer with updated tokens and using it to instantiate a TransferClient.
6706	Searches and lists all containers with custom properties value type set to 'container'. Returns all objects with their IDs and URIs, using either the image name (without .simg extension) or properties URI field. Displays results in a formatted table and returns the matched container objects.
6707	Prints the status of all backends or a specific backend. It reads client secrets, displays the number of clients found, shows the active client if exists, and updates the secrets.
6708	Add a variable to the configuration backend with optional force override, ensuring the variable name follows the SREGISTRY_<CLIENT>_ prefix format and is uppercase.
6709	Remove a variable from the configuration backend settings, handling both prefixed and non-prefixed variable names by converting to uppercase and deleting from the settings dictionary.
6710	Activates a backend by adding it to the .sregistry configuration file. Takes a backend parameter, updates the configuration file with the specified backend, and prints a confirmation message.
6711	Delete a backend from settings and update the secrets file. If the backend is the active client, also remove it from settings. Print appropriate messages based on whether the backend exists and if it was successfully deleted.
6712	Updates the base registry information based on the image name, specifically handling Google Container Registry (gcr.io) by setting the base and updating secrets. Returns the detected base registry name.
6713	Generate a base64 encoded HTTP Authorization header for basic authentication by combining a username and password, then encoding them with base64 and formatting them as "Basic <encoded_credentials>" for use in HTTP requests.
6714	Generate an HMAC-SHA256 signature using a payload and secret key.
6715	Generate an HMAC-SHA256 header signature for client authorization by creating a credential string with request type and timestamp, then signing the payload with the secret to produce an authenticated header string.
6716	Delete request method that sends a DELETE HTTP request to the specified URL with optional headers and returns JSON response.
6717	Method: head
Parameters: self, url
Returns: Result of HEAD request to the specified URL
Description: Performs a HEAD HTTP request to the given URL, primarily used for retrieving status codes and headers without downloading the full content. Includes debugging output showing the URL being requested.
6718	paginate_get is a wrapper for get to paginate results, taking a URL and optional parameters including headers, return_json flag, and start_page. It handles pagination by making multiple requests to fetch all results, appending them to a list, and returning the complete dataset. The method processes paginated responses (where results are in a 'results' key and next page URL is in 'next') or returns non-paginated list results directly. It starts from page 1 by default or the specified start_page, and continues until all pages are exhausted.
6719	Method `verify` returns a boolean value to determine whether SSL certificate verification should be performed. It checks the `DISABLE_SSL_CHECK` flag from `sregistry.defaults`. If disabled, it issues a warning message indicating this is for testing only, and returns `False` to skip verification. Otherwise, it returns `True` to perform verification. This is intended to prevent production systems from bypassing SSL security checks.
6720	Delete an image from Singularity Registry after user confirmation, with optional force flag to skip confirmation.
6721	Returns a lookup dictionary containing global variables from sregistry.version without importing singularity.
6722	Returns a list of dependency strings formatted as "package==version" or "package>=version" based on the version specifications in the lookup dictionary.
6723	The `get_singularity_version` function determines the Singularity version for a build by first checking an environmental variable, then falling back to querying the system version. It takes an optional `singularity_version` parameter, returns the version string if found, or None if not set in environment or installed. The function uses `os.environ.get()` to check for "SINGULARITY_VERSION" and `run_command()` to execute `singularity --version` if needed, with proper error handling and logging.
6724	check_install attempts to verify if a specified software (defaulting to "singularity") is installed by running its version command. It returns True if the software is found and accessible, False otherwise. The function can operate in quiet mode to suppress output messages.
6725	Returns the absolute path of the installation directory by getting the parent directory of the current file's directory.
6726	Return the robot.png thumbnail from the database folder, using a user-exported image if available.
6727	The `run_command` function executes terminal commands using subprocess and returns the output message and return code. It optionally runs commands with sudo privileges, handles potential FileNotFoundError exceptions, and ensures the output message is properly decoded from bytes to UTF-8 string. The function returns a dictionary containing the command output message and its return code.
6728	This method wraps the main client's get_metadata function by parsing Dropbox FileMetadata into a dictionary format. It extracts metadata attributes from a Dropbox FileMetadata object that are of basic data types (str, datetime, bool, int, float), strips underscores from attribute names, and passes the parsed metadata to the primary get_metadata function along with an image file path. The method handles cases where dbx_metadata is None by returning an empty dictionary.
6729	The `_update_secrets` method retrieves a Dropbox token from the environment variable `SREGISTRY_DROPBOX_TOKEN`, creates a Dropbox client using this token, and verifies the account validity. If the token is not found, it exits with an error. If the account is invalid, it logs an error message and exits the program.
6730	Function `print_output` displays build response information on console and optionally writes it to a file. It shows status, file hash, size, bucket location, logs URL, and public URL (if available). If an output file is specified, it writes the same information to that file in a formatted manner.
6731	The `kill` function is a helper method that calls the client's "destroy" function to terminate instances. It imports the SRegistry client, iterates through command arguments to destroy specified instances, and exits the program after completion.
6732	Function `list_logs` is designed to display logs for a specified container or the latest log if no container is specified. It takes two parameters: `args` (an argparse object containing command-line arguments) and `container_name` (a string representing the container name, defaulting to None). If `args.commands` contains elements, the function extracts the first element as the `container_name`. It then uses the Sregistrar client to retrieve and display the logs for the specified container. If no container is specified, it defaults to showing the latest log. The function exits with a status code of 0 after execution.
6733	Get a listing of collections that the user has access to by retrieving account containers.
6734	The `_update_secrets` method updates authentication secrets for Swift object storage by checking the authentication type and retrieving required environment variables accordingly. It supports four authentication methods: pre-authenticated tokens, Keystone v3, Keystone v2, and legacy authentication. For each method, it retrieves the necessary credentials (user, token, URLs, etc.) from environment variables, configures the connection parameters, and establishes a connection using the `swiftclient.Connection` object. If any required environment variables are missing, the method will exit with an error. The method caches the configuration and connection for later use in other operations.
6735	Method `_update_secrets` retrieves Google application secrets from environment variable `GOOGLE_APPLICATION_CREDENTIALS`. If the secrets are not found, it logs an error message and exits the program with status code 1. The method ensures that the required secrets file exists in the environment before proceeding.
6736	Returns the appropriate client instance based on the specified driver or image URI. The client is selected from available options such as AWS, Docker, Dropbox, GitLab, Globus, Nvidia, Singularity Hub, Google Drive, Google Compute, Google Storage, Google Build, Registry, S3, and Swift. If no preference is specified, it defaults to the Singularity Hub client. The function also handles database integration and credential caching.
6737	Function `ipython(args)` provides users with an IPython shell interface, optionally connecting to a specified endpoint. It initializes a client using `get_client()` with the provided endpoint, announces the client type (except for 'get' command), and then embeds an IPython shell for interactive use.
6738	get_manifests retrieves manifests for a repository across different schema versions (v1, v2, and config). It calls _get_manifest for each schema version, and for v2 manifests, it also extracts the config blob. The method stores all retrieved manifests in self.manifests and returns them. If no digest is provided, it uses the latest tag. The function handles both schema version 1 (which includes image layers and metadata) and schema version 2 (which requires additional parsing to get layers and config).
6739	Returns an image manifest for a specified repository and tag by making a GET request to the manifest endpoint with appropriate headers based on the requested version (v1, v2, or config). The method handles version-specific content types and includes error handling to return None if the request fails.
6740	Method `get_download_cache` determines the appropriate cache directory for downloading Docker layers. It first checks for a user-specified destination, falling back to the SINGULARITY_CACHEDIR setting or default cache directory if none is provided. If no destination is set, it uses a temporary directory. The method ensures the destination path ends with the specified subfolder (default 'docker'), creates the necessary directories, and returns the final cache directory path.
6741	Extracts environment variables from the manifest configuration. Returns a string of exported environment variables in the format "export VAR_NAME="VAR_VALUE"", or None if no environment is found. Used by env_extract_image and env_extract_tar functions.
6742	Updates the base URL and API endpoint settings for GitLab integration, including the API base URL, artifacts folder, and job name, then logs these values.
6743	Updates secrets metadata for GitLab operations by retrieving the token and setting the Private-Token header.
6744	Returns a dictionary containing Gitlab metadata including artifacts path, API base URL, base URL, and job ID for user accessibility.
6745	Returns all settings for a specified client if client_name is provided and exists, otherwise returns all settings across clients.
6746	A wrapper method that retrieves and updates a setting, exiting the program with an error message if the setting is not found or is empty.
6747	Update a setting value in the client secrets backend, only if the value is not None.
6748	Authorize a client by generating an HMAC-SHA256 signature for registry operations. Takes client names, optional payload, and request type to create a credential signature for authentication with the registry.
6749	Lists Google Compute Engine builders/instances starting with "sregistry-builder" in a specified project and zone, displaying their names and statuses in a table format.
6750	Loads a particular template based on a name by searching for partial matches in the configuration data and returning the corresponding template objects.
6751	Get the IP address of a specified instance by retrying up to a maximum number of attempts with delays between retries. Returns the external NAT IP address if found, otherwise logs a warning.
6752	Method: run_build

Summary: Executes a build by inserting an instance with retry capabilities on failure. Takes a configuration dictionary as input, retrieves project and zone information, logs the instance creation, inserts the instance via the compute service, retrieves the instance's IP address, and displays a link to the robot logger. Returns the response from the instance insertion operation.

Parameters:
- config: Configuration dictionary generated by setup_build

Returns: Response from the instance insertion operation

Side effects: Logs instance creation messages, displays logger URL, and shows installation waiting message
6753	Returns a list of container objects from a bucket by filtering blobs based on metadata field "type" with value "container". If no containers are found, it logs an info message and returns an empty list.
6754	Method: `search_all`

Summary: This method performs a "list all" search to retrieve all containers from a Google Cloud Storage bucket that have custom metadata with the value "container". It returns a formatted table of container information including size and name.

Key details:
- Lists all containers in the bucket using `_list_containers()`
- Filters results to only include objects with metadata type "container" 
- Formats container sizes in MB
- Displays results in a table format using `bot.table()`
- Returns a list of rows containing [size, name] for each container

Note: This method relies on the upload function having previously added the "container" metadata type to objects for them to be discovered.
6755	The `main` function implements the "list" command for an external resource, distinct from listing local database images. It initializes a client through `get_client`, processes each query parameter (treating empty strings and '*' as None), and calls the `ls` method on the client for each query to display external images.
6756	This function handles the 'sharing an image' functionality by taking an image URI and sharing it with a specified contact. It processes the image through a client interface, detects URIs, and sends a remote share to the provided contact (typically an email address). The function supports sharing multiple images and includes quiet mode for output control.
6757	Initializes the database with the specified path, setting up SQLite database connection and creating all necessary tables. The method configures the database URI, establishes a session factory, and ensures all models are properly registered and created in the database. It uses the provided database path or defaults to a standard location, and sets up the storage backend for managing layers and images.
6758	Returns the default build template by searching for a Singularity build template JSON file in the installation directory. If found, it reads and returns the template content; otherwise, it logs a warning and returns None.
6759	Search for containers in endpoints based on query and endpoint parameters. If no query is provided, lists endpoints. If no endpoint is specified, prompts user to specify one. If both are provided, searches the specific endpoint for containers matching the query pattern.
6760	Lists all available endpoints and displays them in a table format for user selection, returning the endpoint data as rows.
6761	Lists files within a specified endpoint with optional path and query filtering, displaying results in a formatted table with color-coded container contenders.
6762	The `share` method generates a shareable link for a specified image file stored in Dropbox. It takes a query parameter to identify the image and an optional `share_to` parameter. The method first parses the image name from the query, constructs the Dropbox storage path, and checks if the file exists. If the file exists, it attempts to create a shared link using Dropbox's API. If a shared link already exists, it falls back to creating a new one. The method returns the URL of the shared link.
6763	Reads client secrets for private/protected registries from a file or initializes with default secrets if file doesn't exist. Returns the client secrets dictionary.
6764	Method `_get_services` initializes and returns Google Cloud services including storage and compute APIs. It creates a storage client and builds storage and compute services using the discovery API with the specified version (default v1). The method uses application default credentials for authentication and stores the service instances as instance variables (`_storage_service` and `_compute_service`). The method takes an optional version parameter (defaulting to 'v1') and returns the created service objects.
6765	delete_object deletes a file from a specified bucket using the provided storage service. It takes three parameters: storage_service (the service obtained with get_storage_service), bucket_name (the name of the bucket), and object_name (the "name" parameter of the object). The function attempts to delete the object and returns the operation result. If an HttpError occurs during the deletion process, the error is caught and returned instead of the operation result.
6766	delete an image from Google Storage by removing the specified object from the bucket using the storage service, where the object name is extracted from the file object's ID and the bucket name is retrieved from the instance's bucket configuration.
6767	Destroy an instance by stopping its build process and taking it down.

Parameters:
- name: the name of the instance to stop building

Returns:
- The result of the delete operation executed on the compute service

The method first retrieves all instances and checks if the specified instance exists. If found, it logs an info message and deletes the instance using the compute service's delete method.
6768	get_subparsers returns a dictionary of all subparsers from a given parser, indexed by their choice names, to facilitate help text printing and subparser management.
6769	Generate a robot name by combining a descriptor, noun, and random numbers separated by a delimiter. The name format is "descriptor-noun-numbers" where numbers are generated based on specified length and character set.
6770	get a temporary directory for an operation, prioritizing a requested directory or falling back to SREGISTRY_TMPDIR, and create a subfolder with a unique prefix within the temporary directory.
6771	Extracts a tar archive to a specified output folder, with optional whiteout file handling and support for compressed archives.
6772	Extracts a tar archive using the blob2oci tool for handling whiteout files, with error handling for missing dependencies and optional progress output.
6773	Returns the SHA256 hash string of a given file by reading it in 4096-byte chunks and updating the hash digest progressively.
6774	The `read_file` function opens and reads a file with specified parameters. It takes a filename, mode (default "r"), and a flag to determine whether to read all lines or the entire content. The function uses a context manager to ensure proper file handling and returns the file content as either a list of lines or a single string, depending on the `readlines` parameter.
6775	read_json reads a JSON file and returns its contents as a dictionary.
6776	The `clean_up` function deletes a list of files only if they exist. It accepts either a single file path or a list of file paths, checks if each file exists using `os.path.exists()`, and removes it using `os.remove()` if it exists. The function uses `bot.verbose3()` to log cleanup actions.
6777	Pushes an image file to an S3 endpoint with metadata tagging. Takes a file path, image name, and optional tag, validates the file exists, extracts image metadata including size, and uploads the file to S3 with custom metadata for later identification. Returns True on successful upload.
6778	get_or_create_collection(name) retrieves an existing collection by name or creates a new one if it doesn't exist, returning the collection object.
6779	Returns a Collection object by name if it exists in the database, otherwise returns None.
6780	Get a container by name, collection_id, tag, and optional version from the database, returning the container object or None if not found.
6781	Lists local images in the database, optionally filtered by a search query. Returns all matching Container objects.
6782	Method: `inspect(self, name)`

Summary: Inspects a local image in the database by retrieving its container information, extracting basic fields from the model, and printing the details in a formatted JSON structure. The method returns a dictionary containing the image's fields including collection name, metrics (parsed from JSON string), and timestamps, excluding SQLAlchemy internal state.

Parameters:
- `name` (str): The identifier/name of the image to inspect

Returns:
- `fields` (dict): Dictionary containing the image's basic fields including collection name, metrics, created_at timestamp, and other model attributes

Side effects:
- Prints the formatted JSON representation of the image fields to stdout
- Prints the input name parameter

Note: The method handles the conversion of metrics from JSON string to dictionary and timestamp from datetime to string format, while removing internal SQLAlchemy state information.
6783	rename performs a move operation while maintaining the storage path, taking an image name and new path as parameters, and returns the updated container object if successful.
6784	Move an image from its current location to a new path by copying it and removing from original location. Returns the result of the copy operation. If the image is not found, logs a warning.
6785	Remove an image from the database and filesystem.
6786	Adds or updates a container in the registry, creating or retrieving its collection. It supports adding containers from local files or URLs, handles metadata inspection, and manages file storage within the registry. The function ensures the container is uniquely identified by its name, collection, tag, and version, and updates existing containers or creates new ones as needed.
6787	Pushes a Singularity image to a registry by first validating the image path, requiring authentication, parsing the image name to extract metadata, preparing a collection request, and then uploading the image with progress tracking. The method handles errors during path validation, collection creation, and file upload, providing appropriate feedback to the user at each step.
6788	Parse a recipe header by finding a specified key-value pair and optionally removing the key from the result. Returns the complete header line or just the value based on the remove_header parameter.
6789	find_single_recipe parses a single file to find a recipe matching a pattern, returning an updated manifest with recipe information including path and modification time. It uses fnmatch to match filenames against a pattern (defaulting to "Singularity*"), and if a manifest is provided, it only updates entries with more recent files. The function returns either the updated manifest or just the recipe dictionary.
6790	Creates a compressed tar.gz build package from a list of files, hashes the package, and returns the path to the renamed package file.
6791	Run a build by creating it with retry on failure, monitor its status until completion, and upon success update blob metadata and visibility settings.
6792	Updates a blob's metadata with artifact information from a successful Google Build response, including file hash, manifest details, build command, and container identification.
6793	format_container_name takes a name string and removes all non-alphanumeric characters except for specified special characters, returning a lowercase version of the cleaned string.
6794	**Summary:**

The `useColor` method determines whether color should be added to print output by checking user preferences and terminal capabilities. It first retrieves the user's color preference, and if not set, it verifies that both error and output streams are connected to a TTY (terminal) to ensure proper color support. Returns `True` if color should be used, `False` otherwise.
6795	Determines if a given error level should output to stderr. Returns True for all levels except INFO and QUIET.
6796	The `write` method writes a message to a given stream after ensuring proper encoding. If the message is in bytes format, it decodes it from UTF-8 to string before writing to the stream.
6797	The `table` method prints a formatted table with the specified column width. It accepts either a dictionary (where keys become column names) or a list of rows. For dictionaries, it uses the keys as labels and values as data rows. For lists, it creates numbered labels starting from 1. Each row is formatted with left-justified labels and tab-separated values, then displayed using a custom output method.
6798	Pushes a local image to a Globus endpoint by transferring it from a local source endpoint to the specified destination endpoint, ensuring the image exists, a personal endpoint is active, and the destination endpoint has the required cache structure. It uses a transfer client to submit the transfer request.
6799	Returns a default template dictionary for a given function name in sregistry, or None if no template exists. Templates are stored in a dictionary with 'tarinfo' being the only implemented template so far, containing default file metadata (gid, uid, uname, gname, mode). The function converts the input name to lowercase for case-insensitive lookup.
6800	Method: `get_manifest(self, repo_name, tag)`

Summary: Retrieves and returns the image manifest for a specified repository and tag using AWS client. The method first locates the image by querying repository details, then fetches the image manifest using the image digest and tag. The retrieved manifest is stored in `self.manifest` and returned. If the specified image cannot be found, the method exits with an error message.
6801	Returns a build template string for container building, either by name or default template based on package manager (apt/yum). Returns the template content if found, otherwise logs a warning.
6802	The `_update_secrets` method updates client secrets by reading from a credentials file located at `.sregistry` or specified by the `SREGISTRY_CLIENT_SECRETS` environment variable. It retrieves various settings using helper methods, reads all client secrets via `read_client_secrets()`, and handles credential caching by checking if a cache path is enabled through `self._credential_cache`. The method also provides logging information when a credential cache is set.
6803	Generate a repr string for a class by formatting positional arguments and keyword arguments that differ from their default values. Positional arguments are represented as repr strings, while keyword arguments are formatted as `name=value` only when the value differs from its default. Returns a string in the format `ClassName(arg1, arg2, name=value, ...)` where only non-default keyword arguments are included.
6804	Function `s3errors` is a decorator that translates S3 ClientError exceptions into FSErrors. It handles specific S3 error codes like "NoSuchBucket" and HTTP status codes like 404 (ResourceNotFound) and 403 (PermissionDenied), converting them to appropriate custom errors while maintaining original exception information. It also handles SSLError and EndpointConnectionError by converting them to OperationFailed and RemoteConnectionError respectively.
6805	Create a S3File backed with a temporary file.
6806	Builds a Gravatar URL from a user object or email address, returning an empty string if the operation fails.
6807	Builds a Gravatar URL from an email address with optional parameters for size, default image, rating, and security protocol.
6808	Returns True if a user has a Gravatar account, False otherwise. Makes a HEAD request to the Gravatar URL with a 404 default image, and checks if the response code is 200 (OK) to determine if the Gravatar exists. Returns False if any HTTP error or URL error occurs during the request.
6809	Builds a Gravatar profile URL from an email address, using either secure (HTTPS) or insecure (HTTP) protocol based on the secure parameter. Returns the complete URL including the hashed email address.
6810	Generator that yields blocks for a chimera block quotient, producing tuples of coordinates (x, y, u, k) where x ranges from 0 to M-1, y ranges from 0 to N-1, u is either 0 or 1, and k ranges from 0 to L-1.
6811	Creates a block-quotient graph from a graph and its blocks by contracting nodes within each block and connecting blocks based on edge relationships between their constituent nodes.
6812	Returns a set of resonance forms as SMILES strings for a given SMILES string by enumerating all possible resonance structures.
6813	Enumerate all possible resonance forms of a molecule and return them as a list.

**Parameters:**
- `mol`: The input molecule (rdkit.Chem.rdchem.Mol)

**Returns:**
- A list of all possible resonance forms of the molecule (list of rdkit.Chem.rdchem.Mol)

**Behavior:**
The method uses Chem.ResonanceMolSupplier with configured flags to generate resonance forms based on various enumeration parameters (kekule_all, allow_incomplete_octets, allow_charge_separation, unconstrained_anions, unconstrained_cations). Each result undergoes sanitization before being added to the results list. The enumeration respects the max_structures limit.
6814	Normalize a molecule by applying a series of normalization transforms to correct functional groups and recombine charges, handling fragments separately and then recombining them into a single normalized molecule.
6815	Repeatedly applies a normalization transform to a molecule using the given rule until no further changes occur or 20 attempts are made. Returns the final molecule after all possible transformations, or None if the rule was not applicable. If multiple products are generated, the first one (alphabetically by SMILES) is selected.
6816	Return a canonical tautomer by enumerating and scoring all possible tautomers. The canonical tautomer is determined based on a scoring system that considers aromatic rings, SMARTS patterns, and (P,S,Se,Te)-H bonds. If only one tautomer is found, it is returned directly. Otherwise, the tautomer with the highest score (and alphabetically first SMILES if scores are equal) is returned.
6817	Validates a SMILES string using default validations and returns a list of log messages. Uses the Validator class internally for checking molecule validity.
6818	Disconnects covalent bonds between metals and organic atoms according to specific rules, adjusts atomic charges accordingly, and returns the modified molecule.
6819	Standardize a SMILES string to its canonical form using the molvs library's Standardizer class, returning an isomeric SMILES representation.
6820	Returns a set of tautomers as SMILES strings for a given SMILES string by standardizing the input molecule and enumerating all possible tautomers.
6821	Return a standardized canonical tautomer SMILES string given a SMILES string by using Standardizer and TautomerCanonicalizer classes.
6822	Standardizes a molecule through a series of processing steps: sanitization, hydrogen removal, metal disconnection, normalization, reionization, and stereochemistry assignment. Returns the processed molecule.
6823	Returns the tautomer parent of a given molecule by first standardizing it (if not skipped), then canonicalizing and standardizing the tautomer result.
6824	Return the fragment parent of a given molecule, which is the largest organic covalent unit in the molecule. If skip_standardize is False, the molecule is standardized first. The fragment parent is obtained by getting the largest fragment from the molecule.
6825	Return the stereo parent of a given molecule by removing all stereochemistry information from tetrahedral centers and double bonds. If skip_standardize is False, the molecule is first standardized. The function returns a new molecule object with stereochemistry removed.
6826	Return the isotope parent of a given molecule by replacing all atoms with their most abundant isotopes. If skip_standardize is False, the molecule is first standardized. All atom isotopes are set to 0 (most abundant isotope) and the modified molecule is returned.
6827	Return the charge parent of a given molecule by first standardizing it (if not skipped), then getting its fragment parent, removing charges, and finally standardizing again to ensure proper charge distribution.
6828	Return the super parent of a given molecule by applying a series of transformations: charge parent, isotope parent, stereo parent, tautomer parent, and standardization. The super parent is fragment, charge, isotope, stereochemistry and tautomer insensitive.
6829	This code defines a command-line interface for the molvs molecular validation and standardization tool. It uses argparse to create a root parser with subcommands for 'standardize' and 'validate'. The interface supports input from files or SMILES strings, and can output to files or stdout. Both subcommands share common arguments for input/output handling, while the standardize command also supports output format specification. The main function parses arguments and executes the appropriate command function, with error handling for exceptions during execution.
6830	Remove specified fragments from a molecule by iteratively applying FragmentPattern patterns. Returns the modified molecule with fragments removed. If leave_last is True, stops when only one fragment remains. Logs information about removed fragments.
6831	Return the largest covalent unit from a molecule by counting atoms (including hydrogens), preferring organic fragments when configured, and breaking ties by molecular weight and SMILES alphabetically.
6832	Function to integrate an IVP problem of van der Pol oscillator with adaptive or predefined time stepping, optionally plotting the results.
6833	Retrieves GitHub organization statistics for a given organization using provided credentials. The method checks if data already exists in a CSV file and skips retrieval if `force` is False. It logs into GitHub, fetches organization details including members, teams, and repositories, writes the data in JSON and CSV formats to specified paths, and tracks API call usage. The CSV file is saved with a path structured by year, month, and date.
6834	Retrieves the number of members of the organization by iterating through members, storing their JSON representations in `members_json`, and returning the total count.
6835	Retrieves the number of teams in the organization by iterating through teams, storing each team's JSON representation in `teams_json` dictionary, and returns the total count of teams.
6836	Retrieves repository information for a given organization, calculating totals for contributors, forks, stars, pull requests, issues, and commits while storing both JSON data and formatted repository objects.
6837	Retrieves the number of contributors to a repository and tracks them in the organization's unique contributor list and JSON data structure. Returns the total count of contributors for the specified repository.
6838	Retrieves the number of open and closed pull requests for a given repository, storing all pull request data in JSON format within the instance's pull_requests_json dictionary. Returns a tuple containing the count of open pull requests and closed pull requests.
6839	Retrieves the number of closed issues for a given repository, handling cached data and date-based filtering to efficiently fetch only new issues since the last retrieval.
6840	Checks if a repository has a README file, returns 'MD' if found, otherwise searches for README and returns the file path or 'MISS' if not found. Implements rate limiting with sleep functionality.
6841	**Summary:**

The `get_license` method checks if a given repository has a top-level LICENSE file by searching for files named "license" in the repository's path. It includes rate limiting functionality that pauses execution after 28 searches and resets the search limit. The method returns the path of the LICENSE file if found, or 'MISS' if not found. The search is performed using GitHub's code search API with a query that looks for files containing "license" in the path within the specified repository.
6842	Retrieves the number of commits for a repository in an organization, loading all commits if it's the first time or only new commits since the last saved date, and returns the total commit count.
6843	Writes organization statistics to a JSON file with optional list formatting. Creates directory if needed, clears existing data, and formats JSON with indentation. Handles both regular dictionaries and lists of items, removing trailing commas and adding proper JSON array syntax when needed.
6844	Updates the total.csv file with current data, writing headers if the file doesn't exist, removing the last line if it exists, and appending a new line with aggregated statistics including date, organization, repository counts, contributor metrics, and various repository activity indicators.
6845	Writes language data to a CSV file with date, language, count, size, and log size columns, handling missing or invalid data gracefully.
6846	Creates a directory if it doesn't exist, using the directory path from the provided file path. Raises an exception if directory creation fails due to reasons other than the directory already existing.
6847	Removes all rows with a specific date from a CSV file, defaulting to today's date. Creates a temporary file with matching rows filtered out, then replaces the original file with the filtered content.
6848	Returns a list of names of US Government GitHub organizations by fetching data from the government.github.com community page, including federal government, military/intelligence, and research lab organizations.
6849	Create a github3.py session for a GitHub Enterprise instance, using an optional token or defaulting to the GITHUB_API_TOKEN environment variable. Raises a RuntimeError if connection fails.
6850	Summary: Checks GitHub API rate limits and pauses execution when limits are nearly depleted, waiting for the API to reset before continuing.
6851	Creates a GitHub session for making requests to either GitHub.com or GitHub Enterprise based on the provided URL and token. Returns a session object or raises a RuntimeError if connection fails.
6852	Function `query_repos` yields GitHub repository objects based on provided organizations and repository names. It supports three modes: querying specific organizations with public repositories, querying specific repositories by name, or fetching all repositories if neither organizations nor repositories are specified. The function respects API rate limits and can return either public repositories only or all accessible repositories based on the `public_only` parameter.
6853	Retrieves an organization by name, prompting user for input if name is empty, and stores the retrieved organization object.
6854	Writes stargazers data to a file with columns 'date', 'organization', and 'stargazers', sorting the stargazers alphabetically by name.
6855	Creates a CodeGovProject object from a GitLab repository by extracting required and optional fields, setting project properties like name, URL, description, and metadata, and handling labor hours and licensing information.
6856	Create a CodeGovProject object from a DOE CODE record by mapping required and optional fields, handling licenses, setting usage type based on open source status, and inferring version control system from the repository URL.
6857	A helper function to look up license object information from a given license name, returning a dictionary with the license URL and standardized name. Raises a ValueError if the license is not recognized.
6858	Retrieves traffic data for all public repositories in the organization, including referrers, paths, views, clones, and release information.
6859	Retrieves releases for a given repository from the specified URL and stores the JSON response in the releases_json dictionary with the repository name as the key.
6860	Retrieves referrers data for a repository by fetching traffic information from a given URL, stores the raw JSON data, and aggregates referrer statistics (total count and unique visitors) into dictionaries organized by referrer name and lowercase referrer name.
6861	Retrieves data from a JSON API endpoint and stores it in a supplied dictionary. Accepts 'clones' or 'views' as the data type, fetches traffic data from the specified URL with provided headers, and processes the JSON response to accumulate view counts and unique viewers per timestamp. The method handles both JSON storage for later use and CSV-like data processing by aggregating counts for each timestamp, excluding the current day's data. Returns the updated dictionary with accumulated data.

Key parameters:
- url: The base URL for the API endpoint
- headers: HTTP headers for the request
- date: The current date (defaults to today)
- dict_to_store: Dictionary to store accumulated data
- type: Type of data to retrieve ('clones' or 'views')
- repo_name: Repository name for JSON storage

The method processes timestamped data and aggregates counts by converting timestamps to dates, excluding today's data, and updating the dictionary with cumulative counts and unique views.
6862	Writes traffic data to JSON files for each repository. For each non-empty repository in the input dictionary, creates a JSON file with the specified date and organization structure, including proper directory creation and formatted JSON output with indentation.
6863	Writes traffic data to specified files, including referrers, views, and clones data with corresponding row counts.
6864	Checks a CSV file against JSON data to remove redundant entries. Reads through the CSV file, compares timestamps with the provided dictionary, and deletes matching entries from the dictionary. Returns the total count of rows in the CSV file.
6865	Writes a dictionary's data to a CSV file with date, organization, and formatted values, creating the file with headers if it doesn't exist, and appending each dictionary entry as a new row with an incrementing ID.
6866	Writes referrers data to a file with specified path, date, and organization, including logarithmic calculations for count and uniques values.
6867	Processes a DOE CODE JSON file and yields individual project records from the 'records' field of the loaded JSON data.
6868	Function `process_url` fetches DOE CODE JSON data from a given URL using an API key, parses the JSON response, and yields individual records from the 'records' field. It raises a ValueError if the API key is missing and uses basic authentication with the provided key.
6869	Function that yields DOE CODE records from either a local JSON file or a remote server URL using an API key.
6870	Logs into GitHub using provided credentials or prompts user for credentials if none provided. Stores authentication token in CREDENTIALS_FILE for future logins and handles Two Factor Authentication. If credentials are invalid, prompts user to try again.
6871	Retrieves public email addresses of organization members, handling cases where emails are private or unavailable by storing 'none' for missing emails.
6872	Writes user emails to a file in CSV format with columns 'user' and 'email', sorted by username in lowercase order.
6873	Return a connected Bitbucket session by connecting to the specified URL with the given username and password, and log the connection information.
6874	Connect to GitLab API and return a session object.

This function establishes a connection to a GitLab instance using either a provided token or a token from the GITLAB_API_TOKEN environment variable. It validates the connection by checking the GitLab version and raises a RuntimeError if authentication fails. The function accepts an optional URL parameter (defaulting to 'https://gitlab.com') and returns a authenticated GitLab session object that can be used for further API interactions.
6875	Generator function that yields Gitlab project objects either for specified repositories or all projects in the Gitlab session.
6876	Returns the number of lines of code (SLOC) for a given Git repository URL by cloning the repository and analyzing it with cloc tool. Uses temporary directory for cloning and handles JSON parsing errors gracefully by returning 0 SLOC on failure.
6877	Computes labor hours for a given number of source lines of code (SLOC) using the COCOMO II model. Takes SLOC and an optional parameter for hours per month (defaults to COCOMO II book value of 152.0). Makes a POST request to the COCOMO II calculator website, extracts the effort estimate using regex, and calculates total labor hours by multiplying person-months by hours per person-month. Returns the computed labor hours.
6878	Prune the "None" or empty string values from dictionary items, recursively processing nested dictionaries.
6879	Reads a 'pretty' formatted GraphQL query file and returns it as a single-line string with comments and extra whitespace removed.
6880	Submit a GitHub GraphQL query from a file, returning a JSON style dictionary response.
6881	Submits a query to the GitHub API using curl, supporting both GraphQL and REST endpoints. It handles authentication, query formatting, and response parsing including headers and pagination data. Returns a dictionary containing the HTTP status code, response headers, pagination information, and result body.
6882	Wait until the given UTC timestamp by calculating the time difference and countdowning the seconds. Print verbose output showing current and target timestamps, then perform a countdown waiting for the specified time.
6883	Creates a visual countdown timer that displays a formatted message showing remaining seconds. The countdown runs for a specified number of seconds (or defaults to a retry delay), updating the display every second. The message format can be customized using a print string template, and verbose output can be enabled/disabled to control extra print statements. The timer uses backspacing characters to overwrite the same line, creating a smooth countdown animation.
6884	Load a JSON data file into the internal JSON data dictionary, overwriting current data. If no file path is provided, uses the stored data file path. Raises FileNotFoundError if the file doesn't exist. Prints import status and updates the stored file path if specified.
6885	Writes the internal JSON data dictionary to a JSON file. If no file path is provided, uses the stored data file path. Creates the file if it doesn't exist and optionally updates the stored file path.
6886	Creates a TFS connection context using the provided URL and token, falling back to environment variable if token is None.
6887	Creates a ProjectAnalysisClient for Team Foundation Server Enterprise connection to analyze project languages, using provided token or environment variable TFS_API_TOKEN.
6888	Create a core client for Team Foundation Server Enterprise connection. If no token is provided, attempts to use the TFS_API_TOKEN environment variable. Returns a CoreClient instance or raises RuntimeError if connection fails.
6889	Creates a TFS Git Client for accessing Git repository information by establishing a connection using either a provided token or environment variable token, and returns the configured Git client object. Raises a RuntimeError if client creation fails.
6890	Creates a TFS TFVC Client for accessing TFVC repository information by establishing a connection using the provided URL and token, raising a RuntimeError if the client creation fails.
6891	Returns a list of all git repos for the supplied project within the supplied collection by creating a TFS git client and retrieving repositories using the project ID.
6892	Returns a list of all TFVC branches for a specified project within a collection by creating a TFVC client, retrieving branches using the client, and returning the branch list.
6893	Gets year-long commit statistics from GitHub for an organization, handles authentication and rate limiting, waits for GitHub to build statistics, then writes the data to a CSV file.
6894	Calculates total commits by traversing weekly commit data from most recent to oldest, subtracting weekly commits from cumulative total and storing updated values. Requires initial commit count from GitHub stats.
6895	Writes weekly commit data to a CSV file, including formatted dates and commit counts while avoiding duplicate entries.
6896	Instantiates and configures multiple metrics backends based on provided configuration. Takes a list of backend dictionaries specifying class paths and options, imports/instatiates the backend classes, and sets them up for metric collection. Supports both string class paths (dotted notation) and direct class objects. Optionally raises exceptions on configuration errors or logs them instead. Updates the global metrics interface with the newly configured backends.
6897	Returns a MetricsInterface instance with a specified name prefix. The name is constructed based on the input thing (class, instance, or string) and optional extra information. The interface uses the provided name as a prefix for all metric keys but is not tied to specific metrics backends, which are configured globally. This allows creating metrics interfaces without worrying about application bootstrapping order.
6898	Records a timing value to track execution duration of operations. This method logs timing measurements in milliseconds that are collected to form statistical distributions (like count, average, median, 95%, and max) for analysis. It's commonly used to monitor performance metrics such as function execution time, file uploads, or database query durations. The method accepts a metric key, timing value, and optional tags for categorization. Timing values are recorded through configured backends and can be conveniently accessed using the `timer` method or `timer_decorator` for function-level timing.
6899	A context manager for easily computing timings of code blocks, measuring execution time in milliseconds and reporting it using the metrics system. Returns the elapsed time in milliseconds.
6900	Timer decorator that wraps a function to measure and record execution time metrics. Takes a statistic key and optional tags, returns a decorator that times function execution using the instance's timer method and records the duration in milliseconds.
6901	Generate a tag for use with tag backends by sanitizing key and value according to specific rules, ensuring the final tag starts with a letter, is lowercase, truncated to 200 characters, and has a "_" appended if it's a reserved word.
6902	Report a timing statistic with optional tags.
6903	Reports a histogram statistic with optional tags.
6904	Roll up statistics and log them at regular intervals. Logs incrementing counters, gauge values, and histogram data with various statistics like count, min, max, average, median, and 95th percentile. Clears all stats after logging.
6905	Create an annotation value for sorting by an enum field, where members are ordered according to a specified sequence. Takes a field name and iterable of enum members, returning a Case statement that assigns integer priorities to each member for ordering, with unspecified members defaulting to the end of results.
6906	Converts a string value from the database into an Enum instance using the enum mapping.
6907	Convert a string from a form into an Enum value. Returns the enum value if conversion is possible, otherwise raises an exception. Handles None values and existing enum instances by returning them as-is.
6908	Convert an Enum value into a string for database storage by returning the enum's name attribute, or None if the value is None. Raises ValueError for unknown value types.
6909	Resolves a path within an object by navigating through different object types (Text, Fact, Theory, Topic) and their properties, returning a set of matching elements based on the path's index and kind specifications.
6910	Function `project_usls_on_dictionary` takes an iterable of USLs and optionally a set of allowed terms, then returns a mapping from table terms to their associated USLs. It first builds a mapping from cells to USLs by iterating through each USL's terms and their singular sequences. If allowed terms are specified, it filters both the tables and the cell-USL mapping to only include allowed terms. Finally, it constructs and returns a dictionary mapping each table to the list of unique USLs associated with its singular sequences, excluding TableSet instances.
6911	Returns the mean value by dividing the sum by the counter, or 0.0 if counter is zero.
6912	Record an event with the meter, incrementing the counter and updating all three moving average rates (1-minute, 5-minute, and 15-minute) with the specified value.
6913	Returns the mean rate of events since the process started by dividing the event counter by elapsed time.
6914	Record an event with the derive, adjusting the value based on the last recorded value to compute a delta increment.
6915	Sends a metric and its snapshot by serializing them with corresponding configuration and buffering the serialized data for later transmission.
6916	Serializes a metric by formatting its attribute values into strings based on specified keys and metric type.
6917	Format a metric string in statsd compatible format with optional prefixing.
6918	Adds a metric to the buffer and sends the batch when the buffer reaches the configured batch size threshold.
6919	Get method that retrieves configuration values and raises MissingSetting if the value is unset, handling both NoOptionError and NoSectionError exceptions from the parent class.
6920	Converts data to UTF-8 string format for JSON processing, handling potential Unicode encoding errors.
6921	Returns the value of a configuration option from the specified section, or sets and returns a default value if the option doesn't exist.
6922	Converts a set of human-readable ledger codes into a dictionary mapping each code to its corresponding ExactOnline GUID. Takes a list of codes, fetches the corresponding ledger account records from the API, and returns a dictionary with code-GUID pairs. Raises UnknownLedgerCodes exception if any codes are not found in ExactOnline.
6923	Get the current division and return a dictionary of all divisions with their codes and descriptions for selection, along with the current division ID.
6924	Maps ExactOnline invoice numbers to foreign (YourRef) invoice numbers, either for all invoices or a provided list, handling batch processing for large lists.
6925	Solve a Sudoku grid in-place using SAT solving. The function generates CNF clauses representing Sudoku constraints, adds unit clauses for known digits, solves the SAT problem using pycosat, and updates the grid with the solution digits. The solution is read back from the SAT solution set and written back to the original grid structure.
6926	Creates a Django class-based view from an injector class by generating a handler, applying HTTP methods, and returning the view function.
6927	Creates a Django class-based view for form processing by combining a form handler with injected dependencies and applies form-specific methods to the handler.
6928	Create a Flask method-based dispatching view from an injector class by creating a handler, applying HTTP methods, and returning the view with the handler's as_view method.
6929	Creates a Django REST Framework class-based API view from an injector class by creating a handler, applying HTTP methods, applying API view methods, and returning the view function.
6930	Creates a Django REST Framework generic class-based API view from an injector class by assembling handler methods and configuring HTTP and API view behaviors.
6931	Creates a Django REST Framework model view set from an injector class by applying various handler methods and returning the configured view set.
6932	Creates a stream reader and transport from a file descriptor for asynchronous I/O operations.
6933	Method `_read_ready(self)` is called by the event loop when a file descriptor is ready for reading. It attempts to read data from the file descriptor using `os.read()`. If interrupted, it silently continues. If an OS error occurs, it calls `_fatal_error()` to handle the fatal error. On successful read, if data is received, it passes the data to the protocol's `data_received()` method. If no data is read (end-of-file), it pauses reading, notifies the protocol of EOF via `eof_received()`, and schedules connection cleanup via `_call_connection_lost()`.
6934	Closes the connection gracefully, called both manually and on errors, by pausing reading and scheduling connection loss notification.
6935	Finalizes the connection closing process by calling the protocol's connection_lost method, then closes the file descriptor and clears all internal references.
6936	Add a new watching rule for the specified path with given flags, optionally with a custom alias. Raises ValueError if a watch request already exists for the alias. If the watcher has already started, the watch is registered immediately.
6937	Stop watching a given rule by removing the inotify watch descriptor and cleaning up associated data structures. Raises ValueError for unknown aliases and IOError if watch removal fails.
6938	Method `_setup_watch` sets up an inotify watch rule by registering an alias for a file path with specified flags. It first asserts that the alias is not already registered, then calls the C library's `inotify_add_watch` function to create the watch. If successful, it stores the watch descriptor in `self.descriptors` with the alias as key, and maps the watch descriptor back to the alias in `self.aliases`. If the watch setup fails (returns negative wd), it raises an IOError with descriptive error information.

Example usage:
```python
self._setup_watch("my_alias", "/path/to/file", IN_MODIFY | IN_ACCESS)
```

This would register a watch on `/path/to/file` with flags for monitoring modification and access events, associating it with the alias "my_alias".
6939	Initialize inotify watcher and set up file system watches.
6940	Fetches and returns an event from a stream, skipping events for removed watches. This coroutine reads a prefixed event header containing watch descriptor, flags, cookie, and path length, then reads the path data. If the watch descriptor is valid (not removed), it decodes the path and returns an Event object with the event data and associated alias. If the stream is closed, it returns None. If the event is for a removed watch, it skips the event and continues waiting for the next one.
6941	Method `touch()` responds to `nsqd` to request more time for message processing. It asserts that no response has been sent yet, then triggers a TOUCH event with the message.
6942	Update the timer to reflect a successful call by decreasing short and long intervals and updating the interval.
6943	When a call fails, this method increases both short and long retry intervals by their respective time units, caps them at maximum timer values, and updates the actual timer interval.
6944	Closes all database connections and stops periodic callbacks (Redis and query if exists).
6945	Returns True when the reader is starved and should process buffered messages. A reader is considered starved when any connection has in-flight messages exceeding 85% of its current ready count, indicating that messages are being processed faster than they're being sent, which may cause bottlenecks when batching messages together for work. This helps determine when to perform work on buffered messages when max_in_flight > 1.
6946	Connects to an nsqd instance at the specified host and port, setting up event handlers and managing connection attempts with rate limiting.
6947	Method: `query_lookupd`

Summary: Triggers a query to the configured NSQ lookupd HTTP addresses by constructing a proper HTTP request with the topic parameter and making an asynchronous GET request to the lookupd endpoint.

Key functionality:
- Rotates through configured lookupd addresses using round-robin indexing
- Ensures proper URL formatting with HTTP scheme if missing
- Constructs lookup endpoint URL with topic parameter
- Makes asynchronous HTTP GET request with proper headers
- Uses callback mechanism to handle response processing
- Configures connection and request timeouts
- Implements version-specific Accept header for NSQ API
6948	Set the maximum number of in-flight messages for the reader, with 0 disabling the reader immediately. When setting to 0, resets RDY counts for all connections. When setting to other values, marks RDY state for redistribution.
6949	Called when a message has exceeded maximum retry attempts, logs a warning message with details about the message and its attempt count.
6950	Register a callback function to be executed when a specific event is triggered. Raises DuplicateListenerError if the callback is already registered for the event.
6951	Remove a callback from the list of listeners for a specific event name. Raises InvalidListenerError if the callback is not found in the listeners list.
6952	Execute callbacks for listeners on a specified event with supplied arguments.
6953	Publish a message to NSQ topic with optional callback function.
6954	Sets the feature transformation mode and degree for the training data, applies the transformation, and returns the transformed data.
6955	Make prediction on input data using trained model parameters. For future data, returns prediction only. For test data, returns prediction along with actual y value. Requires trained model (W) and valid input data. Returns dictionary with input features, actual y (if available), and prediction result.
6956	Theta sigmoid function implementation that computes 1/(1 + e^(-s)), with numerical stability threshold at -709 to prevent overflow.
6957	Parses a Trimmomatic log file to extract trimming statistics including clean length, total trimmed bases, percentage trimmed, and 5'/3' end trimming details. Returns an OrderedDict with keys: 'clean_len', 'total_trim', 'total_trim_perc', '5trim', '3trim', and 'bad_reads'.
6958	Cleans the working directory by removing temporary FASTQ files. Removes unpaired FASTQ files ending with "_U.fastq.gz" and optionally removes temporary input FASTQ files matching a specific pattern when the 'clear' parameter is "true" and exactly 2 expected output files exist. Uses realpath to get actual file paths and removes files that match the temporary work directory pattern.
6959	Merges all adapter files from the trimmomatic adapters directory into a single fasta file named "default_adapters.fasta" in the current working directory, and returns the path to this merged file.
6960	Main executor of the trimmomatic template that performs quality trimming on paired-end FASTQ files using Trimmomatic. It handles PHRED score detection, adapter trimming with customizable sliding window and quality-based trimming options, and manages output files and cleanup based on provided parameters. The function logs execution details, handles error cases, and updates status files accordingly.
6961	Function that parses a samtools depth file and creates a dictionary with coverage per position for each plasmid. Takes a file path as input and returns a dictionary with reference sequences as keys and nested dictionaries of position-coverage pairs as values.
6962	Function that handles inputs to parse bowtie depth files and generates JSON output for pATLAS import, including coverage statistics and plot data based on a specified cutoff value.
6963	Sets the path to the appropriate Jinja template file by constructing the full path from the template argument and checking if the file exists. Raises a ProcessError if the template file is not found, otherwise stores the template path in the instance variable `_template_path`.
6964	Sets the main channel names by combining a template with provided suffixes and assigns the lane number to the process.
6965	Returns the main raw channel information for a process given an input channel name. Looks up the channel info in RAW_MAPPING using the input type (either provided or from process' input_type attribute). Returns a dictionary containing channel details including the raw channel name, specification string, and params, or None if no matching channel is found.
6966	Wrapper to the jinja2 render method from a template file

Parameters:
----------
template : str
    Path to template file.
context : dict
    Dictionary with kwargs context to populate the template

Returns:
-------
str
    Rendered template as string
6967	Class property that returns a populated template string by rendering a template file with the current context, raising an error if channels haven't been set up first.
6968	Sets the main channels for a process by configuring input/output channels, status channels, and fork connections based on process ID and provided keyword arguments, while also handling process-specific context information.
6969	Updates the forks attribute by adding a sink channel destination to the main forks list and modifies the output channel name. If main_forks is empty, it initializes it with the current output_channel and renames the output_channel. Then it appends the sink to main_forks, sets the operator to "set" if there's only one fork or "into" if there are multiple forks, and updates the forks list with a formatted string containing the output_channel, operator, and all forks. Finally, it updates the context with the new forks and output_channel values.
6970	Sets a secondary channel by creating forks from a source channel to multiple destination channels, handling special cases for main channels to prevent output overlap. The method appends fork definitions to the Process.forks attribute using either 'set' or 'into' operators based on the number of destination channels, and updates the context with the new forks configuration.
6971	Updates the directives attribute from a dictionary object, only modifying directives for processes that have been defined in the subclass. Valid directives include "pid", "ignore_type", "ignore_pid", "extra_input", "group", and "input_type". The "params" attribute is handled specially, updating default values for existing parameters. Other attributes are applied to all directives in the process.
6972	Sets the input channels for the status process using specified operator to combine multiple channels. Supports 'mix' and 'join' operators for combining status channels, with 'mix' creating a mix operator string and 'join' creating a join operator string with mapping. Raises ProcessError if no channels are provided.
6973	Sets the main input channels of the pipeline and their forks using a raw input dictionary. The method processes each input type to update pipeline parameters, create channel definitions, and establish fork relationships between channels. It logs the raw input processing and updates internal attributes including forks and main inputs context.
6974	Sets secondary inputs for the pipeline by adding channel strings from a dictionary to the context under the "secondary_inputs" key.
6975	**Summary:**

The `set_extra_inputs` method initializes extra input channels for a process by configuring parameter definitions and channel assignments based on a provided dictionary. It maps input types to raw channel configurations, sets default values and descriptions for parameters, creates channel assignment statements, and updates the context with extra input definitions. The method handles both single and multiple channel assignments for each parameter.
6976	Parse coverage value from header string by splitting on "_" and searching backwards for the first float value, returning None if no float is found.
6977	Parse an assembly fasta file and populate the Assembly.contigs attribute with contig data, including GC content and proportions, while handling sequence parsing, coverage extraction, and temporary storage management.
6978	Get GC content and proportions for a DNA sequence.

Parameters:
----------
sequence : str
    The complete sequence of the contig
length : int
    The length of the sequence contig

Returns
-------
x : dict
    Dictionary with the at/gc/n counts and proportions
6979	Filters contigs in an assembly based on specified comparisons and stores filtered IDs and results in `filtered_ids` and `report` attributes respectively.
6980	Returns the total length of the assembly by summing the lengths of all contigs that are not in the filtered IDs list.
6981	Writes the assembly to a file, optionally filtering out filtered IDs. If filtered=True (default), contigs with IDs in self.filtered_ids are excluded from the output file. Each contig is written in FASTA format with header ">sample_header" and its sequence. The output is written to the specified output_file path.
6982	Writes a test report for the current assembly to the specified output file, containing contig IDs and their corresponding values.
6983	Removes nested brackets from fork strings using recursive regular expression substitution, returning only processes that belong to a given fork by eliminating inner fork structures.
6984	This function performs sanity checks on a pipeline string to ensure proper fork syntax. It identifies all forks (substrings enclosed in parentheses), verifies that each fork contains at least one lane separator token '|', and checks for duplicated processes within the same fork. The function raises a SanityError if any fork is missing the required '|' separator, providing the problematic fork as context.
6985	Wrapper that performs all sanity checks on the pipeline string by executing multiple validation functions against both the cleaned and original pipeline strings.
6986	Parses a pipeline string into a list of dictionaries representing process connections, handling both linear and forked pipeline structures with unique identifier management for process tracking.
6987	Returns the lane number of the last process in the pipeline that matches the given fork process signature. The function searches backwards through the pipeline list to find a matching process, then verifies that the entire lane sequence matches the fork signature. If a match is found, it returns the lane number; otherwise, it returns 0.
6988	Parses a pipeline string after a fork split to extract lanes, ignoring nested forks. Returns a list of lists where each inner list contains processes for a lane.
6989	Connects a linear list of processes into a list of dictionaries representing links between consecutive processes in the same lane.

Parameters:
- plist: List with process names (at least two entries)
- lane: Corresponding lane number for all processes

Returns:
List of dictionaries containing input/output process links with lane information
6990	Summary: The `fork_connection` function establishes connections between a source process and multiple sink processes in a lane-based system. It creates links from the source process to each sink process, with the source lane remaining constant while the sink lanes increment sequentially starting from `lane + 1`. The function returns a list of dictionaries representing these process connections, each containing input and output process-lane pairs.
6991	The `add_unique_identifiers` function processes a pipeline string to replace duplicate process names with unique identifiers by appending numeric suffixes. It returns the modified pipeline string and a dictionary mapping each new unique identifier back to its original process name. The function uses regular expressions to identify process names and tokens, ensuring proper spacing around special characters for accurate replacement.
6992	Removes unique identifiers from parsed pipelines and replaces them with original process names based on the provided mapping.

Parameters:
- identifiers_to_tags: dict mapping unique process identifiers to original process names
- pipeline_links: list of parsed pipelines containing unique identifiers

Returns:
- list: Pipeline list with original process names instead of unique identifiers
6993	Checks whether the trace and log files are available, raising InspectionError if either file cannot be opened or found.
6994	Parses the trace file header and retrieves the positions of each column key, returning a dictionary mapping column IDs to their positions.
6995	Converts a hms (hours/minutes/seconds) string into seconds, supporting formats like '20s', '1m30s', '300ms', and combinations with days. Handles special case where input is "-" by returning 0. Returns time in seconds as a float.
6996	Converts size string into megabytes by parsing unit suffixes (KB, MB, GB, TB) and performing appropriate unit conversions. Returns the size in megabytes as a float.
6997	Parses the .nextflow.log file to extract process information and pipeline details. Retrieves process names from "Creating operator" log lines, filters out blacklisted processes, and populates process metadata including barriers, resource usage, and tags. Also extracts pipeline name and tag from launch statements. Results are stored in self.processes, self.process_tags, self.pipeline_name, and self.pipeline_tag attributes.
6998	Clears inspect attributes when re-executing a pipeline by resetting tracking variables and cleaning up process barrier statuses.
6999	Method `_update_barrier_status` reads from a log file to monitor barrier status updates across processes. It parses log lines to detect when processes reach a barrier point, extracts process names using regex, and updates their barrier status to "C" (complete) in the processes dictionary. The method stops processing if it encounters a "Session aborted" signal.
7000	Method that retrieves contents of a log file into a list of lines, returning None if file doesn't exist.
7001	Assess whether CPU load or memory usage exceeds allocation limits for process traces.

Parameters:
- process (str): Process name
- vals (list): List of trace information for each tag of that process

Returns:
- cpu_warnings (dict): Tags with excessive CPU load (keys are tags, values contain expected and actual CPU load)
- mem_warnings (dict): Tags with excessive memory usage (keys are tags, values contain expected and actual RSS)

The method compares actual CPU load against 90-110% of expected load and actual memory usage against 110% of allocated memory, reporting warnings for any resource usage exceeding these thresholds.
7002	Updates process statistics by analyzing trace file data, including completion counts, average runtime, CPU hours, resource warnings, and memory/io statistics for each process.
7003	Method that parses the Nextflow log file to update the submitted number of samples for each process, using regex to extract process information and managing process states including submission, retries, and barriers.
7004	Wrapper method that continuously updates inspection class attributes from trace and log files by calling parser methods, with retry logic for file operations and duplicate entry handling.
7005	Displays a curses-based pipeline inspection overview with keybindings, updates inspection data, and handles file not found errors during the inspection process.
7006	Provides curses scroll functionality by moving the view up or down within the content boundaries.
7007	Method `_rightleft` manages horizontal padding for curses display by adjusting the padding value based on direction and screen constraints. When moving left, it decreases padding if not already zero. When moving right, it increases padding only if the screen width plus padding is less than the maximum allowed width.
7008	Returns a list with the last `n` lines of the nextflow log file.

Parameters:
n : int
    Number of last lines from the log file (default: 300)

Returns:
list
    List of strings with the nextflow log lines
7009	Prepares the first batch of static information for a POST request, including pipeline file and configuration files.

Returns a dictionary containing static information with keys:
- "pipelineFile": contents of the pipeline file
- "configFile": contents of nextflow.config (if exists)
- "paramsFile": contents of params.config (if exists)
- "resourcesFile": contents of resources.config (if exists)
- "containersFile": contents of containers.config (if exists)
- "userFile": contents of user.config (if exists)
7010	Function that opens the dotfile named .treeDag.json in the current working directory and returns it as a dictionary. If the file is not found or is corrupted, it logs a warning and returns an empty dictionary.
7011	Gets the hash of the nextflow file by combining:
1. MD5 hash of the pipeline file content
2. MD5 hash of workdir, hostname, and hardware address
Returns concatenated hexdigest of both hashes
7012	Gets the nextflow file path from a nextflow log file by searching for the nextflow run command. Reads through the log file line by line until it finds a line containing a nextflow pipeline file name (ending in .nf) and returns that path. Raises a LogError if no nextflow command path is found in the log file.
7013	Main executor of the split_fasta template that splits a fasta assembly file into individual contig files based on minimum size threshold. Takes sample ID, assembly file path, and minimum contig size as parameters. Reads fasta file, groups entries by header and sequence, filters contigs by size, and writes qualifying contigs to separate fasta files with formatted headers. Returns count of successfully split sequences.
7014	Parses a Nextflow trace file to extract information from processes with a specific tag (" getStats") that have completed successfully. It generates a JSON report containing the relevant process data and saves it both to a statistics file and a report file. The function processes trace file lines, checks for the specified tag and completed status, and accumulates the information into a dictionary which is then written to JSON format.
7015	Summary: The `brew_innuendo` function creates a pipeline by validating and executing a list of processes based on provided arguments. It instantiates an `Innuendo` class, checks if tasks are specified in the arguments, validates the pipeline processes, and returns the final pipeline string. If validation fails, the program exits with an error code.
7016	Returns a pipeline string from a recipe name by dynamically importing recipe modules, finding the matching recipe class, and calling its brew() method. Raises an error and exits if the recipe name is not found.
7017	Method that iterates over all available recipes and prints their information to the standard output. If full parameter is True, it also displays the pipeline string along with the recipe name. Uses pkgutil to discover recipe modules and displays recipe names with colored formatting. Exits the program after listing all recipes.
7018	Validate pipeline string by checking for forbidden characters (parentheses and pipe) in the input string. Returns False if forbidden characters are found, otherwise returns True.
7019	Builds the upstream pipeline of the current process by checking upstream processes and adding them to the current pipeline fragment if they exist in the process list. Handles forkable processes by creating new pipeline fragments for each fork and recursively building upstream for non-forkable processes. Returns the resulting pipeline fragment.
7020	Builds the downstream pipeline of the current process by checking for downstream processes and adding them to the current pipeline fragment, handling both single and multiple forks appropriately.
7021	Builds pipeline forks and connections between provided processes by iterating through tasks, constructing upstream and downstream pipelines when required, and returning all possible fork combinations.
7022	Main method to run the automatic pipeline creation. This method aggregates functions required to build the pipeline string used as input for the workflow generator. It takes a string of space separated tasks and returns a pipeline definition string.
7023	Generates a component string with parameters and directives for the flowcraft engine. Takes a component name, optional parameters dictionary, and optional directives dictionary, and returns a formatted string with JSON-encoded directives. If no directives or parameters are provided, returns just the component name.
7024	Writes a report file with trimming statistics for multiple samples in both CSV and JSON formats, using data from storage_dic with specified output file path and sample ID.
7025	Main executor of the trimmomatic_report template that processes log files, parses their contents, and generates a report.
7026	Removes whitespace from assembly contig names by replacing spaces with underscores in FASTA headers, while preserving sequence data unchanged. Takes an assembly file path as input and returns the path to a new file with fixed contig names.
7027	Cleans temporary FASTQ files by removing their real paths, following symlinks to the actual files. Only removes files matching a specific work directory pattern (.*/work/.{2}/.{30}/.*).
7028	Public method for parsing abricate output files. Called during class instantiation with provided output files, and can be used afterwards to add additional abricate files. Takes a list of file paths and validates each exists before parsing with the internal parser method, logging warnings for non-existent files.
7029	Parser for a single abricate output file that scans the file and populates the Abricate.storage attribute with compliant lines using an arbitrary key. It extracts information such as coverage, identity, accession, and other fields from each line and stores them in the storage dictionary.
7030	A general purpose filter iterator that yields dictionary entries based on custom filters. Each filter specifies a key, comparison operator, and test value to evaluate against entry data. Filters can be combined with 'and' or 'or' behavior. Optional database and field parameters allow for filtering by database source and limiting returned fields, respectively. The method raises a ValueError if filter_behavior is not 'and' or 'or'. It yields filtered entries that match the specified criteria.
7031	The `_get_contig_id` function attempts to extract a contig ID from a fasta header string by searching for specific patterns. It first tries to match the pattern "NODE_([0-9]*)_.*" and if successful, extracts the numeric ID. If that fails, it tries to match "Contig_([0-9]*)_.*" and extracts the ID if found. If neither pattern matches, it returns the original input string unchanged. The function handles cases where the patterns are not found by catching AttributeError exceptions.
7032	Generates JSON report data for plotting gene boxes from abricate file entries. Returns a list of dictionaries containing contig information, gene details, coverage, and identity metrics for each entry.
7033	Writes JSON report data to a file by combining plot and table data into a single dictionary and saving it as ".report.json".
7034	Creates an assembly report including summary statistics and optional sliding window data for GC content and coverage, then writes the data to JSON and status files.
7035	Parse an assembly file in fasta format and populate the Assembly.contigs attribute with contig data.
7036	Generates a CSV report with summary statistics about the assembly, including number of contigs, average contig size, N50, total assembly length, average GC content, and amount of missing data. Calculates these statistics by iterating through contigs and storing intermediate values in summary_info dictionary. Optionally writes results to a specified CSV file.
7037	Returns the mapping between sliding window points and their contigs, and the x-axis position of contig boundaries.

Parameters
----------
window : int
    Size of the window.

Returns
-------
xbars : list
    The x-axis position of the ending for each contig.
labels : list
    The x-axis labels for each data point in the sliding window

Note: The function appears to have incomplete implementation as the 'labels' return value is not populated in the provided code, and the 'window' parameter is unused in the current implementation.
7038	Get proportion of GC from a string.

Parameters:
----------
s : str
    Arbitrary string

Returns:
-------
x : float
    GC proportion.
7039	Calculates a sliding window of the GC content for the assembly by dividing the complete sequence into windows of specified size and computing the GC proportion for each window. Returns a list of GC proportion floats for each window position.
7040	Main executor of the skesa template that runs the SKESA assembler on paired FASTQ files, generates a fasta output file with version information, logs the process, handles output and error messages, and optionally cleans up input files based on the clear flag.
7041	Writes a JSON report containing quality statistics for two data sets across multiple categories. Returns a dictionary with plot data and status indicators for each category.
7042	Returns the optimal trim index from a boolean list by finding the first biased position (True) followed by two consecutive unbiased positions (False), or returns 0 if no biased positions exist or the list starts with unbiased positions.
7043	Assesses the optimal trim range for a FastQC data file by analyzing nucleotide bias in sequence content. It identifies positions with G/C and A/T proportions outside the 80-120% range and determines clipping points for 5' and 3' ends. Returns a list with two elements: the 5' end trim index and the 3' end trim index.
7044	Get the optimal read trim range from paired FastQ read data files by assessing the 'Per sequence GC content' in FastQC reports. Returns optimal 5' and 3' trim indices based on the minimum 3' and maximum 5' trim positions across both paired files.
7045	Parses a FastQC summary report file and returns its information as an OrderedDict with categories as keys and QC results as values.
7046	Checks the health of a FastQC sample by evaluating categories in the summary file. Returns a boolean indicating if the sample passes all tests, along with lists of failed and warning categories. Four categories are "fail sensitive" (sample fails if they fail), and two are "must pass" (sample fails if they don't pass). Additional categories can be configured for warnings.
7047	Parses a Bowtie log file to extract alignment statistics including total reads, alignments with 0, 1, and more than 1 hits, and overall alignment rate. Uses regex patterns to match specific lines in the log file and populates corresponding attributes via the set_attribute method. The parsing logic handles both paired-end and unpaired reads, though unpaired read parsing is noted as not yet implemented. The method prints debug information during execution.
7048	Parses a process string to extract the process name and its directive information. Process strings can contain directive information in the format `proc_name={'directive':'val'}`. The method splits the string by '=' and attempts to parse the directives part as JSON. If parsing fails, it raises a ProcessError with guidance on common causes. Returns the process name and directives dictionary (or None if no directives are present).
7049	Adds a dependency process to a pipeline by creating a new process instance from a template, setting up channel connections, and updating lane assignments while maintaining pipeline integrity. The method handles input/output channel reassignment and lane management to ensure proper process execution order.
7050	Searches the process tree backwards to find a process template in specified parent lanes.

Parameters:
- template (str): Name of the process template attribute being searched
- parent_lanes (list): List of integers with the parent lanes to be searched

Returns:
- bool: True when the template is found, False otherwise
7051	Adds the header template to the master template string by appending the hs.header content to self.template attribute.
7052	Adds the footer template to the master template string.
7053	Sets the main channels for the pipeline by parsing processes and performing channel configuration tasks including input/output channel setup, main input fork management, and secondary channel handling while logging debug and info messages throughout the process.
7054	Sets the main raw inputs and secondary inputs on the init process by fetching the Init process instance and calling set_raw_inputs and set_extra_inputs methods to connect user parameters with pipeline channels.
7055	Sets secondary channels for the pipeline by iterating through the secondary_channels dictionary and configuring secondary links for each source based on the end values.
7056	Compiles all status channels for the status compiler process by collecting status strings from pipeline processes, checking for duplicates, setting the channels in status and report compilers, and adding them to the processes list.
7057	Returns a Nextflow resources string from a dictionary object, compiling resource directives for processes and formatting them for injection into a Nextflow config file template. Ignores specified directives like "container" and "version".
7058	Returns a Nextflow config string for containers from a dictionary, formatting container directives with optional version tags and process identifiers.
7059	Returns the Nextflow params string from a dictionary object by iterating through processes and their parameters, formatting them with appropriate naming conventions and structure.
7060	Returns a merged Nextflow parameters configuration string from process parameters. Gathers all parameters from multiple processes, handles identical parameters by keeping their last occurrence, and formats them as "param = value" pairs. Parameters are extracted from each process's params dictionary and combined into a single string with proper formatting.
7061	Returns the Nextflow manifest configuration string containing pipeline name and main script information.
7062	This method iterates through all processes in a pipeline to generate Nextflow configuration files. It collects resource directives, container specifications, parameters, and manifest information from each process, then renders them into separate configuration files including resources.config, containers.config, params.config, manifest.config, Helper.groovy, and user.config. The method handles parameter merging based on a merge_params flag and skips processes without directives.
7063	Writes a DAG (Directed Acyclic Graph) to a JSON file using the provided dictionary visualization data.

**Parameters:**
- `dict_viz` (dict): Tree-like dictionary containing process tree data
- `output_file` (str): Output filename (default: ".treeDag.json")

**Returns:**
- None

**Side effects:**
- Creates/overwrites a JSON file containing the DAG data in the same directory as `self.nf_file`
7064	```python
def render_pipeline(self):
    """Write pipeline attributes to json for graphical DAG visualization
    
    This function converts pipeline process information into a JSON structure
    that can be rendered as a graphical DAG by resources/pipeline_graph.html.
    It organizes processes by lane and parent-child relationships, adding
    process details like input/output types, directives, and tooltips.
    The function also writes fork tree information to a separate JSON file
    and returns rendered HTML using a Jinja template.
    """
```
7065	Writes all configuration files to the pipeline directory, including resources.config, containers.config, params.config, manifest.config, and user.config (if not present), creates a lib directory with Helper.groovy, and generates a pipeline DAG HTML file from the rendered pipeline.
7066	Export pipeline parameters as JSON to stdout by iterating through pipeline processes (skipping the first init process) and writing each component's params dictionary to stdout.
7067	Export pipeline directives as a JSON object containing process templates and their corresponding directives, skipping the first initialization process, and write the JSON output to stdout.
7068	Fetch and display Docker Hub tags for container components, showing selected tags with default version highlighting and formatted output.
7069	Main pipeline builder that constructs the Nextflow code template by generating header, setting up channels and processes, and writing the final pipeline file.
7070	Returns a kmer list based on the provided kmer option and max read length. Supports automatic selection based on read length, manual specification of multiple kmers, or empty list for automatic SPAdes determination.
7071	Main executor of the SPAdes assembler that sets up and runs metaSPAdes for genome assembly. It handles kmer selection based on input parameters, constructs the SPAdes command with appropriate arguments including threads, output directory, kmers, and paired FASTQ files, executes the assembly process using subprocess, logs the output and errors, writes a status file based on execution success, renames the output contigs file to a more descriptive name, and optionally removes input FASTQ files when the clear flag is specified. The function handles both automatic and custom kmer selection, manages file naming conventions, and provides comprehensive logging of the assembly process.
7072	Returns a hash of the report's JSON file. If in watch mode, generates a hash from the Nextflow pipeline file combined with working directory and hostname information. Otherwise, extracts and concatenates 'scriptId' and 'sessionId' from the report metadata.
7073	Updates the trace watch by parsing the nextflow trace file to find unprocessed report JSON files and adds their paths to the report queue. Returns early if the trace file size hasn't changed since last check. For each line in the trace file, it skips empty lines and already processed task IDs. When it encounters a "report" process, it expands the hash path and adds it to the report queue. All processed task IDs are stored to avoid reprocessing.
7074	Updates the log watch by parsing the nextflow log file and updating run status when the trace file size changes.
7075	Sends a PUT request with report JSON files from the report_queue in batches of 100, logging payload size and status information. Handles connection errors by exiting the program with an error message. Resets the report_queue after sending all reports or when no reports are present but status has changed.
7076	Initializes live reports by sending a POST request to the broadcast address with report metadata and status information. Handles connection errors by logging an error message and exiting the program.
7077	Sends a DELETE request to close a connection and delete a report JSON hash identified by report_id, logging debug information and handling connection errors.
7078	Generates a tab-separated adapter file for FastQC from a FASTA file containing adapter sequences. Reads adapter names and sequences from the input FASTA file, writes them to a tab-separated output file with tab and newline characters escaped, and returns the path to the converted file. Returns None if the input file is not found.
7079	Main executor of the fastq template that runs FastQC on paired FastQ files with optional adapter filtering, logs the process, and organizes output files.
7080	Send dictionary to output json file
This function writes the master_dict dictionary to a JSON file if it contains entries, otherwise it skips file creation. It also generates plot data from the master_dict and creates a report JSON file containing both the table data and plot data. The function handles cases where master_dict is empty by setting number_hits to 0. The output files are named based on the mash_output parameter and include both a .json file with the master_dict and a .report.json file with structured report data containing sample information, mash distance data, and plotting information.
7081	Main function that converts a mash distance text file to JSON format, filtering results based on hash percentage cutoff and organizing data by reference accession numbers.
7082	Writes versions JSON file for a template by collecting metadata and version information from template script attributes and functions. Creates a .versions file containing program name, version, and build information from __version__, __template__, __build__ attributes and __get_version* functions.
7083	Converts top results from mash screen text output to JSON format, filtering results based on median multiplicity cutoff to identify plasmids with higher coverage depth. Generates two JSON files: one with filtered plasmid data and another with report information containing sample ID and plasmid count.
7084	Function `colored_print` enables printing colored text by accepting a message and color label, with default white bold text. It handles UTF-8 encoding issues and uses a COLORS dictionary for color codes, falling back to the color label itself if not found. The function returns the formatted colored string with proper terminal color codes.
7085	This function parses a dictionary of process attributes and prints a formatted list of all components or specified components to stdout. It takes a dictionary where keys are template names and values are dictionaries containing process information such as input/output types, dependencies, and directives. The function sorts the processes alphabetically and displays them with colored formatting, handling special cases for lists and nested dictionaries (like directives) to provide readable output.
7086	Function that collects process arguments from a process map based on specified listing options (detailed or short) and parses the results. It creates a dictionary of process information containing only the requested attributes (like input_type, output_type, description, etc.) and passes it to procs_dict_parser for further processing. The function supports filtering processes by pipeline string when provided.
7087	Guesses the compression type of a file by checking binary signatures at the beginning of the file. Returns the compression format (gzip, bzip2, zip) if detected, otherwise returns None.
7088	Get the Unicode code range (minimum and maximum values) for a given string by analyzing each character's ordinal value.
7089	Returns valid encodings and phred scores for a given Unicode code range by checking against stored encoding ranges.
7090	Parses a TSV file containing coverage information for contigs and returns coverage details, total assembly size, and total coverage.
7091	Generates a filtered assembly file by removing contigs below a specified coverage threshold. Takes an original assembly file, coverage information dictionary, and minimum coverage requirement, then writes filtered contigs to a new output file. Uses a write flag to determine whether to include sequence data for each contig based on its coverage level.
7092	Filters a BAM file using Samtools based on minimum coverage requirements, keeping only contigs that meet the specified coverage threshold and creating an indexed output BAM file.
7093	Evaluates the minimum coverage threshold based on the coverage_opt parameter. If coverage_opt is "auto", it calculates 1/3 of the assembly coverage with a minimum value of 10. Otherwise, it uses the specified coverage_opt value. Returns the minimum coverage threshold as an integer.
7094	Returns the total number of nucleotides and individual contig lengths from an assembly file.

Parameters:
- assembly_file : str - Path to assembly file

Returns:
- assembly_size : int - Total size of assembly in nucleotides
- contig_size : dict - Length of each contig (contig name as key and length as value)
7095	Main executor of the process_assembly_mapping template that processes assembly mapping data. It parses coverage information from assembly and BAM files, evaluates minimum coverage thresholds, and filters assembly contigs based on coverage criteria while ensuring the filtered assembly meets a minimum genome size threshold. The function outputs filtered assembly and BAM files, and writes a status file indicating successful completion.
7096	Converts a CamelCase string into a snake_case string by inserting underscores between words and converting to lowercase.
7097	Collects Process classes from components module and returns a dictionary mapping template names (in snake_case) to their corresponding process classes. Crawls through the components module to find all classes that inherit from Process, converts their CamelCase names to snake_case for template mapping, and returns the resulting dictionary.
7098	Main executor of the process_newick template that processes a Newick file by reading it with Dendropy, rerooting at midpoint, formatting the tree string, and writing the result to a JSON report file along with a status file.
7099	Find data points on the convex hull of a supplied data set using QuickHull algorithm.

Args:
    sample: data points as column vectors n x d where n is number of samples and d is data dimension (should be two)

Returns:
    a k x d matrix containing the convex hull data points

The algorithm works by:
1. Finding the leftmost and rightmost points to establish an initial base edge
2. For each subset of points, finding the point farthest from the current edge
3. Recursively constructing the convex hull by dividing points into subsets
4. Combining results from both sides of the base edge to form the complete hull
7100	Method `_map_w_to_data` maps basis vectors W to the most similar data points by finding the nearest neighbors using vector quantization. It assigns each basis vector to the closest data sample and stores the corresponding data points in `Wmapped`. The method avoids direct assignment to prevent issues with data ordering, particularly when working with HDF5 tables, by iterating through the mapping indices to ensure proper alignment between basis vectors and their corresponding data points.
7101	Applies median filtering along the first axis of a feature matrix using a specified window size.
7102	Creates a Gaussian kernel following Foote's paper by generating a symmetric Gaussian window, constructing a 2D kernel through outer product, and applying sign changes to specific quadrants.
7103	Computes the self-similarity matrix of input data X by calculating pairwise distances using the specified metric, normalizing the distances to [0,1], and returning the complement (1 - normalized_distance) as the similarity matrix.
7104	Computes the novelty curve from a self-similarity matrix and Gaussian kernel by sliding the kernel over the matrix, computing weighted sums, and normalizing the results to [0,1].
7105	Gaussian filter along the specified axis of the feature matrix X using a sigma value of M/2. If axis is 0, filters rows; if axis is 1, filters columns. Returns the filtered matrix X.
7106	Computes the novelty curve from structural features by calculating the Euclidean distance between consecutive feature vectors, then normalizes the result to range [0, 1].
7107	Creates a circular shift of a square matrix to generate a time-lag matrix by shifting rows cyclically.
7108	Time-delay embedding function that transforms a 1D or 2D time series X into a higher-dimensional space using m dimensions and tau delays. For each point in the embedded space, it concatenates time-delayed versions of the input data, handling both integer and fractional embedding dimensions. Returns a 2D array where each row represents an embedded vector.
7109	Formats a plot with proper axis labels, title, ticks, and layout based on the provided parameters, and optionally saves it to a file.
7110	Plots boundaries for multiple algorithms from a JSON estimated file, displaying each algorithm's boundaries as vertical lines on a horizontal axis with customizable formatting and optional output file saving.
7111	Plots all the labels from multiple algorithms along with ground truth boundaries.

This function takes a list of label arrays (one for each algorithm), ground truth times, and an estimated file path. It plots these labels as colored spans on a timeline, with the ground truth boundaries shown as green vertical lines. The plot includes proper formatting with timestamps, algorithm identifiers, and optional title and output file parameters. The labels are indexed and normalized, and colors are assigned based on label values using a rainbow colormap. The function supports specifying which algorithms to include and can save the resulting plot to a file.
7112	Plots the segmentation results for a single track, displaying both ground truth and estimated boundaries with corresponding labels. If ground truth is available, it's plotted in green while estimated boundaries are plotted in blue. Labels are color-coded using a rainbow colormap. The function handles cases where reference data is missing by only plotting the estimated results. Includes formatting for clear visualization of segment boundaries and labels over time.
7113	Plots a hierarchical segmentation tree with time segments represented as horizontal spans colored by level, configurable frame rate resolution and title.
7114	Returns a list of feature segments defined by boundary indices from a feature matrix.

Parameters:
- F: np.ndarray - Matrix containing features, one feature vector per row
- bound_idxs: np.ndarray - Array with boundary indices

Returns:
- feat_segments: list - List of segments, one for each boundary interval

The function ensures boundaries are valid and sorted, then extracts contiguous segments from the feature matrix between consecutive boundary indices.
7115	Converts feature segments into 2D-Fourier Magnitude Coefficients using maximum segment size and zero-padding. Takes a list of feature segments and an offset parameter to remove frames from beginning/end of each segment, then computes 2D-Fourier Transform for each segment. Returns a tensor of 2D-FMC matrices with optional normalization.
7116	Computes segment similarity by extracting feature segments from input data, converting them to 2D-FMCs, and applying clustering (k-means with optional Dirichlet process or Xmeans for automatic k estimation) to generate label predictions for each segment.
7117	Fit the OLDA model by re-initializing scatter matrices and calling partial_fit.
7118	Partial-fit the OLDA model by updating within-scatter and ordinal scatter matrices based on input data segments and their change points, then compute and store the eigenvalues and eigenvectors of the scatter matrices.
7119	Reads boundary times and labels from JAMS annotation file for a given audio file path and annotator ID.
7120	Finds the correct estimation from JAMS file based on boundaries_id, labels_id, and additional parameters. Returns the matchingAnnotation object or None if not found.
7121	Saves segment estimations into a JAMS file, handling both flat and hierarchical segmentations. It validates boundary-interval consistency, manages existing annotations, and stores metadata including algorithm identifiers and parameters. The function supports saving boundary times and corresponding labels, with support for hierarchical structures.
7122	Gets all the possible boundary algorithms in MSAF.

Returns
-------
algo_ids : list
    List of all the IDs of boundary algorithms (strings).
7123	Gets the configuration dictionary from the current parameters of the algorithms to be evaluated, incorporating annotation beats, feature, framesync, and optional boundary and label configurations while ensuring no parameter name duplicates exist between boundary and label algorithms.
7124	Gets all audio files from the given dataset path, ensures required directories exist, creates FileStruct objects for each audio file, and returns them sorted by audio file name.
7125	Reads hierarchical references from a JAMS file, returning segment boundaries, labels, and level identifiers for specified namespaces while optionally excluding certain levels.
7126	Reads a JSON features file and returns the duration value from its global parameters.
7127	Writes segmentation results to a file using MIREX format, where each line contains start time, end time, and label for each segment. Takes arrays of times and labels, converts times to intervals, and saves to the specified output file path.
7128	Returns the path to a dataset file with specified extension by replacing the audio file's extension with the desired one and combining it with the dataset path and directory.
7129	Aligns ground-truth segmentation boundaries to the nearest detected beats in a song.

This function takes beat times and a song path as input, reads the ground-truth segmentation references from the song, and aligns the segment boundaries to the closest beats. It returns three arrays: beat-aligned segment boundaries, true segment times, and segment labels. If reading references fails, it returns None for all three values. The alignment process uses interval matching between beats and segments to find the closest beat correspondences for each segment boundary.
7130	Estimates beats in audio using librosa beat tracking on percussive component. Computes harmonic-percussive separation if needed, tracks beats, converts frame indices to time values, and removes initial zero time if present. Returns beat times in seconds and corresponding frame indices.
7131	Reads annotated beat times and frames from a JAMS file if available.

Args:
    self: The class instance

Returns:
    tuple: (times, frames) where times is a numpy array of beat times in seconds and frames is a numpy array of corresponding frame indices, or (None, None) if no annotations exist or file cannot be read

The method attempts to load beat annotations from a JAMS file using the file structure's reference file path. If successful, it extracts beat times and converts them to frame indices using librosa's time_to_frames function with the instance's sampling rate and hop length. Returns None values if no beat annotations are found or if there are compatibility issues with the JAMS file.
7132	Make the features beat-synchronous by synchronizing them with beat frames and times. If beat_frames is None, returns (None, None). Otherwise, synchronizes features using librosa.util.utils.sync and adjusts times accordingly, padding if specified. Returns beat-synchronized features and times.
7133	Reads features from a JSON file and stores them in the object, including duration, feature parameters, and beat-related data. Raises specific exceptions if file format is incorrect, required features are not found, or file cannot be accessed.
7134	Saves features to a file by first attempting to read existing features, handling various exceptions to either create/overwrite the file with metadata and global parameters, or append new features to existing ones. It includes beat information, feature parameters, and actual feature data for the current features, then writes everything to a JSON file with indentation.
7135	Returns the parameter names for these features, avoiding the global parameters.
7136	Computes frame synchronization times from frame synchronization features by converting frame indices to time values using librosa's frames_to_time function.
7137	Returns the frame times for the current feature type, computing them if necessary for framesync features.
7138	This method computes and returns feature vectors based on the specified feature type. It first checks if features need to be computed (if they haven't been computed yet or are missing), and if so, attempts to read existing features or compute them from audio files. It then selects the appropriate feature type (framesync, beat-synced with estimated beats, or beat-synced with annotated beats) and returns the corresponding feature array. The method handles various error conditions including missing files, wrong formats, and invalid feature types.
7139	Selects features based on the given parameters and returns the appropriate features object.

Parameters:
- features_id (str): Identifier of the features (must be a key in features_registry)
- file_struct (msaf.io.FileStruct): File structure containing files to extract features from
- annot_beats (boolean): Whether to use annotated (True) or estimated (False) beats
- framesync (boolean): Whether to use framesync (True) or beatsync (False) features

Returns:
- features (obj): Features object inheriting from msaf.Features

Raises:
- FeatureTypeNotFound: If the combination of annot_beats and framesync is invalid
- FeaturesNotFound: If the features_id is not found in features_registry
7140	This method preprocesses audio features by validating the specified feature string against a list of valid features and retrieving the corresponding feature data. It raises RuntimeError exceptions if the feature is invalid or not supported by the MSAF library. The method returns the actual feature data (F) if validation passes.
7141	Post-processes algorithm estimations by synchronizing labels with input bounds (if provided), removing empty segments, ensuring matching lengths between boundaries and labels, and converting indices to integers. Returns the processed indices and labels.
7142	Main function that sweeps parameters for an algorithm by parsing command-line arguments for input dataset, features, boundary and label algorithms, and processing parameters, then executes the process with specified arguments and logs the execution time.
7143	Print all the results from a DataFrame by calculating and logging the mean values, with a warning if no results exist.
7144	Computes evaluation results using ground truth data from a reference file against estimated boundaries and labels. Handles both hierarchical and flat segmentation evaluations, returning metrics such as recall, precision, and F-measure. For hierarchical evaluation, it aligns segment hierarchies and computes t-measure at different windows, while for flat evaluation, it computes standard segmentation metrics using the provided bins. The function supports different annotator IDs for hierarchical data and returns results in a dictionary format.
7145	Computes the information gain between annotated and estimated beat intervals, converting intervals to times and using mir_eval for the calculation.
7146	Processes a single track by validating file structures and computing ground truth results using specified boundary and label algorithms.

Parameters:
- file_struct: FileStruct object or audio file path
- boundaries_id: Identifier for boundaries algorithm
- labels_id: Identifier for labels algorithm
- config: Algorithm configuration dictionary
- annotator_id: Annotator identifier (default: 0)

Returns:
- Dictionary containing evaluation results from compute_gt_results function

The function validates that audio files have matching basenames, checks for reference file existence, and computes results using ground truth evaluation.
7147	Returns the file name to store results based on boundaries ID, labels ID, configuration, and annotator ID, ensuring the file path is valid and within length limits.
7148	Main process to evaluate music segmentation algorithms' results. Takes audio files or dataset directory as input, applies boundary and label detection algorithms, computes evaluation metrics, and returns results as a pandas DataFrame. Supports both single file and collection modes with parallel processing options. Results can be saved to CSV file.
7149	Add a new configuration variable to the msaf.config module with the specified name, documentation, and configuration parameter object, handling nested sections and validating the configuration structure.
7150	Computes all features for the given file by iterating through each registered feature, logging the computation process, and extracting the feature data using the Features.select_features method.
7151	Computes features for a single audio file or entire dataset in parallel. If input is a file, processes that file directly. If input is a directory, processes all files in the dataset using multiprocessing with the specified number of jobs. Features are computed either from existing files or newly computed, with optional frame synchronization.
7152	Returns the average log-likelihood of data under a standard normal distribution. Calculates cost using the formula: -0.5 * d * n * log(2 * ) - 0.5 * (n - 1) * sum(variances), where d is dimensions and n is number of samples. Returns 0 for less than 2 samples.
7153	Log-normalizes features to range from `min_db` to 0 by first min-max normalizing with a floor value, then applying logarithmic scaling.
7154	Normalizes features to range between floor and 1 by first shifting by the negative minimum plus floor, then dividing by the maximum value along each column.
7155	Normalizes a matrix of features according to the specified normalization type, supporting min-max scaling, logarithmic scaling, and various Lp norms, with options for floor values and database scaling limits.
7156	Returns a numpy array of time frames evenly spaced from 0 to duration using the number of frames calculated from duration and analysis parameters.
7157	Removes empty segments from time intervals and corresponding labels by filtering out intervals where start time equals end time, returning the cleaned time segments and labels.
7158	Sonifies click positions into audio by adding synthesized clicks to the input audio file.

Parameters:
- audio: np.array - Audio samples of the input track
- clicks: np.array - Click positions in seconds  
- out_file: str - Path to the output file
- fs: int - Sample rate
- offset: float - Offset of the clicks with respect to the audio (default: 0)

The function generates 1kHz clicks with exponential decay, positions them according to click times and offset, adds them to the original audio, and writes the result to a WAV file.
7159	Synchronizes labels from old boundary indices to new boundary indices by first unfolding the old labels into a full frame array and then computing median labels for each new boundary segment.
7160	Processes a level of segmentation by converting frame indices to time stamps and adding silence labels, while ensuring proper segment boundaries and removing empty segments.
7161	Aligns the end points of two hierarchical segment boundaries to have the same duration within a specified threshold. If the durations differ by more than the threshold, no alignment is performed. Otherwise, all hierarchical structures in the first hierarchy are adjusted to end at the same time as the second hierarchy.
7162	This method computes the distances from a specific data point to all other samples in the dataset. It handles both sparse and dense data formats, using chunked processing for memory efficiency when dealing with large datasets. The method accepts an index parameter to specify which data point to compute distances against (with -1 representing the origin), processes the data in manageable steps, and returns an array of distances. It also logs progress information during computation.
7163	Estimates the optimal number of clusters (K) using K-means clustering and Bayesian Information Criterion (BIC). The method sweeps through various values of K from 1 to maxK, computes the BIC for each, and selects the optimal K based on the change in BIC values. It returns the estimated K value, with optional plotting capability to visualize the BIC curve and data distribution.
7164	Returns data points from X that match a specific label_index using previously learned labels, reshaping the result to remove singleton dimensions.
7165	Runs k-means clustering on input data X with K clusters, returns the cluster means and assigned labels for each data point.
7166	Computes the Bayesian Information Criterion (BIC) for a given dataset, means, and cluster labels. The method calculates the log-likelihood of the data using maximum likelihood estimation with whitened data, then applies the BIC formula with penalty term based on model parameters. Returns the BIC value which can be used for model selection to determine optimal number of clusters.
7167	Magnitude of a complex matrix computed as the square root of the sum of squares of real and imaginary parts.
7168	Extracts boundaries from a JSON file containing audio segments and returns them as a numpy array. Reads the "segments" data, collects start times, adds the end time of the last segment, and returns all boundaries as a numpy array.
7169	Extracts boundaries from a JSON bounds file and returns them as a numpy array.
7170	Extracts labels from a JSON file and converts them to numerical indices, returning them as a numpy array.
7171	Extracts beats from a JSON file and returns them as a numpy array.
7172	Computes 2D-Fourier Magnitude Coefficients by performing 2D FFT on input X, calculating magnitude, applying FFT shift, flattening the result, and returning only the non-redundant upper half of coefficients.
7173	Computes labels using bounds by performing CNMF decomposition on input data X, filtering the activation matrix to get label frames, and then determining labels based on the specified bounds and their intersections. Returns a list of labels corresponding to the bound intervals.
7174	Filters the activation matrix G by:
1. Finding the index of maximum value along each row
2. Setting all values to 0 and placing (index + 1) at maximum positions
3. Summing along rows and applying median filtering with radius R
4. Returns the flattened result

The function modifies the input matrix G in-place during processing but returns a flattened copy of the final filtered result.
7175	Obtains the boundaries module given a boundary algorithm identificator. Returns None for "ground truth" or raises RuntimeError if algorithm is not found or not a boundary type.
7176	Returns the label module for a given label algorithm identifier, or None if labels_id is None. Raises RuntimeError if the algorithm is not found or cannot label segments.
7177	Runs hierarchical segmentation on an audio file using specified boundary and label algorithms, computing segment boundaries and labels for each level of the hierarchy while ensuring first and last boundaries are included.
7178	Runs flat segmentation algorithms on audio file using specified boundary and label modules, handling cases where they are the same or different algorithms, and ensuring proper boundary inclusion.
7179	Runs segmentation algorithms on audio file with specified boundaries and labels identifiers, handling both flat and hierarchical segmentation modes while returning estimated segment boundaries and labels.
7180	Prepares parameters, runs segmentation algorithms, and saves results. Takes a file structure, boundary and label algorithm identifiers, configuration dictionary, and annotator ID as input. Returns estimated boundary times and corresponding labels.
7181	Main process to segment audio files or collections of files. Supports single file and collection modes, with options for feature selection, boundary and label computation, sonification of boundaries, and plotting results. Returns estimated boundary times and labels.
7182	This method performs an alternating least squares update for the W matrix under convexity constraints. It uses a quadratic programming solver from cvxopt to optimize each column of W individually, with constraints including convexity and non-negativity. The process involves computing a hat matrix, setting up constraint matrices, and iteratively updating each basis vector while maintaining the convexity constraint that the sum of coefficients equals 1.
7183	Main Entry point for translator and argument parser that processes command line arguments, sets up translation with version info, and handles source text processing with optional transliteration.
7184	A decorator function that initializes coroutines by priming them to the first yield statement. It takes a generator function, creates an instance of it, and advances it to the first yield point using `next()`, making it ready to receive values via `send()`. The decorator uses `@wraps` to preserve the original function's metadata and returns the primed coroutine generator. This is commonly used in producer/consumer patterns where coroutines need to be "warmed up" before they can process data.
7185	Generic accumulator function that combines values based on the type of initial value. If initial value is an integer, it adds the length of the update string; otherwise, it concatenates the values. Used with functools.reduce for iterative accumulation.
7186	**set_task(translator, translit=False)**

A coroutine function that serves as a task scheduler for text translation operations. It collects tasks in a queue and processes them using a thread pool executor with the provided translator function. The coroutine supports both translation and transliteration modes through the `translit` parameter. When the coroutine exits, it processes all queued tasks using the `write_stream` function to handle text I/O operations. The function uses a generator-based approach with `yield` to receive tasks and `GeneratorExit` to trigger final processing. It runs with a fixed thread pool of 8 workers for concurrent processing of translation tasks.
7187	Function `spool` consumes text streams and spools them together for more IO efficient processing. It takes an iterable coroutine and a maximum length parameter, and sends spooled text to the iterable when the maximum length is reached. The function handles GeneratorExit exception to send remaining text and close the iterable.
7188	A coroutine starting point that processes text input from a stream, breaking lines longer than 600 characters at whitespace boundaries and sending processed chunks to a target consumer coroutine. Returns the target coroutine's close value upon completion.
7189	Wrapper function that creates and maintains HTTP connection state for translation API requests, handling retries, SSL verification, and JSON response parsing with error handling.
7190	Returns a dictionary containing the request interface for translation, including URL, parameters, and headers for making a GET request to the Google Translate API with specified source and target languages and phrase to translate.
7191	Function `translation_table` reads a JSON file containing language codes and returns a dictionary mapping language codes to their names for a specified language. It takes two parameters: `language` (the language to look up) and `filepath` (the path to the JSON file, defaulting to 'supported_translations.json'). The function constructs the full file path, validates the file exists, loads the JSON data, retrieves the specified language's data, and returns a dictionary of language codes and names. Raises IOError if the file doesn't exist and AssertionError if the specified language is not found in the data.
7192	The `print_table` function generates and displays a formatted table showing language codes and their corresponding names. It retrieves a translation table for the specified language, sorts the entries by language code, and prints each entry with the code in a left-aligned 8-character field and the name in a 20-character field padded with ideographic spaces. The function returns None after printing all entries.
7193	Remove specified nodes from a pandana Network by filtering out nodes and edges that contain those node IDs, returning cleaned DataFrames of remaining nodes and edges.
7194	Save a Network's data to a Pandas HDFStore file, optionally removing specified nodes.

Parameters:
- network: pandana.Network object to save
- filename: str, path to HDF5 file
- rm_nodes: array_like, optional list of node IDs to exclude from save

Creates an HDF5 store with nodes, edges, two_way flag, and impedance_names series.
7195	Build a Network from data in a Pandas HDFStore.

Parameters
----------
cls : class
    Class to instantiate, usually pandana.Network.
filename : str

Returns
-------
network : pandana.Network
7196	Set urban space characterization variables related to network nodes, with optional variable aggregation and automatic handling of missing values.
7197	Aggregate information for every source node in the network within a specified distance using various aggregation types and decay functions.

Parameters:
- distance (float): Maximum distance to aggregate data within
- type (string): Type of aggregation ("ave", "sum", "std", "count", "min", "25pct", "median", "75pct", "max")
- decay (string): Type of decay ("linear", "exponential", "flat")
- imp_name (string, optional): Impedance name to use for aggregation
- name (string, optional): Variable name to aggregate

Returns:
- Pandas Series: Aggregated values for each origin node in the network
7198	Assign node_ids to data specified by x_col and y_col based on nearest node mapping using KDTree query, optionally filtered by maximum mapping distance. Returns Pandas series of node_ids with same index as input data.
7199	Plots an array of data on a map using matplotlib and Basemap, automatically matching the data to the Pandana network node positions. Supports scatter and hexbin plot types. Returns the Basemap instance, matplotlib Figure, and Axes objects.
7200	Sets the location of all pois for a given category in the Pandana network, connecting them to the closest network node. Parameters include category name, maximum distance, maximum items, and x/y coordinates. Returns nothing.
7201	Find the distance to the nearest points of interest (POIs) from each source node within a specified distance. Returns a DataFrame with distances to the N closest POIs of a given category, where larger values indicate less accessibility. Optionally includes POI IDs in the result.
7202	Identifies nodes with connectivity below a specified threshold within a given distance range.

Parameters:
- impedance (float): Search distance threshold (meters or custom units)
- count (int): Minimum connection count threshold for "low connectivity" classification
- imp_name (string, optional): Specific impedance name for aggregation (uses default if not specified)

Returns:
- node_ids (array): Array of node IDs with connectivity below the specified threshold

The method works by counting connected nodes within the impedance distance and returning those with connection counts less than the threshold value.
7203	Process a node element entry into a dictionary suitable for Pandas DataFrame insertion, extracting basic node information (id, lat, lon) and relevant tags while filtering out uninteresting tags.
7204	Makes a request to the Overpass API with the given Overpass QL query and returns the parsed JSON response.
7205	Build a node-based OSM query string with optional tags filtering within specified latitude and longitude bounds.
7206	Search for OSM nodes within a bounding box that match given tags, returning a pandas DataFrame with node data including latitude, longitude, and tag information.
7207	Returns ``True`` if the input argument object is a native regular expression object, otherwise ``False``. Checks if the value is truthy and matches either a regex expression pattern or is an instance of the regex type.
7208	Method: compare
Arguments: 
- value (mixed): value to compare
- expectation (mixed): value to match  
- regex_expr (bool, optional): enables string based regex matching
Returns: bool
Description: Compares two values with optional regular expression matching support by delegating to a global compare function.
7209	A function decorator that enables method chaining by returning the instance (self) if the decorated method returns None, otherwise returning the method's actual result. This allows for fluent interfaces where multiple methods can be called in sequence.
7210	Function `compare` compares a string or regular expression against a given value. It supports strict equality comparison and regex matching. If the expression starts with a negate character, it will return True for non-matching cases. The function raises an AssertionError for assertion errors and returns a boolean value.
7211	Triggers specific class methods on an instance using reflection based on provided arguments, supporting both method invocation and attribute setting with special handling for response-related attributes.
7212	Match the given HTTP request instance against the registered matcher functions in the current engine. Returns a tuple of (boolean, list[Exception]) indicating whether all matcher tests pass and any error exceptions encountered.
7213	Returns a matcher instance by class or alias name. Searches through available matchers and returns the first one that matches the given name either by class name or alias. Returns None if no matching matcher is found.
7214	Initializes a matcher instance by name and passes variadic arguments to its constructor, acting as a delegator proxy. Raises ValueError if matcher is not found.
7215	Defines response body data by setting the body property, handling both string and bytes input by converting bytes to UTF-8 encoded string, and returns the current Response instance.
7216	Sets the mock response JSON body with the provided data, automatically formatting non-string data as JSON with indentation and setting the Content-Type header to application/json. Returns the Response instance for chaining.
7217	Sets a header field with the given value, removing previous values. If the key already exists, it updates the value and stores all values in a list. Uses lowercase key for storage and retrieval.
7218	Helper function to append functions into a given list.
Appends elements from items to target list if they are functions or methods.
7219	Triggers request mock definition methods dynamically based on request object properties, registering matchers by calling corresponding methods on the instance if they exist. Raises TypeError if request is not a Request instance.
7220	Sets the mock URL to match for the request. The URL can be a full URL with path and query params, and defaults to ``http://`` protocol schema. Returns the current Mock instance.
7221	Sets the headers for the mock request and adds a HeadersMatcher to the matchers list. Header keys are case insensitive. Returns the current Mock instance.
7222	Defines a new header matcher expectation that requires specified headers to be present in outgoing requests, regardless of their values. Header keys are case insensitive. Returns the current Mock instance. Example: `pook.get('server.com/api').header_present('content-type')`
7223	Sets up a matcher that requires specific headers to be present in outgoing requests, regardless of their values. Header keys are case insensitive. Returns the current Mock instance for chaining.
7224	Sets the HTTP Content-Type header for the mock request. Accepts MIME type strings or predefined aliases (json, xml, html, text, urlencoded, form, form-data) and returns the mock instance for chaining.
7225	Defines a set of URL query parameters to match by adding them to the request URL and registering a QueryMatcher. Returns the current Mock instance for chaining.
7226	Sets the body data to match for the mock request. The body can be a string, binary data, or a regular expression. Returns the current mock instance for chaining.
7227	Defines the JSON body to match for the mock request. The json argument can be a JSON string, Python dict/list structure, or regex pattern. Returns the current Mock instance.
7228	Defines a XML body value to match. Arguments: xml (str|regex): body XML to match. Returns: self: current Mock instance.
7229	Reads content from a file and sets it as the mock body.
7230	```python
def persist(self, status=None):
    """
    Enables persistent mode for the current mock.

    Returns:
        self: current Mock instance.
    """
    self._persist = status if type(status) is bool else True
```

Summary: Sets the persistent mode for the mock instance, returning self for chaining operations.
7231	Defines a simulated exception error that will be raised, storing either a new RuntimeError instance from a string error message or the provided Exception object, and returns the current Mock instance for chaining.
7232	Defines a mock response with optional status code and keyword arguments, returning a Response instance.
7233	Matches an outgoing HTTP request against current mock matchers, handling filters, mappers, and callbacks while tracking call counts and raising exceptions as needed. Returns a tuple indicating match status and any error exceptions.
7234	Async version of activate decorator that activates the engine before executing a function and disables it after execution, handling both regular and coroutine functions.
7235	Sets a custom mock engine, replacing the built-in one. Validates that the engine implements required methods ('activate', 'disable') and enables it if the mock is currently active.
7236	Enables real networking mode with optional hostname filtering. When networking is enabled, requests are executed via real network if their hostname matches the provided filters (which can be regular expressions). The method accepts one or more hostnames as arguments and sets up network filters accordingly, then enables the networking mode.
7237	Creates and registers a new HTTP mock in the current engine, with optional activation and additional keyword arguments for Mock constructor. Returns the new mock instance.
7238	Removes a specific mock instance from the collection by comparing object references, leaving only mocks that are not the specified mock instance.
7239	Activates the registered interceptors in the mocking engine, enabling HTTP traffic capture and mock matching functionality. Returns None if already active.
7240	Disables interceptors and stops intercepting outgoing HTTP traffic by disabling the current mock engine and setting the active state to False, but only if the interceptor is currently active.
7241	Returns True if real networking mode should be used for the given request by checking both the networking flag and all registered network filters.
7242	Matches a given Request instance against registered mocks, returning the first matching mock's response or raising PookNoMatches if no match is found and networking is disabled. Applies request filters and mappers before attempting to match against mocks, removing expired mocks during the process.
7243	Copies the current Request object instance for side-effects purposes.

Returns:
    pook.Request: copy of the current Request instance.
7244	## Summary

The `activate` function enables HTTP traffic interceptors and can be used as a decorator. When called without arguments, it activates the interception engine immediately. When used as a decorator, it wraps the decorated function with activation and deactivation of the engine around the function call. For async functions, it returns an async wrapper. The function returns a decorator wrapper when used as a decorator, otherwise returns None.

**Usage:**
- `pook.activate()` - activates engine immediately
- `@pook.activate` - decorates a function to automatically activate/deactivate engine
- `@pook.activate` with async functions - handles async function decoration

**Key behavior:**
- Activates `_engine` when called directly
- Wraps functions with try/finally to ensure engine cleanup
- Supports both sync and async function decoration
- Returns appropriate wrapper based on usage context
7245	Creates a new isolated mock engine for testing via context manager, temporarily replacing the global engine and restoring the original state after use.
7246	Adds one or multiple HTTP traffic interceptors to the mocking engine's interceptor list. Each interceptor is initialized with the engine and appended to the internal interceptors collection.
7247	Removes a specific interceptor by name and returns True if successful, otherwise False.
7248	Get a setting value from either the connection's settings_dict or fallback to the global settings object.
7249	Builds SQL with decryption and casting by calling the parent's as_sql method, then applies decryption SQL formatting with casting to the resulting SQL.
7250	Save the original value by copying it from the field specified in `self.original` to the field specified in `self.attname` before saving the model instance.
7251	Returns a placeholder string for PostgreSQL encryption handling. If no value is provided or if the value starts with '\x', returns '%s' as a placeholder. Otherwise, returns encrypted SQL using the connection object. The compiler parameter is unused in this implementation.
7252	Returns a DecryptedCol object for the given alias and output_field, or returns a cached column if the alias and output_field match the current instance's model table and field.
7253	Returns PostgreSQL encryption placeholder SQL using PGP public key setting.
7254	This function parses YAML data to detect repeated keys and their line numbers. It uses a custom YAML loader that tracks line numbers during parsing, then constructs a mapping while monitoring for duplicate keys. When duplicates are found, it records the line numbers where they occur and returns a dictionary mapping duplicate keys to lists of their line numbers.
7255	Function that calculates regression coefficients for given averages of tip and branch quantities, returning slope, intercept, chi-squared, and Hessian matrix.
7256	Returns the inverse of the covariance matrix by recursively computing the full matrix and returning the inverse stored in the root node.
7257	This method performs recursive calculation of inverse covariance matrix for a tree structure. It processes nodes in post-order traversal, computing either the full inverse matrix or just the weighting vector based on the `full_matrix` parameter. For each node, it calculates variance-based weights and updates the inverse covariance matrix and weighting vector for both terminal and non-terminal nodes, using recursive relationships that combine child node statistics.
7258	This method calculates weighted sums of tip and branch values along with their second moments for all non-terminals in a tree. It performs two-pass traversal: first computing local averages in post-order, then computing total averages in pre-order including outgroup contributions. The calculations are stored in Q and Qtot attributes of each node.
7259	This function propagates means, variance, and covariances along a branch in a tree structure. It handles both terminal nodes (tips) and internal nodes, computing updated quantities based on branch values and variances. For terminal nodes, it returns either zero values, infinite values, or computed statistics based on tip values and variances. For internal nodes, it uses previous node statistics to calculate new values through a series of mathematical operations involving denominators and weighted combinations of existing quantities. The function supports both forward and backward propagation depending on whether the outgroup parameter is set.
7260	Calculate standard explained variance by computing the correlation coefficient between root-to-tip distances and time values. Sets branch values recursively from root to terminals, collects tip values and their corresponding time values, then returns the correlation between these two variables.
7261	Regression method that performs tip value regression against branch values using the tree's root.Q matrix. If no slope is provided, it optimizes the slope during regression. Returns a dictionary containing regression parameters including the correlation coefficient calculated from explained variance.
7262	Finds the optimal root position on a tree that minimizes the bilinear product of the inverse covariance and data vectors. It evaluates each branch to determine the best split fraction `x` and regression parameters. Optionally enforces positive slope constraints. Returns a dictionary containing the best node, split fraction, and regression results, or None if no valid root is found.
7263	Initializes the merger model with a coalescent time. Sets up either a constant coalescent time or an interpolated function based on time points and coalescent time values. Handles both scalar and iterable inputs for Tc with corresponding time pivots T. Uses interpolation to create a smooth function mapping time to coalescent time, with boundary conditions set to large negative and positive values. Finally calculates the integral merger rate based on the initialized coalescent time function.
7264	Calculates an interpolation object that maps time to the number of concurrent branches in the tree by processing tree events, collapsing multiple events at same time points, and computing cumulative branch counts over time.
7265	Returns the cost associated with a branch starting at a given time node, calculated as the difference in integral merger rates plus a logarithmic correction term based on the total merger rate and branch multiplicity.
7266	Attaches the merger cost to each branch length interpolator in the tree by iterating through all clades and setting the merger_cost attribute on each interpolator that has an upstream clade.
7267	Method `optimize_Tc` determines the optimal coalescent time scale by maximizing the coalescent likelihood of the tree using scipy's minimize_scalar optimizer. It defines a cost function that negates the total likelihood, then minimizes this cost over a bounds range [ttconf.TINY_NUMBER, 10.0]. If optimization succeeds, it updates the coalescent time scale Tc with the optimal value; otherwise, it logs a warning and reverts to the initial Tc value. The method uses a nested function approach where the cost function temporarily modifies the instance's Tc parameter during evaluation.
7268	Convert profile to sequence and normalize profile across sites.

Parameters:
- profile: numpy 2D array of shape (L x a) where L is sequence length and a is alphabet size
- gtr: GTR instance to supply the sequence alphabet  
- sample_from_prof: bool, whether to sample sequence according to profile probabilities
- normalize: bool, whether to normalize profile so probabilities at each site sum to one

Returns:
- seq: numpy array of length L containing the sequence
- prof_values: numpy array of length L containing profile values for chosen sequence characters
- idx: numpy array of length L containing indices chosen from profile
7269	Normalize a profile matrix so that each row sums to one. Optionally treat input as log probabilities and return normalization offset information.
7270	Sets a new GTR object after validating its type.

Parameters:
- value: GTR instance - the new GTR object to be set

Raises:
- TypeError: if the provided value is not a GTR or GTR_site_specific instance

The method validates that the input is either a GTR or GTR_site_specific instance before assigning it to the internal `_gtr` attribute.
7271	Sets a GTR model for the TreeAnc class by creating a new model if needed. Takes either a string name of a standard GTR model or a GTR instance, and assigns it as the `_gtr` attribute. If a string is passed, it uses `GTR.standard()` to create the model. If the model has no ambiguous characters, sets `fill_overhangs` to False. Raises TypeError if the input cannot be interpreted as a GTR model.
7272	Sets the length of the uncompressed sequence alignment. The sequence length cannot be changed once set and is typically used as a general length scale. Uses the inverse 'one_mutation' parameter. Raises a warning if attempting to reset an already set sequence length.
7273	Attaches sequences from alignment to tree nodes, handling missing sequences for leaves by assigning ambiguous characters and logging warnings when more than 30% of terminal nodes are missing sequences.
7274	Method `prepare_tree` initializes tree node relationships and calculations. It sets the root branch length to 0.001, initializes mutation length and mutations list for the root node, ladderizes the tree topology, prepares all nodes through internal processing, and creates a lookup dictionary mapping node names to terminal nodes. This method should be called after tree construction, rerooting, topology changes, or branch length optimizations to ensure proper tree state initialization.
7275	Prepare nodes by setting auxiliary parameters including parent references, node names, and bad branch flags, then calculate distances to root and update internal node count.
7276	Sets the root-to-node distance for each node in the tree by calculating cumulative distances from the root, using either mutation_length or branch_length attributes.
7277	Reconstruct ancestral sequences using specified method (Fitch or maximum likelihood), with options for GTR model inference and marginal/joint reconstruction. Returns number of differences from previous reconstruction.
7278	Returns a joint distribution of sequence states at both ends of a branch using marginal ancestral inference results. Calculates mutation matrices for each alignment column using exponential transition matrices, normalizes the distribution, and optionally expands to full sequence length.
7279	Expand a node's compressed sequence into the full sequence by mapping from reduced sequence indices to full sequence positions, optionally including additional constant sites based on the flag parameter.
7280	Reconstructs ancestral states using Fitch's algorithm, iterating from leaves to root to build Fitch profiles, then propagates from root to leaves to infer internal node sequences. Returns the number of character changes since the previous reconstruction.
7281	Determine the Fitch profile for a single character position of a node by taking the intersection of children's profiles, or the union if the intersection is empty.
7282	Find the intersection of any number of 1D arrays, returning sorted, unique values that are present in all input arrays. Adapted from numpy's intersect1d function.
7283	Returns the likelihood of observed sequences given the tree. If a specific position is provided, returns the likelihood at that position (either full or compressed sequence). If no position is specified, returns the total likelihood across all positions. Requires marginal ancestral inference to have been run first.
7284	Calculate the log-likelihood of sequence data on a phylogenetic tree by traversing nodes in post-order, handling root node differently by using sequence profiles and stationary frequencies, and computing transition probabilities for internal nodes using the GTR model.
7285	Set branch lengths to either mutation lengths or given branch lengths for ML analysis, using minimum branch length threshold.
7286	Optimizes branch lengths for the entire tree using either joint or marginal maximum likelihood sequence assignment. For each node, computes optimal branch length based on sequence data, with option to store old lengths for comparison. Handles both ancestral sequence reconstruction modes and includes logging for verbose output. Returns success status after optimization.
7287	This method performs experimental global optimization of branch lengths in a phylogenetic tree. It uses scipy's minimize function to find optimal branch lengths by maximizing the marginal likelihood of the tree sequence. The optimization process:

1. Defines a negative log-likelihood function that:
   - Updates branch lengths from optimization variables
   - Infers ancestral sequences using marginal likelihood
   - Calculates gradients based on marginal branch profiles and GTR model
   - Includes a penalty term for the first branch length

2. Starts optimization from current branch lengths converted to square-root scale

3. Updates all node branch lengths and mutation lengths with optimized values

4. Reconfigures tree structure since branch lengths have changed

The method is experimental and primarily intended for testing global optimization approaches for phylogenetic tree branch length inference.
7288	Calculate optimal branch length for a given node based on its sequence and parent's sequence using either compressed or regular sequence data.
7289	Iteratively optimizes branch lengths and ancestral sequence reconstructions on a tree until convergence. Starts with either provided branch lengths (using probabilistic reconstruction) or Fitch algorithm, then alternates between reconstructing ancestral sequences and optimizing branch lengths up to a maximum number of iterations. Optionally prunes zero-length branches and infers a GTR model. Returns success status upon completion.
7290	Get the multiple sequence alignment, including reconstructed sequences for the internal nodes.

Returns
-------
new_aln : MultipleSeqAlignment
   Alignment including sequences of all internal nodes
7291	Method that computes the rate matrix for the GTR model by multiplying the transition matrix with equilibrium frequencies and setting diagonal elements to negative row sums.
7292	Create a GTR model by explicitly specifying the substitution matrix, equilibrium frequencies, and substitution rate. The method allows for custom configuration of genetic substitution models with parameters for mutation rate (mu), substitution matrix (W), and equilibrium frequencies (pi). Optional keyword arguments can be passed through to the underlying class constructor, with alphabet specification as a special case that defaults to nucleotide alphabet when not provided.
7293	Create a standard model of molecular evolution based on the specified model name and parameters.

Parameters:
    model (str): The name of the model to create. Available models include 'jc69', 'k80', 'f81', 'hky85', 't92', 'tn93', 'jtt92'.
    **kwargs: Additional keyword arguments to be passed to the specific model constructor.

Returns:
    An instance of the specified molecular evolution model.

Available models:
- JC69: Jukes-Cantor 1969 model with equal nucleotide frequencies and transition rates.
- K80: Kimura 1980 model with equal nucleotide concentrations and separate transition/transversion rates.
- F81: Felsenstein 1981 model with unequal nucleotide concentrations but equal transition rates.
- HKY85: Hasegawa, Kishino and Yano 1985 model combining F81 and K80 features.
- T92: Tamura 1992 model accounting for G+C-content bias.
- TN93: Tamura and Nei 1993 model distinguishing between two types of transitions.
- JTT92: JTT 1992 model for amino acid substitutions.

Raises:
    KeyError: If the specified model is not available.
7294	Method `_check_fix_Q` checks and fixes the diagonal of the rate matrix Q to ensure it conforms to the definition of a rate matrix. It normalizes the stationary frequency matrix Pi, breaks rate matrix degeneracy by adding a small perturbation, fixes the diagonal elements of W based on the rate matrix Q and stationary frequencies Pi, and scales the matrix appropriately. If the diagonal fixing fails (not all rows sum to zero), it raises an ArithmeticError with a diagnostic message. The method also adjusts the mutation rate mu if not explicitly fixed.
7295	Calculate the probability of observing a sequence pair at distance t for compressed sequences. Returns either log probability or probability depending on return_log parameter. Handles negative branch lengths by returning a large negative number, and manages numerical stability with small epsilon values.
7296	Find the optimal distance between parent and child sequences by compressing the sequence pair and calculating the optimal distance using the compressed sequences.
7297	Find the optimal branch length between two compressed sequences by minimizing the negative probability, with support for both fixed sequences and profile-based optimization.
7298	Calculate the probability of observing a node pair at a given distance t, considering nucleotide probability distributions and branch length. The method computes the likelihood of observing specific nucleotide patterns at the ends of a branch, optionally ignoring gaps and returning either the log-probability or exponentiated probability.
7299	Evolve computes the probability of a sequence state at time t given a parent profile by matrix multiplying the profile with the time-propagated transition matrix, optionally returning log-probabilities.
7300	Returns the log-likelihood of sampling a sequence from equilibrium frequency, handling compressed sequences with optional pattern multiplicity weighting.
7301	Sets the branch length mode based on input tree's empirical branch length distribution if not explicitly provided. If branch length mode is already set to 'joint', 'marginal', or 'input', it uses that mode. Otherwise, it calculates the maximum branch length from the tree and defaults to 'input' mode if max branch length > 0.1, otherwise defaults to 'joint' mode. If no alignment is available, it defaults to 'input' mode.
7302	Filters outlier branches that don't follow a molecular clock by comparing residuals to an IQD threshold, marks them as outliers, and optionally reroots the tree and plots the results.
7303	Plot root-to-tip regression with optional internal node positioning and labeling. Returns matplotlib axes object with the plotted results.
7304	Resolve polytomies in the tree by scanning for nodes with more than 2 children, attempting to re-optimize the tree topology to increase likelihood, and returning the number of polytomies found. If merge_compressed is True, compressed branches are kept as polytomies; otherwise, a strictly binary tree is returned. Removes obsolete nodes and logs the resolution process.
7305	Print the total likelihood of the tree given the constrained leaves, showing joint or marginal log-likelihood values including sequence and coalescent likelihoods.
7306	Add a coalescent model to the tree with optional optimization. Parameters: Tc (float or str) - inverse merger rate or special values 'skyline', 'opt', 'const'; kwargs - additional optimization parameters. The method supports three Tc types: 'skyline' (optimizes skyline model), 'opt'/'const' (optimizes Tc parameter), or numeric values (sets Tc directly). Returns nothing.
7307	Method: `_find_best_root`

Summary: Determines the optimal root position for a tree by finding the node that results in the best regression of temporal constraints and root-to-tip distances. The method searches through all nodes in the tree and evaluates each as a potential root position using tree regression analysis.

Parameters:
- `covariation` (bool): Account for covariation structure when rerooting (default: True)
- `force_positive` (bool): Only accept positive evolutionary rate estimates when rerooting (default: True)
- `slope` (float): Slope parameter for the regression analysis (default: 0)
- `**kwarks`: Additional keyword arguments

Returns: The node ID that represents the optimal root position for the tree

Side effects: Modifies branch lengths of all nodes in the tree by setting them equal to mutation lengths, and logs the root search process at debug level 2.
7308	Function that attempts to load a tree and build it from the alignment if no tree is provided. If no tree is given, it infers a tree from the alignment using tree inference, removes the temporary directory if it exists, and tries to load the tree. Returns 0 on success, 1 on failure.
7309	Creates a GTR (General Time-Reversible) model based on input parameters, handling both automatic inference and manual specification of model parameters with error handling and default fallback options.
7310	Summary: Checks if the input alignment is in VCF format and reads it appropriately if it is. If VCF format is detected, validates the presence of a reference FASTA file, reads the VCF data, extracts sequences and reference, and calculates fixed nucleotide/protein frequencies for GTR model inference. Returns the alignment data, reference sequence, and fixed pi values if VCF format is detected, otherwise returns None for reference and fixed pi values.
7311	Function `ancestral_reconstruction` performs ancestral sequence reconstruction using TreeTime. It sets up the analysis by checking the tree and creating output directories, then reads alignment data (supporting VCF format), initializes TreeAnc with the specified GTR model, and infers ancestral sequences using maximum likelihood. If reconstruction fails, it returns an error code; otherwise, it exports the results including sequences and tree, then returns success code. The function handles both regular alignments and VCF data with appropriate GTR model inference.
7312	Calculate the full-width-half-maximum (FWHM) of a probability distribution. Returns the width of the distribution at half its maximum height. Handles both interpolation objects and Distribution objects, computing FWHM by finding the x-range where the negative log-probability drops to log(2) below the minimum value. Returns zero with a warning if insufficient data points are available.
7313	Create a delta function distribution with specified position, weight, and minimum width parameters.
7314	Multiplies a list of Distribution objects, handling both delta functions and general distributions. For multiple delta functions, raises an error. For single delta function, computes resulting distribution at the delta peak position. For general distributions, finds overlapping regions and creates new distribution from summed y-values. Returns resulting Distribution object.
7315	Assigns dates to tree nodes, handling bad date constraints and marking problematic branches. Returns success/error code based on validation results.
7316	Instantiates a TreeRegression object with default functions for tip values, branch values, and branch variances tailored for treetime instances. Configures the regression to optionally account for phylogenetic covariation through branch variance calculations based on mutation length and tip slack. Returns the configured TreeRegression instance with the attached tree.
7317	Creates a maximum likelihood tree optimization with temporal constraints using date constraints to calculate the most likely positions of unconstrained nodes, with options for marginal or joint reconstruction of node positions.
7318	Return the likelihood of the data given current branch lengths in the tree by summing branch likelihood contributions and adding root sequence likelihood.
7319	This function converts time-before-present values to numerical dates and human-readable date strings. It processes all nodes in the tree, converting their time_before_present properties to numerical dates (numdate) and formatted date strings (%Y-%m-%d). The function handles edge cases where nodes appear to be later than the present day, issuing warnings for unmarked or marked bad nodes. Dates are calculated assuming a standard calendar with adjustments for leap years, and falls back to a 1900-based approximation for dates that would otherwise cause errors. All modifications are made in-place on the tree nodes.
7320	This method estimates the uncertainty in a node's numdate due to rate variation by using previously calculated rate variations. It calculates confidence intervals based on the rate variation data stored in the node. If the node has rate variation data, it computes the uncertainty bounds using the error function inverse and the specified confidence interval bounds. If no rate variation data exists, it returns None. The method takes a node and an optional confidence interval tuple as parameters, and returns an array of uncertainty bounds.
7321	Returns the highest posterior probability region containing a specified fraction of the probability mass for a given node, incorporating both rate variation and mutation-based uncertainty if available.
7322	Find the global minimum of a function represented as an interpolation object by locating the minimum value in the interpolation results and returning the corresponding x-coordinate. If an exception occurs during this process, re-raise the exception with additional diagnostic information including the x-values and range of the interpolation object.
7323	Find the median of a function represented as an interpolation object by:
1. Creating a refined grid by interpolating between existing data points
2. Computing exponential weights based on function values relative to minimum
3. Calculating cumulative sum using trapezoidal integration
4. Finding the median index where cumulative sum reaches 50% of total
5. Returning the corresponding grid value as the median estimate
7324	Convert datetime object to numeric date format YYYY.F, where F is the fraction of the year passed. If no datetime provided, uses current date. Returns None on error.
7325	Create a conversion object from a regression clock model dictionary containing slope, intercept, and optional statistics.
7326	Creates and returns a socket connection to the guacd server if one doesn't already exist, using the instance's host, port, and timeout parameters.
7327	Close the connection with the Guacamole guacd server by closing the client connection, setting the client reference to None, marking the connection as disconnected, and logging the connection closure.
7328	Receive instructions from Guacamole guacd server by reading from buffer until instruction termination marker is found, handling connection loss if no data is received.
7329	Send encoded instructions to Guacamole guacd server.
7330	Send instruction after encoding.
7331	Establishes a connection with a Guacamole guacd server through a handshake process, including protocol selection, sending size and media support information, and completing the connection with a ready instruction.
7332	Converts a Unicode string to UTF-8 encoded bytes string, handling Python 2/3 compatibility where necessary.
7333	Loads a new GuacamoleInstruction from an encoded instruction string by decoding the instruction and returning a new instance with the decoded arguments. Raises InvalidInstruction if the instruction is not properly terminated.
7334	Encodes an argument string into a GuacamoleInstruction-compatible format by prepending the UTF-8 encoded string length followed by the encoded argument, separated by ELEM_SEP. For example, encode_arg('size') returns '4.size'.
7335	Encode the instruction by joining opcode and arguments with separators, then append instruction terminator.
7336	Returns a versioned URI string for a class using its resource version and API name.
7337	Get instance URL by ID, constructs full URL using base URL and instance ID, raises exception if ID is invalid.
7338	Returns a versioned URI string for a class without pluralizing the class name. The URI follows the format "/v{version}/{class_name}" where version comes from RESOURCE_VERSION attribute or defaults to '1', and class_name is converted using class_to_api_name with pluralize=False.
7339	Downloads a file to a specified path or temporary directory, returning the absolute path to the downloaded file. Uses the object's filename as fallback if none is specified, handles both directory and file path inputs, and manages temporary file creation when no path is provided. Returns the absolute path to the downloaded file.
7340	Returns the parent commit object (Import or Migration) by retrieving it using the parent job model and ID.
7341	Asks the user for their SolveBio credentials (domain, email, and password) and validates that the domain supports password authentication. Returns a tuple of (domain, email, password) if successful, otherwise exits with an SSO error message.
7342	**Summary:**

The `interactive_login()` function prompts the user for login credentials via command line and performs authentication. It clears existing API credentials, collects domain, email, and password from the user, validates the inputs, and attempts to authenticate with the SolveBio API. If successful, it sets the new API token and updates the client authentication; otherwise, it prints an error message.
7343	**Summary:** The `whoami` function retrieves and prints information about the currently logged-in user. If no user is logged in, it prints a "not logged-in" message. The function uses a client library to fetch user information and assumes the user is already authenticated.
7344	Prints user login information including domain, email, and role in a formatted string.
7345	Returns a new Query instance with the specified filters combined with the existing filters using AND logic. Supports both positional Filter arguments and keyword arguments that are converted to Filter objects. Multiple filters within a single call are ANDed together, and multiple filter calls are also ANDed together. For more complex filtering logic, use the F class with & (and), | (or), and ~ (not) operators.
7346	Returns a cloned instance with a genomic range filter applied for the specified chromosome and coordinate range.
7347	Method `position` creates a shortcut for single position filtering on genomic datasets by cloning the object with a GenomicFilter containing the specified chromosome, position, and exact matching parameters.
7348	Returns a dictionary with requested facets by combining string arguments and keyword arguments, raising AttributeError if no fields provided or invalid field types are used.
7349	Processes a list of filters and returns them in JSON API format, handling Filter objects, dictionaries, and other types appropriately.
7350	```python
def next(self):
    """
    Allows the Query object to be an iterable.
    
    This method iterates through a cached result set and fetches successive pages as needed.
    It raises StopIteration when no more results are available or when the requested limit is reached.
    
    Returns: The next result from the query.
    """
    if not hasattr(self, '_cursor'):
        self.__iter__()
        
    if self._cursor == len(self):
        raise StopIteration()
        
    if self._buffer_idx == len(self._buffer):
        self.execute(self._page_offset + self._buffer_idx)
        self._buffer_idx = 0

    self._cursor += 1
    self._buffer_idx += 1
    return self._buffer[self._buffer_idx - 1]
```
7351	Executes a query with optional offset and additional parameters, builds query parameters, handles pagination, logs execution details, makes a POST request to the data URL, and returns the request parameters along with the raw response. In case of a SolveError, it sets the error and re-raises the exception.
7352	Migrates data from the Query's dataset to a target dataset, supporting various customization options through kwargs. Returns the created DatasetMigration object, with optional blocking behavior.
7353	Main entry point for SolveBio CLI that parses arguments, sets API configuration from command line, environment, or local credentials, configures the client, and executes the specified command function.
7354	Downloads a vault folder recursively to a local directory, creating necessary subdirectories and downloading files while handling existing files based on force parameter.
7355	Creates a new object instance from HTTP response values and refreshes it with the provided data.
7356	Logout method that revokes the OAuth token and clears cookies. It attempts to revoke the token using the OAuth2 revocation endpoint with client credentials, then redirects to home page after clearing all cookies.
7357	Issues an HTTP request using the Python requests library with automatic handling of authentication, headers, URL construction, redirects, and error handling. Supports custom headers, parameters, timeouts, file uploads, and debugging. Returns either a JSON-encoded response or the raw response object based on the 'raw' parameter. Automatically handles rate limiting (429 status) by retrying after waiting, and raises exceptions for other API errors.
7358	Returns the child object instance for a task by retrieving it from the task type's corresponding class using the task ID and client.
7359	Cancel a task by setting its status to "canceled" and saving the change. If saving fails, reset the status to its original value and re-raise the exception.
7360	Parses the SnpEff ANN INFO field by splitting on '|' and '&' delimiters, converting empty strings to None values, and organizing the data into a structured dictionary format with proper field mapping. Handles multi-allelic records by checking if items are already processed dictionaries.
7361	Converts a VCF row into a structured dictionary with genomic coordinates, variant identifiers, and related information for JSON output.
7362	Returns the user's stored API key from credentials file, or None if not found. Raises CredentialsError if credentials file cannot be opened or parsed.
7363	Save the class data in .netrc file format, including machine entries with login, account and password attributes, and macro definitions.
7364	Format a value according to its type, supporting Unicode text and different data types including integers, floats, and strings. Handles None values by returning a missing value string. For floats, uses a specified float format string.
7365	Normalize tabular data into list of lists format with optional header handling and sorting. Supports various data types including lists of lists, NumPy arrays, dictionaries, and pandas DataFrames. Can extract headers from the first row or use column indices, and optionally sorts rows by the first column.
7366	Return a string which represents a row of data cells, with padding applied to each cell and line wrapping enforced based on TTY_COLS limit.
7367	Return a string representing a horizontal line constructed from the given parameters.
7368	Prefixes every cell in a row with an HTML alignment attribute based on specified column alignments.
7369	Produces a plain-text representation of a table with specified formatting, headers, rows, and alignment options.
7370	Migrates data from this dataset to a target dataset, creating a DatasetMigration object. Validates that the source dataset has an ID, accepts target as either a Dataset object or ID string, and supports additional migration parameters. Optionally follows the migration process and returns the migration object.
7371	Helper method to parse a full or partial path and return a full path along with a dictionary containing path components. It applies rules for missing domain, vault, or path parts, and supports various path formats. It validates the path format and raises exceptions for invalid formats, returning the validated full path and path components dictionary.
7372	Function `upload` uploads files and folders from local paths to a remote vault, skipping existing items. It validates the remote path and vault, then iterates through local paths, uploading folders with `_upload_folder` and files with `Object.upload_file`.
7373	Helper method to validate and normalize vault paths, handling special cases like personal vault ("~") and missing domain/vault components by defaulting to user account values. Returns a validated full path and its components.
7374	Validate SolveBio API host URL by checking that it's not empty, contains either HTTP or HTTPS scheme, and has a valid network location. Raises SolveError for invalid URLs.
7375	Add one or more files or URLs to the manifest, handling glob patterns, URLs, and local files/directories with appropriate upload methods.
7376	Annotates a set of records with stored fields by processing them in chunks. Takes a list/iterator of records and optional keyword arguments, yielding one annotated record at a time. Uses a configurable chunk size (default 500) to process records in batches, executing annotation on each chunk and returning results as a generator.
7377	Evaluates an expression using the provided data and context, returning the result of the evaluation.
7378	Set the default format name.

:param str format_name: The display format name.
:raises ValueError: if the format is not recognized.
7379	Register a new output formatter by adding it to the class's output formats dictionary with the specified format name, handler function, preprocessors, and keyword argument defaults.
7380	Format the headers and data using a specific formatter.

:param iterable data: An :term:`iterable` (e.g. list) of rows.
:param iterable headers: The column headers.
:param str format_name: The display format to use (optional, if the
    :class:`TabularOutputFormatter` object has a default format set).
:param tuple preprocessors: Additional preprocessors to call before
                            any formatter preprocessors.
:param \*\*kwargs: Optional arguments for the formatter.
:return: The formatted data.
:rtype: str
:raises ValueError: If the *format_name* is not recognized.
7381	Wraps the tabulate library function to format tabular data with specified formatting options, supporting various table formats and whitespace preservation. Returns an iterator over the formatted table rows.
7382	Returns the appropriate configuration directory for an application based on the operating system. On Windows, it uses either roaming or local application data folders. On macOS, it uses the Application Support folder unless XDG is forced, in which case it follows the XDG specification. On Unix-like systems, it uses the XDG config directory. The function takes parameters for the application name, author, roaming preference (Windows only), and XDG forcing option (macOS only).
7383	Returns a list of system-wide configuration folders for an application based on the operating system and configuration parameters. On Windows, returns a path under ProgramData; on macOS (unless force_xdg is True), returns a path under Application Support; on Unix-like systems, returns paths based on XDG_CONFIG_DIRS environment variable or default '/etc/xdg' directory. The function handles proper path formatting and directory expansion.
7384	Reads the default configuration file and validates it if validation is enabled. Raises DefaultConfigValidationError if validation fails. Updates the current configuration with the default configuration values.
7385	Reads default, additional, system, and user configuration files, returning the combined configuration. Raises DefaultConfigValidationError if the default file has validation errors.
7386	Get the absolute path to the user config file by joining the user config directory with the filename.
7387	Returns a list of absolute paths to system config files by joining the system config directories with the specified filename.
7388	Get a list of absolute paths to the additional config files by joining each additional directory with the filename.
7389	Writes the default configuration to the user's config file, with an option to overwrite existing config. Returns early if overwrite is False and config already exists.
7390	Reads a list of configuration files and returns any validation errors that occurred. If no errors occur, returns True.
7391	Truncates string values to a specified maximum width. If the input value is a string and exceeds the maximum width, it returns the substring up to the maximum width; otherwise, it returns the original value.
7392	Replace multiple values in a string by iterating through a list of replacement tuples and applying each replacement operation.
7393	Run multiple commands in sequence, exiting immediately if any command fails.
7394	Apply command-line options to a command by iterating through default and additional options, applying each option if active, and returning the modified command.
7395	Apply a command-line option by substituting placeholders in a command string with the option's value, or removing them if inactive.
7396	Set default options including branch='master' and fix=False, then call parent initialize_options(){}.
7397	Run the pep8radius linter on the specified branch with optional fix and verbose options.
7398	Generate and view documentation by executing clean, HTML generation, and view commands in sequence.
7399	Truncates very long strings in tabular data for display purposes. Takes iterable data and headers, and returns processed data and headers with strings truncated to specified width (or default max width). Returns tuple of (processed_data, processed_headers).
7400	Format numbers in data according to specified format strings for integers and floats, preserving column types and handling None values appropriately.
7401	Formats a row by zipping headers with row data and joining them with ' | ' separator, then joins each pair with newlines.
7402	Wrapper function for TabularOutputFormatter that adapts vertical table data with specified separator options.
7403	Wraps terminaltables functionality in a function for TabularOutputFormatter, yielding formatted table rows based on provided data, headers, and table format specifications.
7404	Copies a template file and substitutes template variables with provided values. Template variables are specified as {{variable_name}} and are replaced with corresponding values passed as keyword arguments. The function reads the template file, performs all replacements, and writes the result to a destination file.
7405	Returns True if the given PKCS#11 type represents a numerical value, False otherwise. Checks against specific numeric attribute types including certificate type, class, key type, and bit lengths.
7406	Returns True if the given PKCS#11 type is a boolean value, False otherwise. Checks against a predefined set of boolean attribute types.
7407	Returns True if the given PKCS#11 type is a byte array value (i.e., not boolean, string, or numeric type).
7408	Generates a secret key using the specified template and mechanism, returning the handle of the generated key. Raises a PyKCS11Error if key generation fails.
7409	Generate a key pair using the specified mechanism and templates for public and private keys, returning a tuple of object handles for the generated key pair.
7410	Find objects matching a template pattern and return their object IDs.

This method searches for cryptographic objects in the PKCS#11 session that match the specified template attributes. It uses the CK_FindObjects API calls to iterate through matching objects, collecting their handles. The method handles the PKCS#11 session state management by calling C_FindObjectsInit, C_FindObjects, and C_FindObjectsFinal. If no template is provided, it returns all objects in the session. The search is optimized to retrieve objects in batches of 10 for performance.

Parameters:
- template: list of attribute-value tuples for filtering objects (default: empty tuple)

Returns:
- list of object handles (CK_OBJECT_HANDLE) that match the template criteria

Raises:
- PyKCS11Error: if any PKCS#11 API call fails during the search operation
7411	Inserts a small icon into the center of a QR code image, resizing it to a fraction of the QR code size and handling various icon sources including local files, static directories, and remote URLs.
7412	Export gene panels to .bed format, taking command line arguments for panels, build, bed format, and version. Uses adapter to export panels and outputs lines to console.
7413	Returns the first date on or after the given date that matches the specified weekday.
7414	Method `repeat` adds days to a given date and counts days until reaching end_repeat or going outside the current month. It handles ValueError for invalid days and can optionally stop at end_on day. The method uses timedelta to increment days by self.num and calls count_it for each counted day.
7415	Method `repeat_reverse` counts backwards from a starting day to an ending day within a month, incrementing a counter for each valid day that falls before or on the end repeat date. It handles cases where the event might extend beyond the actual number of days in the month by catching and ignoring ValueErrors. The method does nothing when start equals end, and skips days that fall outside the allowed repeat period.
7416	Helper method that processes biweekly repeat events by setting repeat interval to 14 days and updating event counts, with special handling for chunked events that may need first week adjustment.
7417	This method handles either a non-repeating event chunk or the first month of a repeating event chunk. It first checks if the event should be processed based on month and repetition rules. Then it creates a Repeater object to generate events, adjusts the repetition parameters based on whether the event starts in the current month, and finally adds the generated events to the instance's count dictionary.
7418	Export causative variants for a collaborator, optionally filtered by document_id or case_id, yielding variants ordered by chromosome and position.
7419	Create lines for an Excel file containing verified variants for an institute, including variant details, sample information, and caller-specific data.
7420	Export mitochondrial variants for a case to create a MT excel report. For each variant, extract position, reference-to-alternative change, protein effect descriptions, gene symbols, and allele depths for a specific sample. Return a list of lines containing this information for Excel reporting.
7421	Update a user in the database by modifying their roles and institute affiliations based on the provided parameters.
7422	Display a list of STR variants for a given institute and case, with pagination and filtering options.
7423	Display a specific structural variant by retrieving it from the store using the provided institute ID, case name, and variant ID.
7424	Display a specific STR variant by retrieving variant data from the store using the provided institute ID, case name, and variant ID.
7425	Starts the variant validation procedure using other techniques and handles missing recipient errors.
7426	Builds a ClinVar submission form for a variant by exporting variant data and handling both GET requests (returning data) and POST requests (processing form submissions and updating ClinVar submissions in the database).
7427	Show cancer variants overview.
7428	This function handles ACMG (American College of Medical Genetics and Genomics) classification for genetic variants. For GET requests, it retrieves the current ACMG classification data. For POST requests, it processes form data containing classification criteria, comments, and links, then updates the variant's ACMG classification in the database and redirects to the variant page with a success message.
7429	This function handles the display or deletion of an ACMG evaluation. It retrieves an evaluation object from the store, passes it to a controller for processing, and if a POST request is made, it deletes the evaluation and redirects to the variant page. Otherwise, it returns the evaluation data for display including associated institute, case, and variant information along with ACMG criteria.
7430	Calculate an ACMG classification from submitted criteria and return it as JSON.
7431	Uploads and processes gene panel files, updating HGNC symbols in filters and redirecting to appropriate variants page while preserving the POST request method.
7432	Download all verified variants for user's cases as a ZIP archive of Excel files, or show a warning if no variants are available.
7433	Return a dictionary mapping HGNC symbols to their associated gene information, where symbols are keys and values contain 'true_id' (if symbol is primary) and 'ids' (list of HGNC IDs the symbol points to).
7434	Add incomplete penetrance information to genes by marking those listed in HPO lines with incomplete penetrance as having incomplete_penetrance=True.
7435	Link genes from multiple sources (HGNC, Ensembl, ExAC, OMIM, HPO) into a unified gene dictionary using HGNC symbols as keys, where HGNC provides the primary gene definitions and additional information is merged from other databases through various linking mechanisms including ENSGID, gene symbols, and aliases.
7436	Send a request to MatchMaker and return its response

Args:
    url(str): url to send request to
    token(str): MME server authorization token
    method(str): 'GET', 'POST' or 'DELETE'
    content_type(str): MME request Content-Type
    accept(str): accepted response
    data(dict): eventual data to send in request

Returns:
    json_response(dict): server response
7437	Return the available MatchMaker nodes by making a GET request to the MME service nodes endpoint using the provided base URL and authorization token. Returns a list of node dictionaries representing connected nodes.
7438	Get the cytoband coordinate for a given chromosome position by looking up the position in the CYTOBANDS dictionary and returning the corresponding data from the interval.
7439	Get the subcategory for a VCF variant based on length comparison and category type, returning one of 'snv', 'indel', 'del', 'ins', 'dup', 'bnd', 'inv'.
7440	Return the length of a variant based on category (snv, indel, cancer, or sv) and provided parameters. For SNVs/indels, calculates length from reference and alternate lengths. For SVs, uses svlen if available, otherwise calculates from pos/end coordinates, with special handling for breakpoints (bnd) using a large fixed length. Returns -1 for uncertain lengths.
7441	Returns the end coordinate for a variant based on its category and available metadata. For SNV/indel variants, uses the provided snvend coordinate. For structural variants (SVs), attempts to use svend first, falls back to svlen if svend equals pos, and handles breakend (BND) variants by parsing the alt field. If no end information is available, defaults to the start position (pos).
7442	Parse variant coordinates and return a dictionary containing position, end, length, sub_category, mate_id, and cytoband information.
7443	This function `cli` takes an input file parameter and performs the following operations:

1. Opens and reads the input file using `get_file_handle()`
2. Parses cytoband data from the file using `parse_cytoband()` 
3. Demonstrates coordinate querying functionality by:
   - Looking up chromosome 1 at position 2 and printing all overlapping intervals with their begin/end positions and data
   - Looking up chromosome 8 at position 101677777 
   - Looking up chromosome X in the range 4200000-6000000

The function serves as a command-line interface demonstration for accessing cytoband interval data by chromosome and genomic coordinates.
7444	Show all panels for a case, handling both creation of new panels from CSV uploads and updating existing panels. Returns a dictionary containing panel groups, panel names, panel versions, and institutes.
7445	Updates a panel to a new version by retrieving the panel object, getting the requested version from form data, applying the pending update, and redirecting to the updated panel page.
7446	Exports a panel to a PDF file by retrieving panel data, rendering it as HTML, and converting to PDF with a formatted filename.
7447	Edit additional information about a panel gene, including handling form validation, processing transcript choices, and managing gene data for existing or new panel genes.
7448	Add delivery report to an existing case by loading the report file and updating the case data in the adapter. If successful, log success message; otherwise, log error and abort the context.
7449	Retrieves HPO terms from the scout database based on optional query and limit parameters, returning them as a dictionary containing a list of HPO objects.
7450	Shows all objects in the whitelist collection by iterating through the collection and echoing each object's ID.
7451	Build a small phenotype object with phenotype_id and description from a MongoDB adapter.

Args:
    phenotype_id (str): The phenotype id
    adapter (scout.adapter.MongoAdapter): MongoDB adapter instance

Returns:
    dict: Dictionary containing phenotype_id and feature (description) if phenotype exists, otherwise returns None
```
7452	Parse gene information from the store based on HGNC ID, extracting build-specific data, gene symbols, descriptions, and related records. Return a dictionary containing gene builds (37 and 38), symbol, description, Ensembl ID, and other gene-related information. Raise ValueError if no gene data is found.
7453	Fetch matching genes from the store based on the query and convert them to a JSON format containing gene names and IDs. The gene names include HGNC ID, HGNC symbol, and aliases, formatted as a string with pipe and comma separators. The function returns a list of dictionaries with 'name' and 'id' keys for each matching gene.
7454	Display the Scout dashboard with institute-specific case data, handling user access restrictions and query parameters.
7455	Displays all transcripts in the database, showing chromosome, start, end, transcript ID, HGNC ID, RefSeq ID, and primary status. If JSON flag is set, outputs transcript objects in JSON format instead of tabular format.
7456	Returns the events that occur on a specific day by filtering month-long event data and sorting them by start time.
7457	Function `sv_variants` preprocesses a list of SV variants by fetching a paginated set of variants from a database query. It calculates whether more variants are available, determines the genome build, and returns a dictionary containing a generator of parsed variants and a boolean indicating if more variants exist. The function uses `skip` and `limit` for pagination, with default page size of 50 variants.
7458	This function pre-processes a list of STR variants by delegating to the generic variants function, as STR variants don't require any unique processing at this level. It takes a store, institute object, case object, variants query, and pagination parameters, then returns the processed variants list.
7459	Pre-processes an STR variant entry for the detail page by gathering and organizing variant information, including institute and case details, variant data, overlapping SNVs, and annotation options for display.
7460	Pre-processes an SV variant entry for the detail page by adding institute and case information, variant frequencies, caller data, overlapping SNVs, gene links, comments, and ClinVar annotations. Returns a dictionary with all the parsed variant information.
7461	Parse and update variant information including compounds, HGNC symbols, predictions, and ACMG classification. Update variant in database if necessary.
7462	Returns a CSV header for exported variants including standard fields plus sample-specific fields (AD reference, AD alternate, GT quality) for each individual in the case.
7463	Get variant information for genes, including canonical transcripts, exon information, and coding sequence names, formatted as colon-separated values. For single gene queries, returns transcript ID, exon, and coding sequence. For multiple genes, includes gene identifier along with the same transcript information. Coding sequences longer than 20 characters are truncated with an ellipsis.
7464	Get SIFT predictions from genes by extracting prediction data and annotations for each gene object, returning structured data including SIFT predictions, PolyPhen predictions, region annotations, and functional annotations.
7465	Pre-processes case information for variant view by adding file paths and VCF region data. Extracts BAM/BAI file paths for individuals in the case, and determines the appropriate VCF file for the variant's genomic region based on gene information. Handles cases with single or multiple genes, and includes error handling for VCF region generation.
7466	The `find_bai_file` function locates the corresponding BAI (BAM Index) file for a given BAM file by checking two possible naming conventions: replacing '.bam' with '.bai' or appending '.bai' to the BAM file name. It returns the path of the BAI file if found, otherwise returns what it determined to be the expected path.
7467	Query observations for a variant from LoqusDB and collect related cases, returning variant observation data including total cases count and associated case information.
7468	Parse variant genes by adding gene links and processing transcripts, selecting RefSeq transcripts as primary ones.
7469	Generate amino acid change as a string from transcript object, including gene part (exon/intron/intergenic), part count, coding sequence name, and protein sequence name, with optional gene name prefix.
7470	Calculate the end position of a variant by adding the number of bases (based on the maximum length between reference and alternative sequences) minus 1 to the variant's start position.
7471	Returns a frequency category ('common', 'uncommon', or 'rare') for a variant based on the highest frequency from thousand genomes or exac databases, where common > 5%, uncommon > 1%, and rare <= 1%.
7472	Converts CLINSIG evaluation objects to human-readable format with links to ClinVar, handling both old and new versions of the data structure.
7473	Create a link to the 1000 Genomes database page for variant information based on dbSNP ID and genome build version.
7474	Compose link to COSMIC Database.

Args:
    variant_obj(scout.models.Variant)

Returns:
    url_template(str): Link to COSMIIC database if cosmic id is present
7475	Compose link to Beacon Network using the given variant object and build version, defaulting to build 37. The function formats a URL template with variant position, chromosome, alternative allele, and reference allele data from the variant object, and returns the composed URL string. Note that Beacon Network currently only supports build 37, with build 38 support commented out.
7476	Creates a UCSC genome browser link for a given variant object with optional build specification (defaulting to build 37). Returns a formatted URL string that displays the variant in the UCSC tracks interface with additional genomic annotations.
7477	Translates SPIDEX annotation to human readable string, returning 'not_reported', 'low', 'medium', or 'high' based on absolute SPIDEX value thresholds.
7478	Returns a list of unique manual inheritance models from the genes in a variant object.
7479	Return information about variant callers by iterating through specified caller categories and collecting caller names with their corresponding variant values from the variant object.
7480	Fetch cancer variants data for a specific case, including parsed variants and form data.
7481	Function `clinvar_export` gathers required data for ClinVar submission form by retrieving institute and case objects, collecting pinned variants, and fetching the specific variant object. It returns a dictionary containing today's date, institute information, case details, variant information, and pinned variants for pre-filling the ClinVar submission form fields.
7482	Collects all variants from the clinvar submission collection with a specific submission_id and returns a dictionary with data for the clinvar_update.html template page.
7483	Collects data needed for rendering ACMG classification form including institute, case, variant objects and ACMG criteria options.
7484	Calculate an ACMG classification for a variant based on provided criteria and store the evaluation result.
7485	Fetch and fill-in evaluation object with institute, case, variant data, reformat criteria dictionary, and map classification using ACMG_COMPLETE_MAP.
7486	The `upload_panel` function parses HGNC gene symbols from a provided stream, validates them against a store of known genes, and returns a list of valid symbols. It first retrieves the institute and case objects using `institute_and_case`, then extracts symbols from the stream while ignoring empty lines and comments. For each symbol, it checks if the symbol exists in the store and flashes a warning if not found. Only valid HGNC symbols are added to the return list.
7487	Creates Excel files containing verified variants for each institute, saving them to a temporary directory. Returns the count of successfully written files.
7488	Exports all genes from the database in .bed format by iterating through genes from the specified build and yielding each gene object.
7489	Parse CLNSIG information from VCF annotations, handling both integer accessions and multiple values separated by different delimiters, with fallback to transcript-based annotations when no direct CLNSIG data is available.
7490	Parse compound information from a variant dictionary and return a list of compound objects with generated md5 keys, scores, and display names.
7491	Export all genes from a build, either as JSON or tab-delimited format with chromosome, start, end, HGNC ID, and HGNC symbol columns.
7492	Builds an Individual object from a dictionary of individual information, handling sex and phenotype conversion, and validating analysis type. Raises PedigreeError for missing individual_id or unknown sex/phenotype. Returns a dictionary representing the Individual object with standardized formatting.
7493	The `variants` function uploads variants to a specified case in the Scout system. It accepts various parameters to determine which variant files to upload and under what conditions. The function first retrieves the case object and verifies its existence. It then processes a list of variant file types (cancer, SV, SNV, STR) and their research or clinical categories, deleting existing variants of the same type and loading new ones. If a gene identifier or symbol is provided, it locates the corresponding gene object for filtering variants. The function enforces that research variants are only loaded if research is requested or the `force` flag is used. It logs operations and handles errors by aborting on failure, and warns if no files are specified for upload.
7494	Return a JSON response containing case data for a given institute and case name, or abort with 404 if case is not found.
7495	Show all collections in the database by iterating through adapter collections and echoing each collection name.
7496	Create a new institute and add it to the database with the specified internal ID, display name, and Sanger recipients, or abort if validation fails or loading encounters an error.
7497	Update an institute with the specified parameters including sanger recipient, coverage cutoff, frequency cutoff, and display name, while optionally removing sanger recipient. Handles exceptions by logging warnings and aborting the context.
7498	Return an opened file handle that supports both regular and gzipped files with UTF-8 encoding.
7499	Get the net difference between 'cal_next' and 'cal_prev' querystring parameters, defaulting to 0 if invalid or missing.
7500	Returns the next and previous querystrings based on the given net value. If net is 0, both next and previous are set to 1. If net is positive, next is net+1 and previous is -(net-1). If net is negative, next is net+1 and previous is abs(net)+1.
7501	Checks if the year is within 50 years from the current year. If not, resets year and month to current values and sets error message. Returns the year, month, and error status.
7502	Returns the nearest weekday (Monday-Friday) for a given date, skipping weekends. If the input date is a weekend, it adjusts to the previous weekday if reverse=True, or the next weekday if reverse=False. Returns the adjusted year, month, and day values.
7503	Parse case data for loading into Scout, handling configuration from either command line arguments or a config file, and return a dictionary with all necessary information including family data, owner, VCF files, peddy information, and multiqc data.
7504	Add information from peddy outfiles to the individuals, including ancestry prediction, sex confirmation, and parental relation confirmation.
7505	Parses individual information from a sample dictionary and returns a formatted dictionary with keys including 'individual_id', 'father', 'mother', 'display_name', 'sex', 'phenotype', 'bam_file', 'vcf2cytosure', 'analysis_type', and 'capture_kits'. Raises PedigreeError if required fields are missing or have invalid values.
7506	Parse individual information from samples, reformat to proper individuals, and validate parental relationships. Raises PedigreeError if no samples exist or if parent IDs don't correspond to existing individuals. Returns a list of parsed individual dictionaries.
7507	Parse case information from config or PED files, validating required fields and constructing a case data dictionary with details like owner, collaborators, case ID, display name, genome build, analysis date, individuals, VCF files, panels, and various metadata. Raises ConfigError if owner or family is missing, and handles madeline XML file if present. Sets track to 'cancer' if cancer VCF files are specified.
7508	Parse PED file stream to extract minimal family information, returning family ID and list of sample dictionaries containing individual details like sex and phenotype.
7509	Builds an evaluation object for database insertion containing variant data, user information, classification, and ACMG criteria.

Args:
    variant_specific (str): MD5 string for the specific variant
    variant_id (str): MD5 string for the common variant
    user_id (str): User identifier
    user_name (str): User name
    institute_id (str): Institute identifier
    case_id (str): Case identifier
    classification (str): ACMG classification
    criteria (list): List of dictionaries containing ACMG criteria information

Returns:
    dict: Formatted evaluation object with created_at timestamp and processed criteria
7510	Exports mitochondrial variants for each sample in a case to Excel files. Takes a case ID, optional test flag and output path as input. Retrieves case and variant data from database, generates variant reports for each sample, and writes them to separate Excel files. Returns count of written files.
7511	Check if ACMG criteria for Pathogenic classification are met based on PVS1, PS, PM, and PP terms. Returns True if any of the valid combinations are present, False otherwise.
7512	Check if ACMG criteria for Likely Pathogenic classification is fulfilled based on combination of Very Strong, Strong, Moderate, and Supporting terms. Returns True if any of the six criteria combinations are met, False otherwise.
7513	Check if ACMG criteria for Likely Benign classification are met, which requires either 1 strong benign term with 1 supporting term, or at least 2 supporting terms.
7514	Function `get_acmg` implements the ACMG algorithm to classifyvariants based on provided prediction terms. It categorizes terms into pathogenic and benign evidence types, then applies ACMG rules to determine the final classification (0-4). The function returns an integer representing the classification: 0 - Uncertain Significance, 1 - Benign, 2 - Likely Benign, 3 - Likely Pathogenic, 4 - Pathogenic. The classification process checks for conflicting evidence and applies hierarchical rules to determine the most appropriate category.
7515	Adds gene information from panels to a variant object, including transcript details, disease associations, and penetrance data.
7516	Returns variants for a specific case based on given parameters, supporting filtering, sorting, and pagination. Accepts case ID, optional query filters, variant IDs, category type, number of variants to return, skip count, and sort key. Uses MongoDB query builder and supports sorting by variant rank, rank score, or position. Yields iterable of variant objects.
7517	Return all variants with sanger information for a given institute and/or case.
7518	Returns the specified variant object by searching with either a case_id and variant_id combination or a unique document_id. If the variant exists, it adds gene information and checks if the variant is in a paralogous region for X/Y chromosomes.
7519	Return all variants seen in a given gene, with options to filter by category and variant type, and control the number of results returned.
7520	Return all verified variants for a given institute by querying validation events and joining with case and variant data.
7521	Return all causative variants for an institute, optionally filtered by case ID. If case_id is provided, returns causatives for that specific case. If only institute_id is provided, returns all causatives across all cases for that institute. Yields variant document IDs.
7522	Check if there are any variants that are previously marked causative in the institute or case, and return matching variants.
7523	Find the same variant in other cases marked causative by comparing variant IDs and case IDs.
7524	Delete variants of a specified type and category for a given case, used when reanalyzing a case. Returns the count of deleted variants.
7525	Return overlapping variants by looking at genes that a variant overlaps to, then return all variants that overlap these genes. For SV variants, it returns overlapping SNVs and vice versa. The method queries variants based on case_id, category (opposite of input variant's category), and overlapping HGNC ids, then sorts by rank score in descending order and limits to 30 most severe variants.
7526	Returns all evaluated variants for a given case, including SNVs/indels and SVs that have ACMG classification, manual rank, dismissal status, or comments. Queries variants by case_id and filters for those with evaluation entries, then adds gene information and includes commented variants that may not have evaluation entries. Returns a list of variant objects with additional metadata.
7527	Method `get_region_vcf` generates a reduced VCF file containing variants from specified genomic coordinates for use in the alignment viewer. It accepts parameters for case object, chromosome, start/end positions, gene object, variant type, category, and rank threshold. The method retrieves the appropriate VCF file based on variant type and category, validates its existence, and creates a temporary file containing header lines and variants within the specified region. If a gene object is provided, it overrides chromosome, start, and end coordinates with gene coordinates. The method returns the path to the temporary VCF file.
7528	Retrieves variant objects from a specific patient by filtering variants based on variant IDs, category, and sample genotype calls. Uses a regex pattern to identify non-wild-type alleles and returns matched variants from the variant collection.
7529	Get a client to the mongo database

Parameters:
host (str): Host of database
port (int): Port of database
username (str)
password (str)
uri (str)
authdb (str): database to use for authentication
timeout (int): How long should the client try to connect

Returns:
MongoClient: A client connection to the mongo database

Raises:
ConnectionFailure: If connection to the database is refused

The function creates a MongoDB client connection using either a provided URI or by constructing one from individual connection parameters. It handles authentication if username and password are provided, and logs the connection attempt with masked credentials for security. The connection timeout can be customized, and the function will raise a ConnectionFailure exception if the connection cannot be established within the specified timeout period.
7530	Extracts objects from a form for ClinVar database submission, either variant or case data types, using specified variant IDs and form fields to create structured submission objects with unique IDs.
7531	This function determines which fields should be included in a CSV header for ClinVar submission by analyzing a list of submission objects. It takes a list of submission objects (variants or case data) and a CSV type parameter ('variant_data' or 'case_data') as input, and returns a dictionary containing only the fields that are actually present in the submission objects, with their corresponding header values from either CLINVAR_HEADER or CASEDATA_HEADER. The function loops through all available fields in the complete header and checks if each field exists in any of the submission objects, then builds a custom header that reflects the actual data being submitted.
7532	Creates CSV lines for ClinVar submission from submission objects and header configuration, handling missing fields by adding empty quoted strings.
7533	Load all transcripts from Ensembl, associate them with HGNC genes, assign refseq identifiers based on priority rules, and build transcript objects with primary transcript information. Returns a list of transcript objects.
7534	Add a gene panel to the database, supporting OMIM, Panel App, or local panel file sources.
7535	Builds and returns an Exon object from exon information dictionary, validating required fields and their types. Raises KeyError for missing fields and TypeError for incorrect data types. The function expects exon_info to contain chromosome, start, end, rank, exon_id, transcript, and hgnc_id fields with appropriate data types. The build parameter specifies the genome build version, defaulting to '37'.
7536	Deletes a specific version or all versions of a gene panel from the database based on the provided panel ID and version parameters.
7537	Deletes all indexes from all collections in the database and logs the operation.
7538	Delete a user from the database by email address, logging a warning if the user is not found.
7539	Delete all genes in the database, with optional build specification. If a build is specified, drops the genes collection for that specific build; otherwise, drops the genes collection for the default build. Logs the operation at INFO level.
7540	Deletes all exons from the database for the specified build using the adapter's drop_exons method.
7541	Deletes a case and its variants from the database based on case_id or display_name, with optional institute specification. Returns error if case doesn't exist or if required parameters are missing.
7542	Show all individuals from all cases in the database, filtered by institute and causatives if specified, and display their information in a tabular format.
7543	Parse MatchMaker matches objects into a readable format for display, extracting match details like date, type, and matching patients with their scores and metadata.
7544	Display cases from the database with optional filtering by institute, display name, or case ID, and optionally show variant counts and apply a variants threshold.
7545	Returns the currently active user as a LoginUser object, or None if no user is found.
7546	Login a user if they have access, handling Google OAuth flow or direct email-based login with whitelist checking.
7547	Builds and returns an institute object with the specified parameters, removing any None valued fields from the resulting object.
7548	Delete an event from the database using the provided event_id. The method logs the deletion operation and handles both ObjectId and string representations of the event_id. It removes the event from the event_collection based on the specified database key.
7549	Creates an event document with the specified parameters and saves it to the event collection. Returns the inserted event dictionary containing institute, case, user, link, category, verb, subject, level, variant_id, content, panel, and timestamp fields.
7550	Fetch events from the database based on institute, case, variant_id, level, comments, and panel parameters, returning a pymongo.Cursor with sorted results.
7551	Fetch all events by a specific user, or all events if no user is specified.
7552	Add a new phenotype term to a case by creating a phenotype term and corresponding event, supporting both HPO and OMIM terms with optional grouping functionality.
7553	Remove an existing phenotype term or group from a case and create a removal event. If is_group is True, removes from both phenotype_terms and phenotype_groups arrays. Returns the updated case document.
7554	Adds a comment to either a variant or a case by creating an event log. If a variant is provided, the comment can be either 'specific' or 'global' and will be associated with that variant. If no variant is provided, the comment is associated with the case. Raises SyntaxError if comment_level is not 'specific' or 'global'. Returns the created comment event.
7555	Parse genotype calls for a variant by iterating through individuals and their positions, returning a list of parsed genotypes.
7556	Check if a variant coordinate falls within a specified genomic interval. Returns True if the variant chromosome matches the coordinates chromosome and the position is within the start and end bounds, otherwise returns False.
7557	Function `hpo_terms()` renders a search interface for HPO phenotype terms. For GET requests, it retrieves up to 100 HPO terms from the store. For POST requests, it searches for specific HPO terms based on user input, returning the search results along with the query term and limit.
7558	Exports all transcripts to a BED-like format with columns: Chrom, Start, End, Transcript, RefSeq, HgncID
7559	Load exons into the scout database by first dropping existing exons if any, then fetching and loading new exons from Ensembl, and finally updating database indexes.
7560	Loads all variants within a specified genomic region into an existing case using the provided adapter.
7561	Returns all events that have an occurrence within the specified month and year, filtering by category and tag if provided, and optionally including location and cancellation data.
7562	Returns a queryset of events that will occur again after 'now', including recurring events and multi-day events, while excluding single-day events that have already passed.
7563	Parse requirements from nested pip files recursively, handling comments, empty lines, and nested requirements files with '-r' flag.
7564	Check if a gene with the given hgnc_id already exists in the panel's genes collection. Returns the gene object if found, None otherwise.
7565	Updates an existing gene panel with genes from CSV data, either adding new genes or replacing all existing genes. Returns the updated panel object or None if the panel doesn't exist or if there's a syntax error in the CSV data.
7566	Creates a new gene panel document in the store with the given parameters, parses genes from CSV input, and handles various error conditions including institute validation, duplicate panel checking, and gene parsing errors. Returns the ID of the newly created panel or None if creation fails.
7567	Preprocesses a gene panel by fetching institute information and creating a formatted name-version string, then returns the modified panel object in a dictionary.
7568	Get information about a case from archive, including collaborators, synopsis, assignees, suspects, causatives, phenotype terms, and phenotype groups, by querying the database for related data.
7569	Migrates case information from an archive into a Scout case document, updating collaborators, assignees, suspected/causative variants, synopsis, and phenotype data. It ensures that variants are either added to or already present in the case, and updates the case as migrated.
7570	Function `migrate` updates manually annotated information from an old Scout instance to a new one. It connects to both source and target MongoDB databases, checks if the case has already been migrated, retrieves archived case data, and either prints it (dry run) or prepares for migration (implementation pending). The function takes parameters including source URI, archive URI, case ID, and flags for dry-run and force operations.
7571	Uploads research variants to specified cases or all cases with research requested. Handles SNV, SV, and cancer variants, deleting existing research variants before loading new ones. Uses a default rank threshold of 8. Requires force flag to load non-requested cases.
7572	Load genes into the database by collecting and merging information from multiple sources (Ensembl, HGNC, ExAC, OMIM, HPO) into gene objects, then bulk load them into the adapter. Handles missing data and logs progress and statistics during the loading process.
7573	This function displays HPO (Human Phenotype Ontology) terms from the database based on the provided context, term, or description parameters. It can search for a specific HPO term by ID, search for terms by description, or list all HPO terms. The output format includes the HPO ID, description, and gene count for each term. The function handles term ID formatting to ensure HP: prefix and proper numeric formatting. It uses click for output formatting and includes logging for informational and warning messages.
7574	This function is a Flask application factory that creates and configures a Flask app with optional configuration from files or dictionaries. It sets up basic application settings, initializes extensions, registers blueprints and filters, configures logging (including email logging for errors in non-debug mode), and sets up a before_request handler to enforce authentication for protected routes. The function returns the configured Flask application instance.
7575	Initializes and configures various Flask extensions including Flask-DebugToolbar, Flask-Bootstrap, Flask-MongoEngine, Flask-Store, Flask-Login, Flask-OAuth, Flask-Mail, and Flask-Markdown. Additionally, it conditionally initializes Flask-coverage and LoqusDB based on configuration settings.
7576	Register Flask blueprints for public, genes, cases, login, variants, panels, dashboard, api, alignviewers, phenotypes, and institutes modules.
7577	Summary: Configures coverage-related extensions for the application, including setting up Chanjo report functionality with SQL Alchemy tracking, initializing Babel for internationalization, and defining a locale selector that determines the language to use for translations based on session parameters, configuration settings, or browser accept headers.
7578	Show all alias symbols and how they map to ids, or find genes by a specific alias symbol. If no symbol is provided, returns all aliases. If a symbol is provided, returns the true HGNC symbol and associated gene IDs for that alias.
7579	Builds a gene panel object from panel information and validates it against the database institute.

Args:
    panel_info (dict): Dictionary containing panel information including id, institute, version, date, and genes
    adapter (scout.adapter.MongoAdapter): Database adapter for institute and gene validation

Returns:
    dict: Complete gene panel object with validated institute, version, date, and gene objects

Raises:
    KeyError: If panel missing required fields (id, institute, version, date)
    IntegrityError: If institute doesn't exist in database or genes don't exist in database

The function validates that the panel has all required fields, checks that the institute exists in the database, converts version to float, builds gene objects for all genes in the panel (with error handling for missing genes), and returns a complete panel object with all validated information.
7580	Export verified variants for an institute and write them to an Excel file. If called for testing purposes, return the number of written files without actually creating a file. For actual use, create an Excel file containing the verified variants data. Returns the number of written files (0 or 1).
7581	This function exports causative variants for a specified collaborator in VCF format. It takes parameters including context, collaborator name, document ID, case ID, and a JSON flag. The function retrieves variants using an adapter, then outputs them either as JSON or in VCF format. When case_id is provided, it includes additional INFO fields and genotypes in the VCF output, along with sample information for each individual in the case. The function uses a VCF header template and formats each variant according to VCF specifications.
7582	Get VCF entry from variant object, including handling SNV and SV types, constructing INFO field with END and TYPE/SVTYPE, and optionally adding genotype calls for samples.
7583	Start a web server with MongoDB connection checking and optional livereload functionality. The function:
1. Configures MongoDB connection parameters from context object
2. Tests the MongoDB connection and aborts if unsuccessful
3. Creates a Flask application with MongoDB configuration
4. Either serves the application with livereload or directly runs it

The server will:
- Connect to MongoDB using credentials from context
- Validate the MongoDB connection before starting
- Run the Flask app on specified host/port with debug mode
- Optionally enable livereload for automatic reloading during development
7584	Generate an MD5 hash key from a list of string arguments by concatenating them with spaces and hashing the resulting string. Raises SyntaxError if any argument is not a string. Returns the hexadecimal digest of the MD5 hash.
7585	Initializes the application by connecting to a MongoDB database using configuration settings from Flask app config.
7586	Setup connection to database by initializing various collection references from the provided database object, including tables for HGNC genes, users, whitelists, institutes, events, cases, gene panels, HPO terms, disease terms, variants, ACMG criteria, ClinVar data, ClinVar submissions, exons, and transcripts.
7587	Creates database indexes by either updating existing indexes or loading new ones based on the update parameter.
7588	Setup a scout database with the provided institute and user information, using the OMIM API key for data retrieval. If any required information is missing, it will use defaults from the context or abort with a warning. The function initializes the database connection and configures the scout adapter with the specified parameters.
7589	Sets up a scout demo instance with a case, gene panel, and variants using the provided context parameters.
7590	Setup scout instances by configuring database connection settings, establishing MongoDB connection with error handling, and initializing a mongo adapter stored in the context object.
7591	Displays all institutes in the database. If an institute_id is provided, shows only that institute. Outputs data in either tabular format or JSON format. Returns error if specified institute doesn't exist or no institutes are found.
7592	Parse the genetic models entry of a vcf by splitting the raw vcf information by comma and colon, then extract the genetic models for the specified case_id by splitting by pipe. Returns a list of genetic models.
7593	Show all gene panels in the database for a given institute, displaying panel name, version, number of genes, and date. If no panels are found, abort the operation.
7594	Adds an institute to the database, checking for duplicates before insertion. Raises IntegrityError if institute already exists. Returns insertion status information.
7595	Update information for an institute, including sanger recipients, coverage and frequency cutoffs, display name, and phenotype groups. Supports adding or replacing phenotype groups and handles user validation for sanger recipients. Returns the updated institute object.
7596	Fetch a single institute from the backend by ID.

Args:
    institute_id (str): The ID of the institute to fetch

Returns:
    Institute object: The fetched institute object, or None if not found

Debug logs are generated to track the fetch operation and indicate when an institute is not found.
7597	Check if a string is a valid date in YYYY-MM-DD, YYYY/MM/DD, YYYY.MM.DD, or YYYY MM DD format (years 1900-2099, months 01-12, days 01-31). Returns True if valid, False otherwise.
7598	Returns a datetime object for a valid date string, raises exception for invalid dates, returns today's date if no date provided. Supports multiple date formats ( '-', ' ', '.', '/') and custom date_format parameter.
7599	Export a list of genes based on HPO terms, displaying gene IDs and their counts. If no HPO terms are provided, it logs a warning and aborts the command. The output is formatted with a header "#Gene_id\tCount" followed by gene data.
7600	Parse a rank score entry string to extract the score for a specific case ID.

Args:
    rank_score_entry (str): The raw rank score entry containing comma-separated family info
    case_id (str): The case ID to look for

Returns:
    float: The rank score for the specified case ID, or None if not found
7601	Add a user to the database with specified institute affiliations and admin role status.
7602	Check if a connection can be established to a MongoDB instance with the specified parameters.

Args:
    host (str): Hostname or IP address of the MongoDB server (default: 'localhost')
    port (int): Port number of the MongoDB server (default: 27017)
    username (str): Username for authentication (default: None)
    password (str): Password for authentication (default: None)
    authdb (str): Database to use for authentication (default: None)
    max_delay (int): Maximum milliseconds to wait for connection (default: 1)

Returns:
    bool: True if connection could be established, False otherwise

The function constructs a MongoDB URI with proper authentication if credentials are provided, tests the connection using MongoClient, and returns True if successful or False if connection fails.
7603	Initializes MongoDB connection from Flask app configuration, sets up database client and database name in app config, handles connection failure by aborting.
7604	Loads a delivery report into a case document in the database. If the case doesn't exist, raises DataNotFoundError. If a delivery report already exists, either replaces it (when update=True) or raises IntegrityError. Returns the updated case document.
7605	Add a user object to the database.

Args:
    user_obj (scout.models.User): A dictionary with user information

Returns:
    user_info (dict): A copy of what was inserted

Raises:
    IntegrityError: If user already exists in database
7606	Visualizes BAM alignments for specified genomic positions with optional VCF, genome, and exon data.
7607	Load exons from Ensembl data into database, skipping those with missing genes or transcripts, and log loading statistics including time and counts.
7608	Update all compounds for a case using the adapter, with error handling and case validation.
7609	Update a gene object with various external links including HGNC, OMIM, Ensembl, HPAs, STRING, Reactome, ClinGen, Expression Atlas, ExAC, Entrez, PPaint, VEGA, and UCSC links based on gene identifiers.
7610	This function queries HGNC (HUGO Gene Nomenclature Committee) gene information using either a gene symbol or HGNC ID. It takes parameters including the click context, HGNC symbol, HGNC ID, and genome build. The function first validates that either a symbol or ID is provided, then retrieves gene data from the database adapter. If an HGNC ID is provided, it fetches the corresponding gene to get the symbol. It then queries for all genes matching the symbol and outputs the results in a tab-separated format including HGNC ID, symbol, aliases, and transcripts. If no results are found, it logs an info message. The function uses click for output formatting and logging for warnings and info messages.
7611	Parse an HGNC formatted line into a dictionary with gene information, including symbol, HGNC ID, description, aliases, and various gene identifiers like ENSEMBL, OMIM, Entrez, RefSeq, UniProt, UCSC, and Vega IDs. Skip genes with 'Withdrawn' status.
7612	Parse HGNC formatted gene lines from an iterable, yielding dictionaries with relevant gene information. Takes lines from HGNC database dumps (ftp://ftp.ebi.ac.uk/pub/databases/genenames/new/tsv/hgnc_complete_set.txt) and yields parsed gene data after processing the header and skipping empty lines.
7613	Retrieve the database id of an open clinvar submission for a user and institute, if none is available then create a new submission and return it.
7614	Updates a ClinVar submission object by saving an official ClinVar submission ID and updating the timestamp. Returns the updated submission object.
7615	Returns the official Clinvar submission ID for a given submission object by querying the clinvar submission collection with the provided submission ID. The method retrieves the 'clinvar_subm_id' field from the submission object, which is only present if previously provided by the user. Returns the Clinvar submission ID string in format "SUB[0-9]" or None if not found.
7616	Adds submission objects (variants and case data) to clinvar collection and updates the corresponding submission object with their IDs. Returns the updated submission object. Handles duplicate key errors during insertion.
7617	Update the Clinvar submission status to 'closed' for a specific submission ID, and also close all other submissions for the same user if the new status is 'open'. Return the updated submission object.
7618	Collect all open and closed clinvar submissions created by a user for an institute, including associated variant and case data.
7619	Delete a variant object from ClinVar database and update the corresponding submission object by removing references and deleting associated data.
7620	Get all variants included in ClinVar submissions for a case by querying the clinvar collection for objects with the specified case_id and csv_type='variant', then return a dictionary with variant local_ids as keys and their corresponding submission objects as values.
7621	Parse HPO OBO formatted lines into structured terms with id, description, aliases, and ancestors.
7622	Function `genes()` renders a search box for genes by getting the query parameter from the request, redirecting to the gene page if the query contains a '|' character, otherwise fetching up to 20 genes from the store and returning them in a dictionary.
7623	Function `gene(hgnc_id=None, hgnc_symbol=None)` renders information about a gene based on either HGNC ID or HGNC symbol. If an HGNC symbol is provided, it queries the store to find the corresponding HGNC ID. If exactly one gene is found, it uses that ID; otherwise, it redirects to a genes page with the symbol as query parameter. The function then retrieves gene information using a controller, returning a 404 error if the gene is not found.
7624	Returns JSON data about genes based on an optional query parameter.
7625	Check if gene panels exist in the database and validate that default panels are defined in the panels list. Returns True if all panels exist and default panels are properly defined, False otherwise.
7626	Loads all variants in a specified genomic region for a given case, supporting SNV, SV, and STR variant types. The region can be defined either by a gene's HGNC ID or by chromosome coordinates. It handles both clinical and research variants, logging the process and raising errors for missing cases or genes.
7627	Loads a new case from a Scout configuration, validates gene panels, and returns the loaded case object.

Args:
    adapter (MongoAdapter): Database adapter
    config (dict): Loading configuration information
    ped (Iterable[str]): Pedigree information
    update (bool): Whether to update existing case

Returns:
    case_obj: The loaded case object

Raises:
    ConfigError: If any panel in the configuration does not exist in the database
7628	Template decorator that renders a template with context returned by the decorated function. If no template is specified, it automatically generates a template name based on the request endpoint. Returns the rendered template with the function's context dictionary, or passes through non-dict return values.
7629	Fetch institute and case objects, validate access permissions, and return appropriate objects or abort requests with 404/403 errors.
7630	Preprocess institute objects by retrieving all institutes for admin users or specific institutes for regular users based on their institute memberships.
7631	Get the HGNC id for a gene based on priority order: 1) use existing HGNC id, 2) match HGNC symbol to gene's proper HGNC symbol, 3) randomly choose from alias matches if symbol only matches aliases. Raises exception if no gene is found for the symbol.
7632	Update a panel in the database by checking if it exists and then updating its version and date information.
7633	This function updates disease terms in a MongoDB database by fetching OMIM data using an API key, dropping the existing disease terms collection, and loading new disease terms from the fetched data. It includes error handling for missing API keys and failed data fetching, logging appropriate messages throughout the process.
7634	Load OMIM phenotypes into database by parsing genemap2.txt and associating HPO terms from disease-to-gene-to-phenotype data, then build and load disease term objects using gene mappings.
7635	Parses variant frequencies from VCF info fields or transcripts, supporting 1000Genomes, ExAC, and gnomAD databases. Returns a dictionary containing available frequency annotations.
7636	Parse a frequency value from a variant's INFO dictionary field.

Args:
    variant (cyvcf2.Variant): The variant object containing INFO data
    info_key (str): The key name for the frequency field in INFO

Returns:
    float or None: The parsed frequency value as float, or None if field doesn't exist or is missing

The function retrieves the specified INFO key from the variant, handles missing values (represented as '.') by converting them to None, and converts valid numeric values to float type.
7637	Parse structural variant frequencies from VCF INFO fields, extracting specific frequency-related annotations and converting their values to appropriate numeric types (float for AF fields, int for others), returning only those with positive values.
7638	Show all users in the database including their name, email, roles, and institutes. If no users are found, log.info("No users found") and abort. Print user information in a tabular format with fields separated by tabs.
7639	Builds a HGNC gene object from gene information dictionary, validating required fields and populating optional fields. Returns a dictionary containing gene metadata including HGNC ID, symbol, Ensembl ID, genomic coordinates, descriptions, aliases, cross-references, inheritance models, and phenotypes. Raises KeyError for missing required fields and ValueError/TypeError for invalid data types.
7640	Loads a gene panel by building a panel object from parsed panel information and adding it to the database through the add_gene_panel method.
7641	Load and create/update the OMIM-AUTO gene panel from OMIM API data, including version management and gene comparison.
7642	Compare two OMIM panels and return genes that are in the new panel but not in the existing panel.
7643	Update the version information for genes in a panel by setting the database entry version to either the new panel version (for new genes) or the old version (for existing genes).
7644	Adds a gene panel to the database, raising an IntegrityError if a panel with the same name and version already exists. Returns the ID of the inserted panel.
7645	Fetch a gene panel by '_id' from the panel collection.

Args:
    panel_id (str, ObjectId): str or ObjectId of document ObjectId

Returns:
    dict: panel object or `None` if panel not found
7646	Delete a panel by '_id' and return the deletion result.
7647	Fetch a gene panel from the database by panel_id and optional version. If version is not specified, return the latest version. If no panel is found, return None.
7648	Return all gene panels, optionally filtered by panel_id, institute_id, and/or version. If panel_id is provided, returns all versions of panels with that name. If institute_id is provided, filters by institute. Returns a pymongo cursor.
7649	Builds a dictionary mapping gene IDs to sets of panel names by collecting all gene panels from a case object and grouping them by gene. Returns a dictionary where keys are gene IDs and values are sets of panel names.
7650	Update an existing gene panel with a new one, keeping the same object ID. If a version is provided, update the panel version while preserving the original date unless a new date object is specified. If no version is provided, update the date to the current date or the provided date object. Return the updated panel document.
7651	Add a pending action to a gene panel by storing it in panel.pending. Takes a panel object, gene object, action type (add/delete/edit), and optional info dictionary. Validates action type, creates a pending action dictionary, and updates the panel document in the database by adding the pending action to the 'pending' array. Returns the updated panel document.
7652	Apply pending changes to a gene panel, either updating the existing panel or creating a new version. Processes add, delete, and edit actions on genes, updates info fields, and handles version control by either replacing the current panel or archiving it and inserting a new one. Returns the ID of the updated or new panel.
7653	Return all the clinical gene symbols for a case by querying panel collections and extracting unique gene symbols from specified panels.
7654	This function interacts with cases in a database by retrieving case objects based on various filter criteria. It can fetch a specific case by ID or a list of cases filtered by parameters like institute, reruns status, finish status, causatives presence, research request status, research flag, and case status. The results can be output as JSON or printed in a formatted way using pretty printing. If no cases are found matching the criteria, it logs an info message indicating so.
7655	Emit a record by formatting it and sending it via email. The method constructs an email message with proper headers (From, To, Subject, Date) using the record data and sends it through an SMTP server. It supports optional TLS encryption and authentication if username/password are provided. If any error occurs during the email sending process, it calls handleError to handle the exception.
7656	Add proper indexes to the scout instance by iterating through defined indexes, removing existing old indexes, and creating new indexes for each collection.
7657	Update database indexes by adding any missing indexes to collections. Returns the number of indexes updated.
7658	Drop all indexes for the database by iterating through all collections in INDEXES and removing their indexes.
7659	Builds a MongoDB query dictionary for variant searching across multiple cases, supporting SNV, SV, STR, and cancer variants with clinical or research types, while ensuring indexed query parameters for performance.
7660	Builds a MongoDB query for variant filtering based on case ID, query parameters, and variant IDs. Supports filtering by genetic models, frequencies, annotations, clinical significance, genomic coordinates, gene panels, and other criteria. Returns a dictionary formatted for MongoDB queries.
7661	Add clinsig filter values to the mongo query object based on query parameters and trusted revision levels.
7662	Adds genomic coordinate-related filters to a query object by incorporating chromosome information and optional start/end position ranges into the database query structure.
7663	Adds gene-related filters to the query object by processing hgnc_symbols and gene_panels from the input query, applying appropriate MongoDB query filters and returning the constructed gene query.
7664	Function `wipe(ctx)` drops a MongoDB database specified in the context object. It retrieves the database name from `ctx.obj['mongodb']`, attempts to drop it using the MongoDB client, and handles any exceptions by logging a warning and aborting the operation. On success, it logs that the entire database has been dropped.
7665	Parse a CSV stream containing panel gene data and return a list of gene dictionaries with their associated metadata including HGNC ID, symbols, disease-associated transcripts, inheritance models, and other genetic annotations.
7666	Builds a clnsig object from clnsig_info dictionary containing value, accession, and revstat fields.
7667	Load a bulk of HGNC gene objects into the database collection, handling potential integrity errors during insertion. Returns the insertion result.
7668	Load a bulk of transcript objects to the database.

Arguments:
    transcript_objs (iterable(scout.models.hgnc_transcript))

Returns:
    result of the bulk insert operation

Raises:
    IntegrityError: if there are duplicate keys or bulk write errors
7669	Load a bulk of exon objects to the database.

Arguments:
    exon_objs (iterable(scout.models.hgnc_exon))

Returns:
    result of the database insert operation

Raises:
    IntegrityError: if duplicate key or bulk write error occurs in database insertion
7670	Fetch a HGNC gene by identifier (either HGNC ID or symbol) and build version, returning the gene object with associated transcripts. Supports build versions 37 and 38, defaults to build 37 if invalid build is specified. Returns None if gene is not found.
7671	Query the genes with a hgnc symbol and return the hgnc id

Args:
    hgnc_symbol(str)
    build(str)

Returns:
    hgnc_id(int)
7672	Fetch all HGNC genes matching a HGNC symbol by checking both symbol and aliases, with optional partial searching support.
7673	Fetch all HGNC genes for a specified build and return them sorted by chromosome.
7674	Return the number of HGNC genes in the collection, optionally filtered by genome build. If no build is specified, returns the total count of all genes. Uses MongoDB's count() method to retrieve the result.
7675	Delete the genes collection, optionally filtering by build version. If a build is specified, removes all documents with that build number from the hgnc_gene collection. If no build is specified, drops the entire hgnc_gene collection.
7676	Delete the transcripts collection, optionally filtered by build number, or drop the entire collection if no build is specified.
7677	Delete the exons collection, optionally filtered by build. If build is specified, deletes exons matching that build. If no build is specified, drops the entire exons collection.
7678	Return a dictionary with ensembl ids as keys and transcripts as values for the specified build.
7679	Return a dictionary mapping HGNC symbols to gene objects for a specific build, optionally filtered by a list of genes.
7680	Return a pymongo cursor with hgnc_genes for a gene symbol. If the symbol is listed as primary, return only one result. Otherwise, return all hgnc genes that have the symbol as an alias.
7681	Return a dictionary mapping HGNC symbols to their associated HGNC IDs, where each symbol maps to a dictionary containing the true ID and a set of all related IDs. If a symbol is listed as primary, only that entry is included; otherwise, all possible IDs are listed in the 'ids' set.
7682	Return a dictionary with ensembl ids as keys and gene objects as value.

Args:
    build(str): The genome build version (default is '37')

Returns:
    genes(dict): A dictionary mapping ensembl gene IDs to their corresponding gene objects

Fetches all genes from the database for the specified build and returns them in a dictionary format with ensembl IDs as keys.
7683	Check if a HGNC symbol is an alias and return the correct HGNC symbol, or None if not found.
7684	Add HGNC IDs to genes by looking up their symbols in the genes_by_alias dictionary, handling cases where genes don't exist or have ambiguous IDs by logging warnings and setting appropriate hgnc_id values.
7685	Return a dictionary with chromosomes as keys and interval trees as values, where each interval represents a coding region of overlapping genes, with start positions adjusted by -5000 and end positions adjusted by +5000.
7686	Update the automatically generated OMIM gene panel in the database using the provided API key and institute information, with error handling and validation checks.
7687	Display a list of cases for an institute with filtering options and sanger evaluation status.
7688	Display a single case by retrieving the institute and case objects, fetching case data, and returning a dictionary containing the institute, case, and case data.
7689	Show all MatchMaker matches for a given case, but only for authorized users with 'mme_submitter' role. Validates MME configuration parameters and returns match data or flashes errors if configuration is invalid or server returns errors.
7690	Starts an internal match or a match against one or all MME external nodes for a given institute and case, after verifying user authorization and valid configuration parameters. Returns a redirect to the referrer page with appropriate flash messages indicating success or failure of the match request.
7691	Remove a case from MatchMaker by deleting patient data, with authorization checks and configuration validation. Returns redirect to referrer with success/error messages.
7692	Function `case_report` visualizes a case report by retrieving institute and case objects, gathering case report content, and returning a dictionary with institute object, case object, HTML format, and additional data.
7693	Download a PDF report for a specified case, including coverage report and pedigree information.
7694	This function adds or removes a diagnosis for a case by retrieving the institute and case objects, getting the current user, determining the diagnosis level (phenotype or gene), extracting the OMIM ID from the request form, and checking if the diagnosis should be removed based on URL parameters. It then calls the store.diagnose method to perform the actual diagnosis update and redirects back to the previous page.
7695	This function handles phenotype operations for a case, including adding or removing phenotype items/groups. It retrieves the institute and case objects, then either deletes a phenotype if `phenotype_id` is provided or adds a new phenotype based on the request form data. The function supports both HPO terms (with 'HP:' prefix or 7-character format) and OMIM terms. After processing, it redirects to the case page. Error handling is included for invalid phenotype terms, returning a 400 error if adding fails.
7696	This function performs various actions on phenotypes associated with a specific case within an institute. It handles multiple operations such as deleting phenotype terms, searching for diseases using Phenomizer, updating gene lists, and generating HPO-based gene lists. The function retrieves the institute and case objects, processes form data to determine the action and associated HPO IDs, and executes the appropriate operation using the store object. The available actions include 'DELETE' to remove phenotypes, 'PHENOMIZER' to query disease associations, 'GENES' to update dynamic gene lists from input symbols, and 'GENERATE' to create gene lists based on HPO terms. After processing, it redirects back to the case page.
7697	Handle events by creating or deleting comments. If event_id is provided, delete the event. Otherwise, create either a variant comment (if variant_id is specified) or a case comment, then redirect to the referrer page.
7698	Updates the status of a specific case in the given institute. Retrieves the institute and case objects, gets the user object, and updates the case status based on the form input. If the status is 'archive', it archives the case; otherwise, it updates the case status. Finally, redirects to the previous page.
7699	Assigns or unassigns a user from a case based on the request action. If user_id is provided, assigns/unassigns that user; otherwise uses the current user. Uses DELETE action to unassign, otherwise assigns. Redirects to the previous page after operation.
7700	Search for HPO terms based on a query parameter and return up to 7 matching terms in JSON format, each containing the term's name and ID.
7701	Marks a variant as Sanger validated by retrieving the institute, case, and variant objects, getting the current user, determining the validation type from form data, creating a link to the variant, and calling the store's validate method to record the validation. Finally, redirects to the referrer or the variant link.
7702	Mark a variant as confirmed causative by adding or removing it from the case's causative list, then redirect back to the case page.
7703	Displays a delivery report for a specific institute case, either the most recent one or the one corresponding to a given date. Returns the report file if found, otherwise returns a 404 error.
7704	Shares or unshares a case with a collaborator institute based on the 'revoke' flag in the request form.
7705	Request a case to be rerun by sending an email notification to the ticket system and redirecting back to the previous page.
7706	Opens the research list for a specified case by retrieving the institute and case objects, getting the current user, creating a URL link, and then opening the research in the store before redirecting to the previous page.
7707	Downloads and delivers a vcf2cytosure file for a given individual as an attachment.
7708	Load and return the multiqc report for a given case. If the report doesn't exist, return a 404 error.
7709	Preprocess case objects for display by adding necessary information and grouping cases by status. Returns a dictionary containing cases grouped by status, total found cases count, and display limit.
7710	Gathers content for a case report by collecting and decorating various types of variants (causatives, suspects, classified, tagged, dismissed, commented) along with case comments and metadata. Returns a dictionary containing the structured case data ready for visualization.
7711	Generates a coverage report by sending a request to chanjo-report, extracts and processes the HTML body content, removes all links from the response, and returns the cleaned body content as a string. The function collects sample IDs and panel information from the case object, uses institute-specific coverage cutoff settings, and formats the panel names with their versions. It makes a GET request to the specified base URL with the constructed parameters and processes the response using BeautifulSoup to extract and clean the body content.
7712	Get all Clinvar submissions for a user and an institute.
7713	Function `mt_excel_files` collects MT variants from a case and exports them to Excel format files, one per sample. It queries the database for MT variants, iterates through each sample, formats the variant data using `export_mt_variants`, creates an Excel workbook with the formatted data, and saves it to the specified directory. The function returns the number of successfully written files.
7714	Updates the synopsis of a case and creates an event only if the synopsis has actually changed.
7715	Function `hpo_diseases` queries Phenomizer with given HPO terms and returns matching disease associations. It takes a username, password, list of HPO IDs, and optional p-value threshold (default 1). The function returns a generator of dictionaries containing disease information including p-values, disease source, disease number, gene symbols, description, and raw line data. Diseases are filtered to only include those with p-values less than or equal to the threshold. If a SystemExit exception occurs during the query, the function returns None.
7716	Returns the display name and vcf2cytosure file path for a specific individual in a case.
7717	Find MultiQC report for the case by retrieving institute and case objects using the provided store, institute_id, and case_name, then return both objects in a dictionary.
7718	Returns a list of variants from an institute that have Sanger validations ordered but not yet evaluated. Each item in the list contains a case display name as key and a list of variant IDs as values, where the variants have Sanger validation ordered but not yet validated (excluding those already marked as True positive or False positive).
7719	Add a patient to MatchMaker server by submitting case data including gender, HPO features, OMIM disorders, and genomic features if specified. Returns information submitted and server responses.
7720	Delete all affected samples for a case from MatchMaker.

Args:
    case_obj(dict) a scout case object
    mme_base_url(str) base url of the MME server
    mme_token(str) auth token of the MME server

Returns:
     server_responses(list): a list of objects with patient_id, message, and status_code for each deletion response
7721	Returns matchmaker submission data for a case and its matches from the MatchMaker server, including institute and case information along with any server errors encountered during the request.
7722	Initiates a MatchMaker match against either internal Scout patients or external nodes, returning a list of match results. For internal matches, it sends patient data to a local MatchMaker node. For external matches, it queries specified external nodes using patient IDs. Handles both specific node matching and matching against all available nodes. Returns detailed response objects containing results, status codes, and messages from each server interaction.
7723	Load HGNC aliases and related gene information (genes, transcripts, exons) into the mongo database from various sources including OMIM, HPO, Ensembl, and HGNC, with optional build specification and API key for OMIM data retrieval.
7724	Parse variant callers' performance from VCF INFO fields, returning a dictionary with caller IDs as keys and their filtering status ('Pass', 'Filtered', or None) as values. Handles both standard 'set' field parsing and custom 'FOUND_IN' field parsing for different variant categories.
7725	Builds an hgnc_transcript object from transcript information dictionary, requiring ensembl transcript ID, chromosome, start position, end position, and hgnc_id. Optional fields include refseq_id, refseq_identifiers, and is_primary status. Validates data types and raises appropriate exceptions for missing or invalid required fields. Removes None-valued keys from the resulting object.
7726	Loads an institute into the database using the provided adapter, internal ID, and display name, with optional Sanger recipients.
7727	Parse CADD phred score from variant info or transcripts, returning the highest score found.
7728	Load a case into the database with optional VCF files and BAM files, using either a scout config file or ped file for case data, and handle potential errors during the loading process.
7729	Updates a variant document in the database by replacing it with the provided variant object and returns the updated document.
7730	Updates the manual rank for all variants in a case based on their rank scores, handling large datasets through bulk operations.
7731	Update compounds for a variant by adding variant information to compound objects, including rank score and gene details from the variant.
7732	Update compound objects for a set of variants by iterating through each variant, checking for compounds, and calling update_variant_compounds to process them. Return the updated variants dictionary.
7733	Update compound information for a bulk of variants in the database by performing bulk write operations on the variant collection, skipping variants without compound information.
7734	Updates compounds for a case by iterating through coding intervals and variants, organizing them by chromosome, variant type, and category, then performing bulk updates for variants within coding regions.
7735	Load a variant object into the database variant collection. Returns the inserted document ID. Raises IntegrityError if variant already exists.
7736	Upsert a variant object into the database. If the variant already exists, update its compounds field. Returns the result of the insert or update operation.
7737	Load a bulk of variants into the database, handling duplicates by inserting variants individually if bulk insert fails. Returns object IDs of inserted variants.
7738	Assign a user to a case by creating an assignment event and updating the case's assignees list. Returns the updated case document.
7739	Share a case with a new institute by adding the collaborator_id to the case's collaborators list and creating a share event. Raises ValueError if the collaborator is already added. Returns the updated case document.
7740	Diagnose a case using OMIM ids by adding or removing diagnoses from case records and creating update events.

**Arguments:**
- institute (dict): Institute object
- case (dict): Case object
- user (dict): User object
- link (str): URL for event
- level (str): Diagnosis level ('phenotype' or 'gene')
- omim_id (str): OMIM identifier
- remove (bool): Flag to remove diagnosis (default: False)

**Returns:**
- updated_case: The updated case document or None

**Behavior:**
- For 'phenotype' level: Uses 'diagnosis_phenotypes' key
- For 'gene' level: Uses 'diagnosis_genes' key
- Adds OMIM ID to case if not present (when remove=False)
- Removes OMIM ID from case if present (when remove=True)
- Creates update event when case is modified
- Raises TypeError for invalid level parameter
7741	Mark or unmark a case as checked from an analysis perspective, update the case document in the database, and create a corresponding event log.
7742	Creates events for variant and case verification when a variant validation is ordered, updates the variant status to reflect that sanger ordering has been initiated, and returns the updated variant object.
7743	Get all variants with validations ever ordered, optionally filtered by institute_id and user_id, returning a list of dictionaries with case_id as keys and lists of variant ids as values.
7744	Marks validation status for a variant by updating its validation field in the database and creating an associated event record.

Arguments:
- institute (dict): Institute object
- case (dict): Case object  
- user (dict): User object
- link (str): URL for event
- variant (dict): Variant object to validate
- validate_type (str): Validation outcome ('True positive' or 'False positive')

Returns:
- updated_variant (dict): The variant object with updated validation status

The function first validates that the validation type is valid, then updates the variant's validation field in MongoDB, and finally creates an event record documenting the validation action.
7745	Mark a variant as causative in a case, update case status to solved, and create events for both case and variant marking.
7746	**Summary:**

The `update_dismiss_variant` method creates an event to track updates to a variant's manual dismiss status and modifies the variant's `dismiss_variant` field in the database. It first logs the update operation, then creates an event with the specified parameters. Based on whether `dismiss_variant` is provided, it either sets the field to the new value or unsets it. Finally, it updates the variant in the database and returns the updated variant object.

**Key operations:**
- Creates event with verb 'dismiss_variant' for tracking
- Updates dismiss_variant field using either `$set` or `$unset` operations
- Returns the updated variant document
- Logs both the event creation and field update operations
7747	Updates the ACMG classification of a variant by creating an event and modifying the variant document in the database. If acmg_str is None, unsets the acmg_classification field; otherwise, sets it to the mapped value. Returns the updated variant document.
7748	Constructs necessary IDs for a variant by calling multiple parsing functions to generate simple ID, variant ID, display name, and document ID based on chromosome, position, reference allele, alternative allele, case ID, and variant type.
7749	Parse a variant's simple ID by joining chromosome, position, reference, and alternate alleles with underscores.
7750	Parse the unique document id for a variant by generating an MD5 hash from chromosome, position, reference allele, alternative allele, variant type, and case ID.
7751	Convert a gene panel with HGNC symbols to a new one with HGNC IDs by adding HGNC IDs to genes and printing a new formatted panel with updated header information.
7752	Create a new variant ID by parsing variant document information including chromosome, position, reference allele, alternative allele, variant type, and family ID.
7753	Return the number of cases from the case collection, optionally filtered by institute_id. If no institute_id is provided, returns the total count of all cases. Uses a MongoDB query to filter cases by collaborators field when institute_id is specified.
7754	Update the dynamic gene list for a case by fetching genes based on HGNC symbols or IDs and store them in the case document.
7755	Fetches a single case from the database using either case_id or a combination of institute_id and display_name. Raises ValueError if required parameters are missing. Returns a single Case document.
7756	Delete a single case from the database based on case_id or a combination of institute_id and display_name. Returns the deleted case object. Raises ValueError if required parameters are missing.
7757	Add a case to the database, raising an exception if it already exists.
7758	Replace an existing case with a new one, keeping the same object id. Updates the case's "updated_at" timestamp and returns the updated case document.
7759	Update case id for a case across the database, including suspects, causatives, ACMG classifications, and events, then insert the updated case and delete the old one.
7760	Submit an evaluation to the database by collecting relevant information, building an evaluation object, and updating the ACMG classification for the variant.
7761	Return all evaluations for a certain variant by querying the database using the variant_id and sorting results by created_at in descending order.
7762	Parse and merge transcript information from input lines or DataFrame into a dictionary mapping transcript IDs to their combined information, including genomic coordinates, mRNA and ncRNA references, and gene IDs.
7763	Parse a dataframe with ensembl gene information and yield gene information dictionaries containing chromosome, start and end positions, ensembl gene ID, and HGNC symbol and ID for each gene entry.
7764	Parse a dataframe with ensembl transcript information and yield transcript info dictionaries containing chromosome, gene ID, transcript ID, transcript start/end positions, and RefSeq annotations (handling missing data as None).
7765	Parse an Ensembl formatted line into a dictionary with standardized field names, extracting information about genes, transcripts, exons, UTRs, and associated identifiers from tab-separated data.
7766	Parse lines with ensembl formatted genes from a biomart dump, yielding dictionaries with gene information including 'Gene ID', 'Chromosome', 'Gene Start', 'Gene End', and 'HGNC symbol'.
7767	Parse Ensembl formatted exon lines from biomart dump, yielding dictionaries with exon information including recalculated start/end positions that account for UTR regions based on strand orientation.
7768	Parse a dataframe with Ensembl exon information and yield dictionaries containing gene information with recalculated start and end positions based on UTR regions.
7769	Initializes logging for a logger with optional file and console output. Configures log format, sets log level, and handles both file logging (if filename provided) and console logging (always outputs warnings and higher to stderr). If no filename is specified, all log messages at the specified level are printed to stderr.
7770	Parses a line from an OMIM file into a dictionary using the provided header fields as keys.
7771	Function to parse OMIM morbid lines, extracting header from comment lines and yielding parsed lines.
7772	Get a dictionary with phenotypes using MIM numbers as keys and phenotype information as values, including description, HGNC symbols, inheritance patterns, and MIM number.
7773	This function `cli` is designed to parse OMIM files including morbid, genemap, mim2gene, and mim_titles. It prints the file paths, opens file handles using `get_file_handle`, and extracts gene information using `get_mim_genes`. The function includes debug prints for specific genes like 'C10orf11' and 'OPA1'. It also processes phenotypes if the phenotypes parameter is provided, though this functionality appears to be partially commented out with `context.abort()` calls that terminate execution early. The function contains unused code sections and debug print statements but essentially serves to parse and display information from OMIM data files.
7774	Convert a string to a number (int or float). If the string represents an integer, convert to int; if it represents a float, convert to float. If conversion is not possible, return None.
7775	Returns a formatted month as a table with navigation links and context data including week rows, date information, and template rendering.
7776	Sets commonly used variables for formatting a day in a calendar, including CSS classes for weekdays (today vs. not today), URL construction for day links, and HTML anchor tags for day navigation.
7777	Format a month name as a table row with "Today" button and optional year display.
7778	Populates variables used to build popovers by constructing formatted strings for when, where, description, event URL, and title2 based on event data and formatting preferences.
7779	Parse metadata for a gene panel from panel file header information.
7780	Parse gene information from a panel file into a structured dictionary containing HGNC ID, HGNC symbol, disease-associated transcripts, inheritance models, and other gene annotations.
7781	Parse gene information from iterable lines, handling various delimiters and headers, returning list of gene dictionaries with unique HGNC identifiers.
7782	Parses a gene panel file and returns a dictionary containing panel information including path, type, date, ID, institute, version, display name, and genes. The function handles both file paths and direct gene lists, and includes default values for optional parameters.
7783	Show all diseases in the database by retrieving disease terms from the adapter and displaying their IDs, or notify if no diseases are found.
7784	```python
def hpo(context):
    """
    Update the HPO terms in the database by dropping existing terms and loading the latest release.
    """
    LOG.info("Running scout update hpo")
    adapter = context.obj['adapter']

    LOG.info("Dropping HPO terms")
    adapter.hpo_term_collection.drop()
    LOG.debug("HPO terms dropped")

    load_hpo_terms(adapter)
```
7785	Display a list of all users and their associated institutes, along with event counts and rankings.
7786	Parse conservation predictors from variant dictionary, extracting GERP, phastCons, and phyloP values using dbNSFP annotations.
7787	Parse conservation prediction from variant info field and return list of conservation terms ('Conserved' or 'NotConserved') based on threshold values.
7788	Returns general information about cases including totals, phenotype cases, causative cases, pinned cases, cohort cases, and pedigree statistics. Filters cases by institute_id and name_query if provided.
7789	Return information about case groups including total cases and grouped statistics by status.
7790	Returns a JSON response by transforming the provided context into JSON format with content type 'application/json'.
7791	Get year and month from kwargs or querystring, with fallback to current year/month. Handles calendar offset and validation.
7792	Check if any events are cancelled on the given date 'd' and append '(CANCELLED)' to the title of cancelled events.
7793	Fetches an HPO term by its ID from the database collection.

Args:
    hpo_id (str): The ID of the HPO term to fetch

Returns:
    dict: The HPO term object if found, None otherwise

Debug logging is enabled to track the fetching operation.
7794	Return all HPO terms, allowing search by query string, specific HPO term, or text search with regex or text index matching. Supports limiting results and sorting by HPO number.
7795	Return a disease term by checking if the identifier is a disease number or id, then query the disease_term_collection with the appropriate query.
7796	Return all disease terms that overlap a gene, or all disease terms if no gene is specified. If hgnc_id is provided, fetch diseases for that specific gene; otherwise, fetch all disease terms from the database.
7797	Load a disease term into the database, raising an IntegrityError if it already exists.
7798	Generate a sorted list of HpoGene namedtuples containing hgnc_ids and their occurrence counts from given HPO terms.
7799	Populates Filterbank instance with data from HDF5 file. This function is deprecated and users should use Waterfall() instead. Reads header information and optionally loads spectral time series data with optional frequency and time axis slicing. Raises DeprecationWarning if called.
7800	Setup frequency axis for spectral data by calculating frequency values based on header information and optional frequency range limits. Returns index values for the specified frequency range.
7801	Setup time axis for a given time range, calculate timestamps based on header information, and return the start index, stop index, and number of integrations.
7802	Populates a Filterbank instance with data from a Filterbank file, supporting frequency and time range selection. Reads header information, sets up frequency and time axes, and loads binary data into a numpy array. Includes error handling for large data arrays and supports different data types based on bit depth. Note: This method is deprecated and users should use Waterfall() instead.
7803	Computes the Local Sidereal Time (LST) for telescope observations based on telescope ID and MJD header values, supporting only Parkes (ID=4) and GBT (ID=6) telescopes. Uses pySLALIB for astronomical calculations if available, otherwise raises an error.
7804	Blank DC bins in coarse channels by setting the middle channel of each coarse channel to the median value of channels 5-10 above the middle channel. Returns early if n_coarse_chan < 1 or not an integer number of coarse channels.
7805	Print header information including formatted key-value pairs, time conversion, unit formatting, and data statistics like number of integrations, data shape, and frequency range.
7806	Calculate plot extent boundaries for visualization, handling both MJD and standard time formats with appropriate scaling.
7807	Plot waterfall data with optional frequency range, logarithmic scaling, and colorbar. Automatically handles frequency axis reversal, applies rebinning for large datasets, and uses viridis colormap with customizable matplotlib parameters. Includes source name title and proper axis labels with MJD or seconds time units.
7808	Plot time series data with optional frequency filtering and formatting options.

**Parameters:**
- `f_start` (float): Start frequency in MHz
- `f_stop` (float): Stop frequency in MHz  
- `if_id` (int): IF identifier (default: 0)
- `logged` (bool): Plot in dB units if True, linear if False (default: True)
- `orientation` (str): Plot orientation ('h' for horizontal, 'v' for vertical, default: 'h')
- `MJD_time` (bool): Use MJD time units if True, seconds if False (default: False)
- `**kwargs`: Additional keyword arguments passed to matplotlib plot

**Returns:**
- None (plots directly to current axes)

**Key functionality:**
- Grabs time series data within specified frequency range
- Converts data to dB scale if logged=True and data is 8+ bits
- Handles single-bin data by taking mean across frequency axis
- Calculates proper time axis extent for plotting
- Supports both horizontal and vertical orientations
- Labels axes appropriately based on units and orientation
- Automatically scales plot axes to fit data tightly
7809	Writes data to a filterbank (.fil) format file. This is a non-standard function that generates a SIGPROC-compatible header and writes the data in the specified bit format (4, 2, or 1 byte integers) to the output file. The function warns users to prefer the Waterfall class for filterbank operations.
7810	Method: calibrate_band_pass_N1

Summary: This method calibrates the band pass by computing the median value for each frequency fine channel across all time samples, then normalizes the original data by dividing each channel's data by its corresponding median value. The calibration is applied in-place by modifying the self.data attribute.

Parameters: None

Returns: None (modifies self.data in-place)

Side effects: Modifies self.data by dividing it by the computed band pass correction factors
7811	Converts a data array to coarse channels by averaging over specified channel ranges.

This function takes a data array and groups consecutive channels into coarse channels by averaging. It reshapes the input array into a 2D array where each row represents a coarse channel, then computes the mean of all channels except the first and last (indices 2:-1) in each coarse channel group. The result is an array containing the averaged values for each coarse channel.
7812	Applies Mueller matrix calibration to Stokes parameters (I, Q, U, V) using differential gains, phase offsets, and channel configuration to return calibrated Stokes parameters.
7813	Calibrates Stokes parameters for a radio astronomy observation using noise diode measurements. Reads cross-polarization data from observation and noise diode measurements, calculates differential gain and phase offsets, applies Mueller matrix correction to obtain calibrated Stokes I, Q, U, V parameters, and writes results to filterbank files. Supports writing all Stokes parameters to a single file or separate files depending on the onefile parameter. Uses either linear ('l') or circular ('c') feed type for antenna dipole basis.
7814	Returns fractional linear polarization (L/I) and circular polarization (V/I) from Stokes parameters I, Q, U, V extracted from a .fil file.
7815	Writes two new filterbank files containing fractional linear and circular polarization data by processing input data and saving results with .linpol.fil and .circpol.fil extensions.
7816	Return the index of the closest value in xarr to the given value val.
7817	Rebin data by averaging bins together. For 2D arrays, rebin both x and y dimensions specified by n_x and n_y. For 1D arrays, rebin only the x dimension specified by n_x. Raises RuntimeError for arrays with more than 2 dimensions. Returns rebinned data with updated shape.
7818	Function `unpack` upgrades data from n-bit format to 8-bit format. It validates that nbit is <= 8 and divides 8 evenly, and that the input data has an 8-bit dtype. When nbit equals 8, it returns the data unchanged. For other values (4, 2, 1), it calls specialized unpacking functions (unpack_4to8, unpack_2to8, unpack_1to8) to perform the conversion. The function raises ValueError for invalid nbit values and TypeError for invalid data types. Note: The function includes a warning that it may be broken.
7819	Returns ON-OFF differences for all Stokes parameters (I, Q, U, V) from noise diode cross-polarization measurements, including frequency array.
7820	Plots the uncalibrated full Stokes spectrum of a noise diode, showing either the difference (ON-OFF) when diff=True or both ON and OFF states separately when diff=False. The function supports different feed types and allows customization through keyword arguments. It displays the data with appropriate labels and legends for I, Q, U, and V Stokes parameters.
7821	Plots the calibrated noise diode spectrum by applying inverse Mueller matrix correction to Stokes parameters and displaying the ON-OFF differences for I, Q, U, and V components.
7822	Plots gain offsets for each coarse channel and displays time-averaged power spectra for X and Y feeds (or LL and RR for circular feeds). The function calculates delta G/2 values from ON-OFF spectra and shows the corresponding power spectra in a 2-panel plot with customizable axes and legend options.
7823	Opens an HDF5 or filterbank file and returns a Reader instance for reading data. Supports '.h5', '.hdf5', and '.fil' file extensions. Raises IOError if file doesn't exist or NotImplementedError for unsupported file types.
7824	Sets up time and frequency selection ranges, ensuring they are within file limits and handling invalid inputs by warning and resetting to default values.
7825	Calculate the size of the data selection based on time integrations, frequency channels, and bytes per sample.
7826	Calculate the shape of the data selection based on time and frequency ranges.
7827	Setup channel borders by calculating start and stop indices based on frequency limits and channel spacing.
7828	Method `_setup_freqs` updates frequency borders based on channel values by calculating start and stop frequencies using the channel start and stop indices, along with the frequency offset from the header. The calculation direction depends on whether the frequency offset is positive or negative.
7829	Populate time axis for the data, either returning all timestamps or just the start time depending on the update_header parameter. The method calculates timestamps based on the header information and optional start/stop indices, converting from seconds to days.
7830	Populates the frequency axis by calculating frequency values based on header information and channel indices. Returns an array of frequency values.
7831	This function calculates the number of coarse channels in a radio astronomy data file based on either a specified channel bandwidth or by analyzing the file's header information. It handles different telescope data types (GBT and Parkes) and their specific configurations, with special cases for high-resolution data and early GBT observations. The function returns the calculated number of coarse channels or raises warnings when the calculation cannot be performed due to insufficient information or unsupported data types.
7832	Given the blob dimensions, calculate how many blobs fit in the data selection.

The method computes the total number of blobs that can fit within the current data selection by:
1. Calculating the total volume of the data selection (`np.prod(self.selection_shape)`)
2. Calculating the volume of each blob (`np.prod(blob_dim)`)
3. Dividing the total selection volume by the blob volume
4. Using ceiling division to ensure we have enough blobs to cover the entire selection
5. Converting to an integer to get the final count

Returns the number of blobs that fit in the data selection.
7833	Check if the current selection is too large by comparing its size in bytes against the maximum allowed size. Returns True if the selection exceeds the maximum size, False otherwise.
7834	Method: `read_data`

Summary: Reads data from a file based on specified frequency and time range selections. The method first sets up the selection range and checks if the requested data size exceeds a maximum limit, issuing a warning and returning early if so. It then converts frequencies to channel numbers, updates frequency ranges, and loads the binary data into a numpy array. The method handles reading specific integrations and channels, with proper file pointer positioning, and stores the resulting data in `self.data`.
7835	Method: `read_all`

Summary: Reads all data from a file and returns it as a 2D numpy array. If the `reverse` parameter is set to True, the x-axis (channels) of the returned data is flipped. The method seeks to the start of the data section before reading.

Parameters:
- `reverse` (bool, optional): If True, flips the x-axis of the data. Defaults to True.

Returns: 
- 2D numpy array containing the read data

Note: The method raises `NotImplementedError` and includes commented-out code showing the intended implementation approach. The actual data reading uses `numpy.fromfile()` with the specified data type and reshapes it according to blocksize and channels dimensions.
7836	Method: `read_row(self, rownumber, reverse=True)`

Summary: Reads a block of data from a specific row in a file, with optional x-axis reversal. The method seeks to the appropriate position in the file based on the row number and channel count, reads the data into a 2D numpy array, and optionally reverses the data along the x-axis if the reverse parameter is True. The method raises NotImplementedError as it needs to be implemented by subclasses.

Parameters:
- `rownumber` (int): The row number to read from the file
- `reverse` (bool, optional): If True, flips the x-axis of the data (default: True)

Returns: A 2D numpy array containing the data from the specified row

Note: This is a placeholder method that raises NotImplementedError and requires implementation in subclasses.
7837	Reads selected data within specified frequency and time ranges, then loads the data into the container.
7838	Updates header information by modifying frequency of first channel based on selection, updating number of coarse channels, and updating time stamp for first time bin.
7839	Prints file header information, derived file statistics, and data selection details including source coordinates in formatted columns.
7840	Writes data to a .fil file with size-based writing strategy and logs conversion time.
7841	Writes data to an HDF5 file using appropriate writing method based on file size, with timing information logged.
7842	Write data to an HDF5 file with optional bitshuffle compression, creating datasets for data and mask with proper dimensional labels and copying header attributes.
7843	Sets blob dimensions to read approximately 1024 MiB at a time, considering chunk size and selection shape constraints.
7844	Sets the chunking dimensions based on file type by checking header values to detect high frequency resolution, high time resolution, or intermediate resolution data, with a default minimum chunking for unknown formats.
7845	Extracts a portion of data by frequency range.

Args:
    f_start (float): start frequency in MHz
    f_stop (float): stop frequency in MHz
    t_start (float): start time in MHz
    t_stop (float): stop time in MHz
    if_id (int): IF input identification (req. when multiple IFs in file)

Returns:
    (freqs, data) (np.arrays): frequency axis in MHz and data subset
7846	Command line tool for plotting and viewing information on guppi raw files, including statistics, histogram, and spectrum visualization.
7847	Reads the first header from file and returns its keyword:value pairs as a dictionary.

**Returns:**
- header (dict): keyword:value pairs of header metadata

**Note:** This method seeks to the beginning of the file twice - once to read the header and once to reset the file position.
7848	Method `find_n_data_blocks` seeks through a file to count the number of data blocks by reading headers sequentially until end-of-file is reached. It returns an integer representing the total number of data blocks in the file.
7849	Method: print_stats

Summary: Computes and displays basic statistical information (average, standard deviation, maximum, and minimum values) for the next block of data read from the data source. The method retrieves a data block, converts it to float32 format, calculates the statistics, and prints them with 3 decimal places. It also imports pylab for potential plotting functionality.
7850	Plot a histogram of data values from the next data block with 65 bins and red color, optionally save to file and display the plot.
7851	Generate a blimpy header dictionary with default values and telescope-specific settings, including source information, observation parameters, and data format specifications.
7852	Function to determine the header size of a filterbank file by locating the 'HEADER_END' marker within the first 1000 bytes of the file.
7853	Command line tool to compare md5sum checksums of two .fil files, including header information extraction. It verifies file integrity by stripping headers and calculating checksums, then compares results between two input files. Raises IOError for non-BL systems and Error for processing issues.
7854	Command line tool for converting guppi raw files into HDF5 format. Reads raw data files, determines total number of data blocks across all files, creates an HDF5 file with appropriate dimensions, and writes data blocks from each raw file into the HDF5 dataset while copying header information as attributes. Uses bitshuffle compression if available.
7855	Function `foldcal` calculates time-averaged spectra from ON and OFF measurements of a calibrator with a flickering noise diode. It takes a 2D dynamic spectrum, sampling time, diode period, and optional parameters for switching behavior and index returns. The function determines time intervals for ON and OFF states based on the diode period and sampling time, averages the spectra over these intervals, and returns the mean spectra for ON and OFF states. If `switch=True`, it swaps the ON/OFF returns. If `inds=True`, it also returns the indices of ON and OFF time intervals.
7856	Integrates and folds Stokes I noise diode data along coarse channels. Loads filterbank data, converts to Stokes I if needed, folds the data to find ON/OFF states, integrates channels by coarse channel grouping, and returns integrated OFF and ON spectra. Handles both cross-polarization and full Stokes IQUV data formats.
7857	Calculate fluxes of a calibrator source across frequency channels using power-law spectral indexing.

Parameters:
- calflux: Known flux of calibrator source at reference frequency
- calfreq: Reference frequency where calflux is measured
- spec_in: Power-law spectral index (flux  frequency^spec_in)
- centerfreqs: Array of central frequencies for each coarse channel
- oneflux: If True, return single flux value for entire band; if False, return individual channel fluxes

Returns:
- Array of flux values (one per channel if oneflux=False, single value if oneflux=True)
7858	Returns central frequency of each coarse channel by calculating the mean frequency within each coarse channel group. Takes an array of frequency values and the number of frequency bins per coarse channel as input, and returns the mean frequency for each coarse channel.
7859	Calculate f_ON and f_OFF ratios using noise diode ON and OFF spectra from calibrator observations, following van Straten et al. 2012 equations 2 and 3. Returns the f_ON and f_OFF values computed as (H/L)-1 for both ON and OFF observations.
7860	Calculate the coarse channel spectrum and system temperature of a noise diode in Jy using two noise diode measurements (ON and OFF) taken on a calibrator source, given the calibrator's known flux, frequency, and spectral index. Returns either averaged or channel-by-channel results.
7861	Returns frequency dependent system temperature given observations on and off a calibrator source by calling diode_spec with appropriate parameters.
7862	Calibrates Stokes I flux densities for radio telescope observations using a noise diode measurement. Takes a target observation file and corresponding noise diode observation, applies flux calibration using the noise diode spectrum and system temperature, and writes the calibrated data to a new filterbank file with ".fluxcal" extension. The calibration accounts for cross-polarization or full Stokes data formats and handles coarse channel averaging. Returns the calibrated data and saves it to disk.
7863	Return the length of the blimpy header in bytes by reading the file in 512-byte chunks until 'HEADER_END' is found, then calculating the total byte offset.
7864	Function `is_filterbank` checks if a given file is a filterbank file by opening it in binary mode and verifying if it starts with the expected 'HEADER_START' keyword. It returns `True` if the file is a valid filterbank file, `False` otherwise.
7865	**Summary:**

The `fix_header` function updates a specified header keyword value in a Filterbank file. It reads the existing header, determines the appropriate data type for the keyword, and overwrites the current value with a new one. The function supports numeric types (int32, float64) and string values, though string updates require the new string to be the same length as the original to avoid file corruption. The file is modified in-place, and the function raises a RuntimeError if attempting to change the length of a string header value.
7866	Generate a serialized SIGPROC header string from a Filterbank object's header information, handling special cases for source coordinates and angles, and return the complete header with START and END markers.
7867	Convert an astropy.Angle to the sigproc angle format string, handling both hours and degrees formats with proper zero-padding and decimal separation.
7868	Calculate number of integrations in a given file by reading header information and computing based on file size and data dimensions.
7869	Convert a Traceback object into a dictionary representation containing frame information, line number, and next traceback in the chain.
7870	Creates a subparser for a specific DNS record type with specified arguments and types.
7871	Creates an ArgumentParser for parsing DNS resource records, including support for $ORIGIN, $TTL directives and various RR types like SOA, NS, A, AAAA, CNAME, ALIAS, MX, TXT, PTR, SRV, SPF, and URI records with their specific argument types.
7872	Remove comments from a zonefile by processing each line through tokenization and serialization, filtering out empty lines, and returning the cleaned content with lines joined by newlines.
7873	Add default name '@' to lines in text that start with supported records, ensuring each line has a name defined.
7874	Parses a line of DNS record data using a given parser, processes the tokens, and updates a dictionary of parsed records. Handles various record types including TXT, PTR, and others, with support for TTL values and origin handling. Returns the updated parsed records dictionary. Raises InvalidLineException on parsing errors.
7875	Parse a zonefile text into a dictionary format by splitting into lines, tokenizing each line, and using a parser to convert records. Optionally ignore invalid lines or raise an exception if encountered.
7876	Parse a zonefile into a dictionary by removing comments, flattening, removing class information, adding default name, and parsing lines.
7877	Quote a field in a list of DNS records by wrapping it in double quotes and escaping semicolons, returning the modified data records.
7878	Parse a schema string into an AvroSchema object by first decoding if necessary, then loading as JSON and parsing through AvroSchemaParser.
7879	Creates a Python package representation from pyschema classes, generating one module per namespace with proper import statements and indentation.
7880	Generate Python source code for a specific class from a schema, including optional namespace definition and field definitions, with proper indentation and warning comment.
7881	Temporarily disables automatic registration of records in the auto_store. Returns a decorator that temporarily sets PySchema.auto_register to False and restores the original value after decoration. Not thread safe.
7882	Converts a record object into a JSON-serializable dictionary by iterating through its fields, getting non-None values, and dumping them using their respective field dump methods.
7883	Create a Record instance from a JSON-compatible dictionary, using optional schema and record store for lookup, with automatic schema detection from the dictionary if not explicitly provided.
7884	Creates a Record instance from a JSON serialized dictionary string.

Parameters:
- s (str): JSON-serialized dictionary string
- record_store: Record store for schema lookups when $schema field is present
- schema: PySchema Record class for the record to load (overrides $schema field)
- loader: Function to fetch attributes from JSON (internal use)
- record_class: DEPRECATED - use schema parameter instead

Returns:
Record instance loaded from JSON data

Raises:
ParseError: If input string is not valid JSON record format
7885	Adds a record class to the record store for later retrieval, can be used as a class decorator. Returns the schema unchanged.
7886	Returns a matching record by name, checking full name first then last part of name if full name not found. Raises KeyError if no record is found.
7887	Return a dictionary containing the field definition with nullable, default, and description (if not None) for use in pyschema class definition.
7888	Decorator for mixing in additional functionality into field type by copying attributes from mixin class to target class, skipping magic properties and converting methods to their underlying functions.
7889	Creates a PySchema class from a given class by transferring its methods and attributes, with optional auto-storage functionality.
7890	Return a Python dict representing the JSON schema of a record, where any references to sub-schemas will be URI fragments that won't be resolvable without a root schema.
7891	Return a root jsonschema for a given record, including the $schema attribute and all sub-record schemas and definitions.
7892	Converts a JSON serialized pyschema records file stream into a stream of pyschema objects for use as a luigi.hadoop.JobTask reader.
7893	Writes a stream of JSON serialized pyschema Records to a file object. Can be used as job.writer in luigi.hadoop.JobTask. Handles ParseError exceptions by printing to stderr and re-raising.
7894	Summary: The `ordereddict_push_front` function adds a key-value pair to the front of an OrderedDict by creating a new OrderedDict instance, setting the specified key-value pair at the beginning, and then updating it with the original dictionary's contents, ensuring the original dictionary remains unmodified.
7895	Method: `query_string`
Parameters: `**params` (keyword arguments)
Returns: `SearchResult` object
Description: Specifies a query string to use with the collection and returns search results by making an API GET request with the provided parameters.
7896	Sends all filters to the API without any additional processing, acting as a simple wrapper that returns a SearchResult object containing the filtered results.
7897	Returns all entities present in the collection with specified attributes included by reloading the collection, creating entity objects with the given attributes, then reloading the collection again.
7898	Returns entity in correct collection by checking if href matches current collection, otherwise finds and creates new collection based on href pattern.
7899	Returns a different quote character from the available quotes, excluding the one passed as parameter. Raises ValueError if no different quote is available.
7900	Summary: The `escape_filter` function processes input values to escape them appropriately for use in filters. It handles `None` values by returning `'NULL'`, integers by converting them to strings, and strings by properly quoting them to avoid conflicts with existing quotes. If both single and double quotes are present in a string, it applies a quoting strategy to ensure proper escaping. The function raises a `ValueError` for invalid input types.
7901	Constructs a 3x3 elementary rotation matrix for rotation around the x, y, or z-axis.

Parameters:
- axis: string specifying rotation axis ("x", "y", or "z")
- rotationAngle: float specifying rotation angle in radians

Returns:
- 3x3 rotation matrix as numpy array

Raises:
- Exception: if axis is not "x", "y", or "z"

Example:
- elementaryRotationMatrix("y", /6.0) creates rotation matrix for 30 rotation around y-axis
7902	Constructs a 6x6 covariance matrix from astrometric parameter uncertainties and correlations, incorporating parallax, radial velocity, and their uncertainties. Takes input covariance vector with 15 elements describing errors and correlations, plus parallax and radial velocity data. Returns the full covariance matrix with proper handling of both single and multiple source inputs.
7903	Calculate radial velocity error from V-band magnitude and spectral type, returning an average sky value in km/s.
7904	Calculate parallax error using input source magnitude and colour, then print the results including G, V, (V-I), (G-V) magnitudes, and the standard error in microarcseconds.
7905	Calculate the G band photometric standard error for single-field-of-view-transit observations as a function of G-magnitude, including a 20% margin. Returns the standard error in magnitude units.
7906	Calculate the end of mission photometric standard error in the G band as a function of G magnitude with a 20% margin included, using the number of observations.
7907	Create a photometric error plot based on command line arguments, showing magnitude errors for G, G_BP, and G_RP bands as a function of either G or V magnitude, with options for EoM or single-FoV transit predictions.
7908	Returns the average number of transits across the Gaia focal plane for given ecliptic latitude value(s), averaged over ecliptic longitude.
7909	Calculate the angular distance between pairs of sky coordinates using a numerically stable formula based on great-circle distance.
7910	Transforms Cartesian coordinates from one reference system to another using a pre-computed rotation matrix. Accepts scalar or 1D numpy array inputs for x, y, z coordinates and returns the rotated coordinates xrot, yrot, zrot after applying the rotation matrix transformation.
7911	Transforms sky coordinates from one reference system to another using the class's rotation matrix. Converts input spherical coordinates (phi, theta) to Cartesian coordinates, applies the transformation, then converts back to spherical coordinates. Returns the transformed azimuthal and elevation angles in radians.
7912	Transforms an astrometric covariance matrix to a new coordinate system using a Jacobian transformation matrix derived from the given longitude and latitude angles.
7913	Lookup numerical scaling factors for astrometric parameter errors based on Ecliptic latitude and number of transits.
7914	Creates a plot showing relative parallax errors as a function of distance for different stellar spectral types, with error bars and color-coded magnitude ranges.
7915	Create a plot showing radial velocity performance predictions across different spectral types, with velocity error as a function of V magnitude.
7916	A utility function that returns a new function to select the first non-null result from multiple query functions. When called with a Node, it applies each function in order and returns the first truthy result, otherwise returning Null().
7917	Decorator for eval_ that prints a helpful error message if an exception is generated in a Q expression, including formatted value information and debug context.
7918	Converts a value to unicode and adds quotes if it was initially a string. Handles binary strings by decoding from UTF-8, with fallback to repr for non-UTF-8 binary data. Returns the unicode string with quotes added for string inputs.
7919	Call the provided function(s) on each element in the collection. If multiple functions are given, each output item will be a tuple containing the results of applying each function to the corresponding input item. Returns a new Collection with the transformed items.
7920	Returns a new Collection excluding items where the given function returns a truthy value. If no function is provided, removes truthy items. Uses filtering with an inverted function to exclude matching items.
7921	Return a new Collection with items filtered based on a boolean function. If no function is provided, removes false-y items. Uses Python's built-in filter() function to apply the filtering logic.
7922	Return a new Collection with items taken from the beginning until the first item where the given function returns False.
7923	Returns a new Collection with the first few items removed, discarding all items before the first item where the given function evaluates to True.
7924	Zips items from this collection and one or more other sequences into a new collection of tuples, where each tuple contains elements from the same position in each sequence. All input sequences must have the same length, otherwise a ValueError is raised. The result is wrapped in a Collection object.
7925	Find a single Node among this Node's descendants using BeautifulSoup-style semantics, returning a NullNode if nothing matches. Supports various search patterns including tag names, classes, functions, and attribute values.
7926	Return potential locations of IACA installation by checking two possible paths:
1. ~/.kerncraft/iaca-{os}/ (user's home directory)
2. package directory /iaca-{os}/ (current package location)

The function returns a list of both potential installation paths based on the operating system.
7927	Generates all characters from a regex-like expression containing character ranges and individual characters.

The function processes a string that may contain:
- Character ranges like 'a-f' (using '-' as range separator)
- Individual characters like '1', 'a', 'B'
- Mixed sequences like '7-9ab'

For ranges, it computes the inclusive character range from the start to end characters in the ordered sequence of letters and digits. Non-sensical ranges (like 'b-a') produce empty results. Individual characters are yielded as-is. The function handles both uppercase and lowercase letters, as well as digits 0-9.

Example usage:
- group_iterator('a-f') yields ['a', 'b', 'c', 'd', 'e', 'f']
- group_iterator('7-9ab') yields ['7', '8', '9', 'a', 'b']
7928	A function that generates register names from simplified regular expressions, supporting bracketed groups (like [0-3]) and pipe unions (like PMC[0-1]|PMC[23]), yielding each possible register name one at a time.
7929	Return a LIKWID event string from an event tuple or keyword arguments.
    The event tuple should contain 2 or 3 elements: (event, register) or (event, register, parameters).
    Parameters are formatted as key=value pairs, with integer values converted to hexadecimal.
    Example: 'L1D_REPLACEMENT:PMC0' or 'MEM_UOPS_RETIRED_LOADS:PMC3:EDGEDETECT:THRESHOLD=0x926'
7930	Builds minimal runs for events by scheduling them into runs based on register availability, eliminating duplicates and organizing events by register groups.
7931	This method reports the analysis results in a human-readable format to the specified output file. It displays detailed results when verbose levels are high, shows bottleneck information including arithmetic intensity and performance metrics, and determines whether the system is CPU bound or memory bound based on performance comparisons. The report includes information about peak performance, memory bottlenecks, and the specific bottleneck level causing performance limitations.
7932	This method generates a human-readable report of a model's performance bottlenecks. It displays information about CPU, memory, and cache bottlenecks, including performance metrics, arithmetic intensity, and bandwidth details. The report indicates whether the system is CPU-bound or memory-bound based on performance comparisons. The output can be directed to a specified file or standard output, with different verbosity levels controlling the amount of detail displayed.
7933	Reports the generated model in human-readable form to the specified output file, displaying layer conditions for each dimension and their solutions. If verbose level is high enough, it also prints the raw results data. For each cache in each dimension's layer condition, it prints whether the condition is unconditionally fulfilled or displays the corresponding inequality or equation solutions.
7934	Function `clean_code` removes comments, macros, and pragmas from source code while preserving line numbers. It handles both single-line (`//`) and multiline (`/* */`) comments, as well as preprocessor macros (`#`) and pragmas (`#pragma`). The function supports three optional parameters: `comments` (removes comments), `macros` (removes macros), and `pragmas` (removes pragmas). It preserves blank lines and supports multiline constructs, though it incorrectly treats comment-like strings as actual comments. The cleaned code is returned with original line structure maintained.
7935	Rounds a float value to the next multiple of the specified base.
7936	Split a list of integers into blocks of specified size and return the block indices. The first block element is placed at the initial boundary (default 0). For example, with indices [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] and block_size 8, it returns [0, -1]. With a single index [0] and block_size 8, it returns [0]. With initial_boundary set to 32, it returns [-4].
7937	Method `calculate_cache_access` dispatches to the cache predictor to retrieve cache statistics and updates the results dictionary with misses, hits, evictions, and verbose information from the predictor.
7938	Calculate performance model cycles from cache statistics, including memory bandwidth and cache miss handling for different cache levels in the memory hierarchy.
7939	Run complete analysis and return results.
7940	Run complete analysis using IACA, calculate normalized metrics per cache line, determine throughput limits considering overlapping and non-overlapping port models, and return comprehensive results including port cycles, throughput, uop counts, and performance predictions.
7941	Strip whitespaces and comments from assembly code lines by removing everything after '#' and trimming whitespace.
7942	Strip all labels from assembly code that are never referenced elsewhere in the code.
7943	Selects the best block from a list of blocks based on a heuristic that prioritizes blocks with more packed instructions, then falls back to a secondary heuristic considering operations, AVX instructions, and vector register usage when packed instruction count is zero. Raises ValueError if no blocks are provided.
7944	Function `userselect_increment` lets the user interactively choose a byte increment for a selected block. It displays the block's lines, prompts the user to input a number of bytes for the store pointer increment, validates the input as an integer, stores the increment in the block dictionary, and returns the increment value.
7945	Function `userselect_block` lets users interactively select a block from a list of blocks by displaying block information and prompting for input. It prints detailed block statistics and optionally shows code and metadata if debug mode is enabled. The function validates user input to ensure a valid block index is selected, defaulting to a provided default value if no input is given. It returns the selected block index.
7946	Insert IACA markers into a list of ASM instructions at specified start and end line indices, wrapping the specified range with START_MARKER and END_MARKER.
7947	Add IACA markers to an assembly file with optional automatic or manual block selection and pointer increment detection.
7948	This function sets up and executes a command-line interface for analyzing assembly code to find basic loop blocks and mark them for IACA (Intel Architecture Code Analyzer) instrumentation. It uses argparse to handle command-line arguments including input source file, output file, and debug mode. The main logic calls `iaca_instrumentation` with the specified parameters, defaulting to stdin for input and stdout for output when no files are provided.
7949	Simulates a model execution with specified blocking parameters by clearing kernel state, setting constants, analyzing the model, and returning the total cycle count from results.
7950	Generate a list of evenly spaced integers over a specified interval, either linearly or logarithmically. Supports optional inclusion of the endpoint and custom logarithmic base. Returns an iterator of rounded integer values.
7951	Return datetime object of latest change in specified directory by finding the maximum modification time among all files.
7952	Function `check_arguments` validates user-provided arguments that argparse doesn't handle automatically. It checks if `asm_block` is either 'auto', 'manual', or an integer, raising an error for invalid values. It also sets a default unit based on the performance model requested - using 'FLOP/s' for Roofline models and 'cy/CL' otherwise.
7953	Initialize and run command line interface by creating a parser, parsing arguments, validating them, and executing the main business logic.
7954	Command line interface that recursively merges multiple pickle files containing dictionary objects into a destination pickle file. Takes a destination file (opened in read+write binary mode) and one or more source files (opened in read binary mode), loads each pickle, asserts they are mapping types, merges them using an update function, then writes the merged result back to the destination file. The destination file is overwritten with the merged content.
7955	Creates a sympy.Symbol with positive and integer assumptions enabled.
7956	Transforms a multidimensional array declaration into a single-dimensional declaration by flattening the dimensions. Takes an AST declaration object, extracts all dimension information from nested ArrayDecl nodes, replaces the original dimensions with a single dimension representing the total array size (calculated by multiplying all dimensions), and returns the array name along with the original dimension information. This is an in-place operation that modifies the input declaration object.
7957	Transforms a multidimensional array reference into a single dimension reference by converting subscript indices into a linear address calculation. The function operates in-place, modifying the original array reference to represent the flattened memory address using the provided dimension information. The transformation handles nested array references and calculates the appropriate offset based on the array's dimensions and the original subscript values.
7958	Returns a list of all nodes of a specified type found in the AST by recursively traversing the abstract syntax tree.
7959	Wraps a function to ensure it always returns an iterable object, converting non-iterable return values into single-item lists while leaving iterable results unchanged.
7960	Check that kernel information is valid and consistent, ensuring no datatype mixing within the kernel.
7961	Set a constant value by name, where name can be a string or sympy.Symbol and value must be an integer. The constant is stored in the constants dictionary with the symbol representation of the name as the key.
7962	Substitutes constants in an expression with their corresponding values, unless the expression is already a number, in which case it returns the number unchanged.
7963	Return a dictionary with all arrays sizes, optionally in bytes or with constants substituted.
7964	Calculate the relative offset from iteration center in number of elements, preserving the order of indices used in access.
7965	Remove duplicate source and destination accesses by converting lists to sets for each variable name in both sources and destinations dictionaries.
7966	Return the total number of global loop iterations, or the length of a specific loop dimension if specified.
7967	Yields loop stack dictionaries ordered from outer to inner loops, optionally substituting constants in loop bounds when subs_consts=True.
7968	Return the order of indices as they appear in array references, filtered by sources and destinations.
7969	Return a dictionary mapping variable names to lists of sympy accesses, filtered by source and destination flags.
7970	Compile relative distances between successive accesses for each variable. Returns a dictionary mapping variable names to lists of simplified symbolic distance expressions between consecutive accesses.
7971	Return sympy expressions translating global_iterator to loop indices. If global_iterator is given, an integer is returned. The method unwinds the global iteration count into loop counters by calculating loop variables based on the loop stack properties and returns a dictionary mapping loop variables to their corresponding sympy expressions or computed integer values.
7972	Return global iterator sympy expression by computing the flattened index from nested loop variables.
7973	Transforms a dictionary of indices to a global iterator integer by substituting the given indices into the global iterator expression. This is the inverse operation of `global_iterator_to_indices()`.
7974	Return global iterator with last iteration number by converting loop stack indices to global iterator.
7975	Print kernel information in human readable format, including loop stack, data sources, data destinations, and FLOPs statistics.
7976	Print variables information in human readable format to the specified output file.
7977	Print constants information in human readable format to the specified output file.
7978	Prints the kernel source code to the specified output file (defaults to stdout).
7979	Convert mathematical expressions from AST to sympy representation, handling parentheses, addition, subtraction, and multiplication operations.
7980	Return a tuple of offsets of an ArrayRef object in all dimensions, handling multi-dimensional array access with right-to-left indexing order. Returns None for c_ast.ID objects.
7981	Return base name of ArrayRef object (e.g. c[i+1][j-2] -> 'c').
7982	Return the index type used in a loop nest, raising an exception if index types differ between loops.
7983	Generate constant declarations with optional initialization from command line arguments. Returns a list of declaration nodes with const qualifier and specified index type.
7984	Return array declarations from the kernel AST block items by filtering for Decl nodes with ArrayDecl types.
7985	Return kernel loop nest including any preceding pragmas and following swaps.
7986	Generate declaration statements for arrays by transforming multi-dimensional arrays to 1D arrays and optionally initializing with malloc. Returns a list of declaration nodes and a dictionary mapping array names to their original dimensions.
7987	Return the innermost for loop in a loop nest by recursively traversing the nested structure and returning the deepest for loop found.
7988	Generate initialization statements for arrays by traversing to the innermost loop, finding all array references, transforming multidimensional references to 1D, and creating static assignments with random float values.
7989	Generate a dummy if-branch with dummy calls for kernel AST declarations, using 'dummy' function and 'var_false' condition to prevent code removal.
7990	Build and return a kernel function declaration with specified name, containing array, scalar, and constant parameter declarations.
7991	Build and return scalar variable declarations from kernel AST, optionally adding initialization values. Copies existing scalar declarations and adds random initial values for numeric types (double, float, int, etc.) when requested.
7992	Generate and return compilable source code with kernel function from AST. If `openmp` is True, OpenMP code will be generated. If `as_filename` is True, save to file and return filename. The kernel function name can be specified with the `name` parameter. The method uses cached versions when available. It builds array declarations, processes kernel loop nests (with or without OpenMP), transforms multidimensional array references to 1D, and generates C code using a CGenerator. Includes are inserted at the top of the generated code.
7993	Generate and return kernel call AST by constructing a function call with the specified name and arguments built from array, scalar, and constant declarations.
7994	Generate and return compilable C source code from AST by replacing template placeholders with generated code sections like constants, arrays, scalars, and kernel function calls, with caching support.
7995	Run IACA analysis on a compiled kernel and return the analysis results along with the chosen assembly block. The method instruments the assembly code with IACA markers, assembles it, and performs the actual IACA analysis on the instrumented binary. The assembly block selection and pointer increment handling can be configured through parameters.
7996	Compile source code into an executable with LIKWID profiling capabilities, handling compiler setup, dependency checks, and linking with LIKWID libraries. Returns the name of the generated executable file.
7997	Converts a string to a SymPy object or None. Handles integers by converting them to sympy.Integer, lists by recursively processing their elements, and None values by returning None. For strings containing symbols, it creates a local dictionary mapping alphabet characters to positive integer symbols, parses the expression with this dictionary, then replaces all free symbols with positive integer versions before returning the final parsed expression.
7998	Return identifier which is either the machine file name or sha256 checksum of data.
7999	Return datetime object of modified time of machine file. Return current time if path is not set or not a file.
8000	Return a cachesim.CacheSimulator object based on the machine description, scaling shared cache sizes according to the number of cores.
8001	Returns the best fitting bandwidth based on cache level, read/write streams, and threading configuration. The method selects an appropriate kernel based on the read-to-write stream ratio, determines the bandwidth from measurement data, and applies corrections for write allocation effects, particularly for L1 cache. It can either return bandwidth for a specific number of cores or the maximum bandwidth across all cores in a NUMA domain.
8002	Return tuple of compiler and compiler flags by selecting from machine description file, commandline arguments, or function arguments.
8003	Parse performance counter events into tuple representation with parameters.

This function takes a performance counter event string and converts it into a tuple format. The input string is expected to have colon-separated components where:
- First component is the event type
- Second component is the event specification
- Additional components are optional parameters in key=value format
- Values starting with '0x' are parsed as hexadecimal integers
- Parameters without '=' are set to None

Returns a tuple containing (event_type, event_spec, parameters_dict).
8004	Enforces that no ranges overlap in internal storage by checking adjacent ranges and merging or removing overlapping intervals. If two consecutive ranges overlap, it extends the first range to match the second's end point and removes the second range.
8005	Return the absolute path to the 'headers' directory located in the same directory as the current file.
8006	Aligns an iteration with cache line boundaries by adjusting based on write/read offsets and cache line size, returning a modified iteration number that ensures proper cache line alignment for memory operations.
8007	Return a list with number of loaded cache lines per memory hierarchy level.
8008	Return a list with number of hit cache lines per memory hierarchy level by dividing HIT_count by first_dim_factor for each cache level.
8009	Return a list with number of missed cache lines per memory hierarchy level.
8010	Return a list with number of stored cache lines per memory hierarchy level by dividing STORE_count by first_dim_factor for each cache level.
8011	Return a list with number of evicted cache lines per memory hierarchy level, normalized by the first dimension factor.
8012	Return verbose information about the predictor, including memory hierarchy details and cache statistics normalized by the first dimension factor.
8013	A context manager that temporarily sets an environment variable to a specified value, restoring the original value (or unsetting it if it didn't exist) when the context exits. If the value is None, the environment variable is unset.
8014	Configures argument parser with three arguments: '--no-phenoecm' to disable phenomenological ECM model building, '--iterations' to set number of outer-loop iterations with default 10, and '--ignore-warnings' to ignore CPU model and frequency mismatch warnings.
8015	Generate a human-readable report of analysis data, including runtime, iterations, performance metrics, memory volume, memory bandwidth, and phenomenological ECM model results. Optionally display detailed results and data transfers based on verbosity settings.
8016	Parse the description in the README file by extracting content between '# Purpose' header and the next '##' header, cleaning up the formatting to make it suitable for PyPI display.
8017	Schedule a retry with specified countdown and max retry attempts from config parameters.
8018	Builds and returns a Sailthru purchase item object with course details, price information, and metadata.
8019	Record a purchase in Sailthru by calling the purchase API with the provided parameters. Returns False if there's a retryable error, otherwise returns True. Handles both API response errors and client exceptions, logging appropriate error messages.
8020	Get course information using the Sailthru content API or from cache, with fallback to ecommerce API if needed.
8021	Get course information from Ecommerce API by course ID, returning title and verification deadline, with error handling that logs exceptions and returns empty dict on failure.
8022	Maintains a list of courses a user has unenrolled from in the Sailthru user record by updating the 'unenrolled' variable in the user's 'vars' field. Adds course URL to the list when unenrolling, removes it when enrolling. Returns False if retryable error occurs, True otherwise.
8023	Sends a course refund email using Sailthru templating system with retry logic for failed deliveries.
8024	Handles sending offer assignment notification emails with retry logic for failed emails. Returns the response object or None if sending fails.
8025	Returns a dictionary containing logging configuration based on the specified parameters. The configuration supports both development and production environments, with options for console or file/syslog handlers, different log levels, and various formatting options. When dev_env is True, logs are written to files in the specified directory instead of syslog.
8026	Retries order fulfillment with exponential backoff until success or maximum retries reached, then re-raises the exception.
8027	Fulfills an order by making API requests, with retry logic for handling various exceptions including client errors (406 specifically ignored), server errors, timeouts, and SSL errors. Returns None upon success or raises Ignore exception for already fulfilled orders.
8028	Returns a Sailthru client configured for the specified site, raising exceptions if Sailthru is disabled or required configuration is missing.
8029	Get an object from the cache by key, returning None if not found or expired. Removes expired entries before checking.
8030	Save an object in the cache with a specified key and duration.

Arguments:
    key (str): Cache key
    value (object): object to cache
    duration (int): time in seconds to keep object in cache
8031	Get a value from configuration with optional site-specific overrides. Retrieves a variable value from a configuration module, checking for site-specific overrides if a site_code is provided. Returns the configuration value or raises RuntimeError if the variable is not found.
8032	Get the name of the file containing configuration overrides from the specified environment variable, raising an error if the variable is not set.
8033	Finds the appropriate value from a dictionary based on the current eplus version, returning the value associated with the largest version tuple that is less than or equal to the current version.
8034	Returns the EnergyPlus version to be used. If `_eplus_version` is defined, returns that version. Otherwise, returns the most recent available version. Raises RuntimeError if EnergyPlus is not installed.
8035	Returns a dictionary of file references with their constructors and path getters, initializing them if needed. The file references include IDF, EPW, EIO, ESO, MTR, MTD, MDD, ERR, and summary table files, each with specific constructors and path retrieval functions.
8036	Populates the object from JSON data by adding records inertly, then activating hooks, links, and external files. Handles comments, external files, and processes records table by table.
8037	Returns a list of all external files from all tables by collecting external file paths from each table's rows.
8038	Sets default values for all null fields in Epm tables that have default values defined.
8039	This function finalizes the initialization of an extensible structure by:

1. Identifying if the structure is extensible and determining the cycle length from tags
2. Finding the cycle start position and extracting patterns from field descriptors
3. Validating that the cycle start is found
4. Trimming unnecessary field descriptors beyond the cycle length
5. Storing cycle information (start position, length, and patterns) for future use
6. Setting extensible information on field descriptors for error handling during serialization

The function raises a RuntimeError if the cycle start position cannot be found, ensuring proper initialization before extensible processing can occur.
8040	Returns the extended name for a field descriptor at the given index, handling extensible name cycles by replacing "1" with the appropriate cycle number. If extensible_info is None or the field descriptor name is None, returns the original field descriptor name or None respectively.
8041	Returns a dictionary mapping full references to their shortened representations, handling collisions by appending indices to duplicate base names.
8042	Returns the first occurrence of a value from a specified column that matches a filter criterion in another column.
8043	Updates a value in the inert data structure at the specified index, handling special cases like Link, RecordHook, and ExternalFile objects by unregistering previous instances and managing primary key updates.
8044	Updates all given fields simultaneously by first validating and storing the data, then activating hooks, links, and external files.
8045	Sets all empty fields without defined default values to their default values.
8046	Adds field values to an extensible record without specifying field names or indexes. Raises TypeError if record is not extensible. Takes variable arguments representing field values and updates the record with these values starting from the next available index.
8047	Remove and return the value at the specified index from extensible fields, shifting remaining values to fill the gap, and return the serialized value of the popped field.
8048	Inserts a value at the specified index in an extensible field, shifting all following values. Handles index preparation, removes extensible fields, performs the insertion, and rebuilds the field list.
8049	Deletes a record from the database by unregistering links, hooks, and external files, then removing the record from the table without further unregistering, and finally marking the record as stale by setting its table and data attributes to None.
8050	Registers a record hook for validation, ensuring no duplicate reference keys exist in the hooks dictionary. Raises FieldValidationError if a key already exists.
8051	Registers a link by looking up hooks and storing the link in both source and target mappings.
8052	Creates a regex pattern from a line and intent name, returning the compiled regex object or None if compilation fails.
8053	Returns the remaining duration for a recording by calculating the difference between the end time and the maximum of the start time and given time, ensuring no negative values are returned.
8054	Serialize this object as dictionary usable for conversion to JSON.

:return: Dictionary representing this object.
8055	Make an HTTP request to a given URL with optional POST data, handling HTTPS verification, authentication, and error handling.
8056	Get available service endpoints for a given service type from the Opencast ServiceRegistry by querying the service registry API, filtering for online and active services, and returning their endpoints.
8057	Creates a directory if it doesn't already exist, silently passing if the directory already exists. Raises any other OSError exceptions that occur during directory creation.
8058	Get the location of a given service from Opencast and add it to the current configuration, with retry logic on failure.
8059	Registers a capture agent with the Matterhorn admin server, updating its status in the admin interface. Skips registration if backup mode is enabled. Sends agent information (address and status) to the admin server via HTTP request, logging responses or warnings as appropriate.
8060	Sends the current recording state to the Matterhorn core service. If in backup mode, the function returns silently without making any changes. Otherwise, it constructs a URL with the recording ID and attempts to make an HTTP request to update the recording status. If the request fails, it logs a warning message.
8061	Update the status of a specific event in the database by modifying the RecordedEvent record that matches the event's start time, then update the event object's status and commit the transaction.
8062	Update the current agent state in opencast by determining the appropriate status based on service states and registering the status with the capture agent. The status is determined with priority: offline (if schedule service is stopped), capturing (if capture service is busy), uploading (if ingest service is busy), or idle (default).
8063	Find the best match for the configuration file. If a configuration file is explicitly specified, return it. Otherwise, probe for the configuration file location by checking for './etc/pyca.conf' and returning '/etc/pyca.conf' if the first one doesn't exist.
8064	Update configuration from file, validate it, and initialize logger. Raises ValueError for invalid configuration or mismatched files/flavors lists. Returns the loaded configuration object.
8065	Function to validate configuration settings including HTTPS security checks, certificate existence, and agent backup mode status.
8066	Initialize logger based on configuration by setting up handlers (syslog, stderr, file) with specified format and level, then add them to root logger.
8067	Serve the status page of the capture agent, displaying preview images, upcoming and recorded events, and service statuses.
8068	Serve a preview image by its ID from the configured preview directory, returning the file if it exists or a 404 error if not found.
8069	Start all services by creating and managing multiprocessing processes for each module's run method.
8070	Parse Opencast schedule iCalendar file and return events as a list of dictionaries containing event properties and attachments.
8071	Loads and parses calendar schedule from Matterhorn core, filters out past events, and stores upcoming events in database. Returns schedule or None on failure.
8072	Main loop that retrieves and processes schedule information, updating service status and notifications while waiting for the next scheduled recording event.
8073	Main loop that continuously updates the capture agent state by setting service status to BUSY, sending ready and running notifications, then periodically calling update_agent_state() at configured intervals until termination is requested. The loop includes watchdog notifications and proper service shutdown sequence with logging.
8074	Return a response with a JSON API error object containing the specified error message and status code (defaulting to 500).
8075	Creates a response containing JSON API formatted data with optional status code, defaulting to 200.
8076	Serve a JSON representation of internal agent state as metadata containing service statuses for capture, ingest, schedule, and agentstate services.
8077	Serve a JSON representation of all events (both upcoming and recorded) by querying the database, ordering them appropriately, serializing each event, and returning the combined result as a JSON response.
8078	Return a specific event's JSON data by UID, searching through both recorded and upcoming events. If found, returns the serialized event data; otherwise, returns a 404 error indicating no event exists with the specified UID.
8079	Delete a specific recorded event by uid. Returns 204 on success, 404 if event doesn't exist. Optional ?hard=true parameter deletes files from disk. Cannot delete events in buffer.
8080	Modify an event specified by its uid with the provided JSON data, supporting updates to status, start, and end attributes. Validates input data and ensures the event exists. Returns the updated event serialized as JSON.
8081	Extract configuration parameters and workflow definition from schedule properties, returning a tuple of (workflow_definition, config_parameters_list).
8082	Ingest a finished recording to the Opencast server by uploading it through a randomly selected ingest service, creating a mediapackage, adding DublinCore catalogs and tracks, and finally ingesting the recording with specified workflow parameters.
8083	Starts the capture process by creating necessary files/directories, moving the event to recording status, executing recording command, and updating event status to finished recording.
8084	Returns a Fragment object containing test HTML, JavaScript, and CSS content.
8085	Returns list of unique `FragmentResource`s by order of first appearance.
8086	Returns the fragment as a dictionary with content, resources, and initialization information.
8087	Creates a new Fragment instance from a dictionary representation by setting content, resources, and initialization parameters.
8088	Add content to this fragment by appending HTML content to the body. The content must be a Unicode string without a `<body>` tag or page-level assumptions.
8089	Add a resource needed by this Fragment with the specified text, MIME type, and placement. If no placement is specified, it defaults based on the MIME type. The resource is stored in the fragment's resources list.
8090	Add a resource by URL needed by this Fragment, using the default placement based on mimetype if none is specified.
8091	Initialize JavaScript resources by registering a JavaScript function to be invoked during browser runtime setup, optionally with JSON arguments.
8092	Returns HTML string containing all resources placed in the specified location (head or foot) by iterating through resources and calling resource_to_html() on each matching resource.
8093	Returns `resource` wrapped in the appropriate HTML tag for its mimetype. Supports CSS, JavaScript, and HTML resources with different kinds (text or url). Raises exceptions for unrecognized resource kinds or mimetypes.
8094	This method handles HTTP requests to render a fragment either as HTML or JSON based on the request format. It first renders the fragment using the request and kwargs, then checks if the response should be JSON by examining the 'format' parameter or 'Accept' header. If JSON is requested, it returns a JsonResponse with the fragment's dictionary representation. Otherwise, it renders and returns a standalone HTML response.
8095	Renders a standalone HTML response for a given fragment, returning a 204 status if fragment is None, otherwise returning the rendered HTML content.
8096	Render the specified fragment to HTML for a standalone page using a template and context containing head, body, and foot HTML content.
8097	Function `calc` computes q-values and false discovery rates for a list of p-values. It takes p-values (sorted in descending order) and a lambda parameter, calculates the proportion of null hypotheses (pi0), and computes the positive false discovery rate (pFDR) for each p-value. The function then derives q-values by taking the minimum of the current and previous q-values, and computes sensitivity values. It returns a DataFrame containing p-values, q-values, FDR, percentile positive, sensitivity, and s-values, along with the number of null hypotheses and total hypotheses. The function assumes p-values are sorted in descending order.
8098	Converts a list, tuple, pandas Series, or n-dimensional array into a 1-dimensional numpy array. If the input is already a 1D array, it returns it as-is. Optionally converts the output to a specified data type. Raises an assertion error if the final array is not 1-dimensional.
8099	Find matching p-value, s-value, PEP, and q-value for each score in 'scores' by locating the nearest cutoff values in the error table dataframe.
8100	Compute posterior probabilities for each chromatogram by evaluating hypotheses about peak correctness versus null hypothesis (all peaks false) for every transition group in the experiment.
8101	Creates a dataframe with uniformly sampled cutoff values based on the range of cutoffs in the input dataframe. The function extends the range by 5% and generates 'num_cut_offs' sample points, then finds the nearest matching rows from the original dataframe to create a new sampled dataframe with the new cutoff values.
8102	Summary error table for specified q-values with duplicate handling and selected columns.
8103	Function `error_statistics` computes error statistics for target scores using decoy scores. It calculates p-values, estimates the proportion of true null hypotheses (pi0), computes q-values and various metrics (tp, fp, tn, fn, fpr, fdr, fnr). It returns a DataFrame with these statistics and the pi0 estimate. Optional calculation of local false discovery rate (lfdr) / posterior error probability (PEP) can be enabled.
8104	Finds the target score cutoff for a specified false discovery rate (FDR) by calculating error statistics and determining the cutoff that minimizes the absolute difference between the calculated q-value and the target FDR. Raises an exception if there is insufficient data to calculate error statistics.
8105	The `score` function performs semi-supervised learning and error-rate estimation on MS1, MS2, and transition-level mass spectrometry data. It accepts various parameters for configuring the classification process, XGBoost settings, and error-rate estimation methods. The function prepares XGBoost-specific parameters and then either applies weights to the data or not, depending on the `apply_weights` flag, before executing the appropriate learner or weight applier class. If no output file is specified, it defaults to using the input file as the output.
8106	Function to infer peptidoforms by scoring MS1, MS2, and transition-level mass spectrometry data, with optional input and output file specification.
8107	Function to infer peptides and estimate error rates with various statistical parameters and contexts.
8108	**Summary:** The `protein` function performs protein inference and error-rate estimation based on input data. It takes an input file, output file, and various parameters related to statistical methods for protein identification and false discovery rate (FDR) control. The function calls `infer_proteins` with these parameters to carry out the actual analysis, handling cases where the output file is not specified by defaulting to the input file.
8109	Subsample OpenSWATH file to minimum for integrated scoring.
8110	```python
def reduce(infile, outfile):
    """
    Reduce scored PyProphet file to minimum for global scoring
    """
    if outfile is None:
        outfile = infile
    else:
        outfile = outfile

    reduce_osw(infile, outfile)
```

Summary: The `reduce` function takes an input file and optional output file, and reduces a scored PyProphet file to a minimal format suitable for global scoring by calling the `reduce_osw` function. If no output file is specified, it overwrites the input file.
8111	Backpropagates multi-run peptide and protein scores to single files using the specified input and output files, applying the given scores in the process. If no output file is specified, uses the input file as the output.
8112	Filters sqMass files using the provided parameters for precursor, peakgroup, and transition peptide maximum PEP values.
8113	Returns a restclients.Group object for the group identified by the passed group ID.
8114	Creates a group using the provided restclients.Group object by sending a PUT request to the API endpoint with the group data, then returns the created group object from the JSON response.
8115	Deletes the group identified by the passed group ID by validating the group ID, constructing the resource URL, and deleting the resource. Returns True upon successful deletion.
8116	Returns a list of restclients.GroupMember objects for the group identified by the passed group ID.
8117	Updates group membership for a given group ID and returns a list of members not found.
8118	Returns the count of effective members for a specified group by making an API call and parsing the response data.
8119	Checks if a given netid is an effective member of a specified group by making an API call. Returns True if the member exists (HTTP 200), False if not found (HTTP 404), and raises exceptions for other errors. Removes '@washington.edu' domain suffix from netid before checking.
8120	This function modifies the Sphinx configuration file (`docs/conf.py`) to add custom extensions and change the HTML theme. It uses the `redbaron` library to parse and modify the Python configuration file, specifically:

1. Adds `"sphinxcontrib.napoleon"` to the `extensions` list
2. Changes the `html_theme` from its current value to `"sphinx_rtd_theme"`

The function reads the configuration file, parses it with `redbaron`, makes the specified modifications to the AST representation, and writes the updated content back to the file.
8121	Create 3 datasets in a group to represent a sparse array, handling different input types including Dataset objects, sparse matrices, and None data with specified sparse format. For Dataset inputs, copy existing datasets and attributes. For sparse matrix inputs, convert to the specified format and create datasets for data, indices, and indptr. For None data with sparse format, initialize an empty sparse matrix. For other cases, delegate to the parent class create_dataset method. Returns a Dataset object wrapping the created group.
8122	Decrypts input from stdin using the specified key and writes the decrypted output to stdout. Supports only AES256CBC encryption type, raises ReturnCode for unsupported encryption types.
8123	Returns a stdin-suitable file-like object based on optional os_path and optionally skipping any configured sub-command.
8124	Returns a stdout-suitable file-like object based on optional os_path and optionally skipping any configured sub-command.
8125	Returns a stderr-suitable file-like object based on optional os_path and optionally skipping configured sub-command.
8126	Returns a debug-output-suitable file-like object based on optional os_path, with optional sub-command skipping.
8127	A context manager that provides a stdin-suitable file-like object, optionally based on a given path and skipping sub-command filters. It yields the appropriate file-like object (either stdin or its stdout) and ensures proper cleanup including closing files and calling callbacks when done.
8128	A context manager that provides a stdout-suitable file-like object, optionally based on a given path and sub-command. It yields the appropriate file handle (stdin if available) and ensures proper cleanup including closing files and calling a callback when done.
8129	A context manager that yields a stderr-suitable file-like object based on optional path and sub-command settings, handling proper cleanup including optional disk callback execution.
8130	A context manager that yields a debug-output-suitable file-like object, optionally based on a given path and sub-command filter. It handles resource cleanup including closing file handles and calling a callback when the underlying disk file is closed.
8131	Deletes all objects and containers in the account, with optional multiple passes to ensure complete emptying. Requires explicit confirmation via `yes_empty_account=True`. Raises `ReturnCode` if confirmation is missing or if listing account fails. Uses `cli_delete` to remove items and handles pagination via marker. If `until_empty=True`, continues until account is truly empty, though this may run indefinitely if new items are constantly being added.
8132	Deletes all objects in a container, with option for multiple passes to ensure container is completely empty. Handles concurrency and error reporting during deletion process.
8133	A decorator that converts an optional file keyword argument in an instance method to an actual file value, checking in this order: explicit file parameter, io_manager's stdout, or sys.stdout.
8134	A decorator that converts an optional file keyword argument in an instance method to an actual file handle, checking in order: explicit file parameter, io_manager's stderr, or sys.stderr.
8135	Outputs an error message to a specified file, stderr, or sys.stderr, and sets error flag to True.
8136	Outputs help information to a specified file, io_manager's stdout, or sys.stdout, and writes raw epilog if available.
8137	Outputs usage information to a specified file, io_manager's stdout, or sys.stdout, then flushes the file.
8138	Method: print_version
Summary: Outputs version information to a specified file, io_manager's stdout, or sys.stdout, then flushes the file buffer.
8139	Method `request` performs a direct HTTP request to the Swift service with various options for handling request parameters, headers, and response processing. It accepts parameters for the HTTP method, request path, request body contents, request headers, and several optional flags controlling response handling including JSON decoding, streaming, query parameters, and CDN endpoint selection. The method returns a tuple containing the HTTP status code, reason phrase, response headers (with lowercase keys and list values for headers with multiple values), and response contents which can be raw string, JSON-decoded object, or a file-like object depending on the stream and decode_json parameters. The method currently raises an exception indicating it is not implemented.
8140	POSTs the account and returns the results, usually done to set X-Account-Meta-xxx headers while preserving existing ones. To remove a header, send it with an empty string value. Accepts additional headers, query parameters, CDN flag, and request body. Returns tuple of (status, reason, headers, contents) from the HTTP response.
8141	Deletes an account by sending a DELETE request. Requires explicit confirmation via `yes_i_mean_delete_the_account=True` unless it's a bulk delete operation. Supports additional headers, query parameters, and CDN options. Returns HTTP status, reason, headers, and response content. Warning: This operation cannot be undone.
8142	PUTs a container and returns the results, typically used to create new containers or set X-Container-Meta-xxx headers. Existing metadata headers remain untouched unless explicitly removed by sending an empty string value. Supports additional headers, query parameters, CDN management, and request bodies for operations like bulk uploads. Returns a tuple containing HTTP status code, reason, headers dictionary, and response contents.
8143	HEADs the object and returns the results.

Parameters:
- container: The name of the container.
- obj: The name of the object.
- headers: Additional headers to send with the request.
- query: Set to a dict of query values to send on the query string of the request.
- cdn: If set True, the CDN management interface will be used.

Returns: A tuple of (status, reason, headers, contents).
- status: is an int for the HTTP status code.
- reason: is the str for the HTTP status (ex: "Ok").
- headers: is a dict with all lowercase keys of the HTTP headers; if a header has multiple values, it will be a list.
- contents: is the str for the HTTP body.
8144	Returns the object from the specified container with given name, supporting streaming and query parameters.
8145	Puts an object into a container, creating or overwriting it. Returns HTTP status, reason, headers, and contents. Supports additional headers, query parameters, and CDN management. Contents can be string or file-like object with read function.
8146	POSTs an object and returns the results, used to update object's header values. Unlike account and container POSTs, existing headers are removed and full list of supported headers depends on the Swift cluster. Returns tuple of (status, reason, headers, contents).
8147	Resolves an option value by setting options.<option_name> to a value from: 1) already set options (highest priority), 2) environment variables (medium priority), or 3) configuration file values (lowest priority). The environment variable name is constructed from the section_name and option_name, while the configuration name uses the same option_name.
8148	Returns a new CLIContext instance that is a shallow copy of the original, copying all public attributes except 'copy' and 'write_headers'.
8149	Writes headers to a file-like object in a formatted manner, with optional suppression of specified headers.
8150	Authenticates a user and outputs authentication information to stdout. Retrieves and displays various authentication-related details such as URLs, tokens, tenant information, and storage paths from the client object. If no authentication information is available, it displays a message indicating that no credentials were provided. The output is formatted with aligned columns for readability.
8151	Generates a temporary URL that is valid for a specified time period and signed with a given key. The URL is constructed by combining the base URL, object path, and temporary URL parameters including signature and expiration time. The signature is created using HMAC-SHA1 hashing of the request method, expiration time, and object path.
8152	Encodes a value as a URL-safe string, ensuring UTF-8 encoding while preserving safe characters.
8153	Function `cli_fordo` issues commands for each item in an account or container listing, handling pagination and concurrency. It supports path-based listings, error handling for 404 responses, and processes items with specified arguments. The function manages client requests, processes results from concurrent operations, and raises exceptions for errors encountered during listing or command execution.
8154	Returns an available client from the pool or creates a new one if none are available. First attempts to get an unused client without blocking, and if that fails (queue is empty), creates a new client with incrementing ID and verbose tracking.
8155	Generator that encrypts a content stream using AES 256 in CBC mode. Takes a key, input stream, optional preamble, chunk size, and content length. Returns encrypted data in chunks, handling padding and EOF conditions. Raises exception if AES256CBC is not supported.
8156	Generator that decrypts a content stream using AES 256 in CBC mode, reading encrypted data from stdin with specified key and chunk size, yielding decrypted data in chunks. Raises exceptions for unsupported AES256CBC or corrupted data.
8157	Performs PUT operations on a directory structure rooted at the specified path using the context input. Raises exceptions if input is not set or is not a directory, or if path is not provided. Creates container and uploads files and empty directories concurrently using `cli_put_object` and `cli_put_container`. Handles concurrency with `Concurrency` class and raises any exceptions encountered during the process.
8158	Performs a PUT request on an account with optional body content, handling stdin or file input, and raises an exception if the operation fails.
8159	Performs a PUT request on a container with optional body data, handling input from stdin or a file, and raises ReturnCode exception on non-2xx status codes.
8160	Returns body for manifest file and modifies put_headers based on static_segments context. If static_segments is True, creates a JSON body with path, size, and etag information for all paths in path2info, sets content-length, and adds multipart-manifest query parameter. If static_segments is False, returns empty body, sets content-length to 0, and adds x-object-manifest header with the given prefix.
8161	Creates a container for file segments by splitting the path, creating a container with '_segments' suffix, and returning a prefixed path with timestamp and size information.
8162	Generates a TempURL for Swift object storage and writes it to stdout. Takes a method (GET/PUT/etc.), path, expiration time, and container flag to create the URL using either account or container-level TempURL keys. Raises ReturnCode exceptions for invalid paths, missing keys, or failed API calls.
8163	Translates X-Trans-Id information into readable format and outputs to context's stdout, showing timestamp, UTC time, and additional info.
8164	Outputs help information for CLI commands. Takes a context, command name, general parser, and command parsers dictionary as input. If command_name is empty or None, prints general help. If command_name exists in command_parsers, prints that command's help. Handles special case where 'for' becomes 'fordo'. Raises ReturnCode exception for unknown commands.
8165	Check whether the "file" is empty by reading a single byte. Returns False if byte is read and adds it to buffer, True if no byte is read (empty file).
8166	Encrypts stdin using AES encryption with the provided key and writes the encrypted output to stdout through the context's io_manager.
8167	Gets the status of a commit for a given repository and SHA hash, making an API request to GitHub and returning the response. Raises an exception if the request fails.
8168	Returns the data for a given pull request by making an API call to the GitHub API, raising an exception if the request fails.
8169	Returns a generator that yields pull request IDs from the last 30 pull requests of a specified repository by making an API call. Raises an exception if the API request fails.
8170	Set all SliderItemTitle objects to published status.
8171	Returns published slider items, optionally limited by amount, ordered by position.
8172	Renders the hero slider by fetching published slider items ordered by position and returning them in the context.
8173	Acquires read lock by incrementing reader count and acquiring necessary mutexes, ensuring exclusive access when first reader arrives.
8174	Release the lock after reading by decrementing the readers count and releasing the access mutex when no readers remain.
8175	Acquires write lock by first acquiring order mutex, then access mutex, then releasing order mutex.
8176	Add a task to the registry using task_id as identifier. Raises AlreadyExistsError if task already exists. Returns the newly created task. Uses write lock for thread safety.
8177	Remove a task from the registry by its ID, raising NotFoundError if not found, with thread-safe write access using a reader-writer lock.
8178	Get a task from the registry by its ID, raising NotFoundError if not found.
8179	Get the list of tasks sorted by task_id.
8180	Returns a dictionary representation of the task configuration object by extracting all class properties and their corresponding values.
8181	Create a configuration object from a dictionary by using key-value pairs to initialize a task configuration object. Raises ValueError for invalid configuration parameters.
8182	Execute a Perceval job on RQ, handling archiving and retries. The function runs a specified backend with given arguments, stores fetched items in a Redis queue, and manages job execution with support for resuming failed jobs up to a maximum retry limit. It raises exceptions for missing backends or unsupported archiving features, and returns a JobResult instance upon successful completion.
8183	Initializes the archive manager with the specified path, raising a ValueError if the path is empty.
8184	Run the backend with given parameters, storing fetched items in Redis queue. Supports resuming from last execution and fetching from archive. Raises exceptions during execution.
8185	Execute a Perceval backend with given arguments, returning an iterator of fetched items. When `fetch_from_archive` is False or not specified, it fetches items using the backend's fetch method. When `fetch_from_archive` is True, it fetches items from the archive using the archive manager and optional `archived_after` filter. Raises AttributeError if required parameters are missing.
8186	Creates or re-creates an Elasticsearch index at the specified URL. Returns True if index was created or re-created, False otherwise. Handles connection errors and index creation failures by raising ElasticSearchError. If clean=True and index exists, deletes and re-creates the index.
8187	Create a mapping in Elasticsearch by sending a PUT request to the specified index URL with the provided mapping configuration. Handles connection errors and logs appropriate messages based on the HTTP response status code.
8188	Custom JSON encoder handler that processes JSON data through CherryPy's request handling and yields UTF-8 encoded JSON chunks using Python's JSONEncoder.
8189	Write items to the queue by continuously retrieving items from a generator and writing them using a writer object with 1-second intervals between writes.
8190	Add and schedule a task with the given parameters, validating arguments and handling potential errors during task creation and scheduling.
8191	Remove and cancel a task by its ID, returning True if successful or False if the task doesn't exist.
8192	Get the items fetched by the jobs by retrieving and removing queued items in an atomic transaction, then yield each item after unpickling it.
8193	Validates that task arguments are valid by checking that task_id, backend, and category are not empty, and that backend_args is a dictionary if provided. Raises ValueError with descriptive messages for any validation failures.
8194	Parse the archive arguments of a task, update with default archive path if not specified, and return an ArchivingTaskConfig object.
8195	Custom method to execute a job and notify of its result via pubsub channel.

Args:
    job: Job object to be executed
    queue: The queue containing the job

Returns:
    The result of the parent perform_job method execution

The method executes the parent's perform_job method, gets the job status and result, serializes this information into a dictionary, pickles it, and publishes it to a pubsub channel. The job result is only included when the job status is 'finished'.
8196	Schedule a job in the given queue with optional delay, generating a job ID and storing the job information in the scheduler's internal data structures.
8197	Cancel the job associated with the given task ID, or log a warning if the task is not found.
8198	Run thread to listen for jobs and reschedule successful ones, with exception handling for critical errors.
8199	Listen for completed jobs on a Redis pubsub channel and reschedule successful ones by calling appropriate result handlers. When a message is received, it deserializes the job data, fetches the job from Redis, and depending on the job status (finished or failed), calls either the success handler or error handler. The method uses a pubsub subscription to listen for job completion notifications and processes them asynchronously.
8200	Starts job scheduling either in async mode (starting scheduler and listener threads) or synchronous mode (direct scheduling).
8201	Schedule a task by adding it to the appropriate job queue based on archiving configuration, then return the scheduled job ID.
8202	Cancel or 'un-schedule' a task by removing it from the registry and scheduler, then log the cancellation. Raises NotFoundError if task is not found.
8203	Handle successful jobs by updating task backend arguments, scheduling the next job execution, and logging the re-scheduling information.
8204	Handle failed jobs by logging an error message with job ID and task ID when a job is cancelled.
8205	Build job arguments for running a task, including backend parameters, category, archiving settings, and scheduler parameters.
8206	Gets the contents of a secret file from the secrets directory. Returns the secret content if found, otherwise returns a default value.
8207	Register an API view class with the bananas router using the view's admin metadata to determine the registration prefix and basename.
8208	Registers a generic class-based view with ModelAdmin and a fake model, allowing the view to be integrated into Django's admin interface with proper permissions and labeling. Can be used as a decorator or with explicit parameters.
8209	Method that extends DRF's reverse_action with version fallback logic, attempting to resolve URLs with the requested namespace when request.version is missing.
8210	Get or generate human readable view name, supporting both class and instance usage with optional name respect and suffix handling.
8211	Derives a PEP386-compliant version number from a version tuple, constructing the main version part (X.Y[.Z]) and sub-version part (.devN, .aN, .bN, or .cN) based on the release stage and build number.
8212	Get engine or raise exception, resolves Alias-instances to a sibling target.

:param cursor: The object so search in
:param key: The key to get
:return: The object found
:raises KeyError: If no matches found for the given key
8213	Lookup engine from _ENGINE_MAPPING using scheme string, handling up to 2 levels of engine specification. Returns the resolved engine string after validating the structure and performing lookups. Raises KeyError for invalid sub-engines and ValueError for invalid configuration.
8214	Parse a path string to extract database name and schema, returning them as a tuple. The path is expected to be "/"-delimited in the format "/<database name>/<database schema>", where the database name and schema are extracted and returned as (database, schema). If the path is None, a ValueError is raised. If the path is empty or has fewer than two components, None is returned for missing parts. The database name is URL-decoded using unquote_plus, while the schema is returned as-is.
8215	Converts a database URL into a Django-style database configuration dictionary by parsing the URL and converting all keys to uppercase.
8216	Parse a database URL and return a DatabaseInfo named tuple containing engine, name, schema, user, password, host, port, and params extracted from the URL.
8217	**Summary:**

The `create` method handles Django staff user login by validating authentication credentials through an `AuthenticationForm`. If validation fails, it raises a `ValidationError` with the form's errors. On successful validation, it authenticates the user using `auth_login` and returns the serialized user data with a 200 OK status. The method includes a TODO comment about decorating the API with sensitive post parameters for security, similar to Django admin practices.
8218	Retrieve logged in user info
8219	Create a method to change the password for a logged-in Django staff user, validating the input data, saving the new password, and updating the user's session authentication hash.
8220	Builds a URL field for a model serializer, overriding the default DRF behavior to use a custom view name instead of the default queryset-based URL name.
8221	Parse a string value to boolean, supporting various string representations of True/False values. Returns True for "True", "Yes", "On", "1" and False for "False", "No", "Off", "0". Raises ValueError for unsupported values.
8222	Parse a numeric string to integer, supporting octal format. If the string starts with "0", it's treated as octal and converted accordingly; otherwise, it's converted as decimal.
8223	Returns the appropriate parser function for a given type, raising NotImplementedError for unsupported types.
8224	Get and parse prefixed Django settings from environment variables, handling type conversion and validation while supporting a configurable prefix.
8225	Creates a ModelDict by extracting field values from a Django model instance, supporting both positional fields and named field specifications with double underscore lookups.
8226	Encodes a string using a Y64 non-standard URL-safe base64 variant, replacing "+", "/", and "=" with ".", "_", and "-" respectively.
8227	Create a field object from a field information dictionary by looking up the field type in FIELDS_NAME_MAP and instantiating the appropriate field class with the remaining parameters.
8228	Creates a Validator instance from a dictionary definition by dynamically building a class with specified fields and their types, returning a new Validator class with the given name.
8229	Generates a Cartesian product of input parameter dictionary values, supporting linked parameter combinations. Takes a parameter dictionary and optional combined_parameters tuple defining parameter groupings, returns a dictionary with lists of cartesian product values. Parameters in the same tuple within combined_parameters are linked together in the output, while ungrouped parameters contribute independently to the cartesian product.
8230	Finds unique parameter combinations from explored parameters, returning tuples of parameter values and their run positions. Uses hash-based approach when parameter ranges are hashable (O(N) complexity) or falls back to O(N) comparison method otherwise.
8231	Helper function to convert simple logging keyword arguments into a structured `log_config` dictionary, handling log levels, folder paths, logger names, and multiprocessing settings.
8232	**Summary:**

A decorator that enables simple logging configuration by allowing specification of `log_folder`, `logger_names`, and `log_levels` parameters. It validates that `log_config` isn't also provided when using the simple configuration approach, and processes the logging arguments before calling the original function.
8233	Summary: Attempts to create directories for a given filename, ignoring any errors but reporting them to stderr.
8234	Returns all valid Python strings found within a given argument string by parsing it with the AST module and extracting string literal values.
8235	Renames a given filename by replacing wildcards with corresponding trajectory or system information. Supports placeholders for environment name, trajectory name, run name, run set name, process name, and host name. If specific values are not provided, they are extracted from the trajectory or system automatically. Returns the new filename with wildcards replaced.
8236	Adds a logger with a given name to the instance. If no name is provided, constructs the name using the class module and name. Stores the logger in self._logger.
8237	Extracts wildcards and file replacements from a trajectory, setting environment name, trajectory name, set name (using '$set' wildcard), and run name (using '$' wildcard).
8238	Displays a progress bar with configurable logging and formatting options. Shows progress percentage and run counters, supporting both print output and custom logger integration with adjustable verbosity levels.
8239	Searches for parser settings that define filenames in a config parser section. If found, renames them according to wildcard rules and creates corresponding directories if requested. Returns the modified parser with updated arguments.
8240	Converts a ConfigParser object into a StringIO stream by writing the parser contents to memory and returning the stream positioned at the beginning.
8241	Searches for multiprocessing options in a ConfigParser and returns a new parser with those options (without the 'multiproc_' prefix). Returns None if no multiprocessing options are found.
8242	Searches for multiprocessing options in a given dictionary, copies them (without the 'multiproc_' prefix) into a new dictionary, and includes version and disable_existing_loggers if present. Returns None if no multiprocessing options are found.
8243	Checks and converts logging configuration settings, including progress reporting and stdout logging options, ensuring proper formatting and validation of configuration files or dictionaries.
8244	Handles configuration file parsing by checking for filenames and translating them, while also creating directories for the files. Returns the parsed configuration.
8245	Recursively processes a log configuration dictionary to handle filename transformations and directory creation. For each key-value pair, if the key is 'filename', it renames the file using environment and trajectory information and ensures the directory exists. For nested dictionaries, it recursively processes them. All other values are copied as-is to the new dictionary. Returns the transformed dictionary with updated filenames and proper directory structure.
8246	Creates logging handlers and redirects stdout. Sets up logging configuration based on multiproc flag, handling both dictionary and file-based configurations. If log_stdout is enabled, redirects stdout to logger with specified name and level.
8247	Finalizes the manager by closing and removing all tools and configurations, and optionally removes all handlers if specified.
8248	Starts redirection of `stdout` by replacing sys.stdout with this object if it's not already redirected, and prints confirmation message.
8249	Writes data from buffer to logger with recursion protection, logging each line at the specified log level while avoiding infinite recursion through a recursion flag and writing error to stderr if recursion is detected.
8250	Compares two result instances for equality by checking full name and all data, excluding comments. Returns True if equal, False otherwise. Raises ValueError if both inputs are parameters (not results).
8251	Compares two parameter instances for equality by checking full name, data, and ranges. Returns True if parameters are equal, False otherwise. Raises ValueError if both inputs are not parameter instances. Does not consider comments when comparing.
8252	Decorator function that wraps a function to execute it as a manual run with optional run-specific functionality including metadata storage and cleanup.
8253	A decorator that marks functions as deprecated, emitting a warning when the function is called. It accepts an optional message to provide additional information about the deprecation.
8254	A decorator that enforces mutual exclusivity between two keyword arguments. When param2_name is provided but param1_name is not, it maps param2 to param1 using an optional mapping function. Raises a ValueError if both parameters are specified simultaneously.
8255	A decorator that handles keyword argument name changes in API functions, issuing deprecation warnings when old argument names are used and automatically converting them to new names. It supports both cases where the old parameter should be discarded entirely or remapped to a new parameter name.
8256	A decorator that retries a function call up to `n` times when specific errors occur, with optional waiting between attempts and logging capabilities.
8257	A decorator that adds prefix naming scheme to a class by implementing `__getattr__` and `__setattr__` methods, raising TypeError if `__getattr__` is already defined.
8258	Adds all necessary parameters to `traj` including Brian2 standard parameter settings and network parameters like capacitance, conductance, reversal potentials, threshold values, time constants, and differential equations for neuron dynamics.
8259	Creates and runs a BRIAN network based on trajectory parameters, initializes neurons with specific conditions, runs the network for 100ms (discarded), then records spikes and membrane voltage data for 500ms.
8260	Euler scheme simulation function that integrates differential equations using the Euler method. Takes a trajectory object containing parameters and initial conditions, and a differential function to integrate. Computes the time evolution by iteratively applying the Euler update rule: x_{n+1} = x_n + dt * f(x_n, params). Stores the resulting time series data in the trajectory object under the key 'euler_evolution'.
8261	Adds all necessary parameters to the `traj` container including simulation settings (steps, dt), initial conditions as an array parameter for a 3-D differential equation, and Lorenz attractor function parameters (sigma, beta, rho) grouped under 'func_params' with descriptive annotations.
8262	Function that computes the Lorenz attractor differential equations returning the 3D derivatives for the system.
8263	Creates a storage service instance using the provided constructor and identifies any unused keyword arguments. Returns the created storage service and a set of unused keyword arguments.
8264	Creates a storage service instance based on the provided storage service parameter, handling filename extensions and class instantiation. Returns the storage service and unused keyword arguments.
8265	Adds necessary parameters to the `traj` container for either Lorenz or Roessler attractor simulations, including step count, time step size, initial conditions, and system-specific parameters, raising ValueError for unrecognized differential equation names.
8266	The `diff_roessler` function implements the Roessler attractor differential equations, which model a chaotic dynamical system. It takes a 3D array of current state values (x, y, z) and two parameters (a, c), then returns the derivatives of the system at that point. The function uses the standard Roessler equations with parameter b set equal to a, producing the characteristic chaotic behavior of the attractor through the coupled differential equations: dx/dt = -y - z, dy/dt = x + ay, and dz/dt = b + z(x - c).
8267	Function `compact_hdf5_file` compresses an HDF5 file to reduce its size by using `ptrepack` command-line tool. It retrieves compression properties from a specified trajectory in the file and applies them to create a compressed version. The function supports specifying a trajectory by name or index, and offers an option to keep a backup of the original file. The process involves creating a temporary file with compression settings, executing the `ptrepack` command, and then replacing the original file with the compressed version, optionally keeping a backup. Returns the exit code from `ptrepack`. Currently only supported on Linux.
8268	Checks if any parameter in the given group node has been explored in the trajectory.

**Parameters:**
- traj: Trajectory container
- group_node: Group node

**Returns:** 
- True if any parameter in group_node is explored, False otherwise
8269	Computes model equations for excitatory and inhibitory neural populations by combining base equations with synaptic equations, replacing PRE and POST placeholders with appropriate population identifiers, and creating Equation objects with compiled variables for each population type.
8270	Pre-builds neuron groups for the network model if no relevant parameters are explored. Adds inhibitory and excitatory neuron groups to the brian_list and network_dict, and sets a flag indicating whether pre-building was performed.
8271	Method: build(self, traj, brian_list, network_dict)

Summary: Builds neuron groups by calling the internal _build_model method if the neuron group has not been pre-built. The method takes a trajectory container, a list of BRIAN network objects, and a network dictionary as parameters. It adds inhibitory and excitatory neuron groups to both the brian_list and network_dict if they haven't been previously built.
8272	Builds neuron groups from trajectory data by creating inhibitory and excitatory neuron groups with specified equations, thresholds, resets, and refractory periods. Sets bias terms and initial membrane potentials for both neuron groups, then adds them to the provided brian_list and network_dict.
8273	Pre-builds connections for the network if no parameters are explored and required neuron groups exist. Checks for explored parameters and presence of inhibitory/excitatory neuron groups, then builds connections if conditions are met.
8274	Builds connections for the network if not previously built, using trajectory data and network components to establish connections between excitatory and inhibitory neuron groups.
8275	Adds simulation duration parameters to trajectory container: initial_run (500ms) with order 0 and measurement_run (1500ms) with order 1.
8276	Computes the Fano Factor for a specific neuron by binning its spikes into consecutive time windows, calculating the variance-to-mean ratio of spike counts across bins, and returning 0 if the mean firing rate is zero.
8277	Computes the average Fano Factor across multiple neurons by calculating individual Fano Factors for each neuron in specified time windows and returning their mean.
8278	Calculates the average Fano Factor of a network by analyzing spike data from excitatory neurons over a specified time window. The method computes the mean Fano Factor across all excitatory neurons and stores it in the trajectory results. It only performs the analysis when all subruns have been completed, using spike data from the SpikeMonitor and applying the configured time window and neuron IDs for the calculation. The result is stored with the key 'statistics.mean_fano_factor' and includes the network parameter R_ee in the output.
8279	Adds monitors to the network for measurement runs, specifically when the current subrun order is 1, by calling the internal `_add_monitors` method to set up spike and state monitors for excitatory neurons.
8280	Adds monitors to track spiking activity, membrane potential, and synaptic currents for excitatory neurons in the network, then registers these monitors with the network and stores them in the network dictionary.
8281	Makes a subfolder for plots and returns the path name to the print folder. Creates the directory if it doesn't exist.
8282	Plots state variable graphs for multiple neurons in a single figure, showing time series data for each neuron's recorded variable.
8283	This method creates and saves multiple plots for a given trajectory, including spike raster plots and voltage/current monitoring data. It generates plots for spike times, membrane potential (V), excitatory synaptic current (I_syn_e), and inhibitory synaptic current (I_syn_i), saving each as a PNG file in a trajectory-specific subfolder. The plots are either displayed based on analysis settings or closed to prevent memory leaks.

Key operations:
- Creates spike raster plot using spike monitor data
- Generates voltage plots from monitoring data
- Creates excitatory and inhibitory synaptic current plots
- Saves all plots with descriptive filenames in designated folders
- Handles plot display/showing based on analysis configuration
8284	**Summary:**

The `analyse` method extracts monitor data from a BRIAN network and generates plots when all subruns are completed. It adds spike times, membrane voltages, and synaptic currents from monitored neurons to the trajectory container, then creates visualizations if plotting is enabled.

**Key operations:**
- Checks if all subruns are complete (`len(subrun_list)==0`)
- Stores monitor results (spikes, membrane voltage, synaptic currents) in trajectory
- Generates plots when `analysis.make_plots` parameter is True
- Uses `_print_graphs` method for actual plotting implementation

**Parameters:**
- `traj`: Trajectory container for storing results
- `network`: BRIAN network object
- `current_subrun`: Current subrun parameter
- `subrun_list`: List of pending subruns
- `network_dict`: Shared network components dictionary

**Results added to traj:**
- Excitatory spikes data
- Membrane voltage data from 4 neurons across 2 clusters
- Excitatory synaptic current data from 4 neurons across 2 clusters
- Inhibitory synaptic current data from 4 neurons across 2 clusters
8285	Function that parses the batch id from command line arguments and returns it as an integer.
8286	The `explore_batch` function generates a list of sigma values for exploration based on the given batch number. For a given batch `b`, it creates sigma values in the range `[10.0*b, 10.0*b+1.0, 10.0*b+2.0, ..., 10.0*b+9.0]` (10 consecutive values with 1.0 step size). The function then passes this exploration dictionary to the trajectory's `f_explore` method to configure the exploration parameters.
8287	Returns the variables associated with this node, creating them if they don't exist yet. Provides an alternative to accessing variables through `node.v_name`.
8288	```python
def func(self):
    """Alternative naming, you can use `node.func.name` instead of `node.f_func`"""
    if self._func is None:
        self._func = NNTreeNodeFunc(self)
    return self._func
```

This method implements a lazy initialization pattern for a `_func` attribute. When called, it checks if `self._func` is None, and if so, creates a new `NNTreeNodeFunc` instance with `self` as the argument. It then returns the `_func` attribute. The docstring indicates this is an alternative way to access function names compared to using `node.f_func` directly.
8289	Renames the tree node by updating its full name and extracting the base name from the last part of the full name split by dots.
8290	Sets internal details including depth, branch, and run_branch attributes for internal handling.
8291	Maps a given node and store_load constant to a message understood by the storage service, returning LEAF/DELETE for leaf nodes or GROUP/DELETE for non-leaf nodes based on the store_load operation.
8292	Removes a subtree from the trajectory tree starting at the specified node. The method deletes the subtree from RAM only, not from disk. It recursively removes nodes based on an optional predicate function that determines whether nodes should be deleted (returns True) or kept (returns False). The method handles both regular nodes and links, and returns True if the subtree was successfully removed, False otherwise. When a node is removed, it also cleans up associated groups, leaves, and links.
8293	Deletes a single node from the tree by removing all references to it, handling both leaf and non-leaf nodes. It manages various parameter groups, explored parameters, links, and cleanup of search dictionaries while ensuring the root node and certain groups cannot be deleted.
8294	Removes a single node from the tree structure by traversing the branch and deleting the specified node. Only removes from RAM, not from the HDF5 file. Can optionally delete group nodes with children based on the recursive flag.
8295	Removes a node from the tree along a specified branch path. Walks recursively down the tree from a given node to locate and delete the target node. If the target is a group node with children, raises an error unless recursive=True is specified, in which case all children are also deleted. Returns True if the node was successfully deleted, False otherwise. Handles both regular nodes and linked nodes during the deletion process.
8296	Maps shortcut names to their corresponding full names with specific rules for run indices, set indices, and predefined shortcuts. Returns a tuple of (success_flag, mapped_name).
8297	Adds the correct sub branch prefix to a given name based on the start node and group type. Handles special cases for root-level nodes and auto-run prefixes, returning the name with appropriate prefixes prepended.
8298	Determines types for generic additions based on node properties and flags. Returns type tuples for link/leaf/group combinations depending on whether link or leaf additions are specified, using SUBTREE_MAPPING for type determination.
8299	Adds a given item to the tree irrespective of the subtree, inferring the subtree from the arguments. It handles various cases for specifying the item to be added, including instances, classes with names, or string names. The method checks naming conventions, handles linking, and ensures proper tree structure and run-time constraints are respected before adding the item to the tree.
8300	Adds a new item to the tree structure, creating intermediate groups if necessary. The item can be an existing instance or a newly constructed object. It navigates through the tree starting from `start_node`, using `split_names` to determine the path. If the final path doesn't exist, it creates the necessary nodes based on `type_name` and `group_type_name`. It handles cases where links are involved and manages conflicts based on the `_no_clobber` flag. Returns the newly added node or raises an error if the operation fails.
8301	Creates a link between nodes and maintains linking metadata including name validation and counts.
8302	Checks a list of names for validity, returning descriptions of any violations found. Returns an empty string if all names are correct. Validates name length, character composition, leading underscores, reserved keywords, Python keywords, and wildcard usage. Issues warnings for names that conflict with method/attribute names or Python keywords, but still allows them.
8303	Creates a new group instance based on the specified type name and adds it to the parent node. It handles different group types (result, parameter, config, derived parameter, or general group) by constructing the appropriate class or using an existing instance. The method also validates that groups are placed under correct parent types and updates the internal tree structure and references. Returns the created or updated group instance.
8304	Creates a new parameter or result instance based on type_name, handling construction or reuse of existing instances, and integrates it into the trajectory's structure and tracking systems.
8305	Sets details for a tree node including depth, branch, and run_branch based on parent node information and instance properties.
8306	Returns an iterator over nodes hanging below a given start node, with options for recursive traversal, depth limiting, predicate filtering, and link consideration. Supports both recursive and non-recursive traversal modes with optional filtering based on run names or indices.
8307	Returns an iterator over a node's children, optionally including links. When using a trajectory as a run, sub branches not belonging to the run are filtered out. The iterator yields tuples of (depth+1, key, value) for each child node.
8308	A breadth-first search tree traversal function that iterates through nodes starting from a given node, yielding nodes based on depth constraints and predicates. It handles linked nodes and can filter results based on a predicate function, supporting both regular and search modes.
8309	Fast search for a node in the tree using reference dictionaries instead of tree traversal. Searches for a node with given key starting from specified parent node, considering maximum depth and run constraints. Raises TooManyGroupsError if too many candidates found, NotUniqueNodeError if multiple matches exist. Returns found node and its depth or None if not found.
8310	Searches for an item in the tree below the given node, first attempting a fast search and falling back to a tree traversal if needed, returning the found node and its depth.
8311	Performs a backwards search from a terminal node back to a start node, finding candidates that match a given name pattern up to a maximum depth. It avoids duplicates using a set of full names and supports shortcut matching where partial name sequences can match. Returns a list of matching candidates.
8312	Returns the kids property of the node, initializing it as an NNTreeNodeKids object if it doesn't already exist. This provides an alternative way to access node children with easier tab completion support.
8313	Summary: Adds a new group from storage service bypassing name checking by calling the generic add interface with group-specific parameters.
8314	Adds a new leaf node from storage service without name checking by calling the generic add interface.
8315	Returns a list of all children names, loading data recursively with skeleton only if the object is root and auto-load is enabled, or if it's a child with auto-load enabled. The method attempts to load data but silently ignores any exceptions. The returned list contains the keys from the _children dictionary.
8316	Creates a debug object containing the entire tree structure for easier inspection during debugging. The debug object includes v_annotations, v_comment, leaves, links, and groups from the original tree, but manipulating it does not affect the original tree. Links are represented as text descriptions indicating their target nodes.
8317	Returns the parent node of the current node, raising TypeError if the current node is root.
8318	Adds an empty generic group under the current node, allowing flexible parameter tree structure creation. If operating within the standard subtrees, it calls the corresponding adding function. When adding items outside a `run_XXXXXXXX` group in single run mode, manual saving is required to prevent data loss after the run completes.
8319	Adds a link to an existing node. Can be called with either a target node (using the target node's name as the link name) or with a link name and target node. Colon-separated names are not allowed. Returns the result of the internal generic addition operation.
8320	Removes a link with the specified name from the current group node. Raises a ValueError if no link with that name exists. Does not delete the link from disk - use Trajectory.f_delete_links for that functionality.
8321	Adds an empty generic leaf under the current node, allowing flexible trajectory tree structure building. If operating within the standard subtrees (config, parameters, derived_parameters, results), it calls the corresponding adding function. When adding items outside a run group during a single run, manual saving is required as items will be lost after completion.
8322	Removes the current group and all its children recursively or selectively based on predicate.
8323	Removes a child node from the current group in RAM. Can remove leaves or empty groups directly, or remove entire subtrees recursively. Raises TypeError if attempting to remove a non-empty group without recursive=True, or ValueError if the specified child doesn't exist. Note: This only affects RAM memory, not disk storage - use Trajectory.f_delete_items for disk memory cleanup.
8324	Checks if the node contains a specific parameter or result by searching via the `f_get` method. Returns True if the item is found, False otherwise. If an item instance is provided, it also verifies if it's the exact same instance. Supports options for including links, disabling shortcuts, and setting maximum search depth.
8325	Returns the default value if `name` is not found in the trajectory, otherwise returns the result of `f_get`. Handles AttributeError and DataNotInStorageError by returning the default value, but lets other errors propagate. Uses fast access by default.
8326	Returns a children dictionary from the group, with an option to return either a shallow copy or the original dictionary. If copy=True (default), returns a copy of the internal _children dictionary. If copy=False, returns the original _children dictionary directly. The method is intended for internal use, with a warning that the original dictionary should not be modified.
8327	Returns a dictionary of groups hanging immediately below this group. If copy=True (default), returns a shallow copy of the internal _groups dictionary; if copy=False, returns the original dictionary directly.
8328	Returns a dictionary of all leaves hanging immediately below this group. If copy=True (default), returns a shallow copy of the internal `_leaves` dictionary; if copy=False, returns the original dictionary directly. Warning: if copy=False, the returned dictionary should not be modified.
8329	Returns a link dictionary from the group, with an option to return a shallow copy of the original dictionary. If copy=True (default), returns a copy that can be safely modified. If copy=False, returns the original dictionary directly, so modifications should be avoided.
8330	Stores a child or recursively a subtree to disk.

:param name: Name of child to store. If grouped ('groupA.groupB.childC') the path along the way to last node in the chain is stored. Shortcuts are NOT allowed!
:param recursive: Whether recursively all children's children should be stored too.
:param store_data: For how to choose 'store_data' see :ref:`more-on-storing`.
:param max_depth: In case `recursive` is `True`, you can specify the maximum depth to store data relative from current node. Leave `None` if you don't want to limit the depth.
:raises: ValueError if the child does not exist.
8331	Stores a group node to disk with optional recursive storage of children, data selection, and depth limiting.
8332	Loads a child node or recursively loads a subtree from disk with specified loading options and returns the loaded node.
8333	Loads a group from disk with optional recursive loading and data flags. Returns the node itself after loading.
8334	Adds an empty parameter group under the current node with support for named groups, comments, and hierarchical subgroups separated by colons, automatically prefixing the current node's full name to the group name.
8335	Adds a parameter under the current node using either a parameter instance or by passing values directly, with the current node's full name as prefix to the parameter name.
8336	Adds an empty result group under the current node with automatic prefixing and subgroup creation support.
8337	Adds a result under the current node using either a Result instance or by passing values directly, with automatic prefixing of the current node's full name and run index handling.
8338	Adds an empty derived parameter group under the current node with automatic prefixing and subgroup creation support.
8339	Adds a derived parameter under the current group, similar to ParameterGroup.f_add_parameter but with naming prefixes handled by DerivedParameterGroup.f_add_derived_parameter_group.
8340	Adds an empty config group under the current node with automatic parent group creation, using the current node's full name as prefix (or 'config' for root trajectory nodes).
8341	Adds a config parameter under the current group, similar to `f_add_parameter` but with 'config' prefix when the current group is the trajectory.
8342	The `eval_one_max` function serves as a fitness function that evaluates an individual solution by calculating the sum of its elements. It records the individual's genome and fitness score in a trajectory object, then returns the fitness value as a tuple. The function is commonly used in evolutionary algorithms where the goal is to maximize the sum of binary string elements.
8343	Adds commit information to a trajectory by extracting and storing commit metadata including timestamp, SHA-1 hash, commit message, and reference name, while avoiding duplicate entries.
8344	Summary: Creates a git commit with trajectory information, returns whether a new commit was made and the commit SHA. Raises GitDiffError if git_fail is True and there are uncommitted changes.
8345	Flattens a nested dictionary by concatenating nested keys with a specified separator, creating a single-level dictionary where nested structures are represented as dot-notation keys.
8346	Nests a flat dictionary by splitting keys on a given separator to create nested dictionary structure. Takes a flat dictionary and separator string as input, returns a nested dictionary where keys are split and organized hierarchically.
8347	A progress bar visualization function for long loops that automatically handles initialization and reset. It displays a growing progress bar with optional time estimation and supports different logging options including print statements. The function can be used directly inside for-loops without prior setup, automatically restarting when a lower index is provided.
8348	Helper function to extract function arguments and starstar usage information, supporting both Python versions. Returns a tuple of (argument names list, boolean indicating if **kwargs is used) or (empty list, False) for non-functions.
8349	Returns keyword arguments that match the given function's parameter names. If the function uses `*args`, returns all kwargs. Otherwise, returns only kwargs that correspond to the function's defined parameters.
8350	Formats a timestamp into a human-readable string with the pattern 'YYYY_MM_DD_HHhMMmSSs'.
8351	Returns a local TCP address for a given port, automatically determining the port if None is provided. The function resolves the local domain name to get IP address information, handles IPv6 addresses, and uses ZeroMQ to bind to a random available port when no specific port is given. It returns the complete TCP address in the format 'tcp://host:port'.
8352	Creates directories safely while handling race conditions, similar to os.makedirs but with error handling for concurrent directory creation attempts.
8353	Resets the progress bar to start a new one by initializing all necessary tracking variables including start time, indices, total count, length, and normalization factors based on the provided parameters.
8354	Calculates the remaining time as a string based on progress through a process. Takes the current time, determines the time elapsed since start, and estimates remaining time using the current index versus start index and total items. Returns string representation of remaining time or empty string if division by zero occurs. Includes backwards compatibility for Python 2.6 datetime handling.
8355	Returns annotations as a dictionary, with an option to return either a shallow copy or the original dictionary object.

**Parameters:**
- copy (bool): If True, returns a shallow copy of the internal `_dict` attribute; if False, returns the actual `_dict` object

**Returns:**
- dict: Either a copy of the internal annotations dictionary or the original dictionary itself
8356	Removes a specified key from the annotations dictionary after translating it, raising an AttributeError if the key does not exist.
8357	Returns all annotations lexicographically sorted as a concatenated string.
8358	Converts a shared data item into an ordinary one within a result container.

Parameters:
- result: Result container with shared data
- key: Name of the shared data item
- trajectory: Optional trajectory object (needed if shared data lacks trajectory access)
- reload: Boolean indicating whether to reload data after conversion (default: True)

Returns: The modified result container with the shared data converted to ordinary format.

The function retrieves the shared data, assigns the trajectory if provided, requests data conversion, removes the original shared data item, and optionally reloads the data if requested.
8359	Summary: Converts an ordinary data item into a shared data item by replacing it in the result container. It detects the appropriate shared class based on the data type (ObjectTableSharedTable, pd.DataFrameSharedPandasFrame, tuple/listSharedArray, np.ndarray/matrixSharedCArray) and initializes the shared data with the specified trajectory. The original data is removed from the trajectory and the result is returned with the new shared data item.
8360	Creates shared data on disk using a StorageService. Takes keyword arguments that depend on data type (e.g., 'obj' for numpy arrays, 'description' for PyTables). Handles various metadata parameters like flag, trajectory, name, and parent relationships. Returns the result of a data creation request.
8361	Interface with the underlying storage by passing requests to the StorageService for processing, handling operations like table row removal by translating them into storage-specific actions.
8362	Returns the actual node of the underlying data, with a warning if the store is not open. For HDF5, this returns the HDF5 leaf node.
8363	Checks if the given item is supported by the outer data structure, considering both the parent class support and whether the item's type is in the supported data types list.
8364	Creates a shared data item by calling the appropriate function on a data item, optionally using a specified name and additional keyword arguments.
8365	Target function that manipulates trajectory data by storing the current process name and overwriting previous settings, then stores the manipulated data using multiprocessing safe storage service.
8366	Handles locking of locks by checking if a lock is already taken. If the lock is free, it acquires it and returns GO. If the lock is taken by the same client, it logs a warning and returns an error. If the lock is taken by a different client, it returns WAIT to indicate the client should wait.
8367	Sends a shutdown signal to the server to notify it to shut down.
8368	Closes the socket and terminates the context if they exist, otherwise performs no operation.
8369	Starts connection to server if not existent, performs ping-pong test if requested. NO-OP if connection already established.
8370	Method `_req_rep_retry` sends a request and waits for a response with retry logic. It returns the response and number of retries used. If no response is received within timeout, it closes and reopens the socket, then retries up to `RETRIES` times. Raises `RuntimeError` if server is unreachable after all retries.
8371	Acquires a lock by communicating with a lock server, blocking until the lock is available. Returns `True` upon successful lock acquisition. Handles three types of responses from the server: GO (lock acquired), LOCK_ERROR (with retry logic), and WAIT (sleeps and retries). Raises RuntimeError for unexpected responses.
8372	Handles listening requests from the client, processing four types of requests: checking queue space, ping tests, sending data (with queue storage), and connection closure. Returns appropriate responses based on request type and queue status.
8373	Puts data into the queue, blocking until space is available if necessary. If the queue is full, it periodically checks for available space every 10 milliseconds until the data can be added.
8374	Detects if the lock client has been forked by comparing the current process ID with the stored PID. If a fork is detected, it logs the event and restarts the connection by resetting the context and updating the stored PID.
8375	Handles incoming messages for data storage operations, supporting 'DONE' to stop processing or 'STORE' to store data with trajectory management. Returns True when done, False otherwise. Handles exceptions gracefully without stopping the queue process.
8376	Method `run` starts listening to a queue by continuously receiving and handling data messages in a loop until a stop condition is met. It handles cleanup by closing the file and clearing the trajectory name when the loop exits, regardless of how the loop terminates.
8377	Gets data from queue with blocking behavior, marks task as done if supported, and returns the result.
8378	Gets data from pipe by reading chunks into buffer and returning the oldest data.
8379	Acquires a lock before storing data through the storage service and ensures the lock is released afterward, logging any errors that occur during lock release.
8380	Stores a reference to data with metadata in a trajectory-specific list, creating the trajectory list if it doesn't exist.
8381	Stores references to disk and may collect garbage.
8382	A decorator that wraps an environment initialization function to integrate configuration file parsing. It uses a ConfigInterpreter to process configuration data from kwargs, passes the interpreted config data back to the original function, and adds configuration parameters to the environment's trajectory object.
8383	Collects all settings within a specified section by parsing options and their values using ast.literal_eval, returning them as a dictionary.
8384	Collects configuration information from three sections ('storage_service', 'trajectory', 'environment') and returns a dictionary with all the collected settings.
8385	Copies parsed arguments from a configuration file into kwargs, with precedence given to already specified kwargs. If no logging configuration is set and simple logging is not being used, it sets the log_config to the config file path. Returns the updated kwargs.
8386	Adds parameters and config from an INI file to a trajectory object by collecting sections and registering them with the trajectory.
8387	Converts a rule number into its binary list representation for cellular automata rules.

This function takes an integer rule number (0-255) and converts it to an 8-bit binary list where each bit represents the output state for a specific 3-cell neighborhood pattern. The conversion processes the rule number from right to left, with the least significant bit (2^0) on the left side of the list and the most significant bit (2^7) on the right side. Each bit in the resulting list corresponds to a specific neighborhood pattern (000 to 111) in the cellular automata transition table.

For example, convert_rule(30) returns [0, 1, 1, 1, 1, 0, 0, 0], where:
- Neighborhood 000 (0) maps to new state 0
- Neighborhood 001 (1) maps to new state 1
- Neighborhood 010 (2) maps to new state 1
- Neighborhood 011 (3) maps to new state 1
- Neighborhood 100 (4) maps to new state 1
- Neighborhood 101 (5) maps to new state 0
- Neighborhood 110 (6) maps to new state 0
- Neighborhood 111 (7) maps to new state 0

The function supports rule numbers from 0 to 255, corresponding to all possible 8-bit cellular automata rules.
8388	Creates an initial state for a cellular automaton with either a single live cell or a random pattern.

Parameters:
- name: Either 'single' for one live cell in the middle, or 'random' for random pattern
- ncells: Number of cells in the automaton
- seed: Random number seed (default 42) for random initialization

Returns: Numpy array of zeros and ones

Raises: ValueError for unknown name parameter
8389	The `plot_pattern` function creates and saves a visualization of a cellular automaton pattern. It takes four parameters: `pattern` (the automaton data to display), `rule_number` (used for labeling), and `filename` (where to save the image). The function generates a plot with proper axes labels and title, saves it to the specified filename, and then closes the plot to free memory. The plotting functionality is commented out by default, so the plot is not displayed on screen.
8390	Simulates a 1-dimensional cellular automaton by evolving an initial state according to a specified rule. Takes an initial state array, a rule number (0-255), and number of steps to compute. Returns a 2D array showing the automaton's development over time, where each row represents a step and each column represents a cell state (0 or 1). Uses binary rule conversion and neighborhood analysis to determine cell states at each step.
8391	Main simulation function that runs cellular automaton simulations for multiple rules and initial states, saving results to disk and generating plots.
8392	Signals the process timer and emits a message when more time than the display time has passed, showing processed nodes count, elapsed time, and nodes per second rate.
8393	Returns the overview group, creating it if it doesn't exist.
8394	Loads a specified item from disk based on the message type and provided parameters. Supports loading trajectories, parameters, results, groups, subtrees, and lists with various loading options. Handles different loading strategies (nothing, skeleton, data, overwrite) and includes error handling for missing data or unsupported message types.
8395	Stores a particular item to disk based on the message type and provided parameters. Supports various operations such as preparing for merge, merging trajectories, backing up trajectories, storing entire trajectories or individual parameters/results, deleting items, storing groups and trees, managing links, storing multiple items at once, accessing data within the storage, and opening/closing/flushing HDF5 files. The method handles different message types (PREPARE_MERGE, MERGE, BACKUP, TRAJECTORY, SINGLE_RUN, LEAF, DELETE, GROUP, TREE, DELETE_LINK, LIST, ACCESS_DATA, OPEN_FILE, CLOSE_FILE, FLUSH) with specific behaviors for each, and raises NoSuchServiceError for unrecognized messages.
8396	Loads multiple items from an iterable where each item is a tuple containing (msg, item, [args, [kwargs]]), processing each tuple by calling the load method with the appropriate parameters.
8397	Method `_srvc_check_hdf_properties` reads HDF5 storage properties from a trajectory configuration and sets them as attributes on the instance. It handles three types of properties: basic attributes from `HDF5StorageService.ATTR_LIST`, table names mapped via `NAME_TABLE_MAPPING`, and parameter attributes from `PR_ATTR_NAME_MAPPING`. For each property, it attempts to retrieve the value from the trajectory config, falling back to default values if the config values aren't found. It also validates that summary tables are enabled when duplicate comment purging is requested, and initializes the filters attribute to None.
8398	Stores multiple items from an iterable, where each item is a tuple containing (message, item, optional_args, optional_kwargs). If optional arguments are not provided in the tuple, uses the current function's args and kwargs. Raises RuntimeError if more than 4 elements are present in any tuple.
8399	Routine to close an HDF5 file. The file is closed only when `closing=True` and the file is open, ensuring it's not recursively opened and closed. It flushes and syncs the file, handles potential OSError on Windows, closes the store, and resets related attributes. Returns True if closing was successful, False otherwise.
8400	Extracts file information from kwargs dictionary by checking for specific keys ('filename', 'file_title', 'trajectory_name', 'trajectory_index') and storing their values in corresponding instance attributes while removing them from kwargs using pop().
8401	Backs up a trajectory to a specified HDF5 file, creating a backup copy of the trajectory data. If no backup filename is provided, it defaults to creating a backup file in the same directory as the original trajectory file with a 'backup_' prefix. The method checks for existing trajectories with the same name in the backup file to prevent conflicts, then copies the trajectory group to the backup file and flushes the data.
8402	Reads a row from a pytables table and returns a dictionary with column names as keys and row values as values.
8403	Prepares a trajectory for merging by storing extended parameters, updating metadata, and filling run tables with new run information.
8404	Loads metadata from an HDF5 trajectory file, including version checking, skeleton information, and run details. Handles both new and existing trajectories, with options to load run information and explorations. Also loads HDF5 configuration settings.
8405	Loads data along a specified branch of a trajectory tree, recursively traversing nodes up to a maximum depth, while handling HDF5 group navigation and node loading with optional link inclusion.
8406	Checks for version mismatch between loaded trajectory and current pypet version. Raises VersionMismatchError if versions don't match unless force=True, in which case only a warning is emitted.
8407	Fills the `run` overview table with trajectory run information, updating existing entries and adding new ones. Processes runs within a specified range and handles updated run information that hasn't been stored yet. Returns early if no rows need to be processed.
8408	Loads exploration parameter names from HDF5 storage into trajectory's explored parameters dictionary, with backwards compatibility support for older data structures.
8409	Stores all explored parameter names from a trajectory in an HDF5 file table for internal recall, creating the table if it doesn't exist and ensuring consistency with the current exploration data.
8410	Creates overview tables in the overview group with specified table names, setting up appropriate column descriptions and expected row counts based on the table type and trajectory data.
8411	Stores a trajectory to an HDF5 file, including its groups, parameters, and results. Handles initialization, metadata storage, and recursive storage of trajectory branches. Raises an error if attempting to overwrite existing data without explicit permission. Logs storage progress and supports optional depth limitations for recursive storage.
8412	Stores data along a specified branch of a trajectory node tree, recursively handling child nodes up to a maximum depth. It manages HDF5 group mappings and handles cases where parent nodes may not exist on disk, potentially traversing upward from the root to ensure proper storage structure. The method supports configurable storage options including data type, link inclusion, and recursion depth limits.
8413	Creates a new pypet leaf instance from HDF5 data and returns the constructed instance.
8414	Loads nodes from an HDF5 file using depth-first search, recursively handling groups and leaves while managing data loading, links, and trajectory tree construction based on specified parameters.
8415	Stores a node to HDF5 and recursively stores its subtree if desired. Handles both regular nodes and linked nodes, creating HDF5 groups and storing parameter/result data accordingly. Supports depth limiting and configurable storage options.
8416	Stores a single row into an overview table based on the specified flags, handling add, remove, or modify operations while extracting necessary information from the instance and additional info dictionary.
8417	Creates a new HDF5 table in the specified location or returns it if it already exists. If the table doesn't exist, it's created with the given description and optional expected rows. If it already exists, the existing table is returned. Uses the file's filter settings for table creation.
8418	Returns an HDF5 node by the path specified in `name` by constructing the full path using the trajectory name and replacing dots with forward slashes.
8419	Stores original data type information as HDF5 node attributes to preserve data types during storage, handling various container types (tuple, list, ndarray, matrix, dict) and scalar types with appropriate type identification and error handling.
8420	Checks if loaded data has the same type as when it was stored in HDF5. If not, converts the data back to its original type. Handles scalars, lists, tuples, empty dictionaries, and matrices. Returns the (converted) data and a boolean indicating whether conversion occurred.
8421	Adds or modifies a row in a PyTables dataset based on specified flags, index, or condition. Supports adding new rows, modifying existing rows, or removing rows. Raises errors for invalid flag combinations or failed operations.
8422	Copies data from `insert_dict` into a pytables `row`, with error handling for keys that cannot be written to the table.
8423	Extracts information from an item to be stored into a pytable row, populating a dictionary with data based on specified column names. Handles various item types like trajectories, runs, and parameters, and includes logic for string length limitations and encoding. Returns a dictionary containing the data to be inserted into a row.
8424	Cuts a string to a maximum length if it exceeds the limit, logging a debug message when truncation occurs. Returns the truncated string with '...' appended if truncation was necessary.
8425	Creates or returns a group with the specified name under the given parent HDF5 group. If the group doesn't exist, it creates a new one with the specified filters and returns the new group along with True. If the group already exists, it returns the existing group along with False.
8426	Creates or follows existing HDF5 group nodes along a colon-separated key path, starting from either the trajectory group or a specified start group. Returns the final group node and a boolean indicating if any groups were created during the process.
8427	Stores annotations into an HDF5 file, with optional overwrite functionality. If overwrite is enabled, removes existing annotations before storing new ones. Only stores new annotations that don't already exist in the HDF5 node attributes, and marks the node as annotated if changes were made.
8428	Loads annotations from HDF5 disk storage into memory, but only if the annotations container is empty to prevent data overwriting. It reads annotation attributes from the HDF5 node and sets them on the annotations object.
8429	Stores a group node in HDF5 format, handling annotations, comments, and class information based on storage configuration. For recursive storage, it traverses the group tree using depth-first search. Supports overwriting existing data and manages node processing signals.
8430	Loads a group node and potentially all its contents recursively below, handling data loading, skeleton loading, and tree traversal based on specified parameters and load conditions.
8431	Reloads skeleton data of a tree node by loading annotations if empty and setting comment from HDF5 attributes if not already present.
8432	Extracts storage flags for data in `data_dict` if they were not specified in `flags_dict`, using default type mappings from `HDF5StorageService.TYPE_FLAG_MAPPING`. Handles special cases for empty numpy arrays and dictionaries by flagging them as `ARRAY`, and raises `NoSuchServiceError` for unsupported data types.
8433	Adds data to summary tables and determines if an instance's comment should be stored in its HDF5 node. Returns a tuple of (subtree string, boolean for comment storage). Checks for duplicate comments using SHA1 hashing and only stores new comments, handling cases where the overview table doesn't exist or other errors occur.
8434	Adds meta information and overview table entries to an HDF5 group for a given instance, including comment, class name, and leaf status, while handling duplicate comment policies and explored parameters.
8435	Stores data from a dictionary into an HDF5 group based on specified storage flags, handling nested groups and various data types including tables, arrays, and pandas data structures.
8436	Stores a parameter or result to HDF5, handling various storage options, overwrite rules, and error recovery. It manages the creation of HDF5 groups, extracts storage flags, and ensures proper cleanup on failure.
8437	Writes data to an HDF5 file by creating arrays of various types (regular array or specialized array types) based on the provided flag, then flushes the file.
8438	Creates a new empty HDF5 table with specified description and filters, and optionally populates it with a first row of data.
8439	Stores a Python dictionary as a pytable in HDF5 format by converting it to an ObjectTable and writing it to the specified group, while preserving dictionary attributes and marking it with the appropriate storage type.
8440	Stores a pandas DataFrame into hdf5 format with specified parameters and handles overwrite/append flags.
8441	Stores data as carray, earray or vlarray in HDF5 file depending on the specified flag, with error handling and type attribute recording for recall.
8442	Stores data as an array in HDF5 file group with type handling and error logging.
8443	Removes a link from disk by translating the link name to an HDF5 path and deleting the corresponding node.
8444	Removes a parameter, result, or group from the HDF5 file. Can delete entire groups (with optional recursion) or specific items from leaf nodes. When using `delete_only`, individual sub-nodes can be removed from leaf nodes, and optionally also from the corresponding instance object. Raises errors if attempting to remove non-empty groups without `recursive=True` or if `delete_only` is used on non-leaf nodes. Handles cases where HDF5 nodes are not found during deletion.
8445	Stores data into PyTables format, creating one or more tables in an HDF5 file. Handles large datasets by splitting them into multiple tables when exceeding maximum column limits, and stores original data types as attributes for accurate data retrieval.
8446	Returns a description dictionary for pytables table creation, converting lists and tuples to numpy arrays and remembering original data types.
8447	Creates a PyTables column instance based on the data type of the first element in the column array, handling different types including integers, strings, bytes, and numpy arrays with appropriate column types and properties.
8448	Returns the maximum string length found in a list of string entries, multiplied by 1.5 to provide buffer room for slightly larger strings. Handles both regular strings and numpy arrays of strings.
8449	Loads data from an HDF5 group into a dictionary based on specified loading criteria and data types. Recursively processes nested groups and handles different data types (dictionary, table, array, pandas DataFrame/Series, shared data) by calling appropriate read methods. Supports filtering through `load_only` and `load_except` parameters and uses `load_flags` to override storage types. Raises errors for unsupported data types or loading failures.
8450	Loads dictionary data from a PyTables leaf node by reading it as a table, converting to dictionary format, and returning the unpacked dictionary with single-element list values. Logs errors if loading fails.
8451	Reads shared data from an HDF5 node and constructs the appropriate class instance based on data type mapping. Returns the constructed object or raises an error if loading fails.
8452	Reads a non-nested PyTables table column by column and creates a new ObjectTable for the loaded data, handling data type conversion and structured tables with separate data type information.
8453	Reads data from a PyTables array or carray, restores original data types, and returns the loaded data while logging errors if the operation fails.
8454	Helper function that creates a new trajectory and loads it from disk. It accepts various parameters to control what data to load and how to handle the loading process. The function requires either a name or index to identify the trajectory to load, and creates a new trajectory with optional renaming and time addition if as_new is True. The actual loading is delegated to the Trajectory.f_load method.
8455	Creates a run set name based on the given index by dividing it by GROUPSIZE (1000) and formatting the result, or returns a dummy name if the index is negative.
8456	Sets object properties with validation, prefixing property names with 'v_' if not already prefixed. Raises AttributeError for non-existent properties.
8457	Adds classes or paths to classes to the trajectory to create custom parameters, accepting either a single item or list of classes/strings representing module paths.
8458	Sets the trajectory to behave as during a particular single run for easier data analysis, configuring v_idx/v_crun and explored parameters to the specified run index/name.
8459	Method `f_iter_runs` creates an iterator that traverses all runs in a trajectory. It accepts parameters for start index, stop index, step size, and what to yield (run name, index, self, or copy). The method temporarily sets the current run during iteration and resets it to None after completion. It supports yielding run names, indices, the trajectory itself, or shallow copies of the trajectory. The iteration follows the specified range parameters and raises a ValueError if stop exceeds trajectory length. The method returns an iterator that modifies the trajectory state during iteration but restores it to normal after completion.
8460	Shrinks the trajectory by removing all exploration ranges from parameters and resetting run information. Raises TypeError if trajectory is already stored to disk unless force=True is specified. Removes all explored parameters and resets trajectory length to 1.
8461	Generic preset function that marks a parameter or config for presetting by storing its arguments and keyword arguments in a dictionary of changed default parameters, but raises an error if the parameter already exists in the trajectory.
8462	**Summary:**

`f_preset_parameter` presets parameter values before parameters are added to a trajectory. It allows users to set parameter values that will be applied when the parameter is created, by storing the provided arguments and keyword arguments for later use during parameter creation. The method ensures the parameter name follows the required 'parameters.' prefix format and delegates the actual presetting to the internal `_preset` method. This functionality enables users to pre-configure parameter values before they are formally added to the trajectory, with a validation check ensuring all preset parameters are properly configured before experiment execution.
8463	Method `_prepare_experiment` is called by the environment to perform initial configurations before running experiments. It first checks if all parameters marked for presetting were actually preset, raising a `PresettingError` if any were missing. Then it locks all parameters and their derived parameters. The method also removes potential results from previous runs to prevent mixing up undesired shortcuts when the trajectory is expanded. This ensures clean experiment execution with properly configured and locked parameters.
8464	Method `f_get_from_runs` searches for all occurrences of a specified name pattern across all runs in a trajectory, returning an ordered dictionary with run names or indices as keys and found items as values. It supports various options such as including default runs, using indices as keys, fast access to values, handling links, enabling shortcuts for path searching, setting maximum search depth, and auto-loading data from storage. The method iterates through run parent groups, attempts to retrieve the specified item from each run, and handles cases where items are not found or are duplicated within a run. The current run state is preserved during execution.
8465	Checks if runs are completed. If no name_or_id provided, returns True if all runs are completed. If name_or_id provided, returns True if the specific run is completed.
8466	Removes all explored parameters from disk storage when a trajectory is expanded, logging any deletion errors that occur.
8467	Copies a node and its subtree from another tree into the current trajectory, with options for copying leaves (shallow or by reference), overwriting existing elements, and handling links. Returns the corresponding new node in the current tree.
8468	Prepares a trajectory for exploring the parameter space by adding exploration ranges to specified parameters. Raises errors if parameters are invalid, not unlocked, or if exploration iterables have inconsistent lengths. Supports consecutive calls for adding multiple parameter explorations and handles cleanup on errors.
8469	Updates the run information for a specific run by overwriting existing information based on the provided dictionary, and tracks the updated run by its index.
8470	Adds a new run to the `_run_information` dictionary with the specified parameters, updating the bidirectional `_single_run_ids` mapping and setting the object's length accordingly. If a run with the given index already exists, it removes the old entries before adding the new one.
8471	Locks all non-empty parameters in the object's _parameters dictionary by calling f_lock() on each non-empty parameter.
8472	Locks all non-empty derived parameters by iterating through them and calling f_lock() on each one that is not empty.
8473	Finalizes the trajectory by restoring it as the root of the tree and storing metadata to disk, updating completion status and timestamps.
8474	Loads the full skeleton from storage service with empty results and derived parameters, and loads annotations only.
8475	Loads a trajectory from storage using the specified parameters and loading options. Supports loading by name or index, loading as new trajectories, and various data loading strategies. Can force loading of incompatible versions and handle dynamic imports. Returns the loaded trajectory with appropriate settings applied.
8476	Backs up the trajectory using the specified storage service, passing through any additional arguments to the storage service for configuration.
8477	Creates a mapping from wildcard translations to their corresponding wildcards and indices.
8478	Merges multiple trajectories into the current trajectory by sequentially merging each trajectory from the `other_trajectories` list. It loads the skeleton of the current trajectory, creates a backup if requested, and then iteratively merges each trajectory while logging progress. After all merges are complete, it stores the final combined trajectory to disk. The method supports various options for handling data movement, configuration merging, and information preservation, but note that backup only applies to the current trajectory, not the others being merged.
8479	Merges run information from another trajectory into the current trajectory, updating run indices and creating new run names while preserving run metadata such as timestamps, completion status, and runtime information.
8480	Renames a full name by replacing wildcards with actual values from a trajectory based on run indices. Takes a full name string, another trajectory object, and optional used runs and new run index parameters. Splits the full name by dots, checks each component against the trajectory's reversed wildcards, and substitutes matching wildcards with formatted values using a wildcard formatting function. Returns the renamed full name string.
8481	Merges derived parameters with `run_ALL` in their name from another trajectory, creating new parameters linked to a first run to avoid duplication across runs. It handles renaming, linking, and ignores parameters specified in `ignore_data`, while also checking for parameter value equality and range conflicts.
8482	Merges all links from another trajectory into this trajectory, respecting allowed translations and ignoring specified data. It handles renaming of full names, checks for valid link paths, and adds links to the appropriate items, logging warnings and errors as necessary.
8483	Merges metadata about previous merges, git commits, and environment settings from another trajectory into the current one, including git commit metadata, environment configuration, and merge history.
8484	Merges trajectories by iteratively loading items from another trajectory and storing them in the current trajectory, using a rename dictionary to map result names. For each item, it checks if the item already exists in the current trajectory, creates a new instance if needed, loads the data from the other trajectory item, copies annotations and comments, and manages memory by emptying loaded instances.
8485	Merges results from another trajectory into the current trajectory, handling name renaming and filtering based on various conditions. It processes each result from the other trajectory, skips ignored data, checks for wildcard translations, generates new names, and warns if duplicate results are found. The method updates a rename dictionary mapping original names to new names and maintains a set of used runs.
8486	Method `f_migrate` is used to rename and relocate a trajectory by updating its name, storage service, and file location. It accepts parameters for specifying a new name, indicating if the trajectory is already stored in the new location, and defining a new storage service. Additional keyword arguments can be passed to the storage service for further configuration. The method updates the trajectory's metadata and validates that all provided keyword arguments are used, raising an error if any are unused. Finally, it marks the trajectory as stored if the `in_store` flag is set to True.
8487	Stores the trajectory to disk, recursively saving all data in the tree. It supports different storage modes (e.g., storing only initialization data, skipping already stored data, or overwriting existing data) and handles special behavior during single runs by storing only sub-trees under `run_XXXXXXXXXX` groups. The `max_depth` parameter limits how deep the tree is stored. For individual parameters or results, use `f_store_items` or `f_store_child` after initial storage.
8488	Restores default values for all explored parameters and resets the internal state by setting `_idx` to -1 and `_crun` to None.
8489	Sets the explored parameters to represent the current point in the parameter space by notifying each parameter to access the specified index.
8490	Sets up trajectory modifications for single runs by initializing run flags and data structures, then returns self for chaining.
8491	Returns a list of run names, optionally sorted using bucket sort for efficiency. When sorting is enabled, it returns run names in order by index, otherwise returns all available run names from the internal run information dictionary.
8492	Returns information about one or all runs in the trajectory. If name_or_idx is None, returns a nested dictionary with run names as keys and info dictionaries as values. Otherwise, returns the info dictionary for the specified run. The info dictionary contains keys like 'completed', 'idx', 'timestamp', 'time', 'finish_timestamp', 'runtime', 'name', 'parameter_summary', and 'short_environment_hexsha'. If copy=True (default), returns a copy of the dictionary to prevent modifications to the original trajectory data.
8493	Finds indices of runs matching a predicate condition on specified parameters. Raises TypeError if used during single multiprocessing run without v_full_copy=True. Takes parameter names (as list or single string) and a lambda predicate, returns generator of matching run indices. Parameter names must reference actual parameters with ranges or single values. Creates iterators for each parameter's values and maps the predicate across them to find matches.
8494	Starts a run manually for an experiment. Sets the trajectory to a specific run if specified, marks the run as started, optionally converts the trajectory into a more efficient run format, and records the start time. Returns the instance for chaining operations.
8495	Method `f_finalize_run` is used to manually finish a run that was started manually. It sets the finish timestamp, optionally cleans up run data if `turn_into_run` was set to `True`, resets run flags, and updates run information. If `store_meta_data` is True, it stores initialization data. The method does NOT reset the run index (requires manual `f_restore_default` call) and does NOT automatically store run data (requires manual `f_store` call). Returns self for method chaining.
8496	Sets the start timestamp and formatted time to the current time, and stores them in the run information dictionary along with environment hexsha if available.
8497	Sets the finish time and computes the runtime in human readable format by calculating the difference between start and finish timestamps, then stores this information along with parameter summary in the run information dictionary.
8498	Creates a new node using the provided constructor, checking if the node needs trajectory information. If the constructor has the 'KNOWS_TRAJECTORY' attribute set to True, it passes the current instance as the trajectory parameter to the constructor; otherwise, it calls the constructor without the trajectory parameter.
8499	Returns a dictionary containing parameters, config, derived parameters, or results based on access parameters. Raises ValueError if copy=False and fast_access=True. When fast_access is False, returns either a copy or original dictionary. When fast_access is True, returns a new dictionary with values retrieved using f_get() method.
8500	Finalizes a run by marking it as completed and cleaning up newly created links and nodes through removal operations.
8501	Returns a dictionary containing full config names as keys and config parameters or data items as values. The method allows controlling whether to return parameter objects or their values (fast_access parameter), and whether to return a copy of the original dictionary (copy parameter). Raises ValueError if fast_access is True and copy is False.
8502	Returns a dictionary containing full result names as keys and corresponding result objects or data items as values. The method allows for fast access to result values instead of objects, and optionally returns a shallow copy of the results dictionary. Raises ValueError if fast access is requested without copying.
8503	Stores individual items to disk from an iterable, useful for managing large results during runtime. It supports optional filtering of non-empty items and allows overwriting specific parts of stored data in HDF5 format. Raises TypeError if trajectory hasn't been stored yet, or ValueError if no items are found to store.
8504	Loads parameters and results from disk into a trajectory. Takes an iterator of items to load, optional arguments to filter empty items only, and additional keyword arguments for partial loading (load_only, load_except). Checks if the trajectory has been stored before attempting to load. Uses the storage service to actually perform the loading operation after fetching valid items through the neural network interface. Raises TypeError if the trajectory has never been stored.
8505	Removes specified parameters, results, or groups from the trajectory. This function only removes items from the current trajectory without deleting data from disk. It can optionally remove child items recursively if removing group nodes. The function takes an iterator of items (either instances or names) and a recursive flag to determine if child items should also be removed. If no items are found to remove, it logs a warning message.
8506	Deletes multiple links from disk storage, supporting both string and tuple formatted link specifications. Can optionally remove links from trajectory structure after deletion.
8507	Removes all children of the trajectory recursively. Raises ValueError if recursive=False. Uses optional predicate to determine which nodes to remove.
8508	Deletes items from disk storage, with options to remove from trajectory and handle recursive deletion. Supports partial deletion for HDF5 files and can remove data from items themselves. Returns warning if no items are found for removal.
8509	Initializes a single run in a pool and passes the storage service, handling different wrap modes and freeing references when necessary.
8510	Single run wrapper for frozen pool that updates job arguments and executes a single run with signal interruption handling.
8511	Configures a worker pool by setting up the storage service, niceness level, and logging settings.
8512	Configures a frozen pool by storing all keyword arguments, setting up niceness and logging preferences, and restoring a full trajectory copy to its original value.
8513	Wrapper function that configures logging, executes a single run with signal interruption handling, and puts the result in a queue.
8514	Wrapper function that configures a frozen SCOOP setup by deleting old data if necessary, checking if reconfiguration is needed, and setting up frozen SCOOP parameters including logging and niceness configuration.
8515	Wrapper function for scoop that handles single run execution without logging configuration, including origin process checking and error handling.
8516	Configures logging system using the logging manager from kwargs. Extracts naming data from trajectory if extract=True, then sets up logging handlers and tools with multiprocessing support. Catches and reports any configuration errors to stderr.
8517	Sets the niceness (priority) of a process. First tries to use os.nice() to adjust the process priority, with a fallback to psutil on Windows systems. Handles exceptions gracefully by writing error messages to stderr.
8518	Wrapper that allows graceful exits during single runs by handling SIGINT signals and logging exceptions during execution.
8519	Performs a single experiment run with the provided parameters, executes the user's job function, handles automatic storage if enabled, and returns the results along with run information.
8520	Starts running a queue handler and creates a log file for the queue, with optional graceful exit handling.
8521	Loads a class from a string naming the module and class name, for example 'pypet.brian.parameter.BrianParameter' returns the BrianParameter class.
8522	Dynamically creates a class by first checking if it exists in the global namespace, and if not, searching through dynamically imported classes. It supports both direct class instances and import string specifications, raising ImportError if the class cannot be created.
8523	Returns the length of the parameter range, raising TypeError if the parameter has no range or NotImplementedError if __len__ is not implemented.
8524	Returns a string representation of the parameter's value by calling `__repr__` on the contained value, without locking the parameter or counting as usage. If evaluation fails, returns 'No Evaluation possible (yet)!'. Restores the original lock state in the finally block.
8525	Checks if two parameter values are equal using nested_equal comparison, handling type support validation and raising TypeError for unsupported types.
8526	Returns a python iterable containing the exploration range.

:param copy: If the range should be copied before handed over to avoid tempering with data
:raises: TypeError: If parameter is not explored.
:Example usage:

>>> param = Parameter('groupA.groupB.myparam',data=22, comment='I am a neat example')
>>> param._explore([42,43,43])
>>> param.f_get_range()
(42,43,44)
8527	Explores a parameter by iterating over an iterable to define its exploration range. Raises ParameterLockedException if the parameter is locked, or TypeError if the parameter already has a range, has no default value, or contains incompatible data types. Stores the exploration range in memory as a tuple and locks the parameter after exploration.
8528	Expands a parameter's exploration range by appending data from an iterable. Raises ParameterLockedException if parameter is locked, or TypeError if parameter is not an array or data types are incompatible. Stores the entire exploration range in memory as a tuple.
8529	Checks if data values are valid by verifying they are supported types and of the same type as the default value, then returns a list of valid data values. Raises TypeError for unsupported types or type mismatches, and ValueError for empty lists.
8530	Returns a dictionary containing formatted data for storage service, with data in 'data' table and exploration range in 'explored_data' table if parameter is explored.
8531	Loads data and exploration range from a load dictionary, handling locked parameters and logging warnings for empty parameters.
8532	Reconstructs data and exploration array from load_dict, handling locked parameters and exploration ranges, with fallback to parent class loading.
8533	Matrices are considered equal if they hash to the same value. The method first checks if both inputs are supported matrices. If so, it serializes both matrices and compares their hash values. If either input is not a supported matrix, it falls back to the parent class's equality comparison method.
8534	Checks if the input data is a supported sparse matrix format (csr, csc, bsr, or dia) and returns True if it is, False otherwise.
8535	Serializes a sparse matrix into a human-readable format by extracting necessary attributes for reconstruction. Returns a tuple containing: 1) a list of matrix data (format, data, indices, indptr, shape for CSR/CSC/BSR; format, data, offsets, shape for DIA), 2) names of the extracted attributes, and 3) a hashable tuple of the serialized data. Handles empty matrices and converts numpy arrays to read-only for hashing.
8536	Formats a name for storage by creating a tuple of names with the format 'explored{IDENTIFIER}.set_{index:05d}.xspm_{property}_{index:08d}' where the property refers to each name in the name list and the sparse matrix index is derived from name_idx.
8537	Reconstructs a sparse matrix from a serialized list of matrix properties, supporting formats 'csc', 'csr', 'bsr', and 'dia'. Takes a data_list formatted as output by SparseParameter._serialize_matrix and returns the corresponding scipy sparse matrix. Handles both empty matrices and regular matrices with appropriate shape and data reconstruction based on the matrix format. Raises RuntimeError for unsupported matrix formats.
8538	Reconstructs a sparse parameter from a load dictionary by restoring the data array and exploration range, handling both diagonal and general matrix formats, and managing parameter locking and exploration state restoration.
8539	Returns a dictionary for storage that pickle-dumps most elements except 'explored_data'. The 'explored_data' contains references to objects to recall their order later. Object reuse is identified by Python's built-in id function. The method sets self._locked to True before returning the store dictionary.
8540	Reconstructs objects from pickle dumps in `load_dict`, restoring exploration range and setting the `v_protocol` property. Raises `ParameterLockedException` if the parameter is locked. Handles backwards compatibility for protocol detection and logs warning if no data is found.
8541	Translates integer indices into named indices by appending the integer (except for 0, which returns the base name).
8542	Summarizes the data handled by the result as a string by calling `__repr__` on all data entries, truncating the result if it exceeds `HDF5_STRCOL_MAX_VALUE_LENGTH` and removing the trailing comma and space.
8543	Returns all handled data as a dictionary, with an option to return a shallow copy of the original dictionary.
8544	Method to store data in the result with positional arguments stored under names 'name_X' and keyword arguments stored under their respective keys. Raises TypeError if outer data structure is not understood.
8545	Returns items from the result based on given names/indices. If no arguments provided, returns the single data item if only one exists, otherwise raises ValueError. If arguments are provided, returns the corresponding data items as a single item (if one argument) or list (if multiple arguments). Raises AttributeError if requested items don't exist.
8546	Sets a single data item in the result with type checking. Raises TypeError if the item type is not supported. Logs debug messages when replacing existing items or modifying stored results.
8547	Supports everything from the parent class plus csr, csc, bsr, and dia sparse matrices.
8548	Returns a storage dictionary for the sparse result, extracting sparse matrices similar to SparseParameter and marking them with `__spsp__` identifier. Non-sparse data is stored directly.
8549	Loads data from a dictionary, reconstructing sparse matrices similar to SparseParameter class by processing keys containing SparseResult.IDENTIFIER, extracting matrix data, and storing the reconstructed matrices in self._data.
8550	Adds a single data item to the pickle result with the specified name, storing it in internal data dictionary. Raises AttributeError if attempting to name an entry 'protocol'. Issues debug warning if modifying already stored result without explicit disk overwrite.
8551	Returns a dictionary containing pickle dumps of all items in self._data, along with the protocol version.
8552	Method `_load` reconstructs items from pickle dumps stored in a dictionary. It extracts the pickle protocol from the dictionary (or infers it for backwards compatibility) and stores it in `v_protocol`. Then it iterates through the dictionary, loads each pickle dump using `pickle.loads()`, and stores the reconstructed objects in `self._data` with their corresponding keys.
8553	Merges all trajectories in the current working directory into a single file, keeping only one trajectory while deleting other files, with dynamic imports enabled and no backup created.
8554	Uploads a file to a remote SFTP server using the specified session and target directory.
8555	Downloads a file from an SFTP server to the local working directory using a provided session. The function constructs the source path using a predefined ADDRESS and WORKING_DIR, copies the file from the remote location to the current working directory, and prints confirmation messages before and after the transfer.
8556	Creates and returns a new SAGA session with authentication context using USER and PASSWORD credentials.
8557	Merges all trajectories found in the working directory by creating and running a SAGA job that executes the 'merge_trajs.py' script, then waits for the job to complete and prints job status information.
8558	Starts all jobs and runs `the_task.py` in batches using SAGA job service. Creates 3 batches, each running the task with different batch arguments, and waits for all jobs to complete.
8559	Function `multiply` performs sophisticated multiplication simulation by multiplying `traj.x` and `traj.y`, then stores the result as 'z' with a descriptive comment using `traj.f_add_result`.
8560	Runs a simulation of a model neuron using Euler integration to calculate membrane potential over time, records action potentials during the refractory period, and returns the estimated firing rate in Hz.
8561	**Summary:**

The `neuron_postproc` function performs postprocessing on neuron simulation results by organizing computed firing rates into a pandas DataFrame table. It takes a trajectory object containing parameters and a list of tuples containing run indices and corresponding firing rate results. The function extracts parameter ranges for input current (I) and refractory time (tau_ref), creates a DataFrame indexed by these parameters, and populates it with firing rates from the results. Finally, it stores the resulting DataFrame back into the trajectory object under the key 'summary.firing_rates' with a descriptive comment. The function leverages pandas' indexing capabilities to directly map parameter values to their corresponding firing rates in a clean tabular format.
8562	Adds all parameters to `traj` including neuron parameters (V_init, I, tau_V, tau_ref) and simulation parameters (duration, dt) with their respective comments and default values.
8563	Adds exploration of `I` and `tau_ref` parameters by creating a cartesian product of their values and applying them to the trajectory object.
8564	Executes a network simulation before the actual experiment by running subruns with specified durations extracted from the trajectory. Takes a trajectory, BRIAN2 network, shared network dictionary, and lists of network components and analysers as parameters. The method retrieves subrun durations from `traj.parameters.simulation.pre_durations` and executes them in order determined by their `v_annotations.order` attributes. Requires at least one subrun and throws AttributeError if none found, or RuntimeError if multiple subruns have equal order properties. Calls `_execute_network_run` internally with `pre_run=True` flag.
8565	Executes a BRIAN2 network simulation by running it through multiple subruns defined in the trajectory. Each subrun involves adding components and analysers to the network, running the simulation for a specified duration, analysing results, and then cleaning up by removing components and analysers. The method handles the complete lifecycle of a network run including setup, execution, and teardown phases for each subrun, with the ability to modify the execution order or cancel remaining subruns based on analysis results.
8566	Extracts subruns from a trajectory by iterating through duration parameters, validating unique orders, and returning subruns sorted by order. Raises RuntimeError for duplicate or missing orders.
8567	Executes a network run by processing subruns in order, handling component and analyzer operations, and managing network simulation with logging and reporting.
8568	Adds parameters for a network simulation by calling the add_parameters method on all components, analyzers, and the network runner in sequence.
8569	Starts a network run before individual runs for shared initial simulation. Calls pre_build, creates a new BRIAN2 network, executes pre-run through NetworkRunner, and stores the network state.
8570	Top-level simulation function that performs individual network runs during parameter exploration. Creates a new BRIAN2 network if needed and executes the network run through NetworkRunner. Handles pre-built and pre-run network states, including restoration from stored states when applicable. Takes a trajectory container as parameter and is designed to be passed to an Environment for automated execution during experimental runs.
8571	Runs a single network simulation experiment by building the network, executing the run, and logging success message.
8572	Creates a filename based on explored trajectory parameters by concatenating parameter names and their values, then appends a '.png' extension.
8573	Returns the next element from a chain of iterators, advancing through empty iterators as needed. Raises StopIteration when no elements remain.
8574	Merges all files with a specified extension in a given folder into a single trajectory, using the last trajectory from each file. Files are processed in alphabetical order, with the first file's trajectory serving as the base for the merge. Additional parameters control data handling, file deletion, and merging options. Returns the merged trajectory object.
8575	Handler for SIGINT signal that allows graceful exit on first interrupt but raises KeyboardInterrupt on second interrupt. On first SIGINT, it sets a flag and writes a graceful exit message to stderr. On second SIGINT, it raises KeyboardInterrupt with an immediate exit prompt.
8576	Function that manages configuration files: writes configuration data to a file when config parameter is provided, or reads and returns configuration data from a file when config parameter is None/False. Returns True on successful write, True on successful read, False on read errors, and empty dict {} when file doesn't exist.
8577	Method to request a PIN from ecobee for application authorization. Sends a GET request to ecobee's authorization endpoint with required parameters (response_type, client_id, scope). On successful request, extracts and stores the authorization code and PIN from the JSON response. Logs instructions for the user to authorize the application through the ecobee portal website. Returns None if request fails due to connectivity issues.
8578	Method to request API tokens from ecobee using authorization code. Sends POST request to ecobee token endpoint with grant_type, authorization code, and client ID. If successful, stores access token, refresh token, and clears PIN. If request fails or returns error status code, logs warning message. Returns None on success or failure.
8579	Method to refresh API tokens from ecobee by sending a POST request with refresh token and client ID. If successful, updates access and refresh tokens and writes them to file, returning True. If unsuccessful, calls request_pin method.
8580	Get thermostats data from Ecobee API and store in self.thermostats. Handles authentication and token refreshing if needed. Returns the thermostats list or None on failure.
8581	Write API tokens to a file by creating a configuration dictionary containing all token values and either saving to a file or storing in instance variable based on configuration settings.
8582	Sets the HVAC mode for a specific thermostat device.

Parameters:
- index (int): The index of the thermostat in the thermostats list
- hvac_mode (str): The desired HVAC mode (auto, auxHeatOnly, cool, heat, off)

Returns:
- The result of the API request to update the thermostat settings

The method constructs a request body with the specified thermostat identifier and HVAC mode setting, then makes the request through the make_request method.
8583	Sets the minimum fan on time for a thermostat.
8584	Set a temperature hold on a thermostat with specified cooling and heating temperatures, along with hold type.
8585	Sets a climate hold (away, home, sleep) for a specific thermostat by creating a request with the specified hold type and climate reference.
8586	Delete a vacation with the specified name from the thermostat at the given index.
8587	Resume a scheduled program for a specific thermostat.

This method sends a request to resume a currently scheduled program for a thermostat at the given index. It can either resume just the specified program or all programs if resume_all is set to True.

Parameters:
- index (int): The index of the thermostat in the thermostats list
- resume_all (bool): If True, resumes all programs; if False, resumes only the specified program

Returns:
The result of the make_request call which typically contains the response from the thermostat API

Example usage:
- resume_program(0) - resumes the program for the first thermostat
- resume_program(0, resume_all=True) - resumes all programs for the first thermostat
8588	Send a message to a specified thermostat by index.
8589	Set the humidity level for a specific thermostat by index.
8590	Generate a random delay between 0 and MAX_DELAY_SELECTING seconds for DHCP discovery, with logging of the delay and scheduled time.
8591	Generate DHCPDISCOVER retransmission timeout with exponential backoff and randomization.

This function calculates the delay (in seconds) before retransmitting a DHCPDISCOVER message, following RFC 2131 guidelines. It uses exponential backoff starting at 2 seconds, doubling with each attempt up to a maximum of 64 seconds, with uniform randomization of 1 second applied to each timeout value. The timeout values follow the pattern: 2^attempts+1  random_uniform(-1, +1), where attempts is the number of retransmission attempts made so far. The function logs the next timeout timestamp and returns the calculated timeout value.
8592	Generate timeout duration for DHCPREQUEST retransmission during lease renewal, waiting half the remaining time until T2 down to minimum 60 seconds.
8593	Generate RENEWING time according to RFC 2131 section 4.4.5, calculating T1 timeout with random fuzz factor to avoid client synchronization, with elapsed time subtraction and debug logging.
8594	Return the object's own attributes (not inherited) as a dictionary, filtering only those keys that exist in FSM_ATTRS.
8595	Reset object attributes when state is INIT, including setting up DHCP client with interface, client MAC address, and XID, loading script if provided, and initializing various state variables and counters.
8596	Returns the timeout value for a given state and function by searching through timeout definitions. Takes a state and function as input, converts the state to its name, then iterates through timeout definitions to find a matching function condition name. Returns the corresponding timeout value if found, otherwise returns None.
8597	Sets a new timeout value for a specific state and function in the ATMT.timeout class method, modifying the timeout configuration in place.
8598	Send a DHCP discover packet and set timeout for response handling.
8599	Selects an offer from received offers by choosing the first one, following DHCP client implementation guidelines.
8600	Send a DHCPREQUEST message based on the current state, update request attempts and timeouts accordingly.
8601	Sets renewal and rebinding timeouts for the current state using the client's lease times.
8602	Process a received DHCP ACK packet by handling the ACK with the client handler, logging the ACK information, and returning True if successful. If an address format error occurs, log the error and transition to SELECTING state. The method does not currently implement ARP probing for the offered IP address.
8603	Process a received NAK packet and return True if it's a valid NAK, False otherwise.
8604	INIT state implementation that waits 1-10 seconds delay for DHCP startup desynchronization, resets variables if needed, and sets up timeout configurations for subsequent state transitions.
8605	BOUND state handler that logs state transition, updates client lease information, and executes scripting or network configuration.
8606	**Method Summary:**

**RENEWING(self)**
Handles the DHCP lease renewal state. Logs the state entry, updates the current state to RENEWING, and executes either a script if available or directly sets up network configuration using the current lease information.

**Key Operations:**
- Logs debug information about entering RENEWING state
- Updates internal state tracking to STATE_RENEWING
- Executes script initialization and execution if script exists
- Falls back to direct network configuration setup using set_net() if no script is available

**Parameters:**
- self: Instance reference to the current object

**Side Effects:**
- Updates state machine to RENEWING
- May execute external scripts or configure network settings
- Logs debug messages for state transition
8607	**Method Summary:**

`REBINDING()` - Handles the rebinding state in DHCP client operations. This method logs the state entry, updates the current state to REBINDING, and executes either a script initialization and execution if a script is available, or directly sets up network configuration using the current lease information.

**Key Operations:**
- Logs state entry with debug level
- Sets current state to STATE_REBINDING
- Conditionally executes script if available (initializes and runs)
- Falls back to direct network setup using set_net() when no script is present

**Parameters:** None
**Returns:** None
8608	END state handler that sets the current state to END, initializes and runs the script if available, otherwise configures network settings.
8609	ERROR state method that logs the state, updates current state to ERROR, initializes and executes script if available, sets network configuration, and raises INIT exception.
8610	Method `timeout_selecting` handles timeout scenarios for the SELECTING state in DHCP client FSM. When timeout occurs, it checks if maximum offers have been collected or maximum discovery attempts have been reached. If maximum offers are collected, it transitions to REQUESTING state. If maximum attempts are reached and no offers were received, it raises ERROR state. If maximum attempts are reached but offers were received, it transitions to REQUESTING state. Otherwise, it remains in SELECTING state.
8611	Timeout requesting in REQUESTING state when maximum attempts are exceeded, raises ERROR if max retries reached (4 times with 60 second total delay) or returns to REQUESTING state if retries not exhausted.
8612	Timeout handler for renewing state that transitions to RENEWING state when maximum request attempts are not reached, or logs and waits for rebinding when maximum attempts are exceeded.
8613	Timeout handler for request rebinding state that transitions to REBINDING state when maximum attempts are not reached, or logs when maximum attempts are exceeded.
8614	Method: receive_offer(self, pkt)
Purpose: Handles incoming OFFER packets during the SELECTING state in a DHCP-like protocol.

Behavior:
- Logs debug message when OFFER packet is received in SELECTING state
- Validates if packet is an OFFER using isoffer() function
- If valid OFFER: 
  * Adds packet to internal offers list
  * If maximum offers collected (MAX_OFFERS_COLLECTED) reached:
    * Calls select_offer() to choose best offer
    * Raises REQUESTING state transition
  * Otherwise: Raises SELECTING state transition

State Transitions:
- From SELECTING to REQUESTING: When maximum offers are collected
- From SELECTING to SELECTING: When fewer than maximum offers collected

Input: pkt - network packet to process
Output: Raises either REQUESTING or SELECTING state exception based on offer collection status
8615	Method receives an ACK packet while in REQUESTING state. If the ACK is processed successfully, it raises a BOUND exception.
8616	Method Summary:
receive_nak_requesting(self, pkt) - Handles NAK packet reception when in REQUESTING state by processing the NAK and transitioning to INIT state if NAK is valid.
8617	Method receives ACK packet while in RENEWING state. If ACK is successfully processed, raises BOUND exception to transition to BOUND state.
8618	Method receives NAK while in RENEWING state and raises INIT exception if NAK is processed successfully.
8619	Method receives an ACK packet while in REBINDING state. If the ACK is processed successfully, it raises a BOUND exception to transition to the BOUND state.
8620	Receive NAK in REBINDING state - if NAK is processed successfully, raise INIT exception.
8621	Action on renewing on RENEWING state.

Not recording lease, but restarting timers.
8622	Assign a value to a parameter, removing it if None. Returns a cloned instance with the parameter set.
8623	Append a value to multiple value parameter.
8624	Remove a value from multiple value parameter.
8625	Get program statuses by communicating with supervisord via either Unix socket or HTTP connection based on the server address, handling authentication if provided, and return the process information via XML-RPC call.
8626	Creates Nagios and human readable supervisord statuses from XML-RPC data, handling program states and generating appropriate exit codes and status messages.
8627	Main program function that parses command line options, creates output based on system status, writes the output to standard output, and exits with the generated exit code.
8628	Validate a decoded SNS message by checking the signing certificate URL format, message age, downloading the certificate from the URL, and verifying the cryptographic signature using the downloaded certificate.
8629	Read a TDMS file and return channel names with units (when available) and corresponding data arrays. Channel names are formatted as "channel_name [unit]" if unit information exists, otherwise just "channel_name". Returns two lists: one containing the formatted channel names and another containing the associated data arrays.
8630	Adds deformation channel to data based on circularity values.

This function checks if "deformation" is not already present in the channel names. If so, and if "circularity" exists, it appends a new "deformation" channel calculated as (1 - circularity) to both the channel names and data arrays. This is useful for RT-DC datasets that contain circularity but need deformation data. The function returns the updated channel names and data arrays.
8631	Converts a TDMS file to an FCS file by reading the TDMS data, adding deformation channels, and writing the formatted data to a new FCS file with the same name prefix.
8632	Returns True if left and right file paths are equal by comparing their contents using the diff command. Returns False if files differ (diff return code 1), raises exception for other errors.
8633	Creates a new patch with the given name in the queue, adds it as the topmost applied patch, and sets up the necessary directory structure and files for the patch. Raises PatchAlreadyExists if a patch with the same name already exists.
8634	Delete the next unapplied patch in the series. If `remove` is True, the patch file is also removed. If both `remove` and `backup` are True, a backup copy of the deleted patch file is created. Raises QuiltError if there is no next patch available.
8635	Delete a specified patch from the series, optionally removing the patch file and creating a backup copy.
8636	Checks if a backup file exists in the current patch and handles the case based on the ignore flag.
8637	Creates a backup of a file by copying it to a destination directory within the quilt patch structure, preserving the file's directory path if it exists.
8638	Adds a file to a patch with optional patch name specification, handling symbolic links, backups, and file permissions while checking for existing files.
8639	Runs a command as a subprocess with optional input data and output suppression. Handles process creation, input writing, and exit code validation, raising appropriate exceptions for failures.
8640	Creates the directory and all its parent directories if it does not exist yet.
8641	Copies the directory tree to a destination path recursively. If destination is a Directory object, its name is used. Uses shutil.copytree to perform the actual copying operation.
8642	Create a hard link named 'link' pointing to this file's filename. If 'link' is a File object, use its filename attribute. Uses os.link() system call to create the hard link.
8643	Copy file to destination, creating parent directories if needed and handling File and Directory destination objects.
8644	Returns the directory where the file is placed in or None if the path to the file doesn't contain a directory.
8645	Backs up a file to a destination directory. Returns a File object pointing to the copied file or None if no file was copied. If the source file exists and is not empty, it's copied to the destination directory. If the source file exists but is empty, it's only copied if copy_empty is True. If the source file doesn't exist, a new file is created in the destination directory only if copy_empty is True. In all other cases, returns None.
8646	Refreshes a patch with the given patch_name or the top applied patch if patch_name is None. It regenerates the patch file by comparing the original and modified files, updates the timestamp, and handles editing the patch if specified. Raises QuiltError if no patch is applied or nothing to refresh.
8647	Unapply patches in reverse order from the patch after the specified patch name, then save the database and emit unapplied signal for the new top patch.
8648	Unapply the top patch from the database by checking conditions, removing the patch, saving changes, and emitting unapplied signal.
8649	Unapply all currently applied patches and update the database state.
8650	Applies all patches up to the specified patch_name, skipping already applied patches, and updates the database accordingly. Raises AllPatchesApplied exception if no patches need to be applied.
8651	Applies the next patch in the series file by checking if there's a top patch, getting the next patch from the series, applying it with optional force and quiet flags, saving the database state, and notifying of the applied patch. Raises AllPatchesApplied exception if no more patches are available.
8652	Apply all pending patches from the series file, skipping already applied patches, and save the database state afterwards. Raises AllPatchesApplied exception if no patches are left to apply.
8653	Reads all patches from the series file and stores them in patchlines list with corresponding line mappings in patch2line dictionary.
8654	Saves the current patches list to the series file by writing each patchline as a string followed by a newline character.
8655	Add a patch to the patches list by creating a PatchLine object, extracting the patch data, and storing it in both the patch2line dictionary and patchlines list if the patch exists.
8656	Inserts a list of patches at the front of the current patches list, creating PatchLine objects for each patch and updating the patch-to-line mapping.
8657	Add a list of patches to the patches list, either at the end or after a specified patch.
8658	Remove a patch from the patches list by checking the patch validity, finding its corresponding line, and deleting both the patch-to-line mapping and the line from respective data structures.
8659	Returns a list of patches that come after the specified patch in the patches list.
8660	Returns a list of patches that come before the specified patch in the patches list, filtering out any None values.
8661	Returns a list of patches from the patches list up to and including the specified patch.
8662	Replace old_patch with new_patch in patchlines list while preserving comments and updating the patch2line mapping.
8663	Creates the directory if it doesn't exist and adds a .version file to it.
8664	Checks if a .version file contains the correct supported version number, raising DBError if the version is not supported.
8665	Adds a named argument group to an ArgumentParser instance, then adds all arguments in the group to that argument group.
8666	Adds an argument to an argparse.ArgumentParser instance using the object's args and kwargs.
8667	Adds this SubParser to the subparsers created by argparse.ArgumentParser.add_subparsers method by creating a new parser, setting default values, and adding base argument groups and arguments.
8668	Sets the arguments and keyword arguments that are passed when creating a subparsers group in an argparse.ArgumentParser's add_subparsers method.
8669	Adds subparsers to an argparse.ArgumentParser instance, handling both named subparser groups and individual subparsers with their respective arguments and keyword arguments.
8670	Checks if a backup file exists in the current patch and raises QuiltError if not.
8671	Checks if a backup file exists in applied patches after the specified patch, raising a QuiltError if the file is modified by any subsequent patch.
8672	Revert uncommitted changes to a file by applying the reverse of the specified patch or the topmost patch. If the file is new and empty, it will be deleted. Otherwise, the method applies the patch temporarily, compares the result with the current file, and if different, copies the reverted version to the working directory. If the file is unchanged after reverting, it notifies that the file is unchanged. Raises QuiltError if no patch is available for reverting.
8673	Imports a patch file into the patch queue by copying it to the quilt patches directory and adding it to the import list. If a new name is provided, the patch is copied to that location instead. The patch is inserted as the next unapplied patch in the queue.
8674	Imports multiple patches into the patch queue by copying them to the destination directory and adding them to the import list.
8675	Process each way by checking if it exists in way_ids, then create a list of Point objects from the way's nodes, handling invalid locations with debug logging, and store the resulting Way object in the ways dictionary.
8676	Get a list of nodes not found in OSM data by comparing requested node IDs with present node IDs.
8677	Process each node by checking if it exists in node_ids, then create a Node object with its location and tags, handling InvalidLocationError exceptions.
8678	Builds a Route object from an OpenStreetMap relation if it represents a route, extracting route information such as short name, long name, type, URL, color, and agency ID. Returns None if the relation is not of type 'route'.
8679	Create a meaningful route name by combining 'from' and 'to' tags if available, or using 'name', 'alt_name', or a default OSM route identifier, while removing the short_name prefix if present.
8680	Constructs an agency ID using the operator tag from a relation. If an operator tag exists, it generates a hash-based ID by hashing the operator name and taking the first 8 digits of the hexadecimal result. If no operator tag exists, returns -1.
8681	Process files to extract and collect public transport data by handling relations, nodes, and ways from OSM data.
8682	Process each relation by filtering based on type, visibility, and version, then store valid relations with their tags and members in the relations and versions dictionaries.
8683	Creates dummy GTFS data including calendar, stop_times, trips, and frequencies by processing routes and stops, then returns them as a DummyData namedtuple.
8684	Fill the fields that are necessary for passing transitfeed checks by yielding an unknown agency entry first, then yielding the rest of the agencies with default values for missing URL and timezone fields.
8685	Create station stop times for each trip by calculating arrival and departure times based on waiting periods and travel times between stops, handling day transitions and yielding time information for each stop in a trip.
8686	Write a GTFS feed to a zip file containing text files from buffers and additional files from paths.
8687	Write GTFS text files to the specified destination path by iterating through buffers and files, creating .txt files from buffers and copying existing files.
8688	Builds agency information from relation tags, extracting operator and URL information to create an Agency object with a hashed ID.
8689	Extract stops from a relation by iterating through member information and yielding Stop objects for valid stops and halts that haven't been visited yet.
8690	Extracts the shape of a route from relation members, yielding Shape objects for nodes in the relation while skipping ways and unknown members.
8691	Gets a list of supported U2F versions from the device, caching the result. Returns ['v0'] if the device doesn't support the version instruction, or an empty list if other APDU errors occur.
8692	Sends an APDU command to the device with specified instruction and parameters, waits for response, and returns the response data after validating the status code. Handles data conversion and APDU packet construction internally.
8693	Function `authenticate` interacts with U2F devices for authentication. It opens all devices, then iteratively attempts authentication using `u2f.authenticate`. If authentication fails due to `APDU_USE_NOT_SATISFIED`, it prompts user to touch the device (unless `check_only` is True). If authentication fails due to other device errors, it removes the device from consideration. The function continues until authentication succeeds or all devices are removed. Finally, it closes all remaining devices and exits with an error if no device is found.
8694	Register a U2F device by processing enrollment data, validating the U2F version, verifying the facet, and generating registration data and client data for the U2F device.
8695	Authenticates a U2F device by signing an authentication challenge. Takes device, data dictionary containing challenge information, and facet URL as inputs. Validates U2F version, verifies facet, and constructs authentication parameters. Sends APDU command to device for signature generation. Returns client data, signature, and key handle as a dictionary. If check_only is True, performs a verification-only operation.
8696	Registers a U2F device interactively by attempting registration with available devices, handling APDU errors and device issues, and providing appropriate feedback when registration fails.
8697	Recursively converts unicode objects to UTF-8 encoded byte strings, handling dictionaries, lists, and unicode strings while leaving other data types unchanged.
8698	Wrap a function with error reporting to backend, supporting both decorator syntax and keyword arguments.
8699	Wraps a class by decorating each of its methods with error reporting functionality. The decorator injects error handling while preserving the original method's behavior and classmethod decorators. Returns the modified class with wrapped methods.
8700	Given a filepath and a list of regex patterns, this function returns True if the filepath matches any of the patterns. If no patterns are specified, it returns True by default.
8701	Returns the appropriate email address after checking remapping rules and handling domain overrides. Returns None for invalid emails, looked-up remapped addresses, or generates a new email with overridden domain when required.
8702	Helper function for retrieving a particular entry from the prefix trees by matching filename and equality condition.
8703	Converts Markdown text to reStructuredText format with specific transformations for parameter formatting, URL handling, and numbered list preservation. Takes a markdown string as input and returns the converted reStructuredText string.
8704	Starts a Flawless server with both HTTP and Thrift components, using configuration from conf_path and optional custom storage factory for horizontal scalability.
8705	Helper function to record errors to the flawless backend, capturing stack traces, local variables, and sending error reports while implementing rate limiting via an LRU cache.
8706	Fetch an image from a URL and convert it into a Pillow Image object.
8707	Converts a string representation of an image into a Pillow Image object by treating the string as a file-like object and opening it with PIL's Image.open() method.
8708	Returns a decorator that validates arguments using the provided validator function. The decorator can bypass validation when validate=False is passed, and stores the validator function as func.validate. The validator function must raise an exception if validation fails.
8709	Check if image size is larger than the specified size, raise ImageSizeError if not.
8710	Check if image width is greater than specified width, raise ImageSizeError if not.
8711	Check if image height is greater than specified height, raise ImageSizeError if not enough.
8712	Converts a text category to a Category instance using a slug mapping, returning None if the slug is not found or the category doesn't exist.
8713	Parse numeric fields by converting values to integers, returning 0 on conversion failure.
8714	Returns an iterator of items from XML source using efficient iterparse, clearing each item from memory after yielding.
8715	Saves an error entry containing the provided data and exception information into the errors list. The exception information is formatted as a string for storage.
8716	Parses all data from the source, saving model instances by loading the source if needed, iterating through items, parsing each item into data, retrieving or creating instances, feeding instances with data, and attempting to save items while handling any errors that occur. Finally, it unloads the source.
8717	Parses an item by extracting field values according to field mappings and custom parsing methods, returning a dictionary of the parsed data.
8718	Get an item from the database using unique fields for lookup, or return a new empty instance if not found.
8719	Saves a model instance to the database optionally committing the transaction.
8720	Downloads a file from a URL and saves it to destination, handling Gzip compression automatically.
8721	```python
def load(self, source):
    """
    Opens the source file.
    """
    self.source = open(self.source, 'rb')    
    self.loaded = True
```

Summary: The `load` method opens a source file in binary read mode and sets a loaded flag to True.
8722	Returns an iterator that reads CSV file rows and yields dictionaries mapping column headers to row values.
8723	Sets the network access permission for the sandbox instance, raising a ValueError if the sandbox is currently running.
8724	Runs a command inside a sandboxed environment using Docker, with optional resource limits and output truncation. Returns a CompletedCommand object containing execution results, stdout, stderr, and truncation information. Supports running as root or regular user, handles timeouts, and can raise exceptions for non-zero exit codes or timeouts when check=True.
8725	Adds specified files to the sandbox working directory, with options for file ownership and read-only permissions. Files are copied into the sandbox using docker cp, and can be assigned to either the sandbox user or root owner. Optional read-only permission can be set on the files.
8726	Copies a specified file to the sandbox's working directory and renames it to the new filename, then updates the file's ownership.
8727	Returns a list of all enrollments for a given course by fetching paginated data from the Canvas API enrollments endpoint and converting each datum into a CanvasEnrollment object.
8728	Returns a list of all enrollments for a course identified by its SIS ID by delegating to the get_enrollments_for_course method with the SIS ID converted to a standard course ID.
8729	Returns a list of all enrollments for the specified section_id by fetching paginated data from the Canvas API enrollments endpoint and converting each datum into a CanvasEnrollment object.
8730	Returns a list of all enrollments for the specified section SIS ID by delegating to the section-based enrollments method.
8731	Returns a list of enrollments for a given user regid, optionally including course information. Supports pagination and backward compatibility for course-related fields.
8732	Enrolls a user into a course with the specified enrollment type. Takes course ID, user ID, enrollment type, and optional parameters. Returns a CanvasEnrollment object.
8733	Returns a list of CanvasRole objects representing the roles available in the specified account, using the Canvas API to fetch role data for the given account ID.
8734	Lists the roles for an account using the provided account SIS ID.
8735	List all course roles available to an account, including inherited roles, excluding AccountMembership base roles.
8736	Get information about a specific role for a Canvas account by making an API call to the roles endpoint and returning a CanvasRole object with the retrieved data.
8737	Get information about a single role for a given account SIS ID and role ID by first converting the account SIS ID to a standard ID format, then retrieving the role information using the converted ID.
8738	Returns course resource for given canvas course id, ensuring term information is included in the response.
8739	Returns the course resource for a given SIS ID by calling get_course with the SIS ID converted to the proper format.
8740	Returns a list of courses for the specified account ID by making paginated API requests and converting the response data into CanvasCourse objects.
8741	Returns a list of courses for the specified account SIS ID by calling the get_courses_in_account method with the SIS ID converted to internal format.
8742	Returns a list of published courses for the specified account ID by filtering courses with published=True parameter.
8743	Return a list of published courses for the specified account SIS ID by converting the SIS ID to account ID and calling the get_published_courses_in_account method.
8744	Returns a list of courses for the given regid by fetching course data from the Canvas API, creating CanvasCourse objects for courses with SIS IDs, or fetching additional course details for others.
8745	Creates a Canvas course under the specified account with the given course name by making a POST request to the Canvas API courses endpoint and returns a CanvasCourse object initialized with the response data.
8746	Updates the SIS ID for a course with the specified course ID using the Canvas API, returning a CanvasCourse object with the updated data.
8747	Returns participation data for a given account and term by making a GET request to the Canvas analytics API endpoint for account activity.
8748	Returns grade data for the given account_id and term_id by making a GET request to the Canvas analytics API endpoint for account grades.
8749	Returns statistics for the given account_id and term_id by making a GET request to the Canvas analytics API endpoint for account statistics.
8750	Returns participation data for a course identified by its SIS course ID by making a GET request to the Canvas Analytics API endpoint for course activity.
8751	Returns assignment data for the given SIS course ID by making a GET request to the Canvas analytics API endpoint for course assignments.
8752	Returns per-student analytics data for a given SIS course ID by making a GET request to the Canvas Analytics API endpoint for course student summaries.
8753	Returns student activity data for a given user ID and course ID by making a GET request to the Canvas Analytics API endpoint for student course participation.
8754	Returns student messaging data for a given user ID and course ID by making a GET request to the Canvas Analytics API endpoint for student communication analytics in a specific course.
8755	Returns external tools for a given Canvas account ID by making paginated API calls to the external tools endpoint.
8756	Returns external tools for a given Canvas course ID by fetching data from the external tools API endpoint, paginating through results and returning a list of tool data dictionaries.
8757	Creates an external tool in Canvas using the provided context and JSON data. Takes a context (COURSES_API or ACCOUNTS_API) and context_id (course or account ID) to construct the API URL, then POSTs the external tool configuration data to create the tool. Returns the API response from the creation request.
8758	Updates an external tool resource with the provided JSON data.

This method sends a PUT request to update an external tool identified by `external_tool_id` within the specified context (courses or accounts). The context is determined by the `context` parameter which should be either COURSES_API or ACCOUNTS_API, and `context_id` should be the corresponding course_id or account_id. The method constructs the API endpoint URL and calls `_put_resource` to perform the update operation with the provided JSON data as the request body.

Parameters:
- context: API context template (COURSES_API or ACCOUNTS_API)
- context_id: Course ID or account ID depending on context
- external_tool_id: ID of the external tool to update
- json_data: JSON data containing the update information

Returns:
Result from the PUT request operation
8759	Delete an external tool by ID from the specified context (course or account).
8760	Check if all required parameters are available on an object, raising a DesignError if any parameter is missing or None.
8761	Returns user profile data for a given user ID by making a GET request to the Canvas API profile endpoint.
8762	Returns a list of CanvasUser objects for a given course ID by fetching paginated user data from the Canvas API.
8763	Returns a list of users for the given SIS course ID by converting the SIS ID to a course ID and fetching users for that course.
8764	Create and return a new user and pseudonym for a specified account, using the Canvas API. Raises MissingAccountID if no account ID is provided and cannot be determined from the instance. The user data is posted to the account's users endpoint, and the response is converted to a CanvasUser object.
8765	Return a user's logins for the given user_id by fetching paginated data from the Canvas API and converting each login record into a Login object.
8766	Updates an existing login for a user in the specified account, returning a Login object with the updated login data.
8767	Return the URL path to the next page of paginated data by parsing the "link" header from the response. Extracts the next page URL from links with "next" relation. Returns None if no next page link is found or if parsing fails.
8768	Method `_get_resource_url` performs a Canvas GET request on a full URL and returns the requested resource representation. It handles pagination by recursively fetching subsequent pages when `auto_page` is True and a next page URL exists. The method accepts parameters `url` (the target URL), `auto_page` (boolean indicating whether to auto-paginate), and `data_key` (key for dictionary data structure). It sets appropriate headers, validates the response status, parses JSON data, and manages pagination by appending data from subsequent pages to the current result. Returns the complete data (either from single response or combined pagination results). Raises `DataFailureException` for non-200 status responses.
8769	Retrieves a paged resource from Canvas API, handling pagination automatically by following links to coalesce all resources when no explicit page/per_page parameters are provided.
8770	Canvas GET method that retrieves and returns a representation of a requested resource using the specified URL and parameters.
8771	Method `_put_resource` performs a Canvas PUT request with the given URL and body. It sets authentication parameters, configures JSON headers, appends URL parameters, and makes the PUT request through DAO. The method raises a `DataFailureException` if the response status is not 200, 201, or 204, otherwise it returns the parsed JSON response data.
8772	POSTs a resource to Canvas with the given URL and body, handling authentication and response validation. Returns the JSON response data. Raises DataFailureException for non-success status codes (non-200, 204).
8773	Deletes a resource at the specified URL using Canvas API DELETE method, handling authentication and proper error handling for non-success status codes.
8774	Returns a list of CanvasAdmin objects representing the admins in the specified account by paginating through the admins API endpoint.
8775	Flags an existing user as an admin within the account by making a POST request to the Canvas admins API endpoint with the specified user ID and role.
8776	Create an admin user within an account using SIS ID by flagging an existing user with the specified role.
8777	Remove an account admin role from a user.
8778	Remove an account admin role from a user for the specified SIS account ID by delegating to the delete_admin method with the converted SIS ID.
8779	Creates a new grading standard for a course with the specified name, grading scheme, and creator.
8780	Returns a section resource for a given Canvas section ID by making an API call to the sections endpoint and wrapping the response data in a CanvasSection object.
8781	Returns the section resource for a given SIS section ID by converting the SIS ID to a section ID and fetching the section with optional parameters.
8782	Return list of sections for the passed course ID by fetching paginated data from the Canvas API sections endpoint and converting each data item into a CanvasSection object.
8783	Returns a list of sections for the specified course SIS ID by delegating to get_sections_in_course with the SIS ID converted to internal format.
8784	Returns a list of course sections with student information included for the specified course ID.
8785	Returns a list of sections including students for the specified SIS course ID by converting the SIS ID to a standard course ID and fetching the sections with students.
8786	Creates a Canvas section in the specified course with the given name and SIS section ID, returning a CanvasSection object.
8787	Updates a Canvas section with the given section ID by modifying its name and/or SIS section ID through the Canvas API.
8788	Get a list of quizzes for a given course ID by fetching data from the quizzes API endpoint and converting each quiz datum into a Quiz object.
8789	Returns the account resource for a given Canvas account ID by making a GET request to the Canvas Accounts API endpoint.
8790	Returns a list of subaccounts within the specified account by making paginated API calls to the Canvas accounts endpoint and converting each response datum into a CanvasAccount object.
8791	Updates an account with the specified name and returns the updated account object.
8792	Updates the SIS ID for a specified account, excluding the root account. Raises an exception if attempting to update the root account's SIS ID. Makes a PUT request to the Canvas accounts API with the provided account ID and SIS account ID, then returns a CanvasAccount object initialized with the response data.
8793	Returns the authentication settings for the specified account_id by making a GET request to the Canvas SSO settings API endpoint.
8794	Updates authentication settings for a specific account by sending SSO settings data to the Canvas API endpoint for that account's SSO settings, and returns a CanvasSSOSettings object populated with the response data.
8795	Returns the term resource that matches the given SIS ID by iterating through all terms.
8796	Imports a CSV string to Canvas SIS. Raises MissingAccountID if account ID is not set. Sets import type to CSV and sends POST request to SIS imports API with CSV data and appropriate headers. Returns SISImportModel instance populated with the response data.
8797	Imports a directory of CSV files to Canvas SIS. Raises MissingAccountID if account ID is not set. Builds archive from directory, sets CSV import type, and posts to SIS imports API endpoint. Returns SISImportModel object containing the import data.
8798	Get the status of an existing SIS import by making an API call to the Canvas SIS imports endpoint and return a SISImportModel object containing the import data.
8799	Creates a zip archive named "import.zip" containing CSV files from the specified directory path, compresses them using ZIP_DEFLATED compression, and returns the archive content as bytes.
8800	Get a list of assignments for a specified course by calling the Canvas assignments API endpoint, process the response data to create Assignment objects, and return the list of assignments.
8801	Update an existing assignment by making a PUT request to the Canvas API endpoint for assignments, using the assignment's course ID and assignment ID to construct the URL, and return a new Assignment object with the updated data.
8802	Returns a list of available report types for a given canvas account ID by fetching data from the accounts API endpoint and converting each data item into a ReportType object.
8803	Returns all reports of a specified type that have been run for a given canvas account ID by fetching data from the accounts API endpoint and converting each report datum into a Report object with the account ID attached.
8804	Creates a report instance for a canvas account with specified parameters, supporting optional enrollment term ID and custom parameters, returning a Report object.
8805	Creates a course provisioning report by calling the create_report method with the provisioning report type, account ID, optional term ID, and parameters including courses=True.
8806	Creates a course SIS export report by calling the create_report method with ReportType.SIS_EXPORT and setting courses parameter to True.
8807	Creates an unused courses report for the specified account and optional term by calling the create_report method with ReportType.UNUSED_COURSES.
8808	Returns a completed report as a list of CSV strings by polling the report status until completion, then fetching and splitting the report data. Raises ReportFailureException if report ID or status is missing, or if status becomes "error". Returns None if attachment URL is missing.
8809	Returns the status of a report by making an API call to the Canvas reports endpoint, validating that the report has required attributes (account_id, type, report_id), constructing the appropriate URL, fetching the report data, and returning a Report object with the retrieved data. Raises ReportFailureException if any required report attributes are missing.
8810	Deletes a generated report instance from Canvas.

**Parameters:**
- `report`: Report object containing account_id, type, and report_id attributes

**Returns:**
- `True` indicating successful deletion

**API Reference:**
- Method: `account_reports.destroy`
- Endpoint: `/api/v1/accounts/{account_id}/reports/{type}/{report_id}`
8811	Moves all detections in the label dictionary by shifting them in the specified direction (dx, dy). For each detection list (keys starting with "detection"), it iterates through all detections and applies a reverse translation using the move_image method with negative dx and dy values.
8812	Horizontally flip object detections in a label dictionary by reflecting x-coordinates across the image width and adjusting orientation angles for 2.5D detections.
8813	Returns a dictionary representation of an object, handling ForeignKey relationships and many-to-many fields properly by converting foreign key IDs to their actual values and collecting primary keys from many-to-many relationships.
8814	Get the arguments given to the template tag element and complete these with the ones from settings.py if necessary. If config_one_by_one is False, use default config only if none specified; otherwise, update the configured config with the default one.
8815	Get the text to display when the field is empty, either from configuration or from inplace settings default.
8816	Parse uniformly args and kwargs from a templatetag, splitting the token contents and handling both positional arguments and keyword arguments with variable assignment support.
8817	Creates and registers metrics from a list of MetricConfigs using the registry.
8818	Setup logging for the application and aiohttp with specified log level, configuring multiple aiohttp-related loggers and the application logger to output to stderr.
8819	Configures the MetricRegistry by optionally registering a ProcessCollector for process statistics monitoring.
8820	Creates Prometheus metrics from a list of MetricConfigs and returns a dictionary mapping metric names to their corresponding Metric objects.
8821	Return a metric by name, optionally configured with labels. If labels are provided, return a labeled version of the metric; otherwise, return the metric as-is.
8822	Async request handler for the home page that generates an HTML response with the application title and a link to the metrics endpoint.
8823	Handler for metrics that updates metrics data and returns formatted metrics response.
8824	A function that queries Wolfram|Alpha with a free-text input and returns the first result's text output.
8825	Summary: Adds forward compatibility for HTTPMessage methods by creating aliases for deprecated Python 2 method names in Python 3 environments.
8826	Queries Wolfram|Alpha using the v2.0 API with the provided input and parameters, returning a Result object. Supports arbitrary parameters including assumptions, and handles URL encoding of query parameters.
8827	Returns an iterator combining pods, assumptions, and warnings from this result.
8828	Returns an iterator of pods that contain query results, including primary pods and pods with the title 'Result'.
8829	Encodes request data as JSON and sets the Content-Type header to 'application/json'. Returns the modified request object. If data is None, returns the request unchanged.
8830	Calls an API endpoint with the specified method and parameters, handling authentication, URL construction, and request processing. Returns the response object and status code.
8831	Method: get
Description: Makes a GET request to the specified URL with optional query parameters and additional kwargs.
Parameters:
- url (str): Resource location relative to the base URL
- params (dict or None): Query-string parameters
- **kwargs: Additional keyword arguments
Returns: ResultParser or ErrorParser object from the API call
Calls: self.call_api() with method "GET" and passed arguments
8832	Deletes a resource at the specified URL using the API.

**Args:**
- url (str): Resource location relative to the base URL
- params (dict or None): Query-string parameters

**Returns:**
- ResultParser or ErrorParser

**Example:**
```python
# Delete a resource
result = api.delete("/users/123")
```
8833	Method: put
Description: Executes a PUT request against the API with the specified parameters.

Parameters:
- url (str): Resource location relative to the base URL
- params (dict or None): Query-string parameters to include in the request
- data (dict or None): Request body contents to send
- files (dict or None): Files to be included in the request
- **kwargs: Additional keyword arguments to pass to the API call

Returns: An instance of ResultParser or ErrorParser based on the API response

Implementation: Delegates to the call_api method with the PUT HTTP method and all provided parameters.
8834	Posts data to the specified URL using the API.

Args:
    url (str): Resource location relative to the base URL.
    params (dict or None): Query-string parameters.
    data (dict or None): Request body contents.
    files (dict or None): Files to be passed to the request.

Returns:
    An instance of ResultParser or ErrorParser.
8835	Process a query by recursively handling long text through segmentation and grouping, submitting parts via POST requests to an API, and returning the processed results with language and entity information.
8836	Split sentences into groups of specified length, returning a list of groups where each group contains consecutive sentence indices.
8837	Method: `disambiguate_pdf`

Summary: Calls the disambiguation service to process a PDF file with optional language and entity parameters. Takes a PDF file path, optional language code, and optional entities list as inputs. Returns a tuple containing the API response ( decoded) and HTTP status code. The method constructs a JSON body with customisation settings and includes language/entity information if provided. It then sends a POST request with the file and body to the disambiguation service endpoint, handling any errors by logging debug messages when the status code is not 200.

Parameters:
- `file` (str): Path to the PDF file to be disambiguated
- `language` (str, optional): Language code of the text content
- `entities` (list, optional): List of entities to be disambiguated

Returns:
- `tuple`: (decoded API response, HTTP status code)
8838	Method: `disambiguate_query`

Summary: Calls the disambiguation service to resolve search queries by providing entity disambiguation and named entity recognition. The method accepts a query string, optional language specification, and a list of entities to be disambiguated, then returns the API response and status code. The method constructs a request body with the provided parameters, sends it to the disambiguation service via POST request, and processes the response. If successful (status 200), it returns the decoded response and status code; otherwise, it logs the failure and returns None with the status code.

Parameters:
- `query` (str): The search query to be disambiguated
- `language` (str, optional): The language of the query text
- `entities` (list, optional): List of entities or mentions to be supplied by the user

Returns:
- `dict, int`: API response and API status code, or `None, status` on failure
8839	Segments text into sentences using a segmentation service and returns the segmented results with status code.
8840	Method: `get_language(self, text)`

Summary: Recognizes the language of the input text using a language detection service. Takes a text string as input and returns a dictionary containing the recognized language and confidence score, along with the HTTP status code from the service response.

Parameters:
- `text` (str): The text whose language needs to be recognized

Returns:
- `tuple`: A dictionary with recognized language and confidence score, and an integer status code

Side effects:
- Makes a POST request to the language service endpoint
- Logs debug messages if language recognition fails
- Uses `self.post()` method for the HTTP request
- Uses `self.decode()` method to process the response
8841	Fetches a concept from the knowledge base using the provided concept ID and language.

Args:
    conceptId (str): The concept ID to be fetched (Wikipedia page ID or Wikidata ID)
    lang (str): Language code for the response (default: 'en')

Returns:
    tuple: A dictionary containing concept information and an integer response code

The method constructs a URL using the concept service endpoint and concept ID, makes a GET request with the specified language parameter, and returns the decoded response along with the status code. If the status code is not 200, it logs a debug message indicating the fetch failed.
8842	Constructs the MDR ensemble from training data by fitting the ensemble model and creating a feature map that maps each unique feature row to its predicted class label from the ensemble.
8843	Estimates the accuracy of predictions from an MDR ensemble by generating a new feature using the ensemble's prediction and comparing it against true class labels using either the default accuracy score or a provided scoring function.
8844	Constructs the MDR feature map from training data by:
1. Validating binary classification requirements
2. Counting class distributions across MDR grid cells
3. Mapping each grid cell to the dominant class based on conditional probabilities
4. Handling ties using the tie-breaking rule
5. Returning the fitted model

The method creates a feature map that assigns each unique feature combination to a class label based on whether that combination's class distribution differs significantly from the overall class distribution.
8845	Convenience function that fits the model on the provided data and returns predictions for the same features.
8846	Method: score

Summary: Estimates the accuracy of predictions from a constructed feature using either the default accuracy score or a custom scoring function.

Parameters:
- features: array-like {n_samples, n_features} - Feature matrix to predict from
- class_labels: array-like {n_samples} - List of true class labels
- scoring_function: callable, optional - Custom scoring function to use instead of default accuracy score
- scoring_function_kwargs: dict - Additional keyword arguments to pass to the scoring function

Returns:
- accuracy_score: float - The estimated accuracy based on the constructed feature

Throws:
- ValueError: If the MDR model has not been fit before calling score method

Notes:
- Raises ValueError if feature_map is None (model not fitted)
- Uses predict() method to generate new feature predictions
- Defaults to accuracy_score() if no custom scoring function is provided
- Supports custom scoring functions with additional keyword arguments
8847	Constructs the Continuous MDR feature map from training data by calculating mean trait values for each feature combination and assigning binary labels based on comparison to overall mean. Returns the fitted model.
8848	Transforms input features using a Continuous MDR feature map to construct a new binary feature. Takes an input feature matrix and returns a new feature vector where each instance is mapped according to the precomputed feature map, falling back to a default label for unseen instances. The output is reshaped to have shape (n_samples, 1).
8849	Estimates the quality of the ContinuousMDR model using a t-statistic by comparing trait values between two groups defined by the feature map, returning the absolute t-statistic value.
8850	Fits a MDR model to the given features X and Y with their corresponding labels, then returns the model's predictions. This is an internal convenience method that combines fitting and prediction in one step.
8851	Fits MDR models to all n-way combinations of features in X, performing exhaustive search through feature combinations. Takes an MDR instance, feature matrix X, target vector y, maximum model sizes n, and optional feature names. Returns tuples of fitted models, their training scores, and corresponding feature names for each combination.
8852	Visualizes the MDR grid for a fitted 2-way MDR model, showing class counts for each feature combination with basic styling and layout. The function creates a grid of subplots where each subplot represents a combination of feature levels, displaying bar charts of class counts and coloring cells based on feature map values. Axis labels and titles are added for clarity, and the layout is adjusted for better visualization. Note that the function is marked as incomplete and lacks proper scaling and 3-way+ model support.
8853	Get security configuration for an application by removing a specified prefix from config keys.
8854	Get a Flask-Security configuration value by key, with optional app specification and default fallback.
8855	Creates a new vector from an iterable of members with optional metadata.
8856	Creates a new vector from the provided members with optional metadata.
8857	Evaluates a file into a Python module AST node by reading each form from the file and compiling/executing it sequentially, returning the result of the last form.
8858	Evaluates forms from a stream into a Python module AST node by reading each form and compiling/executing it sequentially, returning the result of the last form.
8859	Evaluates a string of forms into a Python module AST node by sequentially reading and compiling each form with the provided compiler context and module.
8860	Bootstraps a REPL environment by creating necessary namespaces, importing the REPL module, establishing aliases and references between namespaces, and returning the bootstrapped module for use in REPL commands.
8861	Run a Basilisp script or code snippet with specified compilation and evaluation options.
8862	Creates a multi-function decorator that wraps a dispatch function with optional default behavior, returning a MultiFunction instance with a symbolic name derived from the dispatch function's qualified name and module.
8863	Adds a method to the map with the specified key, replacing any existing method with that key.
8864	Add a new method to this function that will respond to the specified key returned from the dispatch function.
8865	Return the method that would handle the given dispatch key, or None if no method is defined for that key and no default exists. Uses caching to lookup methods and falls back to a default method if available.
8866	Remove a method with the specified key from the map, returning a new map without that method.
8867	Remove the method defined for the given key and return it if it exists, otherwise return None.
8868	Return True if the Var holds a macro function by checking for macro metadata.
8869	Fetch the location (line, column) of a Lisp form from its metadata, returning None if no location information is available.
8870	Attaches location information from the input form to the parsed node's environment, preserving the original parsing function's behavior while enhancing nodes with location data when available.
8871	Asserts that `recur` forms do not appear in non-tail positions of AST nodes. Raises ParserException if `recur` is found in tail position, otherwise recursively checks child nodes.
8872	This function recursively validates that `recur` expressions appear only in tail positions within AST nodes. It checks different node types:
- DO nodes: ensures recur appears only in tail position of statements and return values
- FN/FN_METHOD/METHOD nodes: recursively checks all child nodes
- IF nodes: validates recur appears only in tail positions of then/else branches
- LET/LETFN nodes: checks bindings don't contain recur and body is properly validated
- LOOP nodes: validates loop bindings don't contain recur
- RECUR nodes: passes (recur is allowed here)
- TRY nodes: validates body and catch clauses while ensuring finally clause doesn't contain recur
- All other nodes: recursively checks for recur in all child nodes using `_assert_no_recur`
8873	Resolve a non-namespaced symbol into a Python name or a local Basilisp Var, handling cases where the symbol refers to a builtin or raising an exception if unresolved.
8874	Resolves a Basilisp symbol as a Var or Python name, handling special class instantiation syntax with trailing dots.
8875	Parses a Lisp form into a Basilisp syntax tree matching the clojure.tools.analyzer AST specification, with top_level flag set to True.
8876	Returns True if warnings should be issued when variable names are shadowed in inner scopes. Combines the warn_on_shadowed_name flag with a configuration option, where warn_on_shadowed_name takes precedence.
8877	Add a new symbol to the symbol table with optional warnings for name shadowing and unused symbols.
8878	Produces a Lisp representation of an associative collection with specified start and end delimiters. Takes key-value pairs from a callable entries function and formats them using lrepr for each element. Supports printing limits via print_length and print_dup keywords, and can include metadata when print_meta is enabled. Returns formatted string with optional metadata prefix.
8879	Produces a Lisp-style representation of a sequential collection with specified start and end delimiters, handling printing limits and metadata formatting.
8880	Return a string representation of a Lisp object with various formatting options.
8881	Fallback function for lrepr that handles subclasses of standard Python types by dispatching to type-specific representation functions or using repr() for unrecognized types.
8882	Return a transformed copy of this node with updated location information. If the node's environment lacks line/column data, use the provided start_loc or the node's existing location. Recursively process all child nodes, updating their locations as well. Child nodes without their own location information will use their parent's location. The method ensures all location data is properly set and returns a new node with the updated structure and locations.
8883	Compiles and executes a Lisp form within a given module context, returning the result of the execution. Handles module bootstrapping, AST generation from Lisp form, Python AST transformation, bytecode compilation, and execution. Supports optional bytecode collection and allows customization of the wrapped function name for REPL usage. Returns None for None input forms.
8884	Incrementally compiles a Python module from AST nodes, optimizing and executing it in the given module's namespace. Takes an optimizer, AST nodes, module, and source filename, then compiles and executes the code while optionally collecting bytecode.
8885	Compiles a Basilisp module into Python bytecode for execution, handling the entire compilation process including AST generation and incremental compilation with optional bytecode collection.
8886	Compiles cached bytecode into a given module by first bootstrapping the module with the necessary context and optimizer, then executing each bytecode item within the module's namespace.
8887	Create a Sequence from an Iterable s, returning an empty sequence if the iterable is empty.
8888	Replace invalid Python symbol characters in a string with valid alternatives, ensuring the result is a valid Python identifier by handling keywords and built-ins appropriately.
8889	Function that replaces munged string components with their original representations, using a regex pattern and a replacement dictionary, then converts underscores to hyphens.
8890	Create a Fraction object from given numerator and denominator arguments.
8891	Returns a logging handler for Basilisp, using either a null handler or stream handler based on the BASILISP_USE_DEV_LOGGER environment variable, with the specified level and format.
8892	Creates a new map from a mapping of key-value pairs with optional metadata.
8893	Partition a collection into groups of specified size n, yielding tuples of elements. If the collection length is not evenly divisible by n, the final group will contain the remaining elements.
8894	Wrap a reader function in a decorator to supply line and column information along with relevant forms.
8895	Read a namespaced token from the input stream, separating namespace and name components. Returns a tuple of (namespace, name) where namespace can be None. Handles special cases for '/' character and validates token syntax.
8896	Reads a collection from input stream, parses elements until end token, and constructs collection using provided function. Raises SyntaxError on unexpected EOF.
8897	Read a list element from the input stream by parsing elements until closing parenthesis.
8898	Read a vector element from the input stream by parsing elements between square brackets and returning a vector.Vector object.
8899	Return a set from the input stream by reading elements until closing brace is encountered, validating no duplicate values exist.
8900	Reads and parses a map literal from the input stream, returning a map object with key-value pairs. Handles parsing of map syntax, duplicate key detection, and comment skipping.
8901	Reads and returns a string from the input stream, handling escape sequences according to the context. Raises SyntaxError for unexpected EOF or unknown escape sequences unless arbitrary escapes are allowed.
8902	Returns a symbol from the input stream, handling syntax-quoted forms and resolving symbols when needed. Raises SyntaxError for invalid namespace formats or unauthorized gensyms outside syntax quotes. Converts special names ("nil", "true", "false") to their corresponding Python values.
8903	Reads a keyword from the input stream by advancing past ":" delimiter, parsing namespaced components, and returning a keyword object with validation against dot characters in the name.
8904	Read metadata from input stream and attach it to the next object, handling different metadata types (symbol, keyword, or map) and raising appropriate syntax errors for invalid cases.
8905	Reads a function reader macro from input stream, handling anonymous function definitions with argument replacement and validation.
8906	Read a quoted form from the input stream by advancing past the quote character, reading the next form while consuming comments, and returning a quoted list construct.
8907	Expand syntax quoted forms to handle unquoting and unquote-splicing by converting unquote forms to (list x) and unquote-splicing forms to x, while recursively processing other forms as (list form).
8908	Post-processes syntax quoted forms to generate runtime-assemblable forms by converting lists, vectors, sets, and maps into appropriate function applications with concat, while handling unquote and unquote-splicing operations and passing other forms through unchanged.
8909	Read a syntax-quote character and enter syntax-quoting state while processing the following form.
8910	Read an unquoted form and handle unquoting logic, returning either an unquote or unquote-splicing form based on the presence of the `@` symbol after the tilde.
8911	Read a dereferenced form (starting with @) from the input stream and return it as a list with the _DEREF symbol and the following form.
8912	Reads a character literal from input stream, handling escape sequences like \n, \t, \uXXXX, and single characters. Returns the actual character value after processing escape sequences.
8913	Reads a regex reader macro from the input stream and returns a compiled regex pattern, raising SyntaxError for invalid syntax.
8914	Function `_read_reader_macro` parses and evaluates reader macros from an input stream, handling various macro types like set literals, function literals, quoted symbols, regular expressions, comments, and data readers, raising SyntaxError for unexpected tokens.
8915	Read the next full form from the input stream, consuming any reader comments completely.
8916	Read the next full form from the input stream, handling various token types including lists, vectors, maps, numbers, keywords, strings, quoted forms, characters, symbols, reader macros, metadata, comments, and syntax-quoted forms.
8917	Reads Lisp expressions from a stream, yielding parsed forms while handling comments and optional custom data readers and namespace resolution.
8918	Reads a string as a Lisp expression and yields parsed forms.

This function takes a string containing Lisp expressions and parses them into reader forms. It uses an in-memory buffer to simulate reading from a file-like object, then delegates to the main `read` function for the actual parsing. The function supports optional resolver and data reader functions, as well as EOF handling configuration. It returns an iterable of ReaderForm objects representing the parsed Lisp expressions found in the input string.
8919	Reads a file and yields Lisp expressions from its contents using the basilisp reader.
8920	Updates internal line and column buffers when adding a new character, resetting column to 0 for new lines and incrementing appropriately for regular characters.
8921	Pushes one character back onto the stream, allowing it to be read again. Raises IndexError if pushback depth is exceeded.
8922	Advance the stream forward by one character and return the next token in the stream.
8923	Return the bytes for a Basilisp bytecode cache file.
8924	Extracts and validates Basilisp bytecode from cached data, raising exceptions for magic number, timestamp, or size mismatches.
8925	Returns the path to the cached .lpyc file for a given source file path, creating the appropriate cache file name by replacing the source extension with .lpyc.
8926	Hook into Python's import machinery with a custom Basilisp code importer to enable using standard `import module.submodule` syntax for Basilisp code.
8927	Find the ModuleSpec for the specified Basilisp module, returning None if not found to allow import processing to continue.
8928	Load and execute a cached Basilisp module by retrieving cached data, verifying bytecode integrity, and compiling the bytecode into the provided module.
8929	Load and execute a non-cached Basilisp module, including reading and compiling the module forms, collecting bytecode for caching, and storing the compiled bytecode to a cache file.
8930	Compile a Basilisp module into Python code through incremental form-by-form compilation, handling caching and namespace management while avoiding circular import issues.
8931	Create a new symbol with the given name, namespace, and metadata.
8932	Return an iterable of possible completions for the given text by filtering keywords based on namespace and name prefixes.
8933	Private swap function that either retrieves an interned keyword instance from cache or creates a new one if it doesn't exist. Returns the updated cache mapping hash keys to keyword instances.
8934	Creates a new keyword with the given name and namespace, using a cache to ensure uniqueness. Returns the keyword object.
8935	Chain a sequence of generated Python ASTs into a tuple of dependency nodes and their corresponding AST nodes.
8936	Generate recursive Python AST Attribute nodes for resolving nested names by splitting the attribute path and building nested Attribute nodes.
8937	Wrap simpler AST generators to return a GeneratedPyAST.
8938	Converts an iterable of Lisp forms into Python AST nodes by mapping each form to its AST representation and chaining the results into two PyASTStream objects.
8939	Hydrates Generated Python AST nodes with line numbers and column offsets from the node environment. If line or column information exists in the environment, it sets the corresponding attributes on the AST node and optionally propagates these values to dependent nodes when include_dependencies is True. Returns the updated AST node.
8940	Wrap a generator function in a decorator to supply line and column information to the returned Python AST node, without hydrating dependency nodes.
8941	Wrap a generator function in a decorator to supply line and column information to the returned Python AST node and dependency nodes, where dependency nodes are included only if they are new nodes created in the same function.
8942	Returns True if the Var holds a value that should be compiled to a dynamic Var access, by checking for SYM_DYNAMIC_META_KEY in the variable's metadata.
8943	Return True if the Var can be redefined based on its metadata, otherwise False.
8944	Transforms non-statement AST nodes into ast.Expr nodes so they can stand alone as statements. Returns the original node if it's already a statement type, otherwise wraps it in an Expr node.
8945	Creates a function AST node from a series of expression AST nodes that returns the result of the final expression. This bridges Python's statement/expression mismatch by wrapping expressions in a callable function structure.
8946	Return True if the compiler should emit a warning about a name being redefined, considering various conditions including explicit no-warning flags, existing definitions in the current namespace, and variable binding status.
8947	Returns a Python AST node for a `do` expression by generating AST for statements and return value, then creating an assignment to store the result.
8948	Generate a safe Python function name from a function name symbol by prefixing with "__" and applying munge transformation, using a default prefix if no symbol is provided.
8949	Convert function parameters to Python AST nodes, handling regular arguments and variadic arguments, while generating corresponding AST for function body including argument collection for variadic parameters.
8950	Converts a single-arity function node into a Python AST representation, handling function definition, arguments, decorators, and recursion support.
8951	Generates a Python AST for a function with multiple arities, creating separate AST nodes for each arity and a dispatch function to route calls to the appropriate implementation.
8952	Returns a Python AST node for a `fn` expression, handling both single-arity and multi-arity function cases.
8953	Generate custom `if` nodes to handle `recur` bodies. Recur nodes can appear in then and else expressions of `if` forms and generate Python `continue` statements, which must be handled specially to avoid insertion into expression AST slots. Handles recur nodes by converting them to Python AST, processes DO nodes with synthetic conversion, and handles other nodes by generating standard Python AST with assignment to result name.
8954	Generate Python AST for an if statement that assigns to a temporary variable and handles Basilisp's truthiness rules by checking against None and False values. The function creates a short-circuit OR comparison to evaluate the test condition, with switched then/else bodies for efficiency. Returns a GeneratedPyAST containing the result variable name and all dependencies including the test assignment and if statement.
8955	Returns a Python AST node representing a Basilisp function invocation by generating AST nodes for the function and its arguments, then combining them into a Call AST node.
8956	Returns a Python AST Node for a `quote` expression by converting the quoted expression to a Python AST node.
8957	Generate a Python AST node for a recur expression within a loop, creating assignments for the recursive bindings and a continue statement.
8958	Returns a Python AST Node for a `recur` expression, handling recur nodes that can only legally appear in :then/:else expressions in :if nodes or :ret expressions in :do nodes. The function asserts that a recur point exists and has a corresponding handler, then marks the recur point as having a recur and returns the result of the appropriate handler function.
8959	Generate a Python AST node for a `set!` expression that assigns a value to a target (HostField, Local, or VarRef) using a temporary variable for the value.
8960	Returns a Python AST node for a `throw` expression by generating a function that raises the exception and returns a Call AST node that references this function. The generated function contains the exception expression as a dependency and a raise statement with the exception as its operand.
8961	Converts a Try node into a Python AST representation with proper handling of try-except-finally blocks, including generating unique names for try expressions and properly structuring the AST with dependencies and catch handlers.
8962	Generate a Python AST node for accessing a locally defined Python variable, handling both regular local variables and field-type locals that require 'this' context.
8963	Generate Var.find calls for the named symbol by creating a PyAST node that represents a method call to find a variable with the given name and namespace.
8964	Generate a Python AST node for accessing a Var, using direct access when possible or Var.find indirection when necessary based on dynamic/redef flags or compiler options.
8965	Generate a Python AST node for Python interop property access, handling both reading and assigning contexts.
8966	Generate a Python AST node for accessing a potential Python module variable name by looking up the class name in _MODULE_ALIASES or using the class name directly if not found.
8967	Generate a Python AST node for accessing a potential Python module variable name with a namespace.
8968	Generate Python AST nodes for constant Lisp forms, handling nested values in collections by recursively calling this function for nested elements, with specific handlers for different constant types including sequences.
8969	Convert quoted collection literals of Lisp forms into Python AST nodes containing only constant values.
8970	Generate Python AST nodes from Lisp AST nodes by dispatching to registered handlers based on the operation type.
8971	Generate Python Import AST nodes for importing all required language support modules, including a base import of "basilisp" and additional imports for context imports with optional aliases.
8972	Generate an `ast.ImportFrom` node to import the `Var` class from `basilisp.lang.runtime` module with a specific alias.
8973	Creates an AST assignment node that assigns a Python variable to the current namespace value by calling a find variable function with a newly created symbol.
8974	Creates a new set from iterable members with optional metadata.
8975	Creates a new set from the provided members with optional metadata.
8976	This method processes an `ExceptHandler` AST node to eliminate dead code from its body. It performs a generic visit to process child nodes, then creates a new `ExceptHandler` node with the same type and name but with a filtered body that excludes dead code, preserving the original node's location information.
8977	This method removes no-op constant expressions that appear as standalone statements in the AST. It checks if an expression node contains only constant values (like literals, names, or numbers) and returns None to eliminate it, otherwise returns the original node.
8978	Visits a function definition node and eliminates dead code from its body while preserving the function's structure and metadata.
8979	Eliminates dead code from while loop bodies by filtering out unreachable statements while preserving the loop structure and location information.
8980	Eliminates dead code from try-except bodies by filtering out unreachable statements while preserving the original AST structure and location information.
8981	Create a new empty Basilisp Python module with specified name and documentation, setting required module attributes including __loader__, __package__, __spec__, and __basilisp_bootstrapped__ flags.
8982	Returns the first element from an ISeq, None if input is None, or coerces input to a Seq and returns its first element.
8983	Returns the elements after the first in a sequence. If input is None, returns an empty sequence. If input is already a sequence, returns its rest. Otherwise, converts input to sequence and returns its rest.
8984	Returns the nth rest sequence of coll, or coll if i is 0. Uses a while loop to iteratively apply rest() function i times, returning None if coll becomes None before reaching the desired rest level.
8985	Returns the nth next sequence of coll, where n is the index i. Traverses the collection sequentially, decrementing i at each step until reaching the desired index. Returns None if the collection is exhausted or is None. Converts the final result to a sequence using to_seq().
8986	Creates a new sequence with element 'o' as the first element and 'seq' as the rest. If 'seq' is None, returns a list containing only 'o'. If 'seq' is not an ISeq, attempts to convert it to an ISeq before consing 'o' onto it.
8987	Converts an object to an ISeq. Returns None if the object is None. If the object is already an ISeq, returns it (or None if empty). If the object implements ISeqable, calls its seq() method. Otherwise, converts the object to a sequence using lseq.sequence().
8988	Concatenate the sequences given by seqs into a single ISeq. Filters out None values and converts sequences to a common type before chaining and returning the result. Returns an empty sequence if no valid sequences are provided.
8989	Associates keys with values in an associative data structure. If the input is None, creates a new Map with the given key-value pairs. If the input implements the IAssociative interface, calls its assoc method. Otherwise, raises a TypeError indicating the object doesn't support associative operations.
8990	Conjoins elements to a collection, returning the same type as the input collection. If the collection is None, returns a new list with the elements conjoined. Raises TypeError if the input doesn't implement the Collection interface.
8991	Returns a partially applied function where some arguments are pre-filled, allowing for function customization by fixing certain parameters while leaving others to be specified later.
8992	Dereference a Deref object and return its contents, with optional timeout support for IBlockingDeref objects.
8993	Compares two objects by value with strict type checking. Returns True if objects are equal and have the same type, False otherwise. Unlike Python's standard equality operator, it treats True and 1, or False and 0, as unequal. Uses Python's == operator for all other comparisons.
8994	Division reducer. If both arguments are integers, return a Fraction. Otherwise, return the true division of x and y.
8995	Return a sorted sequence of the elements in coll, optionally using a comparator function f for custom ordering.
8996	Return true if collection contains the key k. Handles both IAssociative objects (using their contains method) and regular collections (using membership test).
8997	Return the value of key k in mapping m, or default if k is not found. Uses entry() method for IAssociative objects, otherwise attempts direct key access with fallback to default on KeyError, IndexError, or TypeError.
8998	Converts Python collections (dict, frozenset, list, set, tuple) into Lisp collections recursively, with optional keywordization of dictionary keys. For non-collection types, returns the object unchanged.
8999	Convert Lisp collections to Python collections recursively, handling sequences and persistent data structures.
9000	Produces a string representation of an object with optional human-readable formatting, using core namespace variables for print settings like print_dup, print_length, print_level, print_meta, and print_readably.
9001	Collect Python starred arguments into a Basilisp list, raising TypeError if args is not a tuple.
9002	A trampoline decorator that repeatedly executes a function until it finishes recursing, preventing stack growth by using a loop instead of deep recursion.
9003	A decorator factory that creates a decorator to set arbitrary attributes on a function. Returns the original function with the specified attributes applied.
9004	Return a new function with the given meta information, merging with existing meta if present. Supports both regular and coroutine functions, preserving the original function's metadata and adding a `with_meta` method to create functions with updated metadata.
9005	Creates a Basilisp function with meta data support and a with_meta method implementation.
9006	Resolve an aliased symbol within a namespace by checking for special forms, resolving namespace aliases, or finding the symbol in the current namespace.
9007	Resolves an aliased symbol to a Var from the specified namespace, returning the Var if found or None if not found.
9008	Adds generated Python code to a dynamic variable in the specified namespace, creating the variable if it doesn't exist.
9009	The `bootstrap` function initializes a Lisp environment by setting up essential namespaces and dynamic variables. It retrieves or creates a namespace, binds core symbols like `unquote` and `unquote-splicing`, and defines the `in-ns` function to switch namespaces. It also sets up dynamic variables for controlling printing behavior, such as `_PRINT_GENERATED_PY_VAR_NAME`, `_GENERATED_PYTHON_VAR_NAME`, and various print-related configuration variables (`PRINT_DUP`, `PRINT_LENGTH`, etc.). These configurations enable the Lisp environment to handle code generation and printing with appropriate controls.
9010	Interns a value bound to a symbol in a namespace, creating a new Var if it doesn't exist or returning the existing one. The var's root value is set to the provided value.
9011	Create a new unbound Var instance for a symbol in a specified namespace.
9012	Return the value currently bound to the name `name_sym` in the namespace specified by `ns_sym`, or None if the namespace doesn't exist or the name is not found.
9013	Returns the Var currently bound to the name in the namespace specified by `ns_qualified_sym`, or None if not found. Raises ValueError if no namespace is specified in the symbol.
9014	Return the Var currently bound to the name in the namespace specified by `ns_qualified_sym`, raising a RuntimeException if no Var is bound to that name.
9015	Add a gated default import to the default imports if the module is in GATED_IMPORTS, avoiding early import of 'basilisp.core' before macro-expansion completion.
9016	Add a Symbol alias for the given Namespace by updating the aliases mapping with the new alias-namespace pair.
9017	Interns a Var in the namespace using the given Symbol as key. Returns the Var that was interned, which may be the existing Var if the Symbol already maps to one and force=False.
9018	Swaps function used by intern to atomically intern a new variable in the symbol mapping for this Namespace. If the symbol doesn't exist in the map or force is True, it associates the new variable with the symbol; otherwise, it returns the original map unchanged.
9019	Find Vars mapped by the given Symbol input or None if no Vars are mapped by that Symbol.
9020	Adds a symbol as an imported symbol in this namespace, optionally with aliases. If aliases are provided, they will be mapped to the original symbol.
9021	Return the module if a module named by sym has been imported into this Namespace, None otherwise. First tries to resolve a module directly with the given name. If no module can be resolved, attempts to resolve the module using import aliases.
9022	Add a symbol-variable reference to the namespace, associating the symbol with the variable if the variable is not private.
9023	Get the Var referred by Symbol or None if it does not exist.
9024	Refer all public interns from another namespace into the current namespace.
9025	Refer all variables from another namespace into this namespace.
9026	Private atomic swap function that retrieves an existing namespace from cache or creates a new one, ensuring the core namespace is referenced when creating non-core namespaces.
9027	Get or create a namespace bound to the given symbol in the global namespace cache. Creates the namespace if it doesn't exist and returns the namespace object.
9028	Get the namespace bound to the symbol `name` in the global namespace cache. Return the namespace if it exists or None otherwise.
9029	Remove a namespace bound to a symbol from the global namespace cache and return it, or None if it doesn't exist. Uses compare-and-set for thread-safe removal.
9030	Returns a function that matches symbol keys against given text by checking if the symbol's name starts with the specified text.
9031	Return an iterable of possible completions matching the given prefix from the list of aliased namespaces. If name_in_ns is given, further refine the list to matching names in that namespace by yielding formatted strings with the prefix and matching names. Otherwise, yield formatted strings with the alias and trailing slash.
9032	Return an iterable of possible completions matching the given prefix from the list of imports and aliased imports. If name_in_module is given, further refine the list to matching names in that namespace.
9033	Returns an iterable of possible completions matching the given prefix from the list of interned Vars, optionally filtering out private variables.
9034	Return an iterable of possible completions matching the given prefix from the list of referred Vars.
9035	Return an iterable of possible completions for the given text in this namespace, handling both prefixed and non-prefixed completion cases by chaining together results from various completion methods.
9036	Return the arguments for a trampolined function, with special handling for varargs by unrolling the final argument if it is a sequence.
9037	Creates a new List object from an iterable of members with optional metadata.
9038	Creates a new list from the provided members with optional metadata.
9039	This function creates a custom representer that applies a specific style to scalar values during YAML serialization, preserving line breaks while formatting the output according to the specified style.
9040	This function decrypts a JWE token, decodes the resulting JWT token, and returns the payload. It first validates that the token has the correct number of components, then decrypts the JWE token using the provided key store and purpose, and finally decodes the JWT token with the specified leeway for expiration time.
9041	Encrypts JSON data using JWE encryption and returns a JWE token by:
1. Getting a private key for the specified purpose and type
2. Encoding the JSON payload using JWT helper with the private key
3. Getting a public key for the specified purpose and type
4. Encrypting the encoded payload using JWE helper with the public key
9042	Remove the key from the request cache and from memcache.
9043	Deconstructs the ``Constraint`` instance to a tuple containing the selector, mapped comparison operator, and argument.
9044	Close the stream by writing EOF if possible, then close the writer.
9045	Parse a FIQL formatted string into an Expression object, handling nesting levels and validating syntax constraints. Raises FiqlFormatException for invalid formatting or unmatched parentheses.
9046	Custom JSON dump function that uses a custom encoder to serialize an NDB model object and write it to a file pointer.
9047	Handles decoding of nested date strings by iterating through key-value pairs and decoding dates recursively.
9048	Tries to decode strings that look like dates into datetime objects, handling UTC timezone offsets by removing timezone info for GAE compatibility. Returns the parsed datetime object if successful, otherwise returns the original value.
9049	Overrides the default decode method to first attempt date decoding, falling back to the default JSON decoder if no date conversion occurs.
9050	Override the default JSONEncoder.default method to add NDB model support by checking for NDB types and using appropriate encoding functions.
9051	Validate version before release by checking if all version components are integers. Returns the version string if valid, None otherwise.
9052	Generate changelog for a specified version using ChangelogGenerator with predefined options.
9053	Find the strongly connected components in a graph using Tarjan's algorithm. The function takes a graph represented as a dictionary mapping node names to sequences of successor nodes and returns a list of tuples, where each tuple represents a strongly connected component. The algorithm uses depth-first search with a stack to track the traversal and identifies components by maintaining low-link values for each node.
9054	Returns a topological sort of the strongly connected components in a graph by first identifying the components and then sorting them.
9055	Sets the parent Expression for this object, validating that the parent is of type Expression. Raises FiqlObjectException if validation fails.
9056	Get the parent ``Expression`` for this object.

Returns:
    Expression: The ``Expression`` which contains this object.

Raises:
    FiqlObjectException: Parent is ``None``.
9057	Add an Operator to the Expression, handling precedence rules that may require creating nested expressions or returning parent expressions. Returns self or related Expression based on operator precedence relationships.
9058	Adds an element (Operator, Constraint, or Expression) to the Expression's working fragment, setting the element's parent and appending it to the elements list. Returns self for chaining. Raises FiqlObjectException if element is not a valid type.
9059	Update the ``Expression`` by joining the specified additional ``elements`` using an "AND" ``Operator``

Args:
    *elements (BaseExpression): The ``Expression`` and/or ``Constraint`` elements which the "AND" ``Operator`` applies to.

Returns:
    Expression: ``self`` or related ``Expression``.
9060	Updates the Expression by joining specified elements using an "OR" operator, returning the updated expression.
9061	A decorator function that adds logging capability to any passed-in function. It logs the arguments passed to the decorated function using the module's logger at debug level, then executes and returns the original function's result. The logging behavior can be customized with 'sep' and 'end' keyword arguments similar to Python's built-in print function.
9062	Parse received response by removing null bytes, splitting into messages, and converting each message to an OrderedDict.
9063	Convert a list of tuples into an OrderedDict, where both keys and values are converted to strings.
9064	Check if a specific message is present in a list of messages based on command and optional value.

Parameters:
- msgs: List of message dictionaries to search through
- cmd: Command string to look for in messages
- value: Optional value to match against the command (if None, only checks for command existence)

Returns:
- OrderedDict: The first message matching the criteria, or None if no match found

The function searches through msgs and returns the first message where:
- If value is provided: msg[cmd] equals value
- If value is None/Falsey: msg[cmd] exists (is truthy)
9065	Prepare message to be sent by adding prefix to commands. If commands are bytes, prepend prefix_bytes; otherwise, convert tuples to bytes with prefix. Returns the prepared message string.
9066	Flush incoming socket messages by continuously receiving and discarding data until a socket error occurs.
9067	Enable a given scan field with specified slide, well coordinates, and field coordinates.
9068	Save scanning template to the specified filename using the 'save' command and wait for confirmation.
9069	Load a scanning template from a file and return the response from LASAF as an ordered dictionary. The filename can include a path and will automatically have '.xml' stripped if present. If the '{ScanningTemplate}' prefix is omitted, it will be added automatically. The method sends a load command to LASAF and waits for the response.
9070	Get information about a specified keyword (defaults to 'stage') by sending a command and waiting for the response.
9071	Include a Python source file in a docstring formatted in reStructuredText, specifying line ranges to include. Supports custom source directory and output function pointer for debugging.
9072	Find and return the location of package.json by checking the SYSTEMJS_PACKAGE_JSON_DIR setting, raising ImproperlyConfigured if not found or invalid.
9073	Extracts JSPM configuration from package.json by reading and parsing the file located via locate_package_json().
9074	Handle YOURLS API errors by parsing JSON responses and raising appropriate custom exceptions based on error codes, falling back to generic HTTP errors if no specific code is found.
9075	Validate response from YOURLS server, handling HTTP errors and API response validation, including specific error types like keyword exists and URL exists errors.
9076	Generate combined independent variable vector from two waveforms and return the independent vector along with interpolated dependent vectors from both waveforms.
9077	This function creates a new dependent variable vector by interpolating values from an existing wave based on specified interpolation and scaling methods. It handles three interpolation types (continuous with log/linear scaling, or staircase) and preserves the original data type of the dependent vector. The function also ensures proper rounding for integer data types and handles edge cases for the last data point in staircase interpolation.
9078	Create a new independent variable vector by finding the overlapping range between two wave vectors and combining their unique values within that range.
9079	Verifies that two waveforms are compatible for mathematical operations by comparing their independent and dependent scales, units, and interpolation methods. Raises RuntimeError if any compatibility checks fail.
9080	Load the SystemJS manifest file, remove any non-existent entries from it, and return the cleaned manifest.
9081	Define trace parameters including file paths and configuration options for a given module name.
9082	Run module tracing for specified test file and return documentation object.
9083	Shortens a URL with optional custom keyword and title. Returns a ShortenedURL object containing the shortened URL and associated data. Supports custom keywords (auto-generated if not provided) and optional title extraction from the web page. Raises various exceptions for duplicate keywords, existing URLs, missing URLs, loop attempts, API errors, and HTTP errors. Uses the YOURLS API for URL shortening operations.
9084	Expands a short URL or keyword into its original long URL by making an API request to the YOURLS service. Takes a short URL or keyword as input and returns the corresponding long URL. Raises HTTP-related exceptions if the API request fails.
9085	Get statistics for a short URL or keyword by making an API request and returning the parsed shortened URL data.
9086	Get statistics about links with specified filter and limit.

Parameters:
    filter: 'top', 'bottom', 'rand', or 'last'
    limit: Number of links to return from filter
    start: Optional start number

Returns:
    Tuple containing list of ShortenedURLs and DBStats

Raises:
    ValueError: Incorrect value for filter parameter
    requests.exceptions.HTTPError: Generic HTTP Error
9087	Get database statistics including total clicks and links count.

Returns:
    DBStats: Object containing total_clicks and total_links statistics

Raises:
    requests.exceptions.HTTPError: Generic HTTP Error when API request fails
9088	Echo terminal output by executing a Bash command and formatting the output in reStructuredText format with specified indentation and directory context.
9089	Prints the output of a Bash shell command in reStructuredText format with syntax highlighting and proper indentation. It supports environment variable substitution, handles Python script execution on Windows, and allows customization of indentation, output function, and window width.
9090	A logging helper method that writes messages to stdout based on verbosity level.
9091	A decorator that creates a cached property. When the decorated method is first accessed, its result is computed and stored as an instance attribute (prefixed with underscore). Subsequent accesses return the cached value instead of re-computing the result.
9092	Break an iterable into chunks of specified size and yield them as lists until exhausted.
9093	A decorator that wraps a function to process iterables in chunks. Takes an iterable and processes it by breaking it into smaller chunks of specified size, then applies the wrapped function to each chunk and yields results as an iterator.
9094	Recursively flattens nested iterable objects, yielding individual elements while preserving strings as single items.
9095	Adds a SIGINT handler that exits gracefully with an optional message, preventing stacktrace display when stopping scripts.
9096	Prints an iterable of iterables in TSV (Tab-Separated Values) format, where each inner iterable is printed as a row with elements separated by tabs.
9097	Create a dummy object with a custom name for its string representation.
9098	Method to parse human-readable size strings into bytes, supporting both decimal (1000-based) and binary (1024-based) units with optional bit-to-byte conversion.
9099	Command line interface for YOURLS that accepts configuration parameters via command line switches or configuration files, supporting two authentication methods (API URL with signature or API URL with username/password), and initializes a YOURLSClient object with the provided parameters.
9100	Trace eng wave module exceptions by setting up tracing for the wave_core module with peng frontend, focusing on Waveform class __init__ method.
9101	Define Sphinx requirements links by reading from requirements.json file, sorting the dependencies, creating reference links with name and URL, wrapping the lines to specified width, and writing the output through mobj.
9102	Generate Python interpreter version entries for specified Python series (2.x or 3.x) by creating formatted strings that combine version prefix with requirement versions. Takes a list to append entries to, Python version number, suffix string, and required version specification, then formats and adds the combined entry to the provided list using helper function to convert operators to words.
9103	Generate Python interpreter version entries by iterating through package Python versions, formatting version strings, and appending formatted entries to a list using converted operation words from a version dictionary.
9104	Converts version requirement specifications into natural language words by parsing operators and translating them into readable text, while validating supported operators and raising errors for unsupported or illegal operators.
9105	Chunks input noise data into valid Touchstone file rows by zipping frequency, noise figure, reflection coefficient magnitude and angle, and resistance data, then yielding each row as a tuple of (frequency, noise figure, reflection coefficient magnitude, reflection coefficient angle, resistance).
9106	Chunks input data into valid Touchstone file rows based on frequency vector, data matrix, and format specification. Processes data in chunks of 4, converts complex data to magnitude/angle format according to specified format (MA, RI, or DB), and yields formatted rows for Touchstone file output.
9107	Writes a Touchstone file with the specified data, options, and optional noise data. Resizes and formats parameter data into scientific notation, and supports two-port noise data. Validates input parameters and raises RuntimeError for invalid inputs or malformed data.
9108	Add independent variable vector bounds to a waveform by ensuring the specified min and max values are included in the independent variable vector, then interpolate the dependent vector accordingly.
9109	Build unit math operations by combining dependent and independent units with the specified operator, handling edge cases where one or both unit sets are empty.
9110	Perform generic operation on a waveform object by creating a copy, updating dependencies and units, applying a function to the dependency vector, and returning the modified waveform.
9111	Calculate the running area under a curve by computing cumulative sum of rectangular and triangular areas between consecutive points.
9112	Validates that the given min and max bounds are within the waveform's independent variable vector range. If bounds are None, they are set to the first and last values of the independent vector respectively. Raises RuntimeError if the bounds are incongruent or outside the valid range, otherwise returns the validated bounds.
9113	Return the arc cosine of a waveform's dependent variable vector.

:param wave: Waveform
:type  wave: `peng.eng.Waveform`

:rtype: `peng.eng.Waveform`

:raises:
 * RuntimeError (Argument `wave` is not valid)

 * ValueError (Math domain error)
9114	Return the hyperbolic arc cosine of a waveform's dependent variable vector.

:param wave: Waveform
:type  wave: :py:class:`peng.eng.Waveform`

:rtype: :py:class:`peng.eng.Waveform`

:raises:
 * RuntimeError (Argument `wave` is not valid)
 * ValueError (Math domain error)
9115	Returns the arc sine of a waveform's dependent variable vector, performing domain validation to ensure all values are within [-1, 1]. Raises ValueError for math domain errors and RuntimeError for invalid input waveforms.
9116	Returns the hyperbolic arc tangent of a waveform's dependent variable vector. Raises RuntimeError if the wave argument is not valid, and ValueError if there's a math domain error (when values are outside the domain [-1, 1]).
9117	Returns the running average of a waveform's dependent variable vector within specified independent variable bounds.
9118	Convert a waveform's dependent variable vector to decibels. Returns a new waveform with the dependent variable expressed in dB, using the formula 20*log10(|x|). Raises ValueError for math domain errors (non-positive values) and RuntimeError for invalid input waveforms.
9119	Returns the numerical derivative of a waveform's dependent variable vector using backwards differences method. Takes a waveform object and optional independent variable range limits, then computes and returns the derivative waveform with updated metadata. Raises RuntimeErrors for invalid arguments or incongruent parameter combinations.
9120	Return the imaginary part of the Fast Fourier Transform of a waveform.
9121	Returns the magnitude of the Fast Fourier Transform of a waveform as a Waveform object. Supports optional parameters for transform points, and independent variable range filtering. Raises RuntimeError for invalid arguments or sampling issues.
9122	Return the phase of the Fast Fourier Transform of a waveform, with options for transform length, data range, phase unwrapping, and phase unit.
9123	Return the real part of the Fast Fourier Transform of a waveform.
9124	Returns the inverse Fast Fourier Transform of a waveform with dependent variables expressed in decibels. Supports optional parameters for transform point count and independent variable range.
9125	Return the imaginary part of the inverse Fast Fourier Transform of a waveform.
9126	Returns the magnitude of the inverse Fast Fourier Transform of a waveform.
9127	Return the phase of the inverse Fast Fourier Transform of a waveform.
9128	Returns the real part of the inverse Fast Fourier Transform of a waveform as a new waveform object.
9129	Return the running integral of a waveform's dependent variable vector using the trapezoidal method.
9130	Return the group delay of a waveform by computing the negative derivative of the normalized phase.
9131	Returns the natural logarithm of a waveform's dependent variable vector.

Parameters:
    wave (peng.eng.Waveform): Input waveform

Returns:
    peng.eng.Waveform: New waveform with natural logarithm applied to dependent variable

Raises:
    RuntimeError: If wave argument is not valid
    ValueError: If math domain error occurs (when minimum value in dependent vector is <= 0)
9132	Returns the numerical average of a waveform's dependent variable vector over a specified independent variable range using trapezoidal integration.
9133	Return the numerical integral of a waveform's dependent variable vector using the trapezoidal method.
9134	Return the maximum value of a waveform's dependent variable vector, optionally bounded by independent variable limits.
9135	Returns the minimum value of a waveform's dependent variable vector, optionally bounded by independent variable limits.
9136	Return the phase of a waveform's dependent variable vector, with options to unwrap phase shifts and specify radians or degrees output.
9137	Round a waveform's dependent variable vector to a given number of decimal places.

:param wave: Waveform to round
:type wave: :py:class:`peng.eng.Waveform`
:param decimals: Number of decimal places to round to
:type decimals: int
:returns: New waveform with rounded dependent variable vector
:rtype: :py:class:`peng.eng.Waveform`
:raises RuntimeError: If wave or decimals arguments are not valid
:raises TypeError: If waveform dependent vector contains complex numbers that cannot be converted to integer
9138	Returns the square root of a waveform's dependent variable vector.

Parameters:
    wave (peng.eng.Waveform): Input waveform

Returns:
    peng.eng.Waveform: New waveform with square root of dependent variable values

Raises:
    RuntimeError: If the wave argument is not valid

The function computes the square root of each value in the waveform's dependent variable vector and returns a new waveform with the results. The dependent variable units are updated to show the square root operation (e.g., "V**0.5" if original units were "V").
9139	Return a waveform that is a sub-set of a waveform, potentially re-sampled.
9140	Convert a waveform's dependent variable vector to complex type and return a copy of the waveform with the converted vector. Raises RuntimeError if the input waveform is not valid.
9141	Convert a waveform's dependent variable vector to float type, raising TypeError if conversion from complex numbers is attempted. Returns a copy of the waveform with converted dependent vector.
9142	Convert a waveform's dependent variable vector to integer type.

**Parameters:**
- `wave` (peng.eng.Waveform): Input waveform object

**Returns:**
- peng.eng.Waveform: New waveform with dependent variable vector converted to integer type

**Raises:**
- `TypeError`: Cannot convert complex to integer
- `RuntimeError`: Argument `wave` is not valid

**Notes:**
The function creates a copy of the input waveform and converts its dependent variable vector to integer dtype using numpy's astype() method. The original waveform remains unchanged.
9143	Return the dependent variable value at a given independent variable point using linear interpolation if necessary.
9144	Method `find` that restricts lookups to only 'jspm_packages' and `settings.SYSTEMJS_OUTPUT_DIR` directories. Returns empty list for paths outside these directories, otherwise delegates to parent class find method.
9145	Get first sentence of first paragraph of long description by parsing lines until end marker is found, then extracting the first sentence from the first paragraph.
9146	Builds a mathematical expression from a hierarchical list of tokens, handling numbers, unary operators, and multi-term operators with proper parentheses based on operator precedence.
9147	Return position of next matching closing delimiter by finding the first item greater than pos, removing it from items, and returning it. Raises RuntimeError if no matching delimiter is found.
9148	Parse function calls from an expression by identifying delimited pairs and extracting function names, expressions, and positions.
9149	Pairs left and right delimiters in an expression by finding their positions and creating tuples of corresponding pairs, processing from right to left.
9150	Parse mathematical expression using PyParsing with custom delimiters.
9151	Remove consecutive delimiters from an expression by identifying and eliminating superfluous consecutive delimiters, then return the modified expression.
9152	Split a string into groups of words using a specified separator count as delimiter, with optional whitespace stripping from left and right ends of each group.
9153	Convert a number to engineering notation and return its mantissa and exponent as a tuple.
9154	Convert a number to a string without scientific notation. If the number is already in non-scientific format, return its string representation. For scientific notation numbers, convert them back to decimal format by adjusting the mantissa and exponent. Handle both integer and floating-point numbers appropriately, ensuring no scientific notation is present in the result.
9155	Convert a number to engineering notation with specified fractional digits and justification.
9156	Converts a number in engineering notation to its floating point equivalent.

This function takes a number represented in engineering notation and returns its decimal floating point value. It handles the conversion by looking up the appropriate power multiplier based on the suffix character (like 'k', 'M', 'G') or uses 10^0 for numbers without suffixes. The function is optimized for performance by directly accessing the power dictionary rather than using separate mantissa and power functions.

Args:
    snum: A number in engineering notation format
    
Returns:
    float: The decimal floating point equivalent of the engineering notation number
    
Example:
    >>> import peng
    >>> peng.peng_float(peng.peng(1235.6789E3, 3, False))
    1236000.0
    
Raises:
    RuntimeError: If the input snum parameter is not valid
9157	Return the fractional part of a number represented in engineering notation.

**Parameters:**
- `snum`: Number in engineering notation format

**Returns:**
- Integer representing the fractional part

**Example:**
```python
>>> import peng
>>> peng.peng_frac(peng.peng(1235.6789E3, 3, False))
236
```

**Raises:**
- RuntimeError: If the argument `snum` is not valid

The function extracts the fractional part after the decimal point from an engineering notation number string, returning 0 if no decimal point exists.
9158	Return the mantissa of a number represented in engineering notation.

Parameters:
    snum: Number represented in engineering notation

Returns:
    float: The mantissa value of the engineering notation number

Example:
    >>> import peng
    >>> peng.peng_mant(peng.peng(1235.6789E3, 3, False))
    1.236
9159	Returns the engineering suffix and its floating point equivalent for a given engineering notation number.

**Parameters:**
- `snum`: EngineeringNotationNumber - The number to process

**Returns:**
- Named tuple with two items: the engineering suffix and the floating point equivalent of the suffix in engineering notation

**Example:**
```
>>> import peng
>>> peng.peng_power(peng.peng(1235.6789E3, 3, False))
EngPower(suffix='M', exp=1000000.0)
```

**Raises:**
- RuntimeError: If the snum argument is not valid
9160	Return engineering suffix from a starting suffix and an number of suffixes offset. For example: `peng.peng_suffix_math('u', 6)` returns `'T'`.
9161	Remove unnecessary delimiters from mathematical expressions by handling consecutive delimiters and implied delimiters based on operator precedence rules. The function validates input expressions and delimiters, ensuring proper formatting and matching parentheses. It recursively processes the expression to eliminate redundant delimiters while preserving valid mathematical syntax.
9162	Convert a number to scientific notation string with specified formatting options.
9163	Convert a number to scientific notation and return its mantissa and exponent as a named tuple. The function handles integers, floats, and strings, preserving full precision when the number is provided as a string. It returns a tuple with the mantissa (as a string) and exponent (as an integer). For example, `to_scientific_tuple('135.56E-8')` returns `NumComp(mant='1.3556', exp=-6)`.
9164	Finds and removes a source map comment from the end of a file. Reads the file in reverse blocks to efficiently locate the comment, then truncates the file at the comment's start position. Returns the source map comment string if found, otherwise returns None.
9165	Check whether `self.app` is missing the '.js' extension and if it needs it based on `settings.SYSTEMJS_DEFAULT_JS_EXTENSIONS`.
9166	Bundle the app and return the static url to the bundle, handling minification, source maps, and system imports.
9167	Trace dependencies for the given app using a cached approach to avoid expensive re-tracing. Executes a subprocess command "trace-deps.js" with the app as parameter, captures stdout and stderr, raises TraceError if there's an error, and caches the JSON result in _trace_cache for future use. Returns the cached result if app already traced, otherwise executes the trace and stores the result.
9168	Compares application dependency tree file hashes with cached hashes and returns True if all match, False otherwise.
9169	Convert a bytes object to a hexdump format with offset, hexadecimal values, and ASCII representation.
9170	Parse a docstring into ParameterInfo and ReturnInfo objects.
9171	Get a list of all valid identifiers for the current context.

Returns:
    list(str): A list of all of the valid identifiers for this context
9172	Lazily loads a callable from a module by performing a deferred import to optimize startup time. Takes an `add_action` string in the format "module_path,object_name" and returns the imported object. If no object is specified, it extracts the context from the module. Raises `ArgumentError` if the specified object doesn't exist in the module.
9173	Split a line into arguments using shlex and a dequoting routine.
9174	Check if the current context matches any initialization command patterns, and if so, execute those commands to initialize the context before proceeding with other commands. Temporarily disable interactive mode during initialization to avoid cluttering output with return values.
9175	Return help information for a context or function, showing available functions when no arguments are provided, specific function help when one argument is given, or an error message when too many arguments are provided.
9176	Find a function in the given context by name, searching builtins first and then the context. Returns the found function or raises NotFoundError if not found.
9177	Return a formatted listing of all functions in the given context including builtins, showing their signatures and descriptions.
9178	Check if an argument is a flag. A flag starts with - or -- followed by a letter, numbers, - or _. Returns True if the argument is a flag, False otherwise.
9179	Process command line arguments into positional and keyword arguments for a function, handling both short and long form flags, boolean flags, and type-aware argument parsing.
9180	Extracts and returns the value for a keyword argument from remaining arguments, handling special cases for boolean types and missing values.
9181	Invoke a function from the current context using command line arguments, handling type conversion and context management. Returns the function's return value, remaining arguments, and context state.
9182	Invokes one or more functions using command line arguments, converting string parameters to appropriate Python types based on context and type annotations. Returns a boolean indicating if the last function created a new context and any remaining command line arguments.
9183	Parse and invoke a string line by splitting it into arguments and executing the corresponding command. Returns a boolean indicating if a new context was created and any remaining command line arguments.
9184	Parse a single typed parameter statement from a docstring, extracting the parameter name, type, and optional description. Raises ValidationError for invalid declarations or malformed type strings. Returns a tuple of (param_name, ParameterInfo) where ParameterInfo contains the type and description.
9185	Parses a return statement declaration from a docstring, extracting the return type, formatting information, and description. Handles three formats: standard type description, 'show-as' with 'string' or 'context' formatting, and 'format-as' with custom formatter. Returns a ReturnInfo object containing the parsed components, raising ValidationError for invalid declarations or unknown formatting specifiers.
9186	Method `_classify_section` attempts to find the canonical name of a section by checking if the lowercase section name matches predefined sets of keywords. It returns the corresponding section type constant (ARGS_SECTION, RETURN_SECTION, or MAIN_SECTION) if a match is found, otherwise returns None.
9187	Classify a line into different object types based on its content and formatting patterns. Returns BlankLine for empty lines, SectionHeader for lines ending with colon, ContinuationLine for lines starting with double spaces, ListItem for lines starting with dash prefixes, and Line for all other lines.
9188	Join adjacent lines into paragraphs using either blank lines or indentation as separators, handling leading and trailing blanks as specified.
9189	Wrap, format and print this docstring for a specific width.

Args:
    width (int): The number of characters per line.  If set to None
        this will be inferred from the terminal width and default
        to 80 if not passed or if passed as None and the terminal
        width cannot be determined.
    include_return (bool): Include the return information section
        in the output.
    include_params (bool): Include a parameter information section
        in the output.
    excluded_params (list): An optional list of parameter names to exclude.
        Options for excluding things are, for example, 'self' or 'cls'.
9190	Converts a value to the specified type, handling binary data conversion and validation. Takes a value, type name, and optional conversion keyword arguments, returning the converted value or raising a ValidationError if conversion fails.
9191	Convert binary data to the specified type by validating size and calling the type's convert_binary method. Raises ArgumentError if size is incorrect or type doesn't support binary conversion.
9192	Get the size of a given type for hex string conversion. Returns the size if known, otherwise returns 0.
9193	Format a value according to type and format specification, converting the value to the specified type and applying the appropriate formatting function.
9194	Validate that a type object has the required methods (convert or convert_binary and default_formatter). Raises ArgumentError if validation fails.
9195	Check if a type is known to the type system.

Returns:
    bool: True if the type is a known instantiated simple type, False otherwise
9196	Split a complex type into its base type and specializers, handling parentheses-separated subtype information.
9197	Instantiate a complex type by validating the base type and subtypes, then building and injecting the type into the system.
9198	Return the type object corresponding to a type name, loading external types if necessary. Handles common abbreviations ('int', 'str', 'dict') by canonicalizing to standard type names ('integer', 'string', 'basic_dict'). First checks known types, then attempts to instantiate complex types from type factories. If type is still unknown, iterates through lazy type sources (entry points and callables) to load external types until the requested type is found or all sources are exhausted. Raises ArgumentError if type cannot be resolved after loading all external sources.
9199	Check if a given format is valid for a specified type by verifying if the type object has the corresponding format attribute. Returns True if the format is known/valid for the type, False otherwise.
9200	Add a module-like object defining a type to the type system for use with iotile tool and annotated API functions. Validates the type and handles both simple types and complex type factories, ensuring types are not already defined and have the required default_formatter attribute.
9201	Loads all public symbols from a module and attempts to inject them as types, skipping any that raise ArgumentError.
9202	Check if enough arguments are provided to call the function based on required positional and keyword arguments.

Args:
    pos_args (list): List of positional argument values available
    kw_args (dict): Dictionary of keyword arguments available

Returns:
    bool: True if sufficient arguments provided, False otherwise
9203	Add type information for a parameter by name, including its type, validators, and optional description. Raises TypeSystemError if annotation is specified multiple times for the same parameter or for an unknown parameter.
9204	Add type information to the return value of this function.

Args:
    type_name (str): The name of the type of the return value.
    formatter (str): An optional name of a formatting function specified for the type given in type_name.

Returns:
    None: Sets the return_info attribute with a new ReturnInfo object containing the type name, formatter, and other parameters.
9205	Sets up a custom return value printer function that converts return values to strings for display purposes.
9206	Try to convert a prefix into a parameter name by matching against available argument names, considering filled arguments. Raises ArgumentError if no match or multiple matches found. Returns the full matching parameter name.
9207	Get the parameter type information by name.

Args:
    name (str): The full name of a parameter.

Returns:
    str: The type name or None if no type information is given.
9208	Return the function signature as a formatted string, using either the default name or a custom name if provided, with type annotations and default values for arguments.
9209	Formats the return value of a function as a string using type information or a custom formatter.

Args:
    value (object): The return value to format

Returns:
    str: The formatted return value, or None if function doesn't return data

The method first ensures the function is loaded, then checks if it returns data. If the return value has a type name, it uses the type system to format it. Otherwise, it applies the function's custom formatter callable to convert the value to a string. Returns None if the function indicates it does not return data.
9210	Convert and validate a positional argument by skipping 'self' for bound methods and using the argument name to convert the value.
9211	Check if there are any missing or duplicate arguments in the provided positional and keyword arguments, and return a dictionary of argument names to their values. Raises ArgumentError for too many positional arguments or missing required arguments, and ValidationError for duplicate arguments.
9212	Converts and validates an argument value based on its type information and defined validators.

This method takes an argument name and value, retrieves the expected type from parameter metadata, converts the value to that type using the type system, and then runs all specified validators on the converted value. If type conversion or validation fails, it raises a ValidationError with appropriate context about the failure.

Args:
    arg_name (str): The name of the argument to convert and validate
    arg_value (object): The value to convert and validate

Returns:
    object: The converted and validated value

Raises:
    ValidationError: If type conversion fails or any validator raises an exception during validation
    ValueError/TypeError: Propagated from validators as ValidationError exceptions
9213	Formats the exception as a string including class name and additional parameters. If exclude_class is True, only the message is returned. Otherwise, the class name and message are combined. Additional key-value parameters are appended in a multiline format if present.
9214	Convert this exception to a dictionary containing 'reason', 'type', and 'params' keys.
9215	Check parameter types, convert as needed, validate arguments, then execute the function with converted parameters.
9216	Parse a list of validator names or n-tuples, checking for errors and return a list of validator function names and their optional parameters.
9217	Find all annotated functions inside a container, including those with metadata or string references to lazily loaded modules, excluding names that start with underscore characters.
9218	Creates a context from top-level annotated symbols in a module, setting documentation and context attributes.
9219	Return usage information about a context or function, including function signatures, argument types, and docstrings.
9220	Decorates a function to add type information and validation for its parameters. Stores type names, descriptions, and validation functions as metadata on the function for runtime type conversion and validation. Returns a decorated function with additional type metadata.
9221	A decorator function that specifies how a function's return value should be handled, allowing customization of return value formatting through a printer function while maintaining backward compatibility with deprecated parameters.
9222	Returns a decorator that specifies the return type of a function in a typed arguments system.
9223	Decorator that marks a class as a context for HierarchicalShell command line functionality, optionally with a custom name.
9224	A function decorator that annotates functions using information from their docstrings, with annotation happening on first function call for better startup time. It sets up metadata to indicate docstring loading and handles decoration logic.
9225	Mark a function as callable from the command line and initialize its metadata.
9226	Returns the first line of a function's docstring, or an empty string if no docstring exists.
9227	Load cron modules for installed applications and django tasks.
9228	Register cron tasks by creating crontab entries for each task in the registry, setting their schedule and command, then write the crontab. Returns the number of tasks registered.
9229	Prints the tasks that would be installed in the crontab for debugging purposes by loading tasks, creating a CronTab instance, adding each task with its schedule, and rendering the complete crontab content.
9230	Uninstalls cron tasks by removing all entries with the KRONOS_BREADCRUMB comment and returns the count of removed tasks.
9231	Create a project handler instance based on URI schema.

Args:
    uri (str): schema://something formatted URI
    local_path (str): the project configs directory

Returns:
    ProjectHandler derived class instance or None if schema is unknown

The method extracts the schema and URL components from the URI using a regex pattern, then instantiates and returns the appropriate handler class based on the schema, or returns None if the schema is not recognized.
9232	Load project configuration data from a local directory path, returning a dictionary mapping project names to their configuration data. Files are filtered by a specific extension and parsed from YAML format, with errors during parsing being silently ignored.
9233	Save project configurations to local files.

This method takes a dictionary of project configurations and saves each project's data to individual YAML files in the specified base path. It iterates through the projects, generates the appropriate file path for each project using `get_project_config_path()`, and writes the project data to those files using `yaml.dump()`. The method logs debug messages for each project that is saved. If the base path doesn't exist, the method returns early without saving anything. The method expects project data to be in a dictionary format where keys are project names and values are the project configuration data to be serialized to YAML.
9234	Creates a singleton property on a carrier object that instantiates the class only on first access with optional initialization arguments.
9235	Get the dependencies of the Project.

Args:
    recursive (bool): add the dependant project's dependencies too

Returns:
    dict of project name and project instances
9236	Decorator that calls a project handler's same-named function after executing the decorated function, passing the command result as a keyword argument. The project handler can add extra arguments to the command, so the decorated function should accept **kwargs. Returns the original function's result.
9237	Initializes a project and returns a list of failed initialization components.

The method attempts to initialize a project at the specified path with given languages, returning a list of components that failed to initialize. It uses a status dictionary to track initialization results and collects all failed components into a list.
9238	Sets an item on an object and returns a new object with the item set, without mutating the original object. Uses `_lens_setitem` method if available, otherwise falls back to copying the object and setting the item normally.
9239	Sets an attribute on an object and returns a new object with the attribute set, used by lenses to modify object states.
9240	Method `from_iter` creates a new object instance by copying the original object and incorporating data from an iterable. It serves as the inverse of `to_iter` function and is used by EachLens to synthesize states from iterables. The method calls the object's `_lens_from_iter` method with the iterable as argument. If the `_lens_from_iter` method doesn't exist, it raises `NotImplementedError`. The method should maintain any state not modeled by the iterable unchanged, and the equality `from_iter(self, to_iter(self)) == self` should hold for correct implementation.
9241	Set the focus to `newvalue`.

>>> from lenses import lens
>>> set_item_one_to_four = lens[1].set(4)
>>> set_item_one_to_four([1, 2, 3])
[1, 4, 3]
9242	Set many foci to values taken by iterating over `new_values`. Returns a setter function that applies these values to the given state. Example: `lens.Each().set_many(range(4, 7))([0, 1, 2])` returns `[4, 5, 6]`.
9243	Apply a function to the focus of a lens, returning a new function that transforms the state by applying the given function to the focused element.
9244	Returns a function that collects arguments over multiple calls and returns them as a tuple when the specified count is reached.
9245	Summary: This method is an abstract placeholder that should be overridden by subclasses. It raises a NotImplementedError with a message indicating which unimplemented lens was attempted to be used.
9246	Runs the lens over the state applying f to all foci and collecting results using applicative functor functions from lenses.typeclass. If no focus exists, uses the provided pure function to handle the case.
9247	Returns the focus within the given state by attempting to join multiple focused items as a monoid. Raises TypeError if the optic is not of kind Fold, and ValueError if there are no foci to view.
9248	Returns a list of all foci within the given state for a Fold optic. Raises TypeError if the optic is not a Fold instance. Uses apply method with pure and func functions to collect foci into a list.
9249	Applies a function to all foci within a state using a Setter optic, raising TypeError if the optic is not a Setter instance.
9250	Summary: Sets all foci within the given state to the specified value using a Setter optic. Raises TypeError if the optic is not a Setter instance. Uses apply method with identity functions to perform the setting operation.
9251	Sets all foci within `state` to values from `iterable` by applying a function that retrieves values from the iterable, requires Setter kind, raises TypeError if optic cannot set foci.
9252	Returns a class representing the 'kind' of optic by checking against known optic types in order of precedence.
9253	A main function that creates a GameState object and runs a REPL-like loop, processing user input, updating the game state, and displaying the updated state until the game ends, at which point it prints the final game message.
9254	Returns a vector moved one step in the direction of the other vector, potentially diagonally.
9255	Handles single character input to alter game state by moving player, performing actions, or ending game. Returns new game state and boolean indicating if input affected state. Supports movement in 8 directions, pause ('.'), quit ('q'), and random teleport ('t'). Returns same state with False for invalid inputs.
9256	advance_robots() produces a new game state where robots move one step toward the player, handle collisions between robots in the same position, and remove crashed robots from the game state.
9257	Returns a completed game state object with an optional end message.
9258	Displays the game board to the player and prompts them to enter a move in the format like "2b". Returns the zero-based coordinates as integers (row, column) after parsing the input.
9259	Play a game of naughts and crosses against the computer, where AI players make moves using player_move and random_move functions, and the game continues until there's a winner.
9260	Return a board with a cell filled in by the current player at position (x, y), or return the unchanged board if the cell is already occupied.
9261	Returns the outcome of the game board, indicating whether X has won, O has won, the game is a draw, or the game is ongoing. Checks all potential winning combinations and the board status to determine the result.
9262	Generates all possible winning combinations on the board including rows, columns, and diagonals.
9263	Process a single item by adding it to the internal items list. If the number of items reaches the maximum chunk size, upload the chunk to S3. Return the processed item.
9264	Method: open_spider

Summary: Callback function executed when a spider is opened. Stores a timestamp in ISO format (with colons replaced by hyphens) to replace the {time} placeholder in the S3PIPELINE_URL configuration variable.
9265	Uploads items to S3 as a chunk. Returns early if items is empty. Creates a file object and builds the object key using the template and URI parameters. Attempts to upload the file object to the specified S3 bucket and key. Increments success or failure stats based on the outcome. Finally, increments the chunk number and clears the items list.
9266	Builds a file object from items using JsonLinesItemExporter, with optional gzip compression, and returns the file object positioned at the beginning.
9267	Returns the account state information associated with a specific address by making a JSON-RPC call to GET_ACCOUNT_STATE method.
9268	Returns the asset information associated with a specific asset ID by calling the GET_ASSET_STATE JSON-RPC method with the provided asset ID as a parameter.
9269	Returns block information for a given block hash or index, with optional detailed JSON response or hexadecimal string output.
9270	Returns the hash value associated with a specific block index by calling the GET_BLOCK_HASH JSON-RPC method with the given block index parameter.
9271	Returns the system fees associated with a specific block index, expressed in NeoGas units.
9272	Returns the contract information associated with a specific script hash by making a JSON-RPC call to GET_CONTRACT_STATE method.
9273	Returns detailed information about a specific transaction hash, with optional verbose JSON output or hexadecimal string format.
9274	Returns the value stored in the storage of a contract script hash for a given key. Converts the key to hexadecimal format and makes a JSON-RPC call to retrieve the storage value, then decodes the hexadecimal result back to bytearray format.
9275	Returns the transaction output information for a given transaction hash and output index by making a JSON-RPC call to GET_TX_OUT method.
9276	Invokes a smart contract with the specified parameters and returns the invocation result. Takes a contract script hash and list of parameters, encodes the parameters, calls the contract via JSON-RPC, and decodes the response.
9277	Invokes a contract function with specified parameters and returns the decoded result. Takes script hash, operation name, and parameters as inputs, encodes the parameters, makes a raw call to the contract function, and decodes the response into a dictionary format.
9278	Invokes a script on the VM and returns the decoded result. Takes a script string as input and optional keyword arguments, calls the VM via JSON-RPC, and decodes the invocation result before returning it as a dictionary.
9279	Sends a raw transaction to the NEO network and returns the transaction result.
9280	Validates if a given string is a valid NEO address by calling the VALIDATE_ADDRESS JSON-RPC method and returns the verification result as a dictionary.
9281	Calls a JSON-RPC endpoint with the given method and parameters, handling request preparation, HTTP communication, response validation, and error processing including transport errors, protocol errors, and JSON deserialization issues. Returns the result from the successful response.
9282	Returns True if the input string is a valid SHA256 hash (64 hexadecimal characters).
9283	Returns True if the considered string is a valid RIPEMD160 hash.
9284	Encodes invocation parameters for JSON-RPC endpoints by converting native Python types into structured dictionaries with type and value fields, handling booleans, integers, hashes (256-bit and 160-bit), byte arrays, strings, and nested arrays recursively.
9285	Decodes the stack values in an invocation result dictionary by deep copying the result and processing its stack component with a dedicated decoding function, returning the modified result.
9286	Decorator that converts default arguments into keyword-only arguments, working with both Python 2 and Python 3. Allows selective conversion of default arguments starting from a specified argument name, with support for required keyword-only arguments using KWONLY_REQUIRED sentinel value.
9287	This function handles timezone-aware datetime transformations while considering daylight saving time changes. It takes a datetime object, applies a series of time transformations specified by an instruction string, and returns the resulting datetime in the specified timezone. The transformations can include operations like adding/subtracting time units, aligning to specific time boundaries (like the start of hour/day/week), and handling timezone conversions. The function uses `reduce` to sequentially apply each transformation to the input datetime, ensuring proper timezone handling throughout the process.
9288	Method `apply_to_with_tz` applies a time unit transformation to a datetime object while preserving the correct timezone, particularly handling daylight saving time transitions. It truncates the datetime according to the specified unit (days, weeks, months, or years) and ensures proper timezone localization to avoid incorrect timezone offsets that might occur during DST switches. The method returns a timezone-aware datetime object in the correct local timezone.
9289	Save the barcode to a file by rendering it and using the writer to save with the specified filename and options. Returns the full filename with extension.
9290	Renders the barcode using the assigned writer with specified options, builds the barcode code, and returns the rendered output.
9291	Calculates the checksum for an EAN13 code by summing digits in even and odd positions, applying the EAN13 algorithm, and returning the modulo 10 checksum.
9292	Renders a barcode by processing a list of binary strings using registered callbacks for painting modules and text, handling quiet zones, module positioning, and optional text rendering with centering options.
9293	Method: connect(cls, settings)
Summary: Configures and initializes a KVS (Key-Value Store) client using provided settings for session management. Sets default values for key prefix and codec, extracts cookie name, and creates a KVS client instance with the remaining server settings.
9294	A command line tool for managing environment variables stored in a S3-like system, supporting remote editing, downloading, and uploading of configuration files with proper error handling and logging.
9295	Downloads a file or folder from an S3-like service, handling both single files and entire folder structures based on whether the remote path ends with a trailing slash.
9296	Uploads a file or folder to S3-like storage service, preserving directory structure when uploading folders.
9297	Downloads environment files from S3 for a given configuration section and stores them locally in a folder named after the section within the local config folder.
9298	This function compares local and remote configuration files for a given section. It retrieves section-specific settings, initializes S3 storage and configuration objects, and then computes and displays the differences between local files (in a section-named folder) and remote S3 files. The function handles the case where an environment file path is not defined by raising a usage error.
9299	Split an environment variable string into key-value tuple, handling quoted values and escaping.
9300	Sets up basic authentication by storing the provided username and password in the configuration object.
9301	```python
def api_key(api_key):
    """Authenticate via an api key."""
    none()
    _config.api_key_prefix["Authorization"] = "api-key"
    _config.api_key["Authorization"] = "key=" + b64encode(api_key.encode()).decode()
```

This function authenticates using an API key by:
1. Calling a `none()` function (likely for initialization)
2. Setting the API key prefix for authorization to "api-key"
3. Encoding the provided API key in base64 format and storing it in the configuration with the "key=" prefix

The function appears to be part of an API client configuration system where authentication is handled through a custom header format.
9302	Generator function that recursively yields JSON objects from all .json files within a given folder and its subfolders.
9303	Return a dictionary mapping schema names to Schema objects, excluding those in NO_SCHEMA.
9304	Return the schema by reading and parsing a JSON file from the schema folder.
9305	Return a jsonschema.RefResolver for the schemas, using a store of resolved schemas from get_schemas() and the current schema.
9306	Validates an object against the schema using jsonschema.validate(). Raises ValidationException if validation fails, allowing for debugging purposes. Uses a resolver obtained from self.get_resolver() during validation.
9307	Return a list of valid examples for the given schema by reading JSON content from the examples/valid directory.
9308	Return a list of examples which violate the schema by reading JSON content from the invalid examples folder.
9309	Builds an authorization URL for user agent authentication by combining the base auth URL with encoded query parameters including client_id, scope, response_type, and redirect_uri.
9310	Process authentication URL to extract authorization code and handle errors. Parses the URL query string and fragment to extract parameters, raises an exception if an error is present, otherwise stores and returns the authorization code.
9311	Get or refresh access token by making authentication request and processing the response.
9312	Returns the "id" of a OneDrive user, caching the result in self._user_id for future calls.
9313	Get OneDrive object representing list of objects in a folder.
9314	Creates a folder with the specified name and metadata under a given parent folder ID, using a POST request to the API.
9315	Add a comment message to a specified object by making a POST request to the object's comments endpoint.
9316	Converts object to unicode string, attempting automatic encoding detection with fallback to UTF-8 decoding, or returns object as-is if already unicode or non-encodable.
9317	Recursively creates and sets drop targets for an object and its children, attaching a ToolBoxDropTarget to container objects and traversing the object hierarchy.
9318	Starts a drag and drop operation for a menu control, creating custom data objects for both control metadata and bitmap representation, then executing the drag and drop with move capability.
9319	Sets the default top level window for toolbox menu default action by storing the designer and inspector references.
9320	Opens an inspector window for a given object and returns the inspector instance.
9321	Open a shell window by creating and displaying a Shell widget instance, then return the shell object.
9322	Convert PythonCard font description to gui2py style by renaming 'faceName' to 'face' and 'sansSerif' family to 'sans serif'.
9323	Loads an HTML page from the specified location and displays it, or clears the display if no location is provided.
9324	Convenience function for accessing tag parameters. Retrieves a parameter from a tag if it exists, otherwise returns a default value or raises a KeyError if no default is provided.
9325	**Summary:** The `send` function processes outgoing communication by retrieving text from an input control, displaying it in an alert dialog, logging the message in the UI, and then clearing the input field while setting focus back to it.
9326	Show a welcome tip message with usage instructions for the gui2py designer, displaying a super tool tip with header, bitmap, and specific styling that auto-hides after 15 seconds.
9327	Handle mouse down event for object selection and rubberbanding. Clears previous selection when Control/Shift are not pressed or Alt is pressed. Sets up rubberband selection for multiple object selection or creates selection markers for individual objects. Captures mouse for drag operations while handling special cases for Notebook controls.
9328	Method: mouse_move(self, evt)
Summary: Handles mouse movement for selected objects, allowing dragging with optional grid snapping. When an object is selected and not in overlay mode, it moves all selected objects by calculating the position difference from the starting point. If Shift is pressed, the movement snaps to a predefined grid. In overlay mode, it draws a rubber-band rectangle for visual selection feedback.
9329	Resizes or moves a wxPython object based on mouse dragging, with optional grid snapping. Handles different resize directions (north, west, south, east) and updates object position and size accordingly, while managing margins and avoiding resize recursion.
9330	Handles keyboard input for component manipulation, supporting cursor keys to move selected components one pixel at a time with optional grid snapping, and processing delete/duplicate key commands.
9331	Delete all selected objects by iterating through the selection, destroying each object, clearing the selection list, and updating the inspector.
9332	Method: duplicate(self, event)

Summary: Creates copies of all selected objects by duplicating each object in the current selection, updating their selection markers, and replacing the original selection with the duplicated objects. The method also refreshes the inspector to display the new objects.

Parameters: 
- event: Event parameter (not directly used in the method)

Behavior:
- Iterates through all objects in self.selection
- For each valid object, destroys its selection marker and creates a duplicate
- Assigns a new SelectionMarker to the duplicated object
- Updates self.selection with the newly created objects
- Calls self.inspector.load_object() to refresh the inspector panel
9333	Refreshes the control superficial image by capturing a new snapshot, then raises, shows, and refreshes the control to display the updated image.
9334	Sets the position of a Top-Level window's tooltip to appear at the absolute lower-right position of the widget, adjusting for the tooltip's own size. For non-Top-Level widgets, delegates to the parent class implementation.
9335	Returns the Python data associated with a given item by mapping from wx data through _py_data_map.
9336	Set the Python item data associated with the wx item by creating a unique key, storing it in wx, and maintaining bidirectional mappings between wx data and Python data in internal dictionaries. Returns the generated wx_data key.
9337	Method to perform reverse lookup for an item containing requested data by first checking internal dictionary mapping and then searching the wx control based on version compatibility.
9338	Remove the item from the list and unset the related data by deleting entries from both Python and wx data maps, then call the parent DeleteItem method.
9339	Remove all items from the list and unset the related data by clearing both Python and wx data maps, then calling the parent ListCtrl's DeleteAllItems method.
9340	Clear all items and column headings by first clearing the collection and then deleting each column in reverse order.
9341	Sets the selected item in a wxPython control at the specified index. If index is None, clears the selection and text (if supported). Otherwise, selects the item at the given index. Triggers a programmatically generated selection event to notify observers.
9342	Returns the label of the selected item(s) as a string or list of strings, or an empty string if none. If multiselect is enabled, returns a list of selected item labels; otherwise returns the label of the single selected item.
9343	Set client data for the item at position n and maintain reverse association between data and string representation.
9344	Adds an item to the control with optional associated data, and maintains a reverse dictionary mapping from data to string items.
9345	Constructs a string representation of an object by formatting its attributes according to specified parameters and constraints, handling special cases like parent references and context, and properly managing indentation and line wrapping based on maximum column width.
9346	Find an object already created by searching through COMPONENTS dictionary or wx window hierarchy, returning the object reference or wx parent if found, otherwise returning None.
9347	Create a new object identical to self, with optional new parent, preserving all properties except parent, generating new ID, and recursively duplicating all children under the new parent.
9348	Adds a child control to the window's sizer with appropriate flags and positioning parameters.
9349	Reparents a child control to a new wxWidgets parent object, updating both the component hierarchy and the underlying wxWidgets control. Called during initialization or when dynamically changing parent controls.
9350	Tiles the background bitmap across the client area by drawing multiple copies of the bitmap, taking into account scrolled window positions if applicable.
9351	Draws the image as background, tiling it if specified or drawing it once at the top-left corner.
9352	Custom draws the label with transparent background support using anti-aliased drawing and semi-transparent colors across all platforms.
9353	Function `find_modules(rootpath, skip)` searches for Python modules in a directory tree starting from `rootpath`, skipping specified modules based on the `skip` dictionary. It returns a dictionary mapping packages to their submodules. The function prints information about the modules found and skipped, and handles `__init__.py` files to identify packages. It uses `os.walk()` to traverse the directory, filters Python files, and organizes them into a module tree structure while applying skip rules.
9354	Return a list of column heading sub-components sorted by their index order.
9355	ResetView updates the grid layout when rows or columns have been added or deleted by processing appropriate grid table messages, updating values, adjusting column attributes, and refreshing the grid display.
9356	Update all displayed values in the grid by sending a request message to refresh the view.
9357	Update column attributes to add appropriate renderer, set read-only status, and configure column widths in the grid.
9358	SortColumn(col): Sorts the data rows based on the values in the specified column index col, maintaining the association between row data and their sort values.
9359	Remove all rows and reset internal structures including key and grid view.
9360	Creates a ComboBox control with specified parent, id, and event handler, then binds a change event to the control.
9361	BeginEdit prepares an edit control for a grid cell by fetching the current value, populating a choice list, setting the current value as selected, and focusing the edit control.
9362	Complete the editing of the current cell. Returns True if changed. Gets the selected string from the text control, compares it with the starting value, updates the grid table if changed, and returns the changed status.
9363	Return True to allow the given key to start editing, but only if it's not a control or alt key combination and not the shift key.
9364	This method handles the first key press in an editor by processing numeric keypad keys and regular printable characters. It converts numeric keypad digits to their string representations and regular characters to lowercase (unless Shift is pressed), then sets the editor's text control to display the character. If the key cannot be processed, it allows the event to propagate normally.
9365	Returns a metaclass generator that registers classes with the FormTagHandler based on a specified type name, converting the type name to uppercase for registration.
9366	Enable or disable all menu items in the menu.
9367	Check if all menu items are enabled by iterating through each item and returning False if any item is disabled, otherwise return True.
9368	Enable or disable all top menus by iterating through each menu and calling EnableTop for each one.
9369	Checks if all top menus are enabled by iterating through each menu and returning False if any menu is not enabled, otherwise returns True.
9370	Helper method to remove a specific menu from the menu list by comparing menu objects rather than using positional indexing.
9371	Process form submission by building data set, adding button information if present, and triggering a form submit event through the container.
9372	Sets a tag attribute on a wx window object by storing the tag's parameters in the object's _attributes dictionary, with parameter names prefixed by underscores, and converts empty string values to None.
9373	This method modifies the HTML table generated for autosummary documentation by making the first column's content non-breaking. It traverses the table structure, finds the first column cells in each row, and replaces regular spaces with non-breaking spaces (U+00A0) in the text nodes to prevent line breaks within the content. The method includes error handling to gracefully handle cases where the expected table structure is not found.
9374	Get an autodoc.Documenter class suitable for documenting the given object, choosing the appropriate documenter based on the object type and its parent context.
9375	Reformats a function signature into a more compact form by parsing arguments and optional parameters, then joining them with appropriate spacing and brackets while respecting the maximum character limit.
9376	Import a Python object given its full name, handling both direct imports and nested attribute access by recursively trying different module splits.
9377	Smart linking role that expands to ':obj:`text`' if `text` is an importable object, otherwise expands to '*text*'.
9378	Shows a simple pop-up modal dialog with optional scrolling and different icon types (exclamation, error, question, info).
9379	Creates a modal dialog box for user input with options for password entry, multiline text, or regular input, returning the entered text or None if cancelled.
9380	Show a dialog to select a font and return the selected font object. If a font is provided as default, use it in the dialog. If the user accepts the dialog, return the selected font with its properties set from the dialog result.
9381	Shows a dialog for picking a color and returns the selected color if accepted, otherwise returns None.
9382	Shows a dialog to choose a directory and returns the selected directory path.
9383	Shows a find text dialog and returns the user's search preferences including text, whole words setting, and case sensitivity.
9384	Sets whether an item in the tree view should display an expand/collapse button, even if it currently has no children. This allows for lazy loading of tree item children to minimize memory usage and loading time.
9385	Set the window icon using a resource path, handling potential errors gracefully.
9386	Displays or hides the window, optionally making it modal by disabling other windows and running an event loop until the window is closed.
9387	Open, read and evaluate the resource from the specified source file, returning the parsed resource.
9388	Save a resource to a file by pretty-printing it as a string.
9389	Creates a gui2py window based on a Python resource definition, handling window configuration, components, and menu bars.
9390	Creates a gui2py control based on python resource specifications by looking up the control type in registries, instantiating the appropriate class with provided kwargs, and recursively building child components.
9391	Function `connect(component, controller=None)` associates event handlers with UI components by mapping controller methods (starting with "on_") to component events. It retrieves controller functions and names, processes event handler names to determine target components and events, validates component existence and event support, and finally binds the event handlers to the appropriate component events. The function handles both dictionary-based and class-based controllers, and provides warnings for deprecated event names while raising errors for invalid components or events.
9392	Method to translate legacy PythonCard attribute names to gui2py format, returning a warning when conversion is needed.
9393	Sets clipboard data that can be either a string or bitmap object. Opens the clipboard, creates appropriate data object, stores data, then closes clipboard. Handles exceptions silently.
9394	Finds autosummary documentation in a given object's docstring by importing the object, extracting its docstring, and parsing it for autosummary directives. Returns a list of autosummary items found, or an empty list if import fails or no autosummary directives are present.
9395	Load an object and all its children into a tree structure. If no object is provided, performs a full reload using the current root object. Clears the existing tree, creates a new root item labeled "application", and builds the tree structure recursively using the provided object. Finally, expands the root node to display all child items.
9396	Selects an object in the tree view and displays its properties, optionally showing a context menu at the specified mouse position.
9397	Loads the selected tree item into the property editor and optionally activates editing or selection.
9398	Update a tree item when an object's name changes by finding the item with the old name and updating it with the new name.
9399	Shows a context menu for a selected tree item with options to delete, duplicate, bring to front, send to back, and add child objects.
9400	Summary: Converts an image field to a URL representation by creating a scaled and cached image thumbnail, then building an absolute URI from the thumbnail URL. Returns None for empty values, and falls back to parent class methods if URI building fails.
9401	Returns a decorator function for adding an expression filter with the specified name and kwargs.
9402	Returns a decorator function for adding a node filter with the specified name and keyword arguments.
9403	Asserts that the current page path matches the given path or regex pattern. Uses synchronization and raises ExpectationNotMet if the assertion fails within the wait time. Returns True upon successful assertion.
9404	Asserts that the current page path does not match the given path or regex pattern within the specified timeout period. Raises ExpectationNotMet if the path matches during the wait time. Returns True upon successful verification.
9405	Checks if the page has the given path by attempting to assert the current path, returning True if it matches and False if it doesn't.
9406	Checks if the page doesn't have the given path. Returns True if the path doesn't match, False if it does match. Uses assert_no_current_path internally and catches ExpectationNotMet exceptions.
9407	Selects this node if it is an option element inside a select tag, with a warning if the option is disabled.
9408	Applies a filter to an expression based on the given value, with validation and error handling. Returns the filtered expression or skips filtering if the value is invalid and no default is provided.
9409	Returns an instance of the specified browser with given capabilities and options.

Args:
    browser_name (str): Name of the desired browser
    capabilities (Dict[str, str | bool], optional): Browser capabilities defaults to None
    **options: Browser-specific options for webdriver.Remote

Returns:
    WebDriver: Instance of the requested browser

Raises:
    ValueError: If browser_name is not supported

Supported browsers: chrome, edge, ff/firefox, ie/internet_explorer, phantomjs, remote, safari
9410	Returns the XPath query for this selector, using the specified exact matching option. If the expression is an AbstractExpression, it applies filters and converts to XPath; otherwise, it returns the expression as a string.
9411	Returns whether the given node matches all filters, including text matching, visibility checks, and custom node filters.
9412	Switch to the specified frame, parent frame, or top frame. Supports switching to an iframe/frame element, "parent" to return to the parent frame, or "top" to return to the top-level frame. Raises ScopeError if invalid nesting is detected and ValueError for invalid arguments.
9413	Accepts an alert dialog by executing the wrapped code within a modal context, optionally matching text and waiting up to a specified time limit. Raises ModalNotFound if no alert is found.
9414	Execute the wrapped code, accepting a confirm modal dialog with optional text matching and wait time, raising ModalNotFound if no modal is found.
9415	Execute the wrapped code, dismissing a confirm modal dialog.
9416	Accepts a prompt modal dialog, optionally matching text and providing a response. Executes the wrapped code within the context of accepting the prompt, waiting up to the specified time for the modal to appear. Raises ModalNotFound if no modal is found.
9417	Executes wrapped code while dismissing a prompt modal dialog, optionally matching against provided text and waiting up to specified time for modal appearance. Raises ModalNotFound if no modal is detected.
9418	Save a snapshot of the current page to an HTML file. If no path is provided, generates a random filename in the configured save path. If a path is provided, saves to that location relative to the save path. Returns the absolute path to the saved file.
9419	Save a screenshot of the page to the specified path or generate a random filename in the save path if no path is provided.
9420	Method that raises server errors if they exist and raising is enabled, then resets the server error state.
9421	Returns whether the given node matches the filter rule with the given value, handling invalid values by either defaulting to a default value or skipping the node based on the filter configuration.
9422	Checks if a page or current node has a radio button or checkbox with the given label, value, or id that is currently checked.

Args:
    locator (str): The label, name, or id of a checked field.
    **kwargs: Arbitrary keyword arguments for SelectorQuery.

Returns:
    bool: Whether the checked field exists.
9423	Checks if there are no radio buttons or checkboxes with the given label, value, or id that are currently checked. Returns True if no such checked fields exist.
9424	Checks if a page or current node has an unchecked radio button or checkbox field matching the given locator criteria. Returns True if such a field exists, False otherwise. Uses the 'field' selector type with checked=False parameter to find unchecked fields.
9425	Checks if there are no unchecked radio buttons or checkboxes with the specified label, name, or id on the page or current node. Returns True if no such unchecked fields exist, False otherwise.
9426	Asserts that the page or current node contains the specified text content, ignoring HTML tags. Uses TextQuery to resolve the text and checks if it matches the expected count and options. Raises ExpectationNotMet if the assertion fails within the specified wait time. Returns True if assertion succeeds.
9427	Asserts that the page or current node doesn't contain the specified text content (ignoring HTML tags). Raises ExpectationNotMet if the text is found within the timeout period. Returns True if assertion passes.
9428	Asserts that the page has the given title by creating a TitleQuery and synchronizing with the specified wait time, raising ExpectationNotMet if the assertion fails during the wait period.
9429	Asserts that the page doesn't have the given title by checking if the title query resolves for the current page. If the title is found within the specified wait time, it raises an ExpectationNotMet exception with a negative failure message. Otherwise, it returns True.
9430	Checks if the page has the given title by attempting to assert the title matches the provided string or regex. Returns True if the title matches, False otherwise.
9431	Checks if the page doesn't have the given title. Returns True if the title is not present, False otherwise.
9432	Find all elements on the page matching the given selector and options, returning a Result object containing the found elements. Supports both CSS and XPath selectors, with options to filter by text or visibility. Raises ExpectationNotMet if no elements are found or if the found elements don't meet expected criteria such as count, minimum, maximum, or between constraints. Uses synchronization with optional waiting time specified in the query.
9433	Find the first element on the page matching the given selector and options, or None if no element matches. If `capybara.wait_on_first_by_default` is True, waits for at least one matching element. Returns the first matching element or None if no matches found.
9434	Returns the inner content of a given XML node, including tags, by concatenating the node's text content, child elements serialized to XML, and text following children.
9435	Returns the inner text of a given XML node, excluding tags, by concatenating text content from the node's text, children, and tail properties.
9436	Normalizes a URL by properly escaping all query parameters. Takes a URL string as input, parses its components, decodes and re-encodes query keys to ensure proper URL encoding, and returns the normalized URL with correctly escaped query parameters.
9437	A decorator that creates write-only properties with multiple assignment methods: traditional assignment, method argument assignment, and decorator assignment. It allows setting a property through `obj.property = value`, `obj.property(value)`, or `@obj.property` decorators, with the latter two executing the setter function with the provided value.
9438	# Summary of `synchronize` method

The `synchronize` method is Capybara's primary mechanism for handling asynchronous operations by retrying decorated functions when certain exceptions occur. It attempts to execute a function repeatedly until it succeeds or a timeout period expires.

## Key behaviors:
- Retries functions when specific exceptions (like `ElementNotFound` or driver-specific exceptions) are raised
- Bubbles up other exceptions immediately for faster failure detection
- Uses a timer-based approach with configurable timeout (defaults to `capybara.default_max_wait_time`)
- Supports time freezing detection to prevent infinite loops
- Can reload the session automatically if enabled

## Parameters:
- `func`: The function to decorate (optional, can be used as decorator)
- `wait`: Timeout duration in seconds (overrides default)
- `errors`: Additional exception types that trigger retries

## Returns:
- The decorated function or decorator function

## Special cases:
- When `synchronized` is True, executes immediately without retries
- Raises `FrozenInTime` if system time appears frozen
- Handles driver-specific invalid element errors
- Supports automatic session reloading when enabled
9439	Returns whether to catch the given error based on whether it matches the specified exception types or the default invalid element errors plus ElementNotFound.
9440	Returns how the result count compares to the query options, returning -1 if too few results, 0 if enough results, or 1 if too many results.
9441	Attempts to fill the result cache with at least the specified number of results by iterating through the result iterator. Returns True if successful, False if the iterator is exhausted before reaching the desired cache size.
9442	Returns whether the given query options expect a possible count of zero by checking if any of the keys "count", "maximum", "minimum", or "between" have non-None values, and if so, delegates to `matches_count(0, options)` for further evaluation.
9443	Returns an expectation failure message for a given query description with optional count, between, maximum, or minimum constraints.
9444	Returns whether the given count matches the given query options, checking for exact count, maximum, minimum, and between constraints.
9445	Normalizes the given value to a string with extra whitespace removed. Byte sequences are decoded, None is converted to empty string, and other values are cast to string.
9446	Normalize whitespace by removing outer whitespace and collapsing inner whitespace into single spaces.
9447	Returns a compiled regular expression for the given text, with optional exact matching. If the input is already a regex object, it returns it directly. Otherwise, it escapes the text and wraps it with anchors for exact matching if specified.
9448	Returns whether this query resolves for the given session by comparing the actual path with the expected path, handling URL parsing and normalization.
9449	Resizes the window to the specified width and height dimensions in pixels. If the window is not currently active, it preserves the previous window state after resizing.
9450	Boots a server for the application if it's not already running, starting the server thread and waiting for it to become responsive. Returns the server instance.
9451	Sets a new class-wide getter for the property and returns the AdvancedProperty instance.
9452	A descriptor method that sets and returns a new instance method for a class. Takes an optional callable as input and assigns it to the internal `__instance_method` attribute, then returns the instance of `SeparateClassMethod`.
9453	A descriptor method that updates and returns a class method. Takes an optional callable as input, assigns it to the instance's `__class_method` attribute, and returns the instance itself. Used to modify class method behavior through descriptor protocol.
9454	Get outer traceback text for logging, including exception information and traceback details.
9455	Get object representation string. If log_object_repr is True, returns the object's repr() representation. Otherwise, returns a formatted string containing the object's class name and memory address.
9456	Get logger for log calls, prioritizing instance-specific loggers over a default logger.
9457	Sets the logger instance to use as an override. If logger is None or already a logging.Logger instance, it's assigned directly. Otherwise, a logger is retrieved using logging.getLogger() with the provided string name.
9458	Low-level method to call the Slack API with the specified method and parameters. It constructs the API URL, adds the authentication token to parameters, sends a GET request, and returns the JSON response. If verification is enabled and the response indicates an error (response['ok'] is False), it raises an exception with the error details.
9459	Returns a list of channels for this Slack team, fetching them from the API if not already cached.
9460	Method that returns a list of users for the Slack team by calling the 'users.list' API endpoint, caching the results in self._users for subsequent calls.
9461	Creates a message packet with the given text and channel information, handling both channel names and IDs.
9462	Translate machine identifiers (user IDs and channel IDs) into human-readable names by looking up the corresponding Slack users and channels, handling cases where the identifiers might be missing or invalid.
9463	Send a message to Slack channel (defaults to 'general' if no channel specified).
9464	Read messages from channel and send to protocol, then schedule next read call.
9465	Method summary:
Runs the main interface by instantiating SlackAPI, connecting to RTM, and starting the client with the specified token and channel layer.
9466	Method: run(self, args)
Summary: Parses command line arguments, validates Slack token presence, imports specified channel layer, and initializes and starts a Slack client using the provided configuration. Raises ValueError if no Slack token is provided.
9467	Return a dictionary of keys that differ between two config objects, showing the previous and new values as tuples.
9468	Adds color formatting codes to a string message based on the specified color, unless colorization is disabled globally.
9469	Method called when a task starts in a playbook execution. Updates the last task name and resets the printed flag.
9470	This method handles the successful completion of an Ansible task. It prints task information when the task is tagged with "print_action", fails, is unreachable, or when verbose output is enabled. For failed or unreachable tasks, it displays detailed error information including messages, stderr output, and diffs. For successful tasks with results, it iterates through nested results to display individual item details. When tasks succeed without special conditions, it prints a dot to indicate progress.
9471	Display playbook statistics for each host, showing success/failure status with color coding based on task outcomes.
9472	This method handles the event when a task is skipped during playbook execution. It displays information about the skipped task including the host name, "skipped" status, and an optional reason. The output is formatted with proper spacing and coloring, and if the reason is long, it's indented and printed on separate lines. The method only executes when verbosity level is greater than 1.
9473	Converts a CIDR formatted prefix into an address netmask representation with customizable separator between address and netmask parts.
9474	A decorator that checks if a value passed to a Jinja filter evaluates to false and returns an empty string (or a specified default), otherwise calls the original filter function.
9475	Add a model to the instance, assigning it to a class attribute with the YANG name. If force=False, validates the model is in SUPPORTED_MODELS. Supports both model objects and string references to models.
9476	Returns a dictionary with the values of the model, optionally filtering out unset values. If filter=True, only values that have been set are included in the returned dictionary.
9477	Load a dictionary into the model, handling element loading and data assignment with optional model auto-loading and overwrite capabilities.
9478	Returns a dictionary representation of the model's values, with leaf values converted to Python types. If filter=True, only values that have been set are included in the result.
9479	Parse native configuration and load it into corresponding models, using either a device to retrieve configuration or provided native configuration data. Only parses models that have been added to the root object.
9480	Parse native state and load it into corresponding models, only parsing models that have been added to the root object. Uses either provided native data or retrieves from device if not provided. Supports loading from device or file sources.
9481	Translate the object to native configuration with optional merge and replace operations.
9482	Loads and returns all filters by iterating through JINJA_FILTERS and collecting filters from modules that have a filters() method.
9483	Find the necessary file for the given test case by constructing the full path from the module directory, profile, path, and filename. If the file exists, return the full path; otherwise, log an error and raise an IOError.
9484	Converts a PybindBase model into a dictionary representation, useful for visualizing the model structure. Supports filtering by mode (config, state, or all) and option to show default values. Returns a nested dictionary where keys are model names with read-write/read-only indicators and module prefixes, and values are either nested dictionaries for containers/lists or data types/defaults for leaf nodes.
9485	Returns the difference between two Pybindbase models as a dictionary. Handles root containers, lists, and scalar values differently, returning detailed comparison results including items unique to each model and differing values.
9486	POST to URL and get result as a response object.

**Parameters:**
- url (str): URL to POST, must use HTTPS protocol
- data (str): Data to send in the form body

**Returns:**
- requests.Response: Response object from the POST request

**Raises:**
- ValueError: If URL does not start with 'https://'
9487	Constructs and returns a full URL for obtaining an authorization code from a provider's authorization endpoint. The URL includes the client ID, redirect URI, and response type (using default if not specified) as query parameters.
9488	Get an access token from the provider token URI using the provided authorization code and parameters. Returns a dictionary containing access token, refresh token, etc.
9489	Return query parameters as a dictionary from the specified URL by parsing the URL and extracting the query string parameters.
9490	Remove the query component from a URL, returning the URL with only scheme, netloc, path, params, and fragment components.
9491	Constructs a URL by combining a base URL with additional query parameters, preserving existing parameters and handling None values in additional parameters.
9492	Handle an internal exception that was caught and suppressed by logging the exception details.
9493	Return a response object with the specified body, headers, and status code.
9494	Return a HTTP 302 redirect response object containing the error.
9495	Return a response object from the given JSON data with default headers including Content-Type, Cache-Control, and Pragma.
9496	Generate authorization code HTTP response for OAuth2 authorization flow, validating response type, redirect URI, client ID, access permissions, and scope. Returns appropriate error responses for invalid conditions or redirects to the client with authorization code upon successful validation.
9497	Generate an access token using a refresh token by validating client credentials, scope, and refresh token validity, then creating new access and refresh tokens and returning them in a JSON response.
9498	Generate an access token response using the authorization code grant type. Validates client credentials, redirect URI, scope, and authorization code. Returns appropriate error responses for invalid conditions or creates and persists a new access token with refresh token upon successful validation.
9499	Get authorization code response from a URI by parsing query string parameters, handling missing parameters and server errors with appropriate error responses.
9500	Get a token response from POST data by validating OAuth 2.0 parameters and handling either refresh token or authorization code flows, returning appropriate JSON error responses for missing parameters or server errors.
9501	Get authorization object representing status of authentication, handling Bearer token validation if present in authorization header.
9502	Open the smbus interface on the specified bus by opening the corresponding I2C device file, closing any previously opened device first.
9503	Read a single byte from the specified device address by selecting the device and reading one byte from the opened bus.
9504	Read many bytes from the specified device.
9505	Read a single byte from the specified command register of the device via I2C.
9506	Write multiple bytes to a specified device address using the opened bus connection.
9507	Write a byte of data to the specified command register of a device via I2C bus. Takes device address, command register, and byte value as parameters. Sends the command and value as a 2-byte data packet to the device. Requires bus to be opened first.
9508	Writes a buffer of data to the specified command register of an I2C device by constructing a byte array with the command register at the start, selecting the device, and performing a single transaction write operation.
9509	Returns the file's CDN URL by combining the CDN base URL with the file's CDN path, optionally including default effects if specified.
9510	Creates a file copy on Uploadcare or custom storage. This method is deprecated since version 3.0.0 and will be removed in 4.0.0. Use `create_local_copy` and `create_remote_copy` instead. If a target storage is specified, creates a remote copy; otherwise, creates a local copy. Supports CDN image effects when provided.
9511	Creates a local file copy on Uploadcare Storage with optional image effects and storage settings. Returns a REST request response for the created file.
9512	Creates a file copy in remote storage with specified options.

Args:
    target (str): Name of custom storage connected to the project
    effects (list, optional): CDN image effects to add
    make_public (bool, optional): Whether to make files publicly accessible (default: True)
    pattern (str, optional): S3 object key name pattern

Returns:
    Response from REST API request

The method copies a file to remote storage with optional effects, public access control, and custom naming pattern. If no pattern is specified, it defaults to '${uuid}/${filename}${effects}${ext}'. The target storage must be configured in the project settings.
9513	Constructs a `File` instance from file information dictionary. Takes a `file_info` dict containing at minimum a 'uuid' key, creates a new File object with that UUID, sets the default_effects from the info (if present), caches the full info, and returns the constructed file object. Used to initialize File objects from API response data.
9514	Uploads a file object to UploadCare and returns a File instance. The store parameter controls whether the file should be automatically stored (True/False/None for project settings). Uses uploading_request to handle the actual upload process and returns a new File instance constructed from the response data.
9515	Uploads a file from a given URL and returns a `FileFromUrl` instance.

**Args:**
- `url` (str): URL of the file to upload
- `store` (Optional[bool]): Whether to automatically store the file (True/False/None for project settings)
- `filename` (Optional[str]): Name of the uploaded file (optional)

**Returns:**
`FileFromUrl` instance

**Raises:**
`APIError`: If token is not found in the response

**Details:**
The method sends a POST request to '/from_url/' endpoint with the URL, store preference, and optional filename. It processes the response to extract a token and creates a `FileFromUrl` instance using that token. The store parameter is converted to 'auto', '1', or '0' based on its value.
9516	Uploads a file from a given URL and returns a File instance, with options for storage settings, custom filename, timeout, interval, and CDN availability waiting.
9517	Returns CDN urls of all files from group without API requesting.
9518	Constructs a ``FileGroup`` instance from the provided group information dictionary, setting the group ID and caching the full information.
9519	Creates a file group from an iterable of File instances and returns a FileGroup object. Raises InvalidParamError if items are not File instances or if the file set is empty. Makes a POST request to create the group and constructs the FileGroup from the response.
9520	Base method for storage operations that processes UUIDs in chunks and makes REST requests to the storage URL using the specified method.
9521	Extract UUID from each item of specified sequence, yielding UUIDs for File objects or raw strings, raising ValueError for invalid types.
9522	A common function for building "list showing" methods that handles pagination and ordering, parses starting points as dates when appropriate, retrieves items using an API list class, and prints them in a formatted way while handling potential value errors.
9523	This function `bar` creates a progress bar visualization during iteration over `iter_content`. It divides the progress into `parts` segments and displays a visual bar with percentage completion. The bar is updated in real-time using a lambda function for drawing. The function yields each chunk from the input iterator while updating the display. When completed, it ensures the progress bar shows 100% and moves to the next line.
9524	Makes an Uploading API request and returns the response as a dictionary. Takes parameters such as HTTP verb, request path, data, files, and timeout. Uses settings from the conf module and handles various response status codes, including JSON parsing for successful responses and appropriate error handling for different failure cases. The path parameter should not contain a leading slash.
9525	Returns the status of Home Mode by making an API call and extracting the 'on' field from the response data.
9526	Return a list of Camera objects by fetching camera data from the API and converting each camera's data into a Camera instance.
9527	Return a list of Camera objects matching the specified camera IDs by making an API call to get camera information.
9528	Returns the raw image data (bytes) from a specified camera by making an API request to fetch a snapshot.
9529	Disable a camera by sending a disable API request with the specified camera ID and optional parameters. Returns True if the operation is successful.
9530	Returns motion settings for a specified camera by querying the camera event API with the given camera ID and optional parameters.
9531	Update motion detection settings for a specific camera by sending MDParamSave API request with provided parameters.
9532	Update cameras and motion settings with latest data from API by fetching camera list and motion enums, then mapping them by camera ID.
9533	Determine if a given list item element is the last item in its containing list by traversing subsequent elements and comparing their list numbering identifiers. Returns True if the element is the last list item, False otherwise.
9534	Generator function that yields consecutive li elements with the same list ID, stopping when encountering different list items, headings, or end of document.
9535	Returns the indentation level (ilvl) of a list item (li) tag from a Word document XML structure, used to determine nesting hierarchy. Returns -1 if no indentation level is found.
9536	Returns the vMerge element from a table cell, which indicates if the cell is part of a rowspan. Returns None if the cell is None or if there isn't exactly one vMerge element. The vMerge element's attribute value can be 'restart' (indicating the start of a rowspan) or other values (indicating continuation of a rowspan).
9537	Returns the colspan value of a table cell by extracting the gridSpan element's val attribute from a docx table cell element. If no gridSpan element is found or multiple gridSpan elements exist, returns 1 as the default colspan value.
9538	Returns the td element at the specified index in a table row, accounting for cell colspans when traversing through table cells.
9539	Returns True if the style is not explicitly set to False, False otherwise. Handles namespace-aware checking for bold, italics, and underline styles by examining the 'w:val' attribute and returning False if the style is None or explicitly set to 'false'.
9540	The function `is_bold(r)` checks if a given XML element `r` (representing a run element in WordprocessingML) is formatted as bold. It does this by:

1. Getting the 'w' namespace from the element
2. Finding the `rPr` (run properties) element within `r`
3. If `rPr` exists, it looks for a `b` (bold) element within the run properties
4. Returns whether the bold formatting is set to False (meaning not bold) using the `style_is_false` helper function

The function returns `True` if the text is bold, and `False` otherwise.
9541	Returns True if the given XML tag 'r' (run) represents italicized text by checking for italic styling in its properties.
9542	The function `is_underlined(r)` checks if a given XML tag `r` represents underlined text in a Word document. It does this by:

1. Getting the Word namespace prefix using `get_namespace(r, 'w')`
2. Finding the `rPr` (run properties) element within the tag
3. If `rPr` exists, it looks for the `u` (underline) element within it
4. Returns `True` if the underline style is set to false (meaning no underline), otherwise `False`

The function essentially determines whether text is underlined by examining the XML structure of Word document elements.
9543	Returns True if the given p tag is considered a title tag based on its style attribute.
9544	This function iterates through elements in a run (r) and yields valid elements in their appearance order. It handles elements like text (t), drawing, pict, and break tags (br) that can appear within run tags. The function properly namespaces these elements using the 'w' namespace prefix before yielding them.
9545	Returns a dictionary mapping relationship IDs to their escaped targets, with image targets converted using provided media and image sizes. Skips relationships without IDs or targets ending with specified image extensions. Uses CGI escaping for security.
9546	Extracts document data from a Word document ZIP file, including XML content, numbering information, relationships, styles, and image data, while handling metadata and optional image processing.
9547	Returns the list type for ordered lists based on numbering dictionary metadata, defaulting to decimal style if numId or ilvl are invalid.
9548	Builds a nested list structure from a sequence of list item nodes and metadata, handling indentation levels and list nesting while tracking visited nodes and returning the root list object.
9549	Builds a single tr element with populated td elements from Word document table rows, handling merged cells, lists, nested tables, and proper HTML formatting.
9550	This function creates a table object by populating rows and cells from the input table and metadata. It generates a blank table element, retrieves rowspan data for cells, processes each table row element, builds table rows with proper metadata and rowspan information, appends them to the table element, and returns the completed table element along with a list of visited nodes.
9551	Generate string content for a t tag with optional bold and italics formatting, escaping XML special characters.
9552	Remove all elements with the specified tag name from the tree by iterating through all elements and removing those that match the given tag.
9553	Find the location of a dataset on disk, downloading it from a URL if it doesn't already exist. Creates the dataset directory if needed.
9554	Loads the MNIST digits dataset, returning training, validation, and test sets. Optionally flattens images to 1D arrays or keeps them as 28x28x1 shaped arrays. Can return either just image data or both images and labels.
9555	Loads the CIFAR10 dataset from a tar.gz file, extracting and preprocessing training, validation, and test images. Returns flattened or reshaped image arrays with optional labels.
9556	Plot an array of square images arranged in a grid pattern. The function takes a matrix of images where each row represents a square image, and displays them in a single figure arranged in an nn grid. It assumes the input images are square and have the same dimensions. The function handles the layout by creating a composite image with spacing between sub-images and normalizes the pixel values to [0,1] for display. Optionally adds a title to the subplot.
9557	Creates a plot of weight matrices visualized as pixel arrays for each layer, showing how features evolve through the network. For each layer (except the last), it applies the weight transformation to the identity matrix and plots the resulting images. For the final layer, it either plots the decoding weights or the transformed images if weights are tied, with proper title formatting and channel handling. Returns early if the final layer's output shape doesn't allow for square image arrangement.
9558	Plot convolution filters as a grid of images, handling both grayscale and RGB filters by arranging them in a square pattern and normalizing their pixel values for visualization.
9559	Create a callable that generates samples from a dataset for training recurrent networks. The callable returns batches of sequential data with specified batch size and time steps, using random sampling from input arrays.
9560	Encode a text string by replacing characters with alphabet index values. Returns a list of integers representing the alphabet indices of each character in the input text.
9561	Creates a callable that generates batches of training data for a classifier model. Each batch contains input-output sequences where inputs are one-hot encoded representations of text segments and outputs are the corresponding next character predictions. The method generates random offsets within the text to create diverse training examples, ensuring each batch has the specified number of training examples (batch_size) and time steps (steps). Returns a callable that when invoked produces a batch of data suitable for training a classifier model.
9562	Generate sequential class labels from a trained network by sampling from the model's probability distribution, supporting multiple parallel streams and handling potential normalization errors during sampling.
9563	Add a convolutional weight array to this layer's parameters with specified mean, standard deviation, and sparsity settings.
9564	Encodes a dataset using hidden layer activations from the network. If sample=True, returns binary samples drawn from Bernoulli distributions defined by the activations. Otherwise, returns the raw activations.
9565	Decode an encoded dataset by computing the output layer activation.

Parameters:
----------
z : ndarray
    A matrix containing encoded data from this autoencoder.
layer : int or str or :class:`Layer <layers.Layer>`, optional
    The index or name of the hidden layer that was used to encode `z`.

Returns:
-------
decoded : ndarray
    The decoded dataset.
9566	Find a layer output name for the given layer specifier.

Parameters:
layer : None, int, str, or :class:`theanets.layers.Layer`
    A layer specification. If this is None, the "middle" layer in the
    network will be used (i.e., the layer at the middle index in the
    list of network layers). If this is an integer, the corresponding
    layer in the network's layer list will be used. If this is a string,
    the layer with the corresponding name will be returned.

Returns:
name : str
    The fully-scoped output name for the desired layer.
9567	Compute R^2 coefficient of determination for the autoencoder by comparing input data with its own predictions, serving as a measure of information loss.
9568	Compute a greedy classification for the given set of data by feeding forward through the network and returning the class with the highest output value for each example.
9569	Compute class posterior probabilities for given input data by performing forward propagation and returning output from the last layer.
9570	Compute the logit values that underlie the softmax output.

Parameters
----------
x : ndarray (num-examples, num-variables)
    An array containing examples to classify. Examples are given as the
    rows in this array.

Returns
-------
l : ndarray (num-examples, num-classes)
    An array of posterior class logit values, one row of logit values
    per row of input data.
9571	Compute the mean accuracy score on labeled data, with optional instance weights. Returns weighted or unweighted mean accuracy depending on whether weights are provided.
9572	Extract a single batch of data for model training by padding sequences to the maximum length in the batch, creating feature arrays, label arrays, and corresponding masks indicating valid data positions.
9573	Returns a callable that samples batches of sequences from netcdf dataset by randomly selecting sequence indices and extracting corresponding input and target data.
9574	Load a saved network from a pickle file on disk and set it as the experiment's network attribute.
9575	Creates a matrix of randomly-initialized weights with optional sparsity, spectral radius scaling, and diagonal configuration. Supports random number generator seeding and various initialization parameters.
9576	Create a vector of randomly-initialized values with specified mean and standard deviation using numpy's random number generator.
9577	Get the outputs from a network that match a pattern.

Parameters
----------
outputs : dict or sequence of (str, theano expression)
    Output expressions to filter for matches. If this is a dictionary, its
    ``items()`` will be processed for matches.
patterns : sequence of str
    A sequence of glob-style patterns to match against. Any parameter
    matching any pattern in this sequence will be included in the match.

Yields
------
matches : pair of str, theano expression
    Generates a sequence of (name, expression) pairs. The name is the name
    of the output that matched, and the expression is the symbolic output in
    the network graph.
9578	Get the parameters from a network that match a pattern.

Parameters
----------
layers : list of :class:`theanets.layers.Layer`
    A list of network layers to retrieve parameters from.
patterns : sequence of str
    A sequence of glob-style patterns to match against. Any parameter
    matching any pattern in this sequence will be included in the match.

Yields
------
matches : pair of str, theano expression
    Generates a sequence of (name, expression) pairs. The name is the name
    of the parameter that matched, and the expression represents the
    parameter symbolically.
9579	Construct regularizers from keyword arguments, handling dropout, noise, and other registered regularizers based on network layer patterns.
9580	A list of Theano variables used in this loss, including the target and optionally weights.
9581	Computes the accuracy of neural network outputs by comparing predictions to target values. Takes a dictionary of Theano expressions and returns a Theano expression representing the accuracy metric. Uses argmax to get predictions, compares them to targets, and calculates the mean accuracy. If weights are provided, computes weighted accuracy instead.
9582	Helper method for defining a basic loop in Theano using scan operation. Takes inputs, outputs specifications, and optional parameters to configure the scan. Processes output specifications to handle different cases (None values, integers for batch sizes, tensor variables for initial state, or dictionaries for full output specifiers). Returns the scan results along with updates for use in Theano functions. Supports configurable step functions, constants, backward iteration, and truncated backpropagation through time.
9583	Constructs an activation function by name, handling various activation types including pre-defined functions, composition of functions, and custom activations with additional parameters.
9584	Select a random sample of n items from xs using reservoir sampling, normalizing each item by its l2 norm, and padding with distorted duplicates if needed.
9585	Sets a new loss function by clearing existing losses and adding a new one, passing all arguments to the add_loss method.
9586	Train a neural network one batch at a time, yielding training and validation monitor values. Supports various optimization algorithms and can save model progress periodically. Returns dictionaries of monitor values for training and validation data at each iteration.
9587	Train the network until convergence by iterating through training data, returning final training and validation monitor values.
9588	Constructs a hash key representing the computation graph by combining network topology, losses, and regularizers information into a unique string identifier.
9589	Builds a computation graph by connecting layers in the network.

Parameters:
- regularizers: list of Regularizer objects to apply during graph construction

Returns:
- outputs: list of Theano variables representing each layer's output
- updates: list of update tuples for Theano functions

The method caches computed graphs using a hash of the regularizers and logs layer and regularizer information during construction.
9590	Returns a list of Theano variables for feedforward computations by collecting input variables from all Input layers in the network.
9591	A list of Theano variables for loss computations, including inputs and unique variables from losses.
9592	Get a parameter from a specified layer in the network by layer index or name.

Parameters:
- which: int or str - layer identifier (index or name)
- param: int or str - parameter name or index to retrieve

Returns:
- Theano shared variable - the requested parameter from the specified layer

Raises:
- KeyError - if layer or parameter not found
9593	Compute a forward pass of all layers from the given input by compiling and caching the feed_forward function, then returning the activation values of each layer as a dictionary mapping layer names to their corresponding arrays of activations.
9594	Compute a forward pass of the inputs, returning the network output by calling feed_forward and returning the output of the last layer.
9595	Compute the R^2 coefficient of determination for predicting target values using the network. Returns a float representing the correlation between predictions and targets.
9596	Save the state of this network to a pickle file on disk.
        If filename_or_handle is a string, it names the file where the pickle will be saved.
        If it is a file-like object, this object will be used for writing the pickle.
        If the filename ends in ".gz", the output will automatically be gzipped.
9597	Load a saved network from disk by unpickling from a file or file handle. Supports gzip-compressed files ending in ".gz". Returns the loaded model object. Raises an assertion error if called on an instance instead of the class.
9598	Return a Theano expression representing the regularized loss for this network, which includes both the network's loss computation and any regularization terms. The regularization terms are computed using the provided keyword arguments, and the final loss is the sum of the weighted losses and regularization terms.
9599	Return expressions to run as updates during network training.

Returns
-------
updates : list of (parameter, expression) pairs
    A list of named parameter update expressions for this network.
9600	Returns the number of neurons in the layer's default output by taking the last element of the output shape, raising a ConfigurationError if the output shape is undefined.
9601	Create Theano variables representing the outputs of this layer given symbolic inputs, returning the outputs as a dictionary and updates as a sequence of parameter-expression tuples.
9602	Bind this layer into a computation graph by performing initialization tasks including resolving inputs/outputs, building activation function, and setting up parameters.
9603	Resolves input names for a layer into their corresponding shape tuples by checking against available layers and handling unresolved shapes through a resolution process.
9604	Resolve the names of outputs for this layer into shape tuples. Validates input shapes are compatible, then determines output shape based on either explicit shape or size parameter, storing the result in _output_shapes['out']. Raises ConfigurationError for incompatible input shapes or missing size specification.
9605	Logs information about this layer including class name, name, output shape, activation function, input shapes, and learnable parameters.
9606	Log information about the layer's parameters including their names and shapes, and return the total number of parameters.
9607	Helper method to format an object's name into a string, automatically prepending '{}.' if no format placeholder is present.
9608	Given a list of layers, find the layer output with the given name.

Parameters:
name : str - Name of a layer to resolve.
layers : list of :class:`theanets.layers.base.Layer` - A list of layers to search in.

Raises:
util.ConfigurationError - If there is no such layer, or if there are more than one.

Returns:
name : str - The fully-scoped name of the desired output.
shape : tuple of None and/or int - The shape of the named output.
9609	Find a shared variable for a parameter by name or index.

Parameters:
- key (str or int): The name or index of the parameter to look up

Returns:
- shared variable: A shared variable containing values for the given parameter

Raises:
- KeyError: If a param with the given name does not exist

The method searches through self._params to find a parameter matching either the numeric index or formatted name, returning the matching shared variable or raising KeyError if not found.
9610	Helper method to create and add a new bias vector parameter with optional mean and standard deviation settings.
9611	Create a specification dictionary for this layer containing its configuration details including form, name, and activation function.
9612	Returns the envelope of a LogGabor filter with specified parameters, applying orientation and band filters, optional translation, preprocessing, and energy normalization.
9613	Returns the spatial image of a LogGabor filter by applying inverse Fourier transform to the frequency domain LogGabor response with specified position, orientation, spatial frequency, bandwidth parameters, and phase.
9614	Add an IntervalTier or TextTier at the specified location, creating it with the given name and type. If no number is provided, the tier is added at the end. Raises ValueError if the number is out of bounds or if the tier type is invalid. Returns the created tier.
9615	Remove a tier by name or number, with first match removed when multiple tiers exist with the same name. Raises IndexError if tier number is invalid.
9616	Returns a tier by name or number, raising IndexError if it doesn't exist. If name_num is an integer, returns the tier at that index (1-based). If name_num is a string, returns the first tier with that name.
9617	Convert the object to a pympi.Elan.Eaf object with optional point length and empty annotation handling.
9618	Add a point to the TextTier with optional overlap checking. Raises Exception if tier type is not TextTier or overlap is detected when check is True.
9619	Add an interval to the IntervalTier with specified begin time, end time, and value. Optionally checks for overlaps and validates that begin time is not greater than end time. Raises exceptions for invalid tier type, overlaps, or incorrect time ordering.
9620	Remove an interval at the specified time from the IntervalTier. If no interval exists at that time, nothing happens. Raises TierTypeException if the tier is not an IntervalTier.
9621	Remove a point at the specified time from the intervals list if the tier type is TextTier. If no matching point is found, do nothing. Raises TierTypeException if the tier is not a TextTier.
9622	Returns all intervals or points, optionally sorted. Yields intervals/points one by one.
9623	Returns a sorted list of all intervals including empty intervals, with proper handling of boundary conditions for IntervalTier type.
9624	A function to pretty print XML by adding appropriate indentation and newlines. It recursively processes XML elements, inserting tab characters for indentation and newline characters to format the structure. The function handles text content and tail content of elements to ensure proper formatting while preserving existing content.
9625	Adds an annotation to a specified tier with given start and end times, value, and optional SVG reference. Validates that the tier doesn't contain ref annotations, start and end times are valid (non-negative, start <= end), and start and end times are not equal. Generates unique IDs for the annotation and timestamp, then stores the annotation in the annotations dictionary and updates the tier's annotation list. Raises KeyError if tier doesn't exist and ValueError for invalid parameters.
9626	Add an entry to a controlled vocabulary with validation of language references.
9627	Add a description to a controlled vocabulary for the specified language reference. Raises ValueError if language doesn't exist, KeyError if controlled vocabulary id is not found.
9628	Add an external reference with the given eid, etype, and value, validating that etype is one of the allowed types. Raises KeyError if etype is invalid.
9629	Add a language to the languages dictionary with the specified ID, definition, and label.
9630	Add a lexicon reference to the internal collection with the specified parameters, storing it under the given internal ID.
9631	Add a linguistic type with specified parameters or from a parameter dictionary.
9632	Add a linked file to media descriptors with specified properties including file path, relative path, mimetype, time origin, and extracted from field. If mimetype is not provided, it will be guessed from the file extension. Raises KeyError if mimetype guessing fails for unknown extensions.
9633	Add a locale with the specified language code, country code, and variant to the locales dictionary.
9634	Add a secondary linked file with specified properties including file path, relative path, MIME type, time origin, and association. If MIME type is not provided, it guesses based on file extension. Raises KeyError if MIME type cannot be determined for unknown extensions.
9635	Adds a tier to the annotation container with specified parameters. When no linguistic type is provided or available, it defaults to the first linguistic type in the list. Raises ValueError if tier_id is empty. Supports optional parameters for linguistic type, parent tier, locale, participant, annotator, and language, with validation and default handling for each. When tier_dict is provided, it's used directly instead of individual parameters.
9636	Clean up unused timeslots by removing orphaned entries from the timeslots dictionary based on active timeslot references across all tiers.
9637	Extracts a selected time frame from an EAF object and returns it as a new EAF object.

**Parameters:**
- start (int): Start time of the extraction
- end (int): End time of the extraction

**Returns:**
- class:`pympi.Elan.Eaf` object containing only annotations within the specified time frame

**Process:**
1. Creates a deep copy of the original EAF object
2. For each tier, removes annotations that fall outside the specified time range
3. Cleans up unused time slots
4. Returns the modified copy with only the selected time frame
9638	Generate the next annotation ID by incrementing the maximum existing annotation ID found in timeslots, or start from 1 if no annotations exist, returning format 'a{number}'.
9639	Generate the next timeslot ID by incrementing a counter and assigning it to the timeslots dictionary. If an initial time is provided and is negative, raise a ValueError. If maxts is not set, calculate it from existing timeslots. Return the generated timeslot ID.
9640	Get all child tiers for a given tier by searching through all tiers and finding those that have a 'PARENT_REF' attribute pointing to the specified tier ID. Returns a list of child tier names. Raises KeyError if the specified tier does not exist.
9641	Returns the full time interval of the file as a tuple (min_time, max_time), or (0, 0) if no timeslots exist.
9642	Returns the reference annotation after a specified time from a given tier. If no annotation exists after the time, returns an empty list. Raises KeyError if the tier doesn't exist.
9643	Returns the reference annotation that occurs before or at the specified time in a given tier. If multiple annotations exist, returns the one with the latest start time. If no annotations exist before the time, returns an empty list. Raises KeyError if the tier doesn't exist.
9644	Returns a list of tier names that match a specific linguistic type, optionally filtered by parent tier.
9645	Merge multiple tiers into a new tier by combining annotations with gaps below the threshold, creating a new tier with merged annotation data.
9646	Removes all annotations from a specified tier by deleting their references from the annotations dictionary and clearing the tier's annotation lists. Optionally cleans up unused time slots if the clean parameter is True. Raises KeyError if the tier does not exist.
9647	Remove a controlled vocabulary description entry with the specified language reference from the controlled vocabulary with the given name. Raises KeyError if the controlled vocabulary does not exist.
9648	Remove all licenses matching both name and url criteria. If name is None, matches any name. If url is None, matches any url. Removes all matching license entries from self.licenses.
9649	Remove linked files that match all specified criteria from media descriptors, ignoring None criteria.
9650	Remove all properties matching both key and value from the properties list. If key is None, all properties with the specified value are removed. If value is None, all properties with the specified key are removed. If both are None, all properties are removed. The method iterates through a copy of the properties list to avoid modification during iteration.
9651	Remove reference annotations from a specified tier at a given time position, returning the count of removed annotations.
9652	Remove all secondary linked files that match all specified criteria, ignoring criteria that are None.
9653	Remove a tier by name, optionally cleaning associated timeslots.

**Parameters:**
- `id_tier` (str): Name of the tier to remove
- `clean` (bool): Flag to also clean the timeslots (default: True)

**Raises:**
- `KeyError`: If the specified tier does not exist

**Behavior:**
Deletes the tier from `self.tiers` and if `clean` is True, calls `self.clean_time_slots()` to remove unused timeslots.
9654	Remove multiple tiers from the object efficiently by batching the removal operation and cleaning timeslots only once at the end, raising KeyError if any tier doesn't exist.
9655	Rename a tier and update all child tiers that reference the original tier as parent. Updates the tier's ID in both the main tiers dictionary and child tiers' parent references. Raises KeyError if the original tier doesn't exist.
9656	Shift all annotations in time, handling cases where annotations become negative or are removed. Returns tuples of squashed and removed annotations in the format (tiername, start, end, value).
9657	This function creates a console script for bidirectional text display. It uses optparse to handle command line arguments including encoding, debugging options, and base direction settings. The script reads input lines from command line arguments or stdin, processes each line through a display algorithm that handles Unicode bidirectional text, and outputs the processed text to stdout while properly handling character encoding. The function supports treating uppercase characters as right-to-left for debugging purposes and can override the base text direction.
9658	Displays debug information for storage including base level/directory, runs, and character details with their levels and types.
9659	Get the paragraph base embedding level. Returns 0 for LTR, 1 for RTL.
    Processes unicode text to determine base level according to Unicode Bidirectional Algorithm.
    If upper_is_rtl is True, uppercase characters are treated as strong 'R' for debugging.
    Surrogate pairs are handled for UCS2 encoding.
    Returns 0 if no strong directional character is found.
9660	Get the paragraph base embedding level and direction, setting the storage to an array of characters with their bidirectional types. Processes text character by character, handling Unicode surrogates and optional uppercase RTL detection, then populates the storage with character information including character data, embedding level, bidirectional type, and original type.
9661	Applies Unicode Bidirectional Algorithm rules X1-X9 to process explicit embeddings and overrides in text storage, handling level calculations, overflow conditions, and character type adjustments while removing explicit marker characters.
9662	Split the storage into runs of characters at the same level, determining run types based on adjacent levels according to Unicode Bidirectional Algorithm X10 rules.
9663	Resolves weak type rules (W1-W3) according to Unicode Bidirectional Algorithm:
1. W1: NSM characters take the type of the previous character
2. W2: European numbers become Arabic numbers if preceded by AL
3. W3: All AL characters become R
4. W4: Separators between numbers change to number type
5. W5: European terminators adjacent to numbers become numbers
6. W6: Separators/terminators become Other Neutral
7. W7: European numbers become L if preceded by L

The function modifies character types in-place within the storage structure according to these rules.
9664	Resolves neutral types according to Unicode Bidirectional Algorithm rules N1 and N2, processing sequences of neutral characters and assigning them directional types based on surrounding strong text or embedding direction.
9665	Reverses contiguous sequences of characters in the given range that are at the specified level or higher, iterating from the highest level down to the lowest odd level.
9666	**Summary:**

The `reorder_resolved_levels` function implements Unicode Bidirectional Algorithm rules L1 and L2 for text directionality. It processes characters in reverse to apply L1 rules, resetting embedding levels for paragraph separators (B), segment separators (S), and trailing whitespace characters. Then it applies L2 rules per line by calculating the highest and lowest odd embedding levels, and reverses contiguous character sequences based on these levels to determine proper text order. The function handles line breaks and maintains debug output capability.
9667	Method that retrieves the current working file path from Maya and stores it in the context data under 'currentFile' and 'current_file' keys for backwards compatibility.
9668	Converts a compiled .ui file from PySide2 to Qt.py by replacing PySide2 import statements with Qt.py imports and updating QApplication.translate calls to use Qt.QtCompat.translate. Takes a list of lines from a .ui file and returns a modified list with the necessary import and method name changes.
9669	Adds a new attribute to an object and tracks it in self.__added__ list for Qt.QtCompat accessibility.
9670	This function implements a command-line interface for Qt.py that handles conversion of compiled Python modules. It supports converting existing UI files (using the `--convert` flag) and provides options for stdout/stdin handling and compilation, though the latter two features are not implemented yet. When converting, it creates a backup of the original file and writes the converted content back to the same file, displaying progress messages to the user. The conversion process uses a `convert` function that processes the input lines and returns the converted content.
9671	Add backwards compatibility members from self to binding, marking them as deprecated with __added__ tracking.
9672	Shows the most desirable GUI by cycling through registered graphical user interfaces and presenting it to the user, or displays a "no GUI" message if none are available.
9673	Returns the most desirable registered GUI by trying to import and return the show method of the last registered GUI, falling back through registered GUIs on import/attribute errors.
9674	Function to deregister supported hosts including "mayabatch", "mayapy", and "maya" from the pyblish API.
9675	Add Pyblish to Maya's file menu by first building the menu dynamically, then using evalDeferred to execute the menu addition in a batch-safe manner.
9676	Maintains the previous selection state within a context block, restoring it after code execution. Returns to the original selection when exiting the context, or deselects if no previous selection existed.
9677	Maintains the current time during a context by saving the time at the beginning and restoring it at the end.

Example:
```python
with maintained_time():
   cmds.playblast()
# Time restored to original value
```
9678	Displays a warning message box when no GUI is available, providing instructions on how to register a GUI such as Pyblish Lite, including installation and registration commands, and listing currently registered GUIs if any exist.
9679	The `setup_types` method resolves circular references in Message objects by replacing type names with actual class references. It iterates through `self.types`, converting string type names to their corresponding Type classes using `Type._type()`, while asserting that class objects are valid Type subclasses. The resolved types are stored back in `self.types`.
9680	Returns cumulative sum of data sets, where each yield contains the sum of all previous data sets up to that point.
9681	Return all values for a single axis of the data by extracting the appropriate index from each data point in the dataset.
9682	Draw a constant line on the y-axis with the specified value, label, and style, including a text label next to the line.
9683	Caches the transformation parameters needed to convert x and y coordinates. Calculates scaling factors (x_step, y_step) based on graph dimensions and data ranges, then stores all parameters in a dictionary excluding 'self'.
9684	Returns a new dictionary with keys and values swapped from the original mapping.
9685	A generator function that creates a sequence of floats, similar to Python's built-in range() function but accepts float values for start, stop, and step parameters. It yields floating-point numbers starting from 'start' (inclusive) up to but not including 'stop', incrementing by 'step' each time. The function converts the start value to float and continues yielding values while start is less than stop. Example: float_range(0, 9, 1.5) yields (0.0, 1.5, 3.0, 4.5, 6.0, 7.5).
9686	Add a dataset to the graph by aggregating it with existing data. Multiple calls sum corresponding elements, with missing elements treated as zero. The 'title' key is ignored.
9687	Add SVG filter definitions including a drop shadow filter with Gaussian blur effect.
9688	Adds data to the graph object by validating, processing, and storing the provided configuration dictionary containing 'data' and 'title' keys.
9689	Process the template with set data and config, then return the resulting SVG. Raises ValueError if no data is available. Executes calculations if they exist, then draws the graph including titles, legend, and data before returning the rendered SVG.
9690	Calculates the left margin of the plot area by determining the maximum height needed for Y-axis labels, titles, and labels based on various configuration options, then sets the border_left attribute accordingly.
9691	Calculate the right margin in pixels for the plot area, setting the border_right attribute. If a key is present and positioned to the right, the margin includes the key length, font size, and additional padding.
9692	Calculate the top margin in pixels for the plot area, setting border_top based on graph title and subtitle visibility and font sizes.
9693	Adds pop-up information to a point on the graph with text label and interactive circle element that shows/hides the label on hover.
9694	Calculate the bottom margin in pixels for the plot area, setting the border_bottom attribute based on key visibility, x-axis labels, and x-axis title dimensions.
9695	Method: draw_graph
Summary: Creates the main graph structure in an SVG document by setting up the graph group element with translation transform, adding a background rectangle, drawing x and y axes, and calling methods to draw axis labels. Sets the self.graph attribute to the created 'g' element in the SVG root.
9696	Method: `make_datapoint_text(self, x, y, value, style=None)`

Summary: Adds text labels for data points to a visualization. The method creates two text elements for each data point: first a wide white stroke for better visibility against the background, then the actual text with specified styling. The operation is skipped if data value display is disabled. The method takes coordinates (x, y), a value to display, and optional CSS style parameters.
9697	Draw X axis labels and guidelines if show_x_labels is enabled, using specified labeling steps and guidelines.
9698	Draw Y axis labels if enabled, enumerate and slice labels based on stepping rules, then draw each label and guidelines.
9699	Draw X-axis guideline lines on the graph at specified intervals, skipping the first position.
9700	Draw Y-axis guideline lines on the graph by creating path elements for each guideline, configured based on label height and count, but only if Y-guidelines are enabled.
9701	Draws the graph title and subtitle by calling individual title drawing methods based on show_graph_title, show_graph_subtitle, show_x_title, and show_y_title flags.
9702	Hard-codes CSS styles directly into SVG XML elements by inlining stylesheet rules into style attributes. When CSS inlining is enabled, parses CSS rules and applies matching class styles directly to elements with corresponding class attributes, preserving existing inline styles.
9703	Creates the base SVG document with namespace definitions, root element, stylesheet processing instruction, comments, definitions, and background rectangle.
9704	Get the stylesheets for this instance by loading them with class variables substitution.
9705	Summary: A convenience function that starts an IRC bot by creating a connection to the specified host and port, initializing the bot instance, connecting to the server, joining any specified channels, and entering the event loop to handle bot operations.
9706	Send raw data over the wire if connection is registered, otherwise save to output buffer. If force flag is True, always send data regardless of registration status.
9707	Connect to the IRC server using the nickname.
9708	A multipurpose method for sending responses to either a channel or a single user via private message. If a channel is specified, it ensures the channel name starts with '#' before sending the message. If a nickname is specified, it sends a private message directly to that user.
9709	Method that returns a tuple of regex patterns and their corresponding handler methods for low-level socket data dispatching, including nickname handling, PING responses, and various channel/user events.
9710	Generates a new nickname by appending a random number (1-1000) to the base nickname, logs the change, and updates the registered nickname and nick change handlers.
9711	Responds to periodic PING messages from server by logging the ping and sending back a PONG response with the same payload.
9712	When the server connection is registered, sends all pending data.
9713	Main loop of the IRCConnection that reads from socket and dispatches events based on regex pattern matching.
9714	Register the worker with the boss by sending a registration message and waiting for confirmation.
9715	Run tasks in a greenlet, pulling from the workers' task queue and reporting results to the command channel.
9716	Decorator to ensure that commands only can come from the boss.
9717	Method that defines the command patterns listened for by the worker bot, returning a tuple of regex patterns and their corresponding handler methods for registration success, worker execution, worker ping, and worker stop commands.
9718	Method `register_success` handles registration acknowledgment from BotnetBot by setting the command channel, joining it, and marking registration as complete.
9719	Summary: The `worker_execute` method processes tasks assigned by a BotnetBot. It determines whether the current worker (identified by `self.conn.nick`) should execute a task based on a provided list of workers or defaults to executing if no specific workers are specified. If the worker should execute the task, it adds the task to a queue with the task ID and command, then returns a confirmation message including the task ID.
9720	Add a worker with given nickname to track their participation in this task.
9721	Send a validation email to the user's email address if they are not already verified, using the current site context.
9722	Send a password reset notification to the user's email address using the current site context.
9723	Validates password strength by ensuring it contains mixed case letters, numbers, and optionally ASCII symbols and spaces. Raises ValidationError if password contains non-ASCII characters or lacks required character types. Does not enforce length restrictions.
9724	Verify a token for one-time access to a view, validating the token's expiry and checking if the user exists and hasn't already been verified. Raises exceptions for invalid/expired tokens or already verified users.
9725	Delete the user's avatar by setting `user.avatar = None` and saving the user object, returning a 204 NO CONTENT response. This approach avoids test errors with django.inmemorystorage by not calling `user.avatar.delete()` directly.
9726	Throttles POST requests only, allowing all other request methods without restriction.
9727	Returns a singleton ThreadPoolExecutor instance for the class, creating it with the specified max_workers if it doesn't already exist.
9728	Returns a single global client instance, creating it if necessary with optional TLS configuration and environment variables.
9729	Returns a tuple of TLS client certificate and key if both are provided, otherwise returns None.
9730	Returns the service name in Docker Swarm format: "{service_prefix}-{service_owner}-{server_name}" where server_name defaults to 1 if not set.
9731	Wrapper for calling docker methods that can be passed to ThreadPoolExecutor. Takes a method name and arguments, gets the corresponding method from self.client, and executes it with the provided arguments.
9732	Calls a docker method in a background thread using the object's executor and returns a Future object.
9733	Check the state of a docker service task similar to `docker service ps id` and return 0 if service not found, None if there's a running task, or 1 if no running task exists.
9734	Stop and remove a Docker service by yielding a docker remove_service command with the service ID, then log the removal and clear the service state.
9735	Filter queryset to check if lower-cased email is unique by calling parent class method with lower-cased value.
9736	Method to update user password by validating old password and setting new password.
9737	Update user's password with the new validated password and save the instance.
9738	Method `validate_email` validates if a user exists with the given email address and ensures the email requires verification. It sets a `user` attribute on the instance for sending email confirmation. The method raises `serializers.ValidationError` if the user doesn't exist or if the email is already verified. Returns the email if validation passes.
9739	Creates a new authentication token for a user upon POST request, sending a login signal and returning the token in the response. If the serializer is invalid, returns a 400 error with serializer errors.
9740	Delete auth token when `delete` request was issued. Validates token format from authorization header and deletes the token if valid, sending a user_logged_out signal. Returns 204 NO CONTENT on success or 400 BAD REQUEST on invalid token.
9741	This method validates that authenticated users can only request email confirmation resends for their own email address. It checks if the user is authenticated and if the requested email matches their own email, raising a PermissionDenied exception if there's a mismatch. If validation passes, it calls the parent class's initial method to continue with the normal flow.
9742	Validate email and send confirmation request. Returns 204 NO CONTENT on success, 400 BAD REQUEST if validation fails.
9743	Update token's expiration datetime based on creation time and optionally save the changes.
9744	Function that generates email context for password reset, including protocol, user ID, token, and site information.
9745	Send a notification via email using the provided email context and notification details.
9746	Password reset email handler that sets the email subject based on a custom setting or defaults to a formatted domain-based subject, then processes the notification with password reset email context.
9747	Validation email handler that sets email subject based on domain and custom settings, then processes the notification with validation email context.
9748	Authenticates a user using a token from the request data. Returns a tuple of (user, token) if successful, otherwise returns None if authentication fails or token is invalid.
9749	Method to authenticate credentials by checking if authentication token has expired and updating its expiration date if valid.
9750	Displays bokeh output inside a notebook by publishing plot HTML, comm manager, and bokeh plot JS with proper MIME types and metadata.
9751	Temporary fix to patch HoloViews plot communications by updating plot callbacks and replacing plot IDs with widget plot IDs, then returning the processed Bokeh plots.
9752	Returns a CustomJS callback for sending widget state across notebook comms, configured with specified parameters and callback functionality.
9753	Get widget for param_name, creating it if it doesn't exist.
9754	The `render_function` handles HoloViews objects by converting them to bokeh plots. It imports holoviews, checks if the object is a Dimensioned type, and creates a bokeh renderer. Depending on whether the view is in notebook mode or not, it sets up the renderer accordingly. It then generates a plot from the object and returns the plot's state. If the object is not a HoloViews object, it returns the object unchanged.
9755	Force a parameter value to be text by converting it to string and removing options, then return a TextInput widget.
9756	The `named_objs` function takes a list of object pairs and creates a dictionary mapping object names to the objects themselves. It processes each pair by extracting the name from the first element (using `__name__` attribute if available, otherwise converting to unicode) and returns the resulting name-object pairs as a list of tuples.
9757	Returns the instance owning the supplied instancemethod or the class owning the supplied classmethod.
9758	Assign HTTP authentication values by splitting the input into username and password components. Handles three cases: None input (does nothing), tuple/list input (assigns elements directly), and string input (splits on ':'). Raises ValueError for invalid input types.
9759	Returns True if the cluster is up, False otherwise by performing a HEAD request to the root path. Raises TransportError if the cluster is down.
9760	Get basic information from the current cluster.

**Args:**
- params (dict, optional): Optional query parameters

**Returns:**
- dict: Cluster information data

**Example:**
```python
# Get cluster info
cluster_info = yield client.info()
```
9761	Coroutine that queries the cluster Health API and returns a 2-tuple of (status, data) with optional query parameters.
9762	Converts bytes to a human readable format (Kb, Mb, Gb, etc.) with appropriate unit scaling.
9763	Returns the total CPU load for Synology DSM by summing system load, user load, and other load components. Returns None if any of the individual loads are not available.
9764	Returns the total memory size of the Synology DSM, optionally formatted in a human-readable way. If `human_readable` is True (default), returns a readable string like "16 GB"; otherwise returns the raw byte value. The memory size is extracted from `self._data["memory"]["memory_size"]` and converted from KB to bytes.
9765	Returns the total network upload speed being used. If `human_readable` is True (default), returns the speed in a readable format (e.g., "1.2 MB/s"). If `human_readable` is False, returns the raw byte value. Returns None if network data is unavailable.
9766	Returns all available volume IDs from the internal data structure.
9767	Returns a specific volume by its ID from the stored data, or None if not found.
9768	Returns the total size of a volume, with an option to format the result in human-readable format.
9769	Returns the percentage of used space for a given volume. Calculates (used space / total space) * 100 and rounds to 1 decimal place. Returns None if volume data is invalid or if used/total values are non-positive.
9770	Average temperature of all disks making up the volume
9771	Returns the maximum temperature among all disks that make up the specified volume by iterating through each disk and comparing their temperatures.
9772	Returns a specific disk by its ID from the stored data, or None if not found.
9773	Builds and executes a login request to authenticate with the Synology API, storing the access token from the response if successful. Returns True on successful authentication, False otherwise.
9774	Method `_get_url` handles GET requests with session management and automatic retry logic. It creates a new session when needed (when access token is None, session is None, or session error occurred), performs login if required, executes the GET request, and retries on error if specified. The method returns the response object or None if failed after retries.
9775	Method to execute a GET request with optional SID appending, handle response parsing, and manage session errors. Returns JSON data on success or None on failure.
9776	Updates the instanced modules (utilization and storage) by making API calls to the Synology DSM system to fetch current information. The method checks if each module is initialized, constructs the appropriate API URL with authentication, and calls the update method on each module with the retrieved data.
9777	Getter method that retrieves and caches system utilization data from the Synology API. Returns a SynoUtilization object containing CPU, memory, and network usage statistics, caching the result after the first call.
9778	Getter method that retrieves and caches storage information from the Synology API. Returns a SynoStorage object containing storage data, loading it from the API only once and caching it in self._storage for subsequent calls.
9779	Creates a context object for a specific request by extracting tenant information and sender data from the request and body, then returns a Context instance with tenant, sender details, signed request, and context data.
9780	Returns the cached token of the current tenant, fetching it from the tenant if not already cached.
9781	Helper function for building an attribute dictionary by calling the widget's build_attrs method and returning the result.
9782	A class decorator that ensures specified apps are included in INSTALLED_APPS by merging them with existing apps and returning an override_settings decorator.
9783	A class decorator that removes specified apps from INSTALLED_APPS using override_settings.
9784	Return a dictionary of all global_settings values where keys are uppercase attribute names and values are their corresponding values from the global_settings module.
9785	Handles HTTP GET requests for OAuth2 authorization flow, serving redirect callback with authorization code or a link page, with proper response codes and content types.
9786	Helper method to retrieve and process a value from the configuration, supporting boolean conversion, value splitting, and custom function processing with error handling.
9787	Change the value of the given key in the configuration file to the given value. If the section doesn't exist, it will be added. The configuration is then written back to the file.
9788	Migrates an old-format OAuth2Util config file to the new format by reading from the old file and writing to the new file with a "[app]" section header.
9789	Starts a webserver to receive OAuth2 authorization codes, configured with the specified authorize URL and running in a separate daemon thread.
9790	Wait for a response from the user by checking the server's response code in a loop with 2-second intervals, then wait an additional 5 seconds before shutting down the server.
9791	Get new OAuth access information from Reddit using a built-in webserver, handle the authentication flow, and store the obtained tokens.
9792	Check if authentication tokens are present and request new ones if any are missing.
9793	Sets the OAuth2 access credentials on the Reddit object, with retry logic up to 5 attempts. If token setting fails due to invalid token or HTTP exceptions, it logs the request for a new token and retrieves new access information. Raises ConnectionAbortedError if maximum retry attempts are exceeded.
9794	Method `refresh(self, force=False, _retry=0)` checks if an OAuth2 token is still valid and requests a new one if needed. It includes a retry mechanism up to 5 attempts and can force a token refresh regardless of validity. The method handles token expiration by checking against a refresh margin and updates token information in the configuration. It also manages exceptions like invalid tokens by falling back to requesting new access information.

Key aspects:
- Validates token expiration based on current time and refresh margin
- Uses retry logic with maximum 5 attempts
- Forces refresh when `force=True` parameter is used
- Handles OAuth token expiration and HTTP exceptions
- Updates token values in configuration and sets new credentials
- Implements fallback to `_get_new_access_information()` on refresh failure

The method should be called before making praw requests if more than an hour has passed since last token use.
9795	Creates a DynamoDB table for run manifests with a simple hash key on the run ID attribute, using provisioned throughput of 5 units for both read and write operations. Waits for the table to exist before returning. If the table already exists, it silently ignores the error.
9796	Split an S3 path into bucket name and path components, removing the protocol prefix and normalizing the path prefix.
9797	Check if any object within a given S3 prefix is stored in Glacier storage class by examining the storage class of the first object in that prefix. Returns True if Glacier storage class is found, False otherwise.
9798	Extract date part from run id

Arguments:
key - full key name, such as shredded-archive/run=2012-12-11-01-31-33/
      (trailing slash is required)

Returns:
- If the run_id part of the key contains a valid date in format '%Y-%m-%d-%H-%M-%S', returns the original key
- If the date is invalid or missing, returns None

Examples:
extract_run_id('shredded-archive/run=2012-12-11-01-11-33/') returns the key unchanged
extract_run_id('shredded-archive/run=2012-12-11-01-11-33') returns None
extract_run_id('shredded-archive/run=2012-13-11-01-11-33/') returns None (invalid month)
9799	Remove all keys with Nones as values from a dictionary.

>>> clean_dict({'key': None})
{}
>>> clean_dict({'empty_s': ''})
{'empty_s': ''}
9800	Add run_id to a DynamoDB manifest table using the provided DynamoDB client and table name.
9801	Check if a run_id exists in a DynamoDB table by querying for the item with that run_id as the key. Returns True if the item exists (run_id is stored) or False if it doesn't exist. Uses the DynamoDB get_item operation with the specified table name and run_id to perform the check.
9802	Extracts schema information from an Iglu URI by matching it against a regular expression pattern and returning a dictionary containing vendor, name, format, and version components. Raises SnowplowEventTransformationException if the URI doesn't conform to the expected format.
9803	Create an Elasticsearch field name from a schema string by extracting schema components, converting to snake_case, and formatting with a prefix.
9804	Converts a contexts JSON to an Elasticsearch-compatible list of key-value pairs, where keys are fixed schema names and values are lists of context data objects grouped by schema.
9805	Converts an unstructured event JSON to a list containing one Elasticsearch-compatible key-value pair, where the key is a fixed schema name and the value is the inner data. Raises an exception if the inner data field cannot be extracted.
9806	Transforms a Snowplow enriched event TSV into JSON format by splitting the input line by tabs and processing it with the jsonify_good_event function, using optional parameters for field types and geolocation data handling.
9807	Converts a Snowplow enriched event array into a JSON object by mapping fields to known field types, handling geolocation data, and applying transformation functions while collecting any parsing errors.
9808	Get the template used in a TemplateResponse, returning a tuple of "active choice, all choices". Handles cases where template_name is None, a list/tuple of templates, or a single string/template object, and returns appropriate template names and choices.
9809	Prints the entire template context by formatting each context scope with both detailed and summary views, automatically collapsing long objects by default for better readability.
9810	Prints a set of variables by resolving them in the given context and formatting their values, handling cases where variables don't exist by showing available context variables.
9811	Highlight common SQL words in a string by wrapping them in strong tags and converting newlines to HTML line breaks.
9812	Dump a variable to a HTML string with sensible output for template context fields, filtering out unusable fields. Handles QuerySet, Manager, string, Promise, dict, list, and object types with appropriate formatting. Uses fallback to regular pprint for unknown types.
9813	Summarizes a dictionary by printing its keys in a formatted HTML string, showing "..." for non-expanded types. Returns an empty string if the dictionary is empty.
9814	Apply HTML highlighting to text content by escaping and replacing specific patterns with styled HTML elements, including special handling for iterator objects, dynamic items, proxy objects, functions, generators, object addresses, managers, and class representations. Also handles Django's WSGIRequest formatting consistency.
9815	Formats an item in the result (dictionary key, value, etc.) using the parent PrettyPrinter's format method, with exception handling that catches HANDLED_EXCEPTIONS and returns formatted exception information instead.
9816	Summary: Recursive formatting implementation with exception handling that falls back to formatted exception output when primary formatting fails.
9817	Parse the next token in the stream and return a `LatexToken`. Raises `LatexWalkerEndOfStream` if end of stream reached. Deprecated: use `LatexWalker.get_token()` instead.
9818	Parses LaTeX content and returns a tuple containing a list of LatexNode objects, the current position, and length. The parsing can be configured to stop at specific delimiters. This function is deprecated - use LatexWalker.get_latex_nodes() instead.
9819	Extracts text from LaTeX content for database indexing, using LatexNodes2Text internally. Deprecated since version 1.0.
9820	Sets the directory for looking up input files when encountering ``\input`` or ``\include`` macros. Configures file search directory, strict input validation, and parse flags for LaTeX parsing. Registers callback functions for input/include macros or discards them if no directory is specified.
9821	Reads and returns the contents of a LaTeX input file, with support for `.tex` and `.latex` extensions. Respects strict input directory policies to prevent directory traversal attacks. Returns empty string on error.
9822	Converts LaTeX code to its textual representation by parsing it with LatexWalker and converting the resulting node list to text.
9823	Encodes a UTF-8 string to a LaTeX snippet with options for ASCII character handling, bracket usage, and bad character substitution or failure.
9824	Unpacks `\uNNNN` escapes in a string, converting them to UTF-8 encoded characters while handling surrogate pairs and preserving ASCII strings efficiently.
9825	Get information for this organisation. Returns a dictionary of values.
9826	Get all boards for the organization by fetching board JSON data and converting each JSON object into a Board instance, returning a list of Board objects.
9827	Get all members attached to this organisation. Returns a list of Member objects.

Returns:
    list(Member): The members attached to this organisation
9828	Updates the organization's information by sending a PUT request to the base URI with optional query parameters, then returns a new organization object created from the response JSON.
9829	Remove a member from the organisation by sending a DELETE request to the members API endpoint. Returns JSON data of all remaining members if successful, or raises an Unauthorised exception if the operation fails.
9830	Add a member to the board by their ID with specified membership type (normal or admin). Returns JSON of all members on success or raises an Unauthorised exception if unsuccessful.
9831	Adds a member to the board with specified email, fullname, and membership type (normal/admin). Returns JSON of all members on success or raises an Unauthorized exception if not authorized.
9832	Returns a dictionary containing information about the list by fetching JSON data from the base URI with optional query parameters.
9833	Creates a new card for the list using the provided query parameters and returns a Card object.
9834	Get all information for this Label by fetching JSON data from the base URI with optional query parameters, returning a dictionary of values.
9835	Get all items for this label by fetching JSON data from the checkItems endpoint, returning a list of dictionaries containing item values.
9836	Updates the current label's name and returns a new Label object with the updated name.
9837	Updates the current label by making a PUT request with provided query parameters and returns a new Label object created from the response.
9838	Returns a URL for browser-based authorization to retrieve an access token, including parameters for application name, token expiration, response type, and required scopes.
9839	Returns card information as a dictionary by fetching JSON data from the base URI with optional query parameters.
9840	Get board information for this card by fetching board JSON data and creating a Board object from it.
9841	Get list information for this card by making a request with optional query parameters and return a List object populated with the retrieved data.
9842	Get the checklists for this card. Returns a list of Checklist objects.

Returns:
    list(Checklist): The checklists attached to this card
9843	Adds a comment to this card by the current user.
9844	Adds an attachment to a card by encoding multipart form data and making a POST request to the attachments endpoint using the client's API key and user authentication token.
9845	Adds a checklist to the card and returns a Checklist object.
9846	Add a label to this card from a dictionary by making a POST request to the labels endpoint.
9847	Add an existing label to this card by posting the label ID to the card's labels endpoint.
9848	Add a member to this card and return a list of Member objects.
9849	Returns member information as a dictionary by fetching JSON data from the base URI with optional query parameters.
9850	Get all cards this member is attached to. Return a list of Card objects.

Returns:
    list(Card): Return all cards this member is attached to
9851	Get all organisations this member is attached to. Returns a list of Organisation objects.
9852	Creates a new board by making a POST request to the '/boards' endpoint with the provided query parameters, then returns a Board object built from the response JSON.
9853	Enable singledispatch for class methods by creating a wrapper that dispatches based on the type of the second argument.
9854	Get all information for this board by fetching JSON data from the board's URI path with optional query parameters, returning a dictionary of board values.
9855	Get the lists attached to this board by fetching JSON data and converting it to List objects. Returns a list of List objects.
9856	Get the labels attached to this board. Returns a list of Label objects.

Returns:
    list(Label): The labels attached to this board
```
9857	Get a Card for a given card id. Returns a Card object.

Returns:
    Card: The card with the given card_id
9858	Get the checklists for this board. Returns a list of Checklist objects by fetching JSON data and converting each item to a Checklist object.
9859	Returns the Organisation object attached to this board by fetching organisation JSON data and creating an Organisation instance.
9860	Updates the board's information by making a PUT request to the board's URI and returns a new board object created from the response.
9861	Creates a new list for a board by making a POST request to the lists endpoint and returns a new List object.
9862	Creates a label for a board by making a POST request to the labels API endpoint and returns a new Label object based on the response.
9863	Get all information for this Checklist. Returns a dictionary of values.
9864	Get the card that this checklist is associated with by retrieving the card ID from checklist information and fetching the card details from the client.
9865	Get the items for this checklist. Returns a list of ChecklistItem objects by iterating through checklist item JSON data and creating corresponding ChecklistItem objects associated with the card and checklist.
9866	Updates the current checklist with a new name and returns a new Checklist object.
9867	Adds an item to the checklist and returns a dictionary containing the new item's values.
9868	Deletes an item from this checklist.
9869	Updates the name of the current checklist item and returns a new ChecklistItem object with the updated name.
9870	Update the state of the current checklist item. Returns a new ChecklistItem object with the updated state.
9871	Adds the API key and user auth token to the query parameters.
9872	Method that checks HTTP response status codes and raises appropriate exceptions for unauthorized access (401) and other non-successful responses (non-200 status codes).
9873	Builds a complete API URI by combining the base URL, cleaned path, and encoded query parameters.
9874	Make a call to Trello API and capture JSON response. Raises an error when it fails.

Returns:
    dict: Dictionary with the JSON data
9875	Create an Organisation object from a JSON object.

Returns:
    Organisation: The organisation from the given `organisation_json`.
9876	Creates a Board object from a JSON representation by initializing it with the provided board data and trello client.
9877	Creates a Label object from a JSON object containing label data.
9878	Creates a List object from a JSON object by extracting the id, name, and data fields from the input JSON and passing them to the List constructor along with the current trello_client instance.
9879	Creates a Card object from a JSON representation using the Trello client.
9880	Creates a Checklist object from a JSON object containing checklist data.
9881	Creates a Member object from JSON data by extracting the member's ID, full name, and raw data, then initializing and returning a new Member instance with the provided trello client.
9882	Get an organisation by ID, optionally filtering by name, and return the organisation object.
9883	Get a board by ID, optionally specifying a name, and return the board object.

The method takes an optional name parameter and returns a Board object by calling create_board with a dictionary containing the provided id and name.
9884	Get a list by ID, optionally filtering by name, and return the list object.
9885	Get a card by ID, optionally with a name, and return the created Card object.
9886	Get a checklist by ID, optionally with a name, and return the checklist object.
9887	Get a member by ID or the current member if no ID is provided, returning a Member object.
9888	Extracts the root domain from a URL by removing subdomains, protocol, paths, and query strings. Raises InvalidURLException for invalid URLs.
9889	A generator function that converts raw text into tokenized sentences without markup, replacing dates with '7777' and optionally preserving whitespace for offset alignment.
9890	Converts raw text with markup and non-textual content to tokenized sentences by removing URLs, markup, dates, and other non-text elements while normalizing the text.
9891	A generator that converts raw text into tokenized sentences by removing markup, normalizing dates to '7777', and preserving wikipedia anchors while optionally maintaining whitespace for offset correspondence.
9892	Writes an encrypted password to a configuration file with base64 encoding.
9893	Splits a string into substrings based on decision locations, yielding parts only where 'SHOULD_SPLIT' occurs, with the last part including any remaining text.
9894	Marks regex matches in text by adding 'SHOULD_SPLIT' markers at the end locations of each matching group in split_locations.
9895	Marks begin and end locations of regex matches in split_locations array, adding SHOULD_SPLIT markers at match boundaries and SHOULD_NOT_SPLIT markers within matches.
9896	Main command line interface that handles argument parsing and execution with keyboard interrupt handling.
9897	Create an AES cipher object using Argon2 key derivation for encryption/decryption with specified parameters.
9898	Returns the AES mode constant for a given mode string, or returns a list of all valid AES modes if no mode is specified.
9899	```python
def priority(self):
    """
    Applicable for all platforms, where the schemes, that are integrated
    with your environment, does not fit.
    """
    try:
        __import__('argon2.low_level')
    except ImportError:     # pragma: no cover
        raise RuntimeError("argon2_cffi package required")
    try:
        __import__('Crypto.Cipher.AES')
    except ImportError:     # pragma: no cover
        raise RuntimeError("PyCryptodome package required")
    if not json:            # pragma: no cover
        raise RuntimeError("JSON implementation such as simplejson "
            "required.")
    return 2.5
```

Summary: This method checks for required dependencies (argon2_cffi, PyCryptodome, and JSON implementation) and returns a priority value of 2.5, typically used to determine the preference level of this authentication scheme when multiple schemes are available. It raises RuntimeError exceptions if any required packages are missing.
9900	Method `_check_scheme(self, config)` validates the encryption scheme from a configuration object. It extracts the scheme string, verifies the AES mode is supported, validates the scheme matches the expected value, and handles scheme string parsing. Raises `AttributeError` if scheme is missing or `ValueError` for invalid or mismatched schemes.
9901	Method: onPublish
Description: Callback method that receives messages from a publisher. Logs the received message payload at debug level.
Parameters: topic, payload, qos, dup, retain, msgId
Returns: None
Logging: Debug level logging of payload content
9902	Generate sequential protocol packet IDs that persist beyond session lifetime, ensuring IDs stay within 16-bit range (1-65535) and never use 0.
9903	Summary: The `connect` method sends a CONNECT control packet but currently raises an MQTTStateError with the message "Unexpected connect() operation" and the current class name, indicating that the connect operation is not expected or valid in the current state.
9904	Handles CONNACK packet from the server and logs an error message indicating an unexpected CONNACK packet was received in the current class's logging source.
9905	Encodes a UTF-8 string into MQTT format by prepending the byte length (2 bytes) to the UTF-8 encoded string bytes, with length validation (max 65535 bytes). Returns a bytearray containing the length-prefixed UTF-8 string. Raises StringValueError if string length exceeds 65535 bytes.
9906	Decodes an UTF-8 string from an encoded MQTT bytearray by extracting the length from the first two bytes, then decoding the subsequent bytes as UTF-8, returning the decoded string and remaining bytearray.
9907	Encodes a 16-bit unsigned integer into MQTT format by converting it to a 2-byte bytearray where the first byte contains the upper 8 bits and the second byte contains the lower 8 bits.
9908	Encodes a value into a multibyte sequence using MQTT protocol format, where each byte contains 7 bits of data and the high bit indicates if more bytes follow. Used for encoding packet length fields.
9909	Decodes a variable length value defined in the MQTT protocol, typically representing remaining field lengths. The function processes each byte of the encoded value, extracting the 7-bit payload and accumulating it with proper multiplication by powers of 128 (0x80). The loop continues until a byte without the most significant bit set is encountered, indicating the end of the encoded value. Returns the decoded integer value.
9910	Encode and store a DISCONNECT control packet by creating a 2-byte header with value 0xE0 and returning it as string (Python 2) or bytes (Python 3).
9911	Encode and store a CONNECT control packet with variable header and payload sections, handling protocol version, flags, keepalive, client ID, will topic/message, username, and password according to MQTT specification, raising ValueError if string lengths exceed 65535 bytes.
9912	Decode a CONNECT control packet by parsing its fixed header, variable header containing protocol version, flags, and keepalive timer, and payload containing client ID, optional will message, username, and password information.
9913	Encodes and stores a CONNACK control packet by constructing header and variable header bytes, then returns the encoded packet as string or bytes.
9914	Decode a CONNACK control packet by parsing the fixed header to determine the variable length field size, extracting the remaining packet data, and then reading the session present flag and result code from the variable header fields.
9915	Decode a SUBSCRIBE control packet by parsing the packet structure, extracting the message ID, and collecting topic subscriptions with their quality of service levels.
9916	Encodes and stores a SUBACK control packet by constructing the header with fixed and variable parts, including message ID and granted QoS codes, then returns the encoded bytes.
9917	Encodes and stores an UNSUBSCRIBE control packet with QoS=1, including topic strings in the payload. Raises ValueError if any topic string exceeds 65535 bytes. Returns the encoded packet as string (Python 2) or bytes (Python 3).
9918	Decode a UNSUBACK control packet by parsing its length, message ID, and topic list from the encoded packet data.
9919	Encode and store an UNSUBACK control packet by creating a header with fixed byte value 0xB0, appending the message ID as a 16-bit integer, and including the length-encoded variable header, then store the complete encoded packet.
9920	Encodes and stores a PUBLISH control packet by constructing header, variable header with topic and message ID (when QoS is enabled), and payload. Raises ValueError for excessive topic or packet size, and TypeError for invalid payload types. Returns the encoded packet as bytes.
9921	Decode a PUBLISH control packet by parsing its header flags, topic, and payload while handling variable-length length encoding and QoS levels.
9922	Decode a PUBREL control packet by parsing its remaining length and message ID, while extracting the DUP flag from the packet header.
9923	Return URL for API call method with optional method name and keyword arguments.
9924	Sends an API request using the specified method and parameters, automatically including version and token if available, and returns the JSON response as a dictionary.
9925	Refresh the list of blocks to disk by broadcasting block data from rank 0 to all processes in the communicator.
9926	Method: `format_data`

Summary: Converts a dictionary of analytical data into a numpy array format suitable for scikit-learn clustering algorithms. The method handles both single and multiple analytes, removes NaN values, and optionally scales the data using a pre-defined scaler.

Parameters:
- `data` (dict): Dictionary containing analytical data with keys matching the analytes
- `scale` (bool): Whether to apply data scaling (defaults to True)

Returns:
- Tuple of (processed_data_array, sampled_indices) where processed_data_array is the cleaned, potentially scaled numpy array suitable for sklearn clustering, and sampled_indices represents the indices of valid (non-NaN) samples

The method first extracts nominal values from the input data, handles single vs. multiple analytes differently, removes any rows containing NaN values, and applies scaling if requested.
9927	Formats data for cluster fitting by scaling it using StandardScaler.
9928	Fit KMeans clustering algorithm to data.

Parameters:
- data: array-like, a dataset formatted by `classifier.fitting_data`
- n_clusters: int, the number of clusters in the data
- **kwargs: passed to `sklearn.cluster.KMeans`

Returns:
Fitted `sklearn.cluster.KMeans` object
9929	Fit MeanShift clustering algorithm to data using scikit-learn's MeanShift implementation. Automatically estimates bandwidth if not provided, scales data before clustering, and supports bin seeding option. Returns the fitted scikit-learn MeanShift object.
9930	Fit classifiers from large dataset using specified clustering method.

Parameters:
- data: dict containing data for clustering
- method: str defining clustering method ('kmeans' or 'meanshift')
- n_clusters: int for K-Means only (number of clusters to identify)
- bandwidth: float for Meanshift only (bandwidth value for clustering)
- bin_seeding: bool for Meanshift only (whether to use bin_seeding)
- **kwargs: additional arguments passed to sklearn.cluster.MeanShift

Returns:
- list

The method fits clustering classifiers to the provided data using either K-Means or Meanshift algorithms, sorts cluster centers by the first column value to avoid random variation, and recalculates labels to be consistent with the cluster centers.
9931	Labels new data with cluster identities using a fitted classifier.

Parameters:
- data (dict): A data dictionary containing the same analytes used to fit the classifier
- sort_by (str): The name of an analyte used to sort the resulting clusters (default: first analyte used in fitting)

Returns:
- array: Clusters array with the same length as the input data
9932	Map cluster identities from sampled data back to original data size, filling non-finite values with -2.
9933	Sort clusters by the concentration of a particular analyte by calculating mean values and ranking clusters accordingly.
9934	The `get_date` function converts a datetime string into a datetime object, with an optional custom time format. If no time format is provided, it uses `dateutil.parser` to automatically detect the format. If a time format is specified, it parses the datetime string using the provided format. The function returns the resulting datetime object.
9935	Returns the total number of data points in the values of a dictionary by summing the lengths of all values.
9936	Returns the total length of analysis by finding the maximum uTime value across all items in the dictionary.
9937	Function that determines the most appropriate plotting unit for data by finding the optimal scale factor and unit string based on the input value and focus stage, returning a tuple of (multiplier, unit).
9938	Formats an element string with superscript numbers in LaTeX style, extracting the element symbol and numeric part from input like "H2" and returning "$^{2}$H".
9939	Converts analyte format from '27Al' to 'Al27' by extracting the element symbol and mass number using regex patterns. Takes a string input of format [A-z]{1,3}[0-9]{1,3} and returns a string of format [0-9]{1,3}[A-z]{1,3}.
9940	Converts analyte format from 'Al27' to '27Al' by extracting element symbol and mass number using regex patterns.
9941	Function to copy all files with specified extension from a nested directory structure to a single destination directory. Takes an input directory, file extension (default '.csv'), and output directory (creates new one if not provided). Copies all matching files from subdirectories to the output directory. Returns None.
9942	Enumerates contiguous boolean groups in an array by assigning consecutive numbers to True values while preserving False values as zeros. Takes a boolean array and optional starting number, returning an array where each contiguous group of True values is labeled with incrementing integers starting from nstart+1, and False values remain as 0.
9943	Generate boolean array from list of limit tuples, where True indicates x values are between each pair of tuples.
9944	Returns rolling window smooth of a 1D array using stride_tricks for efficient computation. Applies a moving average filter with specified window width, padding the edges with mean values. The window size is automatically adjusted to be odd if even. Uses convolution with a uniform kernel for smoothing operation.
9945	Returns rolling window gradient of a 1D numpy array using stride_tricks for efficient computation. Takes an array and window width as input, ensures window width is odd, creates rolling windows of the specified width, and calculates the gradient of each window using polynomial fitting. The gradient is returned as a numpy array with the same length as the input array minus the window size plus one.
9946	Function to find local minima in 1D arrays. Returns x-coordinates where y has local minima by comparing adjacent points.
9947	Identifies clusters in data using the MeanShift algorithm. Returns cluster labels and a list containing a single NaN value.
9948	Identifies clusters in data using the K-Means algorithm and returns cluster labels and NaN value.

The function applies K-Means clustering to the input data with the specified number of clusters, returning the cluster assignments for each sample along with a NaN placeholder value. The implementation uses scikit-learn's KMeans class and returns a tuple containing the cluster labels array and a list with a single NaN value.
9949	DBSCAN clustering algorithm implementation that identifies clusters in n-dimensional data. The function supports automatic epsilon selection when the number of expected clusters is specified, iteratively adjusting epsilon until the target number of clusters is found or maximum iterations are reached. It returns cluster labels and core sample masks for each data point. The algorithm requires normalized data with mean=0 and variance=1 for optimal performance.
9950	Returns a list of unique SRM names defined in the SRM database file by reading the table and extracting unique index values.
9951	Read LAtools configuration file and return parameters as a dictionary. If 'DEFAULT' is specified, uses the default configuration from the settings. Returns a dictionary containing the configuration parameters with the config name updated.
9952	Reads the latools configuration file and returns a tuple containing the config file path and a ConfigParser object.
9953	Prints all currently defined LAtools configurations by reading the configuration file and displaying each section with its key-value pairs, marking the default configuration and indicating protected sections.
9954	Creates a copy of the default SRM table file at a specified location using the given configuration. If no destination is provided, saves it as 'LAtools_[config]_SRMTable.csv' in the current working directory. Returns the destination path.
9955	Creates a new configuration in latools.cfg by copying settings from an existing configuration and optionally setting it as the default for future analyses.
9956	Summary: The `change_default` function allows users to change the default configuration in a LaTeX tools configuration file. It first validates that the specified configuration exists, then prompts the user for confirmation before updating the default configuration in the config file. The function handles special case for 'REPRODUCE' configuration with an additional warning message. User must respond with 'y' to confirm the change, otherwise no action is taken.
9957	Exclude data after the first excluded portion based on a threshold, useful for LA-ICPMS spot measurements where contamination persists.
9958	Defragments a boolean filter by removing consecutive fragments (sequences of values) that are shorter than or equal to a specified threshold length. Depending on the mode, it either includes or excludes these fragments by changing their values. Returns the defragmented boolean array.
9959	Applies exponential decay and noise spike filtering to experimental data. Uses either a provided exponent or automatically calculates it, applies rolling window standard deviation filtering, and updates the despiked data while recalculating total counts.
9960	Plots a detailed autorange report for the sample using specified parameters for signal processing and visualization. Supports different analytes and transformations, returning the figure and axes objects.
9961	Transform boolean arrays into list of limit pairs for signal/background ranges. Gets time limits of signal/background boolean arrays and stores them as sigrng and bkgrng arrays. Also calculates trace numbers from signal array.
9962	Divides all analytes by a specified internal standard analyte and stores the ratios in self.data['ratios']. If internal_standard is provided, it updates the internal standard analyte. The method sets the focus to 'ratios' and returns None.
9963	Apply calibration to data using provided calibration parameters and store results in calibrated data.
9964	Calculate sample statistics for given analytes with specified filtering and statistical functions.

Parameters:
- analytes: list of analytes to calculate statistics on (defaults to all analytes)
- filt: boolean or string specifying filter to apply (True uses default filter, string uses specific filter)
- stat_fns: dictionary of {name: function} pairs where functions take array input and return single statistics
- eachtrace: boolean indicating whether to calculate per-ablation statistics (True) or whole sample statistics (False)

Returns:
- None (stores results in self.stats dictionary containing analytes and statistic arrays of shape (samples, analytes))

The method calculates statistics from the 'focus' data variable and handles NaN values appropriately. It applies the specified filter to data before computing statistics, with options for either per-trace or aggregate sample statistics.
9965	Function for calculating the ablation time for each ablation.

Returns
-------
    dict of times for each ablation.
9966	Apply threshold filter to given analyte, creating two filters - one keeping data above the threshold and one keeping data below the threshold.
9967	Apply gradient threshold filter to specified analyte data, creating two filters (above and below threshold) based on gradient calculations.
9968	Calculate local correlation between two analytes using a rolling window approach, with optional filtering and caching behavior.
9969	Filter data based on correlation analysis between two analytes using rolling window calculations, excluding data points with correlation coefficients above the threshold and p-values below the significance level.
9970	Creates a new filter by combining existing filters using logical operations and adds it to the filter collection.
9971	Returns a dictionary of analysis parameters including sample, ratio_params, despike_params, autorange_params, bkgcorrect_params, filter_params, filter_sequence, and filter_used.
9972	Plot histograms for all items in a dictionary of arrays.

Parameters:
- dat: dict containing {key: array} pairs to plot
- keys: array-like of specific keys to plot (None for all)
- bins: int number of bins in each histogram (default=25)
- logy: bool whether y-axis uses log scale
- cmap: dict mapping keys to colors (None for grey)
- ncol: int number of subplot columns (default=4)

Returns:
- fig, axes: matplotlib figure and axes objects

The function creates a grid of histograms with automatic layout, handles NaN values, supports custom colors and log scales, and adds key labels to each subplot.
9973	Computes summary statistics for paired x, y data including residual statistics, regression analysis, and Kolmogorov-Smirnov test. Returns a pandas DataFrame with metrics such as N, median, IQR, regression slope and intercept with p-values, and KS test statistics.
9974	Loads LAtools reference data from an online repository. Downloads either a specific dataset or all datasets based on the 'name' parameter. Returns a pandas DataFrame or dictionary of DataFrames containing reference data with proper indexing and column naming.
9975	Looks up an instance of type class `TC` for type `G` by traversing G's method resolution order and checking for matching type class instances.
9976	Returns a DataFrame of all elements and isotopes loaded from 'latools/resources/elements.pkl'. If all_isotopes=True (default), returns the full DataFrame with all isotopes indexed by element. If all_isotopes=False, returns a DataFrame with weighted average atomic weights for each element. The data is scraped from https://www.webelements.com/ and includes columns: element, atomic_number, isotope, atomic_weight, percent.
9977	Calculates the molecular weight of a chemical compound given in standard notation. Uses regular expressions to parse molecular formulas, handling both simple components and parenthetical subgroups. Applies atomic weights and percent compositions from a periodic table to compute the total molecular weight. Supports formulas like 'CO2', 'HCO3', or 'B(OH)4'.
9978	Generate a single ANSI escape sequence mapping by combining field names and values from positional and keyword arguments, returning a named tuple with the combined ANSI sequences.
9979	Summary: The `annihilate` function filters out elements from a stack that match a given predicate, keeping only the last matching element at the end of the result. It uses `filter` to remove predicate matches and `reduce` to find the last matching element, returning a new tuple with non-matching elements followed by the last match if one exists.
9980	Remove duplicates from the stack in first-seen order.
9981	Calculate Gaussian weighted moving statistics (mean, standard deviation, and standard error) for data smoothing.

Parameters:
x : array-like
    The independent variable
yarray : (n,m) array
    Dependent variables to smooth, where n = x.size
x_new : array-like
    New x-scale for interpolation
fwhm : int
    Full Width Half Maximum of the Gaussian kernel

Returns:
(mean, std, se) : tuple
    Tuple containing the Gaussian weighted moving mean, standard deviation, and standard error arrays
9982	Gaussian function with parameters amplitude (A), center (mu), and width (sigma).
9983	Calculate the standard error of array 'a' by dividing the nan-standard deviation by the square root of the count of finite values in the array.
9984	Helper function to get sample names from a specified subset. If no subset is specified, returns all samples. Raises KeyError if the specified subset does not exist.
9985	Despikes data using exponential decay and noise filters based on specified parameters. Applies filters iteratively up to `maxiter` times, with options to automatically determine exponential decay coefficient and plot results. Updates analysis stage to 'despiked' upon completion.
9986	Calculates the background using a Gaussian weighted mean for specified analytes. It optionally applies filtering to isolated background regions and allows customization of the weighting window and calculation steps. The result includes mean, standard deviation, and standard error for each analyte.
9987	Background calculation using 1D interpolation with scipy.interpolate.interp1d. Supports multiple analytes, custom interpolation kind, minimum point threshold, custom step size, and optional rolling filter for background regions. Processes data through different analysis stages specified by focus_stage parameter.
9988	Subtracts calculated background from data for specified analytes, using uncertainty-aware interpolation and applying corrections to the designated analysis stage. Updates progress bar during processing and tracks completed stages.
9989	Calculates the ratio of all analytes to a specified internal standard analyte after background subtraction, updates the processing stages, and returns None.
9990	Creates a subset of samples that can be treated independently. Returns the name of the created subset.
9991	This method applies a gradient threshold filter to specified analyte data based on percentile values. It calculates moving gradients over a given window and generates boolean filters above and below the specified percentiles. The filter can be applied at either population or individual sample level, and supports filtering by specific samples or subsets. The method updates the data's filter object with new filters identifying gradients that are either above/below a single percentile or outside/inside a range of percentiles. Returns None.
9992	Fit a clustering classifier using specified analytes and clustering method. Supports 'meanshift' and 'kmeans' algorithms with optional parameters. Allows selection of samples or subset for training. Returns the classifier name.
9993	Apply a clustering classifier to samples, either all samples or a specified subset, and add filtered results with classifier labels to the data.
9994	Filters data based on rolling correlation between two analytes, excluding samples where correlation exceeds threshold and is statistically significant.
9995	Activates data filters for specified analytes and samples. Supports partial matching for filter names and can apply filters to specific samples or all samples. Shows filter status if requested. Handles exceptions gracefully with warnings.
9996	Turns data filters off for particular analytes and samples.

Parameters:
- **filt**: optional, str or array_like - Name, partial name or list of names of filters. Supports partial matching. Defaults to all filters.
- **analyte**: optional, str or array_like - Name or list of names of analytes. Defaults to all analytes.
- **samples**: optional, array_like or None - Which samples to apply this filter to. If None, applies to all samples.
- **subset**: optional, None - Not directly used in the function.
- **show_status**: optional, bool - If True, displays the filter status after turning filters off. Defaults to False.

Returns:
- None

The function iterates through specified samples and turns off the specified filters for the given analytes. If a sample fails to have filters turned off, a warning is issued. If show_status is True, it displays the current filter status.
9997	Prints the current status of filters for specified samples, subsets, or all samples. Can display filter information for a specific sample, a specific subset, or all subsets depending on the provided parameters. If stds is True, standards are included in the output.
9998	Remove 'fragments' from the calculated filter by applying a defragmentation operation to specified samples and filter, where contiguous data regions with the given threshold or fewer points are considered fragments and either included or excluded based on the mode parameter.
9999	Report how many data are removed by the active filters for each sample subset, and optionally print a formatted summary table. Returns a dictionary mapping sample names to tuples of (total_count, filtered_count, percent_removed).
10000	Plot histograms of gradients for specified analytes across samples, with options for filtering, binning, and subset selection. Calculates gradients if needed and returns the matplotlib figure and axes objects.
10001	Plot analyte gradients against each other using 2D histograms or scatter plots, with options for filtering, log normalization, and custom styling.
10002	Plot histograms of specified analytes with customizable styling and filtering options.
10003	Plots analytes as a function of time for specified samples and analytes, with options for filtering, scaling, statistics overlay, and saving plots to a directory. Supports different focus stages of analysis and can show signal/background regions. Returns None.
10004	Plot analyte gradients over time for specified samples and analytes, with options for customizing the plot appearance, saving location, and focus stage of the analysis. It generates and saves gradient plots for each sample in the specified subset.
10005	Filter reports for all filters containing `filt_str` in the name, plotting them for specified analytes and saving to the output directory.
10006	Calculate sample statistics for given analytes and statistics functions, optionally filtered by sample type. Returns statistics for each sample and analyte combination.
10007	Returns a pandas DataFrame containing all sample statistics. The method aggregates statistics from samples, handles multi-index formatting for 2D data, optionally appends ablation time data, removes internal standards, and saves the result to a CSV file if specified. The resulting DataFrame is stored in self.stats_df and returned.
10008	Exports a minimal dataset for reproduction purposes, creating CSV files for specified analytes and samples with metadata headers.
10009	Exports raw data traces from specified analysis stages to CSV files. Supports filtering by analytes and samples, with options for different data stages (raw, despiked, background-subtracted, ratios, calibrated). Can create a zip archive of the exported files.
10010	Save analysis.log in specified location.
10011	Exports analysis parameters, standard info, and a minimal dataset for another user to import, with options to specify target analytes and export path.
10012	Split a large analysis file into multiple smaller files based on a regex pattern. The function reads an input file, identifies section boundaries using a regular expression pattern, and creates separate output files for each section. Optional parameters allow specifying global header rows to include in each section, filename patterns for the output files, and trimming of lines from the beginning and end of each section. If no output directory is specified, it creates a 'split' directory in the same location as the input file. Returns the path to the output directory containing the split files.
10013	Maps function `f` over the traversable `fa`, then folds over the result using initial element `z` and operation `g` (defaulting to addition).
10014	Creates a comprehensive PCA visualization plot showing component loadings and pairwise scatter/histogram plots of principal components. Returns the figure, axes, and data arrays used in the plot.
10015	Normalize data by removing mean and dividing by standard deviation using Bayesian statistics, handling cases with insufficient data by returning NaN values.
10016	**Summary:** The `median_scaler` function performs median-based normalization on input data by subtracting the median and dividing by the interquartile range (IQR). It handles missing values by excluding NaN entries when calculating statistics. If fewer than 3 non-NaN values are present, it returns an array of NaN values. Otherwise, it returns the scaled data where values are centered at zero and scaled by the IQR.
10017	Apply standard deviation filter to remove anomalous values by iteratively identifying outliers more than nlim standard deviations from the rolling mean and replacing them with local mean values.
10018	Remove physically impossible data points from a signal using exponential decay filtering based on instrumental washout characteristics, iteratively applying the filter up to a maximum number of times until no more points are removed. The function identifies outliers that exceed expected bounds based on exponential decay models and noise levels, replacing them with preceding values. Returns the filtered signal.
10019	Add a filter with given parameters to the object, storing it with a generated name and updating internal data structures including index, sets, components, info, params, and switches. The filter is associated with a specific set number, generating a unique identifier based on the current count and provided name.
10020	Remove a filter from the object by name or set number. Can remove specific filter by name, remove entire set by set number, or remove all filters from the same set as the specified filter. Updates internal data structures accordingly.
10021	Clear all filters by resetting all internal dictionaries and counters to their initial empty states.
10022	Remove unused filters by iterating through sorted components and checking if each filter is unused across all analytes, then removing it if unused.
10023	Fuzzy string matching method that identifies filter names by comparing input string against all filter names using `fuzzywuzzy.fuzzy.ratio`. Returns the most closely matched filter name, or all equally matched names if `multi=True`. Raises ValueError if multiple filters match equally well and `multi=False`.
10024	Create a filter from a logical expression by parsing and evaluating string-based boolean operations on filter components. Takes a string key with logical operators (&, |, parentheses) to combine filters, where filter names are matched using fuzzy matching against available components. Returns a boolean array filter where True values indicate matching elements. Example: key = '(Filter_1 | Filter_2) & Filter_3' creates a filter combining Filter_1 OR Filter_2 AND Filter_3.
10025	Method that provides flexible access to specific filters using various key formats (string, dictionary, or boolean) and returns a boolean filter array. Supports lookup by filter name, dictionary of expressions, or logical filtering based on analyte specifications.
10026	Get info for all filters by iterating through sorted component keys and formatting their information into a string with key-value pairs separated by newlines.
10027	A decorator function that logs method calls with their parameters to a log list.
10028	Writes an analysis log to a file with specified header. Takes a log list, header list, and file name as input. If no file extension is provided, defaults to '.lalog' extension. Returns the full path of the created file.
10029	Reads a latools analysis.log file and returns dictionaries of analysis arguments and file paths. The function parses the log file to extract run arguments for each analysis step and the locations of the data directory and SRM database used in the analysis. It returns a tuple containing runargs (a list of function calls with their arguments and keyword arguments) and paths (a dictionary mapping path names to their file locations).
10030	Decorator that attempts to automatically login and retry a failed async function call before raising an error. It wraps the function with a timeout and if the initial call fails due to timeout, client error, or other errors, it tries to relogin and retry the function once. If the retry also fails, it raises an Error with the function's name as the error message.
10031	Async function that retrieves and prints SMS information from a modem by logging in with provided credentials, fetching SMS data, displaying it using pretty print, and then properly closing the modem connection and web session.
10032	async def send_message():
    """Example of sending a message."""
    jar = aiohttp.CookieJar(unsafe=True)
    websession = aiohttp.ClientSession(cookie_jar=jar)

    modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)
    await modem.login(password=sys.argv[2])

    await modem.sms(phone=sys.argv[3], message=sys.argv[4])

    await modem.logout()
    await websession.close()
10033	Parse a file-like object or string using MySQL grammar syntax and return pyparsing ParseResults.
10034	Returns a Jupyter nbviewer link for a given notebook URL by determining the URL type (github or generic) and constructing the appropriate nbviewer URL.
10035	Returns a formatted string using THUMBNAIL_TEMPLATE with snippet, thumbnail, and ref_name values.
10036	Returns a formatted code example string for gallery display using the CODE_TEMPLATE, or None if no code example exists.
10037	Returns the code example from notebook metadata, falling back to None if not found.
10038	Returns the jupyter nbviewer URL for this notebook, or None if unknown. Uses cached URL if available, otherwise tries to get URL from notebook metadata. If a URL is found, returns a nbviewer link.
10039	Returns the output file path with a specified file ending.
10040	Process a Jupyter notebook by executing it, generating output files, and creating Python and RST representations while optionally clearing output, removing tags, and disabling warnings.
10041	Creates a Python script from a notebook by using jupyter nbconvert, then cleans up IPython magic commands by commenting them out.
10042	Create an rst string for downloading supplementary data files, handling both single and multiple files with proper formatting.
10043	Create a thumbnail for HTML output by copying a thumbnail figure, saving it if found, or using the last PNG picture in reverse order if no thumbnail figure exists.
10044	Get summary and description of this notebook by parsing the first markdown cell and optionally the second markdown cell if the first one doesn't contain a description. Returns a tuple of (header, description).
10045	Scales an image to fit within specified dimensions while maintaining aspect ratio, centered in the output image. If input and output filenames are the same, image can only be scaled down. Uses PIL for image processing.
10046	Save a thumbnail image by scaling the original image to 400x280 pixels and storing it in a 'thumb' subdirectory with a '_thumb.png' suffix based on the reference name.
10047	Copy thumbnail figure from source location to output directory, returning the path to the copied file or the original object if it's not a string. If no thumbnail figure is found, return None.
10048	Return the URL corresponding to the given notebook file by looking up in urls dictionary or constructing URL from base url if urls is a string.
10049	Generator function that yields language codes for database change fields by:
1. Yielding language codes for fields that don't exist in db_table_fields
2. Yielding language codes extracted from database table field names that match the pattern 'field_name_language_code'
10050	Returns a function that gets the default value for a field in the current language, falling back to the default language or settings.LANGUAGE_CODE if needed.
10051	Post processors are functions that receive file objects, perform necessary operations, and return the results as file objects. This function takes a thumbnail file and processes it according to the specified size configuration's post-processors.
10052	Process the source image through defined processors, resize if necessary, generate a new filename, and save the processed image while keeping the original file reference.
10053	Refreshes the thumbnail cache by populating self._thumbnails with Thumbnail objects created from metadata returned by the metadata backend.
10054	Return all thumbnails in a dict format, refreshing cache if necessary.
10055	Creates and returns a thumbnail of a given size using the image creation function with specified parameters.
10056	Deletes a thumbnail of the specified size by removing it from storage and removing the reference from the thumbnails dictionary.
10057	Creates a thumbnail file and its metadata, returning a Thumbnail instance with the specified size using optional storage and metadata backends.
10058	Returns a Thumbnail instance for the given source name and size, or None if the thumbnail doesn't exist. Uses default storage and metadata backends if not provided.
10059	Deletes a thumbnail file and its relevant metadata using specified or default storage and metadata backends.
10060	Simulates receiving an incoming message by creating an IncomingMessage object with incrementing message ID, logging the traffic, handling the message through _receive_message method, and returning the created message.
10061	Registers a virtual subscriber with a phone number and callback function to handle messages directed to that number, returning the provider instance.
10062	Get the set of states. Mostly used for pretty printing

Returns: set of 'accepted', 'delivered', 'expired', 'error'
10063	Register a provider on the gateway, creating an instance of the provider class with the given configuration and storing it under the specified name. The first provider registered becomes the default provider. Returns the created provider instance.
10064	Send a message object using the appropriate provider based on routing rules, and return the sent message with populated fields. Raises various exceptions for different error conditions.
10065	Returns a Flask blueprint for handling incoming messages and status reports for a named provider. The blueprint includes a before_request handler that initializes the Flask global `g.provider` with the current provider instance, making it available to the blueprint's routes. Raises KeyError if provider not found or NotImplementedError if provider doesn't implement receiver functionality.
10066	Get Flask blueprints for every provider that supports it, returning a dictionary mapping provider names to their corresponding blueprints while ignoring providers that don't support receivers.
10067	Incoming message callback that populates message fields, fires the Gateway.onReceive event hook, and returns the processed message.
10068	Method `_receive_status` handles incoming status callbacks by populating the provider name, firing the Gateway.onStatus event hook, and returning the updated status object. It ensures proper message status processing including phone number formatting, appropriate MessageStatus subclasses, and required field population (msgid and meta). If the method fails, the provider must respond with an error to the service.
10069	A view wrapper for JsonEx responses that catches exceptions and returns appropriate HTTP responses with JSON content. It handles HTTPException by returning the exception's code and error message, and general exceptions by returning a 500 error with the exception details. The response includes proper JSON formatting and content-type headers.
10070	Forward an object to selected clients, handling both parallel and sequential execution modes. Raises exception if any client fails.
10071	Signs a web3 transaction and returns the RLP-encoded transaction and its hash. Takes an unsigned transaction dictionary and signature components (v, r, s), then encodes the transaction using the provided signature. The method returns both the signed transaction data and the transaction hash, though it's noted that pyEthereum's implementation is more robust for handling invalid signatures.
10072	Estimates transaction gas using web3 by calling the ethereum client's estimate_gas method with the provided parameters and pending block identifier.
10073	Estimates transaction gas by calculating the maximum of safe method estimation and web3 estimation for CALL operations, or just safe estimation for other operations. For CALL operations, it attempts web3 estimation and falls back to safe estimation if web3 fails. Includes proxy and old call gas costs in calculations.
10074	Appends data to the write queue and optionally waits for buffer flush. Returns immediately unless `await_blocking=True` is specified, in which case it waits for all data to be written.
10075	Reads one line from the serial instance, waiting for a linefeed if necessary. Returns the line as bytes. If no data is available, it sleeps asynchronously for a specified duration before trying again.
10076	Sends a message after verification, handling email sending through SMTP host with proper error checking and email dispatching.
10077	Creates and returns a formatted email message string with proper encoding, attachments, and headers based on the email's content and configuration. Handles different message types (plain text, multipart, or with HTML content) and processes attachments with appropriate content dispositions and encodings.
10078	Checks for bad headers (newlines in subject, sender or recipients) and returns True if any are found, False otherwise.
10079	Adds an attachment to the message with the specified filename, content type, data, disposition, and headers.
10080	Register services with the DAL by providing keyword arguments where keys are service names and values are service instances. Each service is initialized upon registration, raising an AlreadyExistsException if a service name is already registered. Returns self for chaining.
10081	Load a configuration module and return a Config object containing all uppercase variables from the module.
10082	Register resources with the ResourceManager, raising AlreadyExistsException if a service is already registered.
10083	Method `require(self, key)` checks if the value associated with `key` is empty and raises a `ValueError` if it is, otherwise returns the value.
10084	Summary: Handles teardown of Resource or Middleware objects, managing both normal exit (StopIteration) and exception scenarios (throwing exceptions). Raises RuntimeError for invalid iteration patterns and properly propagates or suppresses exceptions based on their relation to the original context exception.
10085	Sets up the service with a DataManager and recursively sets up sub-services. Initializes the DAL from the data manager if available, otherwise sets it to None. For each sub-service, calls its setup method with the same data manager.
10086	The method `ng` calculates the group index with respect to wavelength using the formula: n - dn/d, where n is the refractive index and dn/d is the first derivative of the refractive index with respect to wavelength. It takes a wavelength parameter (float, list, or None) and returns the corresponding group index value(s).
10087	A helper function that evaluates Cauchy equations for calculating refractive index at given wavelength(s) using provided coefficients.
10088	Initializes backend authentication, retrieves user and realm information, and sets up default timeperiods. Logs in using provided credentials, verifies authentication, and stores user details including default realm. It also finds and stores references to the 'All' realm and '24x7'/'Never' timeperiods for later use. If authentication fails, it exits with error code 1.
10089	Log into the backend with the provided credentials and handle token generation based on the 'generate' parameter. Returns True if authentication is successful, False if refused, and raises BackendException in case of errors. Supports proxy configuration and handles different token generation modes: 'enabled' (use current token), 'force' (generate new token), and 'disabled' (do not generate token).
10090	Method `get_domains` connects to the alignak backend to retrieve all available child endpoints from the root. It returns a list of resources with their titles and relative endpoints, or an empty dict if no child endpoints are found. Raises BackendException on connection errors.
10091	Get all items from a specified backend endpoint, handling pagination and optional multiprocessing for improved performance. Returns a dictionary containing the items and a success status.
10092	Method to update an item via PATCH request. Requires 'If-Match' header with object _etag. If _etag doesn't match (412 error), raises BackendException unless inception=True, which triggers a retry with refreshed _etag. Handles various HTTP errors by raising BackendException with appropriate codes and messages. Returns decoded response dictionary on success.
10093	Method to delete an item or all items via DELETE request. Requires 'If-Match' header with _etag identifier. Returns response dictionary with status information. Handles non-204 status codes by decoding response.
10094	Returns True if path1 and path2 refer to the same file by comparing volume serial numbers and file index numbers from filesystem information.
10095	Creates a junction point at link_name that points to the specified source directory. The function validates that the source is a directory and that the link name doesn't already exist, then uses Windows API calls to create a reparse point (junction) with the Windows FSCTL_SET_REPARSE_POINT control code. If successful, returns True; otherwise raises an exception and cleans up any created resources.
10096	Initializes logger with command name and formatting, sets up log file location and verbosity based on arguments, and stores logging metadata including user, host, start time, and tool name.
10097	Override error method to suppress default exit behavior and raise UsageError instead.
10098	Claims MuTect VCFs from input file readers, returning tuple of unclaimed readers and MuTectVcfReaders.
10099	Returns a standardized column header by replacing MuTect sample names with "NORMAL" and "TUMOR" based on metadata. Raises JQException if normal and tumor sample ordering cannot be determined from MuTect metaheader.
10100	Claims VarScan VCF files from input collection by recognizing high-confidence files and pairing them appropriately, returning unclaimed readers and VarScanVcfReaders.
10101	Initialize population statistics by calculating mean and standard deviation using Welford's online algorithm from Knuth's variance computation method, returning None for both values when less than 2 data points are available.
10102	Claims incoming files from unclaimed_file_readers by iterating through self._callers and their claim methods, returning a tuple of remaining unclaimed file readers and claimed VcfReaders.
10103	Split binary data into lines using specified line terminators and return a list of lines without the terminator characters.
10104	Returns the line terminator from the given data if it begins with one of the defined line terminators, otherwise returns None.
10105	Returns the line terminator from the given data if it ends with any of the defined line terminators, otherwise returns None.
10106	Seek next line relative to the current file position.

:return: Position of the line or -1 if next line was not found.
10107	Seek previous line relative to the current file position.

:return: Position of the line or -1 if previous line was not found.
10108	Return the last lines of the file by seeking from the end and reading backwards, handling line terminators properly to avoid empty lines in the result.
10109	Return the top lines of the file by seeking to the specified number of lines and reading the content from the beginning up to that point, then processing the data to remove trailing line terminators and split into lines.
10110	Iterator generator that yields lines from a file as they are added. Returns None when no new line is available. Handles file truncation and line terminators properly. Uses a trailing flag to manage line terminator detection and seeks back to previous position when no new data is found.
10111	Recognizes and claims Strelka VCFs from input file readers by finding Strelka files, splitting them by patient, validating the readers, and creating VCF readers. Returns a tuple of unclaimed readers and Strelka VCF readers.
10112	Alternative constructor that parses VcfRecord from VCF string, handling fixed fields and optional sample data.
10113	Creates a dictionary mapping sample names to their corresponding format-tag value dictionaries for VCF variant records. Takes sample names, format string, and sample field data, splits the fields by colon delimiter, and pairs them with format tags to create structured sample data, returning '.' for missing values.
10114	Returns set of format tags by extracting keys from the first sample's tag values, or empty set if no sample tag values exist.
10115	Updates the info attribute by joining fields from the info_dict dictionary, separated by semicolons. If info_dict contains multiple fields, removes any entry with key "." before joining. Each field-value pair is formatted as "field=value" unless field equals value, in which case only the value is kept. If info_dict is empty, sets info to ".".
10116	Returns string representation of format field by joining tag names with colons, or "." if no tag names exist.
10117	Returns string representation of sample-format values joined by colons, or "." if no values exist. Raises KeyError if sample is not defined.
10118	Returns a tab-delimited, newline terminated string representation of the VcfRecord object, including chrom, pos, vcf_id, ref, alt, qual, filter, info, format field, and all sample fields.
10119	Adds a new format tag-value to all samples in the object, raising KeyError if the tag already exists or sample names don't match.
10120	Adds a new filter to the existing filter list or replaces the current filter if it's in the list of filters to replace. If the current filter is null or blank (in lower case) and is found in `_FILTERS_TO_REPLACE`, it replaces the filter with the new filter. Otherwise, it appends the new filter to the existing filter list, separated by semicolons, only if the new filter is not already present in the filter list.
10121	Returns the categories available to the user, filtered by optional product restrictions. If no product restriction is specified, returns all categories containing available products for the user, sorted by order. If a product restriction is specified, only returns categories containing those specific products that are available to the user.
10122	Creates and returns an appropriate ProductsForm subclass based on the category's render type, sets up form fields from products, and optionally wraps it in a formset for item quantity rendering.
10123	Creates a StaffProductsForm that restricts available products to those accessible to a specific user by filtering inventory products through ProductController.
10124	Adds an error to the specified product's field using the field name derived from the product.
10125	Decorator that caches function results per user until batch completion, using positional arguments as cache keys. Raises ValueError if no User argument is provided.
10126	Creates a form factory for selecting model fields to display, using the model's meta fields to generate choices with verbose names.
10127	Returns the items that this user has purchased or has pending by filtering with paid and active cart statuses.
10128	Sends an email to the specified address using Django templates for subject and HTML message based on the email kind.
10129	Generator function that streams OSM changesets from a replication feed. It yields individual changesets and finished markers, with optional state persistence and rate limiting. The function handles state management, timestamp parsing, and automatic retries when the next sequence number isn't available.
10130	Parse an OSM XML file-like object into memory and return a tuple containing lists of nodes, ways, and relations.
10131	Function `iter_osm_notes` parses the global OSM Notes feed and yields note information. It takes parameters `feed_limit` (default 25) and `interval` (default 60) for controlling the number of notes and polling frequency. The function fetches the feed, processes each note item to determine action type (create, comment, close), skips already seen notes using GUID tracking, retrieves note details with `get_note`, and yields notes in chronological order. It includes a delay between iterations and yields a `Finished` marker after each cycle.
10132	Returns True if the condition passes the filter by checking if the condition exists in the pre-filtered queryset for the given user.
10133	Returns True if the flag condition is met for the given user, False otherwise. When filtered=True, it immediately returns True without requerying. Otherwise, it determines the result by calling passes_filter with the user.
10134	Returns the quantity remaining under the stock limit for a user, or 0 if the date range is violated. If filtered=True and a "remainder" annotation exists on the condition, it returns the annotated value. Otherwise, it queries the condition with pre_filter applied and returns the remainder from the first result, or 0 if no results exist.
10135	Returns all items from queryset where the user has a product from a category invoking that item's condition in one of their carts, excluding items that are already in released carts.
10136	Returns all items from queryset where the user has a product invoking that item's condition in one of their carts, excluding items that are in released carts but not in paid or active carts.
10137	Filters a queryset to return items that are currently available based on date ranges and stock limits, excluding items that have been reserved beyond their limits.
10138	Returns all items from queryset that are enabled by a user being a presenter or copresenter of a non-cancelled proposal. Filters out cancelled proposals and checks if user is either presenter or copresenter of the proposal.
10139	Returns all items from conditions that are enabled by a user's membership in Django Auth Groups.
10140	Decorator that raises ValidationError if cart modification is attempted on an inactive cart, wraps function execution in a database transaction, and marks cart operation batch boundaries while tracking modified state in batch cache.
10141	Returns the user's current cart, or creates a new cart if there isn't one ready yet.
10142	Updates the cart's time last updated value and calculates the new reservation duration based on elapsed time, vouchers, and product reservation requirements.
10143	Applies a voucher to the cart by code, ensuring idempotency and validating the voucher before adding it to the cart.
10144	Validates the current cart's status before invoice generation or payment by checking voucher validity, product quantity limits, required categories, and discount availability. Returns validation errors if any checks fail.
10145	This method attempts to fix common errors in a shopping cart by removing unavailable items and updating discounts. It first processes vouchers to remove any that are no longer valid, then checks all products in the cart against available inventory and sets quantities to zero for any unavailable products.
10146	Method `_recalculate_discounts` recalculates all available discounts for products in a cart by deleting existing discount entries, ordering products by price (highest first), and applying available discounts to product items based on their value.
10147	Applies the best available discounts to a product based on quantity and matching criteria, creating discount items and updating remaining quantities accordingly.
10148	A decorator function that converts a report view function into a Report display view, optionally including a form. It creates a ReportView instance with the specified title and form type, applies staff-only permission checks, wraps the original view function, and registers the report view in a global list of all report views.
10149	Returns an iterator of data rows for the table, where each row is a list of formatted cell text values based on the specified content type.
10150	Creates a form instance of type self.form_type using request.GET data, pre-validates it, and returns the form object. Returns None if self.form_type is not set.
10151	Renders reports based on the content type specified in the input data, using different renderers for CSV, HTML, or default HTML format, and returns the corresponding HTTP response.
10152	Lists all available reports with their names, URLs, and descriptions, then renders them in a template.
10153	Returns a report summarizing items sold and discounts, including description, quantity, price, and total cost for each item, along with a grand total.
10154	Summarizes paid items and payments by calculating total sales, all payments, credit notes, and their various applications. Returns a report with categories like "Items on paid invoices", "All payments", "Sales - Payments", and various credit note types with their respective amounts.
10155	Shows the history of payments into the system by retrieving all payment records and returning a QuerysetReport with payment details including invoice ID, payment ID, reference, and amount.
10156	Shows all credit notes that have been generated, returning a QuerysetReport with credit note refund information including id, reference, and amount.
10157	This function generates an inventory status report by filtering product items based on selected products and categories, grouping them by cart status, and organizing the data into a structured report with headings for Product, Paid, Reserved, Unreserved, and Refunded quantities.
10158	Summarizes the usage of given discounts by categorizing discount items by cart status (paid, reserved, unreserved, refunded) and returns a report with discount descriptions and their respective totals for each status category.
10159	Returns a report showing product line items from paid invoices, including invoice details, attendee information, quantities, products, and statuses. Filters invoices by specified products or categories and displays related cart information.
10160	Summary: This function generates a report showing the daily count of paid invoices that contain specified products or categories. It filters invoices based on product or category selections, identifies invoices with payments (using the latest payment time) and zero-value invoices (using issue time), groups them by date, and returns a formatted report with date and count data.
10161	Returns a QuerysetReport displaying all credit notes in the system with their id, owner, status, and value, linked to the credit note details view.
10162	Shows all invoices in the system with their ID, recipient, value, and status, ordered by status and ID, and links to individual invoice views.
10163	Returns a list of all attendees with their registration status, including user ID, name, email, and registration information, sorted by registration status and ID.
10164	This function generates a report showing the registration status of speakers based on presentation proposal kinds. It filters presentations by the specified proposal kinds (excluding cancelled ones), identifies associated users (speakers and co-speakers), and annotates them with the count of their paid carts. The results are ordered by the number of paid carts and returned as a QuerysetReport containing speaker information including ID, name, email, and paid cart count.
10165	Creates a registration manifest report for users based on selected products and categories, organizing user items by payment status (paid, unpaid, refunded) and formatting them into a structured list report.
10166	Returns the set of categories that are available but not currently held by the user, by comparing available categories with categories of items the user has pending or purchased.
10167	Calculates the sum of unclaimed credit from the current user's credit notes and returns it as a negative Decimal value.
10168	Function `sold_out_and_unregistered` checks if unregistered users have any available products in the ticket category. It returns `True` if no products are available (sold out), `False` if products are available, and `None` if the user is registered.
10169	This view guides users through a multi-step registration process, ensuring they complete all necessary steps in order. It handles four main steps: attendee information, ticket selection, additional product selection, and completion confirmation. The view enforces that users progress through steps sequentially and redirects them appropriately based on their current registration status. It uses helper functions to build forms for each step and processes submissions to verify user input before advancing. The registration flow is designed to prevent users from skipping steps or accessing future steps without completing previous ones. It also checks for product availability and handles redirects to the appropriate step based on user progress.
10170	View for editing an attendee's profile. Requires user to be logged in. Processes POST requests by handling the profile data and redirecting to dashboard on success, otherwise renders the profile form template with any validation errors.
10171	Returns a profile form instance and a boolean indicating if the form was handled. Retrieves attendee profile data, loads initial name from speaker profile if available, creates form with appropriate initial data and instance, and processes form submission if POST data is present and valid.
10172	Returns a rendered template or redirects to dashboard depending on form submission status, displaying products from a specified category with discount information and voucher functionality.
10173	Handles a products list form in the given request. Returns the form instance, applicable discounts, and whether contents were handled. Processes product quantities from cart items, validates the form, enforces category requirements, and calculates available discounts.
10174	Handles a voucher form submission by validating the voucher code, checking if it's already applied to the current cart, and attempting to apply it if valid and not duplicate. Returns the form instance and a boolean indicating whether the voucher code was processed.
10175	Function `checkout` handles the checkout process for a user's cart. It supports optional staff access to checkout for other users via `user_id` parameter. When `fix_errors=true` is in the query string, it attempts to resolve common checkout issues like expired discounts or unavailable products. The function returns a redirect to the invoice page upon successful checkout or renders checkout errors if validation fails.
10176	Redirects to an invoice for an attendee using an access code, selecting the most relevant invoice based on payment status and recency. Returns Http404 if no invoices exist.
10177	Displays an invoice with authentication checks based on user permissions or access code. Returns invoice data rendered in 'registrasion/invoice.html' or raises Http404 if access is denied.
10178	This function allows staff members to process manual payments or refunds for a specific invoice. It requires authentication and staff privileges. The function handles a POST request with a manual payment form, validates the input, creates a new manual payment record linking it to the invoice and the user who entered it, updates the invoice status, and returns the appropriate template data for rendering. The form is reset after successful submission to allow for additional payments.
10179	Function: `refund(request, invoice_id)`
Summary: Marks an invoice as refunded and requests a credit note for the full amount. Requires staff login. Takes an invoice ID as parameter and returns a redirect to the invoice page. Handles validation errors by displaying error messages.
10180	Displays a credit note and handles forms for applying the credit note to an invoice, processing a manual refund, or generating a cancellation fee invoice. Requires staff login. Returns a rendered template or redirects based on form submission.
10181	This function allows staff to modify a user's registration cart by updating product quantities and applying vouchers. It retrieves the user and their current cart, prepares a formset for managing cart items, and handles form submissions for both product adjustments and voucher application. If the forms are valid, it updates the cart or applies the voucher, redirecting on success. If there are validation errors, it displays appropriate error messages. The function also prepares and returns the necessary data for rendering the amendment template.
10182	Summary: The `extend_reservation` function allows staff members to extend a user's cart reservation by a specified number of days (default is 7 days). It retrieves the user and their cart, extends the reservation duration, and redirects back to the previous page.
10183	This view allows staff members to send mass email notifications to users based on their invoice status. It processes a form with filtering options (category, product, status) and email content (subject, body, sender), then generates and sends personalized emails to users associated with selected invoices. The function supports filtering invoices by multiple categories and products, and can send emails to multiple recipients based on the invoices selected in the form. It uses Django's `send_mass_mail` function to efficiently send all emails in a single operation and provides user feedback through Django messages.
10184	This function handles the generation and download of user badges in SVG format. It accepts GET parameters for filtering by category, product, and status, and displays a form for selecting invoices. When the form is valid, it creates a ZIP file containing SVG badge representations for each user in the selected invoices. If the form is invalid, it renders the form for user input. The badges are generated using a `render_badge` function and saved within the ZIP archive with filenames like "badge_{user_id}.svg".
10185	Renders a single user's badge by loading the 'registrasion/badge.svg' template and populating it with the user data.
10186	Returns all discounts available to a user for given categories and products, including available quantities. Filters discounts based on user eligibility, usage limits, and product/category matches.
10187	Annotates a queryset with past usage count for discount clauses by a given user, filtering by category or product matches and paid cart status.
10188	Returns a sorted list of available products for a user based on category limits, product limits, and flag conditions. Filters products by category or explicit product list, checks against user remainders for both categories and products, then applies flag tests to determine final available products. Raises ValueError if neither products nor category is provided.
10189	Applies the credit note's total value to the specified invoice, creating a credit note application record. If the credit note overpays the invoice, a new credit note with the remaining value is created. Validates that the invoice is allowed to be paid and updates the invoice status accordingly.
10190	Generates an invoice with a cancellation fee based on a percentage of the credit note value, applies credit to the invoice, and returns an InvoiceController instance for the generated invoice.
10191	Generates a 6-character access code using uppercase letters and digits 1-9 (excluding 0 to avoid confusion with O), producing approximately 1.8 billion unique combinations for payment access and check-in fulfillment purposes.
10192	Creates a lazy evaluation wrapper for functions that delays execution until the first time the returned callable is invoked, caching the result for subsequent calls.
10193	Returns the named object by importing a module and accessing a property from it.

Arguments:
    name (str): A string of form `package.subpackage.etc.module.property` that specifies the module to import and property to retrieve.

Returns:
    The specified property from the imported module.

Example:
    get_object_from_name("os.path.join") would import the os.path module and return the join function.
10194	Returns an invoice object for a given cart at its current revision. If no invoice exists, validates the cart and generates a new invoice.
10195	Generates an invoice for arbitrary items not in a user's cart by creating line items from description-price pairs and calling the internal _generate method with the specified due time.
10196	Generates an invoice for the given cart by creating line items from product and discount items, then calls the parent class's generate method with the cart details and line items. Raises ValidationError if cart is empty.
10197	Applies credit notes to an invoice during creation, but only if the user has exactly one unpaid invoice. It loops through unclaimed credit notes for the user and attempts to apply each one to the invoice, stopping when overpaying would occur. Finally, it refreshes the invoice from the database.
10198	Returns True if the accessing user is allowed to view this invoice, or if the given access code matches this invoice's user's access code. Checks if user equals invoice user, if user is staff, or if access code matches the user's attendee access code.
10199	Refreshes the underlying invoice and cart objects by refreshing them from the database.
10200	Method that validates whether an invoice can be paid by checking if it's unpaid, has a valid cart, and the invoice matches the cart contents. Raises ValidationError if any validation fails.
10201	Updates the status of an invoice based on payment totals and handles status transitions between unpaid, paid, refunded, and void states, while generating credit notes for residual amounts and sending email notifications about status changes.
10202	Marks the invoice as paid and updates the associated cart status to paid if a cart exists, then saves both the cart and invoice.
10203	Returns True if there is no cart, or if the invoice's cart revision matches the current cart revision.
10204	Updates invoice validity by checking if the attached cart is still valid. If the cart is no longer valid due to revision changes or expired reservations, voids the invoice or refunds payments if it has been partially paid.
10205	Method that voids an invoice if valid, raising ValidationError for invoices with payments or already refunded invoices, and releases cart if invoice is paid before marking void.
10206	Method `refund` generates a credit note for the full payment amount of an invoice, marks the invoice as refunded, and releases the underlying cart. Raises ValidationError if the invoice is void. If payment amount is zero, voids the invoice instead.
10207	Sends an email notification to the invoice's user about a specific invoice-related action.
10208	Updates the object with new data by setting attributes from a fields list and flattening nested fields into an annotation dictionary.
10209	Flattens nested dictionary structures into dot-separated keys with field metadata. Takes a field, schema, and path as input and returns a flattened dictionary where each key is a dot-separated path and each value contains the field's name, value, type, and label information.
10210	Print file fields from annotation data to standard output, showing paths that start with 'output' and have a file type annotation.
10211	Download a file from a specified field.

This method downloads a file from a given field in the annotation. It validates that:
1. The field starts with 'output' (processor results only)
2. The field exists in the annotation
3. The field type is 'basic:file:'

If all validations pass, it returns a file handle from the cloud download service.

Parameters:
    field (string): The file field to download

Returns:
    file handle: The downloaded file

Raises:
    ValueError: If field doesn't start with 'output', doesn't exist, or isn't a basic:file: type
10212	Return a list of Data objects for the given project by retrieving project data from API, caching objects, and hydrating reference fields in annotations.
10213	Return a list of Processor objects, optionally filtered by processor name. If processor_name is provided, returns processors matching that name; otherwise returns all processors.
10214	Print processor input fields and their types for a given processor name.
10215	Method: rundata
Parameters: self, strjson (JSON string)
Returns: Result of POSTing parsed JSON data to the server API
Description: Parses a JSON string and sends the resulting data object to the server via a POST request through the API's data endpoint.
10216	Upload files and data objects to a specified processor within a project. Validates processor existence and input fields, checks if files exist, uploads files if necessary, and creates an upload task with the specified inputs. Returns an HTTP response object.
10217	Upload a single file to the platform in 1KB chunks with retry logic and progress tracking. Returns a session ID upon successful upload.
10218	Download files from data objects by generating requests.Response objects for each file.

The method validates that:
- The specified field starts with 'output' (processor results only)
- Each data object ID is a valid 24-character hexadecimal string
- The field exists in the object's annotation
- The field type is 'basic:file:'

For valid objects, it constructs URLs for each file and yields streaming GET requests with authentication.
10219	Gets all subclasses of a class recursively, including nested subclasses.
10220	Returns repository and project by prompting user input or using command line arguments, with validation and saving of the data.
10221	Function that retrieves variant phenotypes along with suggested changes from CIViC database. For each variant in the input list, it fetches all associated evidence items and their suggested phenotype changes. For each evidence item, it makes an API call to get suggested changes and compares the current phenotype IDs with suggested ones to identify added and deleted phenotypes. Returns a generator yielding tuples of (evidence_item, phenotype_changes_dict) where phenotype_changes_dict contains both current phenotypes and suggested changes (added/deleted phenotype IDs).
10222	Returns an iterator of (evidence, merged_phenotype) tuples for each variant in variant_id_list, where merged_phenotype is obtained by applying suggested changes to the current phenotype status. For each variant, it processes the suggested changes by first removing deleted phenotypes and then adding new phenotypes, and yields the final non-empty merged phenotype along with its corresponding evidence.
10223	Searches for variants in the cache that match provided genomic coordinates based on the specified search mode. Supports multiple search modes: 'any' for any overlap, 'include_smaller' for variants fully within the query, 'include_larger' for variants encompassing the query, and 'exact' for precise coordinate and allele matching. Returns a list of variant hashes matching the criteria.
10224	Function `bulk_search_variants_by_coordinates` searches a coordinate cache for variants matching a list of sorted genomic coordinates, yielding results based on specified overlap criteria. It supports four search modes: 'any', 'exact', 'include_smaller', and 'include_larger'. The function uses two pointers to efficiently traverse the sorted queries and the coordinate table, checking for overlaps or exact matches depending on the mode. Only 'any' and 'exact' modes are implemented, with the others raising `NotImplementedError`. Matches are returned as a dictionary mapping each query to a list of matching coordinate entries.
10225	Updates a record and returns True if the record is complete after update, else False. If kwargs are provided, initializes the record with those values. If force is False and the record exists in cache, loads the record from cache. Otherwise, fetches the record from the API and initializes it.
10226	Returns a unique list of elements from seq, preserving the original order by using a set to track seen elements.
10227	Connects to Github and Asana and authenticates via OAuth. Saves API keys for both services and establishes authenticated connections using basic auth for Asana and the GitHub API client. Sets up error handling and retrieves user information for both services. Returns False if already authenticated.
10228	Selects an item from a list by index or name input. Takes a list, prompt string, and optional offset. Prompts user for input, tries to convert input to integer index (with offset) first, then falls back to treating input as a direct name match. Returns the selected item or raises assertion errors for invalid input.
10229	Returns issue data from local storage for a given issue number and namespace. Retrieves data using a key generated from the namespace, and ensures the issue data structure is initialized before returning the specific issue's data dictionary.
10230	Moves issue data from one namespace to another namespace by transferring the issue data associated with a specific issue number from a source namespace to a target namespace.
10231	Returns task data from local data based on task identifier.

Args:
    task: Task identifier (int, string, or dict with 'id' key)

Returns:
    Task data dictionary from local storage
10232	Retrieves a task from Asana by its ID, returning None if the task is not found or access is forbidden.
10233	Save data to a file by pruning, adding version info, and dumping as formatted JSON.
10234	Applies a setting value to a key with optional prompting and transformation. Returns early if value is explicitly set or key already exists. Uses prompt function or raw_input for user interaction when value is None. Transforms values through on_load and on_save lambdas during processing.
10235	Decorator that adds retry logic to transport functions with specific handling for Asana API error types, including invalid requests, forbidden errors, not found errors, and retryable errors, with a maximum of 3 retry attempts.
10236	Waits until the queue is empty by continuously checking if items are available. If the shutdown event is set, it returns immediately. Optionally calls a provided callback function during each iteration. If the queue is empty, it returns; otherwise, it peeks at an item and puts it back before continuing.
10237	Creates a task in Asana with the specified parameters including workspace ID, name, notes, assignee, projects, and completion status.
10238	Formats a list of task IDs into links for Asana tasks, or plain task numbers if no project ID is available. Each task is formatted as either "[#ID](URL)" (with a clickable link) or "#ID" (plain number), separated by newlines.
10239	Creates a missing task in Asana with the provided details, announces it as a Git issue, saves it to drive, and synchronizes tags/labels.
10240	Return a sorted list of unique data types from project data.
10241	Sends a string message to the module level log with a timestamp if the message priority meets the current log level threshold. The function supports two priority levels (3 as default, 4 as special) and formats the log message with a prefix, timestamp, and the provided log string. The actual logging is delegated to an external logging function.
10242	Initializes serial port connection using pyserial with specified parameters (port, baudrate, parity, stopbits, bytesize). Returns True on successful initialization, False on failure. Includes error handling and logging.
10243	Sets the polling loop parameters including maximum waits and sleep duration between waits.
10244	Method `combineAB` combines serial block definitions from V3 and V4 meters to create a unified field list. It retrieves field definitions from both V3Meter and V4Meter objects, then adds unique fields (excluding those containing "RESERVED" or "CRC") to the instance's `m_all_fields` dictionary. The method processes V3 definitions first, then V4 definitions, ensuring no duplicate fields are added.
10245	Simple since Time_Stamp query returned as JSON records.

Args:
    timestamp (int): Epoch time in seconds.
    meter (str): 12 character meter address to query

Returns:
    str: JSON rendered read records.
10246	Sets the context string for serial commands. Logs the context string (if it doesn't start with "request" and the current context is empty) and stores the provided context string.
10247	Calculates legacy push power factor value from meter reading. Takes a power factor string with format "YX" where Y is the type indicator and X is the numeric value, returns integer legacy PF value (200 - X for capacitive lead, X for inductive lag).
10248	Sets the maximum demand period via serial communication with password authentication. Returns True on successful completion with ACK response.
10249	Sets the meter password via serial communication with authentication. Takes a new 8-digit password and optional old password (defaults to "00000000"). Returns True on successful password change with ACK response. Requires password authentication before allowing the password change operation. Uses CRC16 checksum for communication integrity.
10250	Wrapper for struct.unpack with SerialBlock buffer definitions.

Args:
    data (str): Implicit cast bytes to str, serial port return.
    def_buf (SerialBlock): Block object holding field lengths.

Returns:
    tuple: parsed result of struct.unpack() with field definitions.
10251	**Summary:**

The `convertData` method processes raw data from a tuple, scales and converts it according to field definitions, and stores the results in a buffer. It handles different data types (float, hex, int, string, power factor) and applies appropriate scaling based on `kwh_scale` and field-specific scale values. The method returns `True` upon completion and logs any exceptions encountered during processing.
10252	**Summary:** The `jsonRender` method translates a `SerialBlock` object into a formatted JSON string. It creates a new dictionary with the meter address and copies over non-reserved, non-CRC fields from the input block. If an exception occurs, it logs the error and returns an empty string. Otherwise, it returns the JSON representation of the dictionary with 4-space indentation.
10253	**Summary:**

The `crcMeterRead` method is an internal function that validates the Cyclic Redundancy Check (CRC) of a serial data read operation. It takes raw serial data and a populated buffer as inputs, calculates the expected CRC from the raw data, and compares it with the CRC value stored in the buffer. The method returns `True` if the CRC values match, indicating valid data, and `False` otherwise. It includes exception handling for `struct.error`, `TypeError`, and `ValueError` to manage potential issues during CRC calculation or data conversion, logging errors without stopping execution.
10254	Function `splitEkmDate` takes an integer representing an Omnimeter datetime and breaks it down into a named tuple containing year, month, day, weekday, hour, minutes, and seconds. If the input string representation is not exactly 14 characters long, it returns a tuple with all values set to 0. The function returns a named tuple with fields: yy, mm, dd, weekday, hh, minutes, ss.
10255	Get the months tariff SerialBlock for meter based on direction parameter, returning either forward or reverse month tariffs buffer.
10256	Sets the CT (Current Transformer) ratio for an attached inductive pickup through serial communication. Validates the CT ratio against a predefined list of legal values and authenticates with a password before sending the configuration command. Returns True if successful, False otherwise.
10257	Assigns a schedule tariff period to meter buffer with validation checks for bounds and indices. Returns True on successful assignment.
10258	Define a single season and assign a schedule with validation checks for bounds and indices, returning True on successful completion.
10259	Sets the season schedules table on a meter using serial communication with optional password authentication. Takes an optional dictionary of season schedule parameters and a password, constructs a serial command with the schedule data, sends it to the meter, and returns True if successful. Uses default season schedule parameters from the meter object if no dictionary is provided. Handles CRC calculation and response validation.
10260	Sets a single holiday's date by storing the month and day values in the object's holiday date parameters buffer. Validates input ranges for month (1-12), day (1-31), and holiday index (0-19), returning False if any values are out of bounds or if the corresponding parameter keys don't exist in the buffer, otherwise returns True after successful assignment.
10261	Method: readSchedules
Description: Serial call to read schedule tariffs buffer
Parameters: tableset (int) - buffer to return
Returns: bool - True on completion and ACK
Processing: Constructs request string with tableset, sends over serial port, receives response, validates CRC checksum, unpacks and converts data based on tableset type (Schedules 1-4 or 5-6), logs success message on CRC validation, returns True if successful otherwise False
Exceptions: Catches and logs any exceptions that occur during the process
10262	Extracts a single schedule tariff from meter object buffer based on schedule and period parameters, returning a named tuple with Hour, Min, Tariff, Period, and Schedule values. Performs bounds checking and validates table indices before accessing schedule data. Returns default values (0) if out of bounds or invalid indices are encountered.
10263	Reads month tariffs block into meter object buffer based on the specified months type and returns True on successful completion.
10264	Extracts the tariff information for a specified month from the meter object buffer, returning a named tuple with kWh and Rev kWh values for four tariff periods plus totals. Handles out-of-range months by returning zero values and logging an error.
10265	Method to read holiday dates into meter object buffer via serial communication, including CRC validation. Returns True on success.
10266	Extracts a single holiday date from meter buffer for a given holiday setting.

Args:
    setting_holiday (int): Holiday from 0-19 or in range(Extents.Holidays)

Returns:
    tuple: Holiday tuple with elements as strings (Holiday, Month, Day)

The method validates the holiday setting range, checks for existence of day and month indexes in meter buffer, and returns the corresponding holiday date information. Returns zeros for all values if the holiday is out of bounds or missing from buffer.
10267	```python
def readSettings(self):
    """Recommended call to read all meter settings at once.

    Returns:
        bool: True if all subsequent serial calls completed with ACK.
    """
    success = (self.readHolidayDates() and
               self.readMonthTariffs(ReadMonths.kWh) and
               self.readMonthTariffs(ReadMonths.kWhReverse) and
               self.readSchedules(ReadSchedules.Schedules_1_To_4) and
               self.readSchedules(ReadSchedules.Schedules_5_To_6))
    return success
```

**Summary:** Reads all meter settings in a single call by invoking multiple read operations including holiday dates, month tariffs for both forward and reverse kWh, and schedules. Returns True only if all operations complete successfully with ACK responses.
10268	**Summary:** Internal method that sets a command result string and logs the message with context information.
10269	Password authentication step for serial commands that sends password over serial connection and waits for ACK response.
10270	Fire update method on all attached observers in order of attachment, logging any exceptions that occur.
10271	Initialize lookup table for LCD field string inputs by mapping string keys to corresponding LCDItems enum values.
10272	Combined A and B read request for V4 meter that executes both requestA() and requestB(), then processes the results through makeAB(), calculateFields(), and updateObservers() if both requests succeed, returning True on completion or False on failure.
10273	Method: requestA

Description: Issues an A read command to a V4 meter and processes the response.

Parameters: None

Returns: bool - True if the CRC check passes on the received data

Functionality:
1. Gets current context and sets new context for request processing
2. Writes an A read command to the serial port using meter address
3. Reads the response from the serial port
4. Unpacks and converts the received data using block structure
5. Extracts kWh precision value from the data
6. Calculates CRC checksum for validation
7. Restores original context
8. Returns CRC validation result
10274	Issue a B read request on V4 meter and return True if CRC matches.

**Returns:**
bool: True if CRC matches at end of operation
10275	Merges A and B read blocks into a single serial block by copying unique fields from both blocks while filtering out fields containing "RESERVED" or "CRC" (case insensitive).
10276	This method calculates power factor and net watt values for three phases based on cosine theta values and watt measurements, adjusting for power direction using a direction flag. It updates both string and native values in the data block for power factor and net watt calculations.
10277	Sets LCD display configuration by initializing LCD, validating display items, adding them to the display list, and applying the LCD settings with optional password protection. Returns True if successful, False otherwise.
10278	Sets a relay status for a specified duration via serial communication with password authentication. Returns True on successful completion and acknowledgment.
10279	Send termination string to implicit current meter by writing hex data "0142300375" to serial port, with error handling and logging.
10280	Sets the pulse input ratio for a specified line on an EKM meter through serial communication, with optional password protection. Returns True if successful, False otherwise.
10281	Serial call to zero resettable kWh registers with password authentication. Returns True on successful completion and ACK.
10282	Sets the LCD display content on an EKM meter using serial communication with optional password authentication. Returns True on success.
10283	Recursively iterates over all DictField sub-fields, yielding schema-field pairs. For each field in the input fields dictionary, if the field has a 'group' in the schema, it recursively processes the group fields. Otherwise, it yields the schema definition and field properties for the current field. The function maintains the hierarchical relationship between fields and their corresponding schema definitions during iteration.
10284	Recursively iterates over all schema sub-fields, yielding field schemas along with their corresponding field data and path information. For grouped fields, it recursively processes nested schema structures, while for individual fields, it yields the field schema with associated field data and full path designation.
10285	Function that generates random paragraphs with customizable options including quantity, separators, HTML wrapping, and sentence count. Returns either a joined string or list of paragraphs.
10286	Random text generator that creates strings of specified length or within a range, using configurable character sets (lowercase, uppercase, digits, spaces, punctuation).
10287	Return combined time and result summary statistics as a formatted string.
10288	Color some text in the given ANSI color.
10289	Write the text to the stream and flush immediately.
10290	Return a summary of test results containing the number of examples, errors, and failures.
10291	Parse command line arguments using a custom parser, with "run" as default action if no valid action is provided.
10292	Setup the environment for an example run by creating a formatted result object with optional verbose and colored output based on configuration.
10293	Runs the test suite with the given configuration, setting up the environment, loading specifications, handling errors, and exiting with appropriate status code based on test success or failure.
10294	Run transform mode by registering ExampleLoader, temporarily replacing command line arguments with config.args, executing the runner script, then restoring original command line arguments.
10295	Transforms a describe node into a TestCase class definition with a dynamically generated name based on the described object.
10296	Transforms the body of an ExampleGroup by processing each node in the body, extracting the name and context variable from the with statement, and yielding the transformed example.
10297	Transforms an example node into a test method by generating a appropriate function definition with a formatted name and transformed body. Returns the unchanged node if it wasn't an Example. The test method name is constructed by joining "test", the group variable, and the example name components, with underscores separating them. The function body is generated by transforming the example's original body using the provided context variable. The resulting FunctionDef node has no decorators and takes only 'self' as an argument.
10298	Transforms an Example's body into a method body by replacing context variable references with "self".
10299	Return an argument list node that takes only ``self``.
10300	Registers a path hook by creating a FileFinder with the class and its suffix, then appends it to sys.path_hooks for MIME type handling.
10301	Transforms source code into a code object by parsing it with AST, applying ExampleTransformer, then compiling the result.
10302	Apply the argument parser to parse command line arguments, returning the parsed arguments. If options are provided, parse those instead of the command line arguments.
10303	Load a spec from either a file path or a fully qualified name by checking if the input exists as a file path, and loading from path if it exists, otherwise importing it as a module.
10304	Load a spec from a given path, discovering specs if a directory is given. If the path is a directory, it discovers all specs within that directory. For each spec (either from the directory or the single file), it loads the spec using `imp.load_source` with the spec's base name as the module name.
10305	Discover all specs recursively inside the given path and yield their full relative paths.
10306	A function that monitors a directory for changes in JSON configuration files and notifies a receiver of additions, removals, or modifications. It tracks file contents to detect changes and calls receiver methods accordingly. Returns a partial function ready to check the directory.
10307	Constructs a function that monitors a directory for messages, calls a receiver method with message content, and deletes processed messages.
10308	Add a process configuration to a Places instance.

This function creates a process configuration file with the specified parameters. It takes a Places instance, process name, command, and various process settings (environment variables, user/group IDs, etc.) and stores them in a configuration file. The configuration includes command arguments, environment variables, user ID, group ID, and any additional parameters. Environment variables can be specified as a list of "key=value" strings or inherited from the parent process. The function returns None after writing the configuration to disk.

Parameters:
- places: a Places instance for configuration storage
- name: string, the logical name of the process
- cmd: string, executable command
- args: list of strings, command-line arguments
- env: dictionary of environment variables (optional)
- uid: integer, user ID for process execution (optional)
- gid: integer, group ID for process execution (optional)
- extras: dictionary of additional configuration parameters (optional)
- env_inherit: list of environment variables to inherit (optional)

Returns: None
10309	Remove a process by deleting its configuration file.

The function takes a Places instance and process name as parameters, constructs the file path to the process configuration using the Places instance, and then removes that file from the filesystem. The function does not return any value.

Parameters:
- places: A Places instance containing configuration paths
- name: String representing the logical name of the process to remove

Returns: None
10310	Restart a process by creating a restart message and adding it to the message queue.

Parameters:
- places: a Places instance
- name: string, the logical name of the process

Returns:
- None
10311	Summary: The `call` function executes a specified function on a `Places` object constructed from the input dictionary-like object. It extracts configuration, messages, and the target function from the input, creates a `Places` instance, and then calls the target function with the `Places` object and any remaining attributes as keyword arguments.
10312	Return a service which monitors processes based on directory contents, constructing a service that runs processes based on configuration directory contents, restarts them when file contents change, and stops them if files are removed, while also listening for restart messages.
10313	Create and configure a service instance using command-line options, setting process monitoring parameters like threshold, kill time, and restart delays.
10314	Refreshes or adds a node session in the nodelist with current timestamp. If no node_id provided, uses the current connection's ID. Stores the timestamp in milliseconds in a Redis hash under the nodelist key.
10315	Removes expired nodes from the nodelist. If node_ids are provided, verifies they haven't been refreshed before removal. Requires a lock to be acquired before execution. Uses Redis HDEL to remove the expired nodes from the nodelist key.
10316	Removes a specific node from the nodelist using the provided node ID, or defaults to the current connection's ID if none is provided.
10317	Returns the last updated timestamp for a node as a unix timestamp, or None if not found. If no node_id is provided, uses the connection's id.
10318	Returns all nodes in the hash with their last refresh timestamps as a dictionary mapping node IDs to timestamps.
10319	Refreshes the session for this node by updating the reference time and removing any expired nodes from the node list.
10320	Increments the modification count for this resource across all processes, setting a TTL expiration on the counter key.
10321	Method `dereference` decrements the reference count for a resource and returns True if this was the last reference. It operates only when the reference is locked and queries the backend value only when this instance is the last reference. The method executes an optional callback function if the current process holds the only reference, and cleans up related keys from the backend. It returns a boolean indicating whether there are no more references among all processes.
10322	Returns a list of values interleaved with the specified delimiter. Takes a list of values and a delimiter (string or list/tuple of delimiters), and returns a new list with the delimiter inserted between each pair of values. If the input list is empty, returns an empty list. If a single delimiter string is provided, it's converted to a list containing that delimiter before processing.
10323	check which processes need to be restarted

:params path: a twisted.python.filepath.FilePath with configurations
:params start: when the checker started running
:params now: current time
:returns: list of strings
10324	Merge failure message from another status into this one, keeping the status that represents parsing that has gone the farthest. If both statuses have gone the same distance, merge their expected values. Returns this Status with updated farthest and expected values.
10325	Query to test if a value exists by checking if it's not null, using OptionalMatch, Return with IS NOT NULL predicate, and Limit 1. Raises TypeError if value is not a Token or doesn't support identifier. Automatically generates identifier if missing.
10326	Creates a query to get a value by constructing a Match-Return chain with proper identifier handling and type validation.
10327	Produces a function that always returns a supplied value, ignoring any arguments passed to it.
10328	Converts a function that takes multiple arguments into a function that takes a single iterable argument, where each element of the iterable is passed as a separate argument to the original function.

Example: `splat(lambda a, b, c: a + b + c)([1, 2, 3])` returns `6`
10329	Converts a function that takes a single iterable argument into a function that takes multiple arguments by passing them as elements of an iterable to the original function.
10330	Run a process with timeout and grace period, returning a deferred that fires when done. The process is terminated after timeout seconds and killed after grace seconds if still running. Uses reactor to spawn process and handle timing.
10331	Creates a scheduler service with specified options including frequency, arguments, timeout, and grace period, and returns a MultiService containing the scheduler and heart monitoring.
10332	Consume a reader using the given parser and return Success only if the entire input is consumed. If parsing fails or doesn't consume all input, return a Failure with an appropriate error message. The function handles both Continue results (indicating successful parsing) and failure cases with expected input information.
10333	Match a literal sequence. In the `TextParsers` context, this matches the literal string provided. In the `GeneralParsers` context, this matches a sequence of input. If multiple literals are provided, they are treated as alternatives. Args: literal: A literal to match, *literals: Alternative literals to match. Returns: A `LiteralParser` in the `GeneralContext`, a `LiteralStringParser` in the `TextParsers` context, and an `AlternativeParser` if multiple arguments are provided.
10334	Returns an OptionalParser that attempts to match the given parser. If successful, it returns a list with the parsed value; if failed, it returns an empty list.
10335	Matches a parser one or more times repeatedly, returning a list of values from each match. If the parser doesn't match at all, it fails. Takes a parser or literal as input.
10336	Matches a parser zero or more times repeatedly, returning a list of match values or an empty list if no matches are found.
10337	Match a parser one or more times separated by another parser, returning a list of parser match values while discarding separator values.
10338	Matches a parser zero or more times separated by another parser, returning a list of values from the main parser while discarding separator values.
10339	Check all processes by comparing current and previous states, closing removed processes and initializing new ones, then return list of processes that are currently active.
10340	Closes the instance by discarding data, canceling all calls, and marking it as closed. Raises ValueError if already closed. Instance cannot be reused after closing.
10341	Method `check` verifies the HTTP state by first ensuring the connection is not closed, then resetting if necessary. It returns `False` if no URL is set, otherwise performs a status check and returns the result. Raises `ValueError` if the connection is closed.
10342	Add a heart service to a service collection if the heart service is successfully created.

The function creates a service using `makeService()`, and if the service is not None, it sets the service name to 'heart' and adds it as a child service to the provided master service collector. If the service creation fails (returns None), the function returns early without adding anything.
10343	Wrap a service in a MultiService with a heart.
10344	Freezes and shrinks a graph from a checkpoint by converting variables to constants, using the specified output node names, and saving the result to the output file path.
10345	Freezes and shrinks a graph from a session by saving it as a checkpoint and then freezing from that checkpoint, with the specified output node names.
10346	Save a simplified version of a graph based on a session and specified output node names to a file.
10347	Save a minimal version of a graph from a checkpoint file by specifying output node names.

This function takes a checkpoint file and saves only the necessary parts of the computational graph that are needed to produce the specified output nodes. It first validates the checkpoint file, converts the output node names to a list if needed, creates a TensorFlow session, restores the model from the checkpoint, and then saves only the relevant portions of the graph to the specified output file path.

Args:
    input_checkpoint: Path to the checkpoint file to read from
    output_file_path: Path where the simplified graph will be saved
    output_node_names: String or list of node names to include in the saved graph
    as_text: If True, saves the graph in human-readable text format instead of binary

Example:
    save_graph_only_from_checkpoint('model.ckpt', 'simplified_graph.pb', ['output_node1', 'output_node2'])
10348	Save weights from a checkpoint file to separate files in the output path, optionally filtering for convolutional and transposed convolutional variables.
10349	Restores a TensorFlow model from a checkpoint by importing the metagraph and restoring variables to the provided session, returning the saver object.
10350	Parse the tag, instantiate the class.

**Parameters:**
- `parser`: django.template.base.Parser
- `token`: django.template.base.Token

**Returns:**
- Instantiated class with parsed arguments

**Process:**
1. Parse token arguments and keyword arguments using `parse_token_kwargs`
2. Validate parsed arguments using `cls.validate_args`
3. If end tag name is specified, parse the nodelist until end tag
4. Return new instance of the class with all parsed parameters
10351	Method: render_tag
Description: Renders the tag with all arguments resolved to their actual values. This is an abstract method that must be implemented by subclasses.
Parameters: 
- context: The context in which to render the tag
- *tag_args: Variable length argument list
- **tag_kwargs: Arbitrary keyword arguments
Returns: NotImplementedError exception with a message indicating the method is not implemented
Defined in: Base class (abstract method)
10352	Validate the syntax of the template tag by checking that the number of arguments meets the required minimum and maximum limits defined by the tag class. Raises TemplateSyntaxError with appropriate messages if the argument count is invalid or if unexpected keyword arguments are provided when none are allowed.
10353	Method `get_context_data` is declared in the class but not implemented, raising `NotImplementedError` with a message indicating the method needs to be implemented by subclasses. It takes `parent_context`, `*tag_args`, and `**tag_kwargs` as parameters and is intended to return context data for an included template.
10354	Parse the "as var" syntax and validate arguments for template tag processing.
10355	Return the context data for the inclusion tag, including a value obtained from get_value() method. If 'template' is not in allowed_kwargs, remove it from tag_kwargs before processing. The context data is returned as a dictionary with the context_value_name as key and the computed value as value.
10356	Create a TensorFlow session from a Caffe model by converting it using caffeflow, then loading the converted model parameters into a TensorFlow session.
10357	Freezes and shrinks a TensorFlow graph from a Caffe model by converting the Caffe model to TensorFlow, saving it as a checkpoint, and then freezing the graph to remove variables, producing a single serialized graph file.
10358	Save a simplified version of a Caffe model graph by converting it to TensorFlow format, using specified input tensors and output node names, and freeze the graph to a file.
10359	Function `make_rows` takes a number of columns and a sequence, then rearranges the sequence into rows with the specified number of columns. It calculates the minimum number of rows needed, breaks the sequence into columns of equal length, and transposes the result to return rows. The function handles sequences that don't divide evenly by padding with None values. The implementation uses `more_itertools.grouper` to group elements and `zip(*result)` to transpose columns into rows.
10360	Take a sequence and break it up into chunks of the specified size. The last chunk may be smaller than size. Works with strings and other iterables. For strings, chunks are joined back into strings; for other iterables, chunks remain as lists. Returns a generator of chunks.
10361	Yield every other item from the iterable, starting with the first item. For example, given 'abcdefg', it yields 'a', 'c', 'e', 'g'.
10362	Removes sequential duplicate elements from an iterable while preserving non-duplicate elements. Unlike unique_justseen, this function does not remove triplicates. Returns an iterator with sequential duplicates removed. For example, 'aaaabbbbb' becomes 'a a b b b' and 'abcaabbccaaabbbcccbcbc' becomes 'a b c a b c a a b b c c b c b c'.
10363	Returns the first value from an iterable along with a new iterable that contains that value and the rest of the original iterable.
10364	Take elements from a peekable iterable while a predicate is true, without consuming the first element that doesn't match. Returns a generator that yields matching elements, leaving the non-matching element (and rest of iterable) available in the peekable iterator.
10365	Given the total number of items and a bin size limit, partitions the items into bins where each bin contains at most the specified bin size items. The function distributes items as evenly as possible across the bins, with some bins potentially containing one fewer item than others if the division is not exact.

For example:
- partition_items(11, 3) returns [3, 3, 3, 2] (three bins with 3 items and one bin with 2 items)
- partition_items(10, 3) returns [3, 3, 2, 2] (two bins with 3 items and two bins with 2 items)
10366	Returns an iterable from any object. If the item is already iterable, it returns it as-is. If not, it wraps the item in a tuple. None returns an empty iterable. Mappings are treated as singletons rather than sequences. Uses `more_itertools.always_iterable` with base types including strings, bytes, and mappings.
10367	Function that calls each callable in a sequence, suppressing specified exceptions and yielding results from successful calls. If no exceptions are specified, all exceptions are suppressed.
10368	Returns duplicate items from multiple sorted iterables by grouping items with the same key and filtering groups with more than one item. Takes optional key function for extracting comparison keys from items.
10369	Function that asserts all items in an iterable are in order based on a comparison function, yielding items in order. Raises AssertionError if items are not properly ordered according to the comparison.
10370	Swaps the before and after elements in a partition result if the item is missing (None/empty).
10371	Partition an ordered dictionary by a key, returning the items before the key, the keyed item, and the items after the key. If the key is not found, return all items in before, None for the item, and empty after.
10372	Get the first n queues by fetching until n queues are created, returning any missing queues as empty iterables.
10373	Resets the iterator to the beginning by creating a new iterator from saved data, discarding any remaining values in the current iteration.
10374	Parses a token to extract an "as varname" clause, returning the remaining bits and the variable name if present.
10375	Decorator to register class tags

Registers a template tag class with a Django template library. Takes a library instance and tag name as parameters, and returns a decorator that registers the tagged class with the library's tag registry. The decorator handles both classes with explicit parse methods and classes that can be used directly as compile functions.

Parameters:
- library: The template tag library (typically ``register = Library()``)
- name: The name of the template tag

Returns:
- Decorator function that registers the class with the library

Example:
```
@template_tag(register, 'my_tag')
class MyTag(BaseNode):
    pass
```
10376	Returns a descendant public key chain by deriving children through a hexadecimal chain path, where each step processes 4 bytes and applies modulo 2^31 to stay within the valid range, ultimately returning a PublicKeychain object.
10377	Get sqlite_master table information as a list of dictionaries.
10378	Generates a postorder iteration of nodes in an object graph, yielding Node objects for each element in lists and dictionary values, while maintaining parent-child relationships and positional information.
10379	Function `select` applies a CSS selector to an object and returns matching nodes. If only one node is found, it returns that node; otherwise it returns a list of matches. Returns `False` on syntax error or `None` if no results are found. Uses a `Parser` object to parse the selector and handles `SelectorSyntaxError` exceptions.
10380	Parses a selector string into a list of tokens and returns the matched nodes from self.obj. If the selector starts with '*', it returns all object items via object_iter. Otherwise, it processes the selector using selector_production. The results are filtered to extract node values, with special handling for single results (returned as primitives) and empty results (returned as None).
10381	Method `selector_production` processes a full CSS selector by parsing tokens and applying validators to filter nodes. It handles various selector types (type, identifier, class, nth-child, pseudo-class functions) and combines them using logical operators (comma, child, sibling, descendant). Returns filtered node results after applying all validations and operator combinations. Raises `SelectorSyntaxError` for unrecognized selectors or operators.
10382	Find nodes in rhs that have parents present in lhs.
10383	Return nodes from rhs which have ancestors in lhs by recursively searching up the parent chain from each node in rhs.
10384	Find nodes in rhs that have common parents with nodes in lhs by checking if each node's parent exists in the parents list of nodes in lhs.
10385	This method parses CSS nth-child selectors and returns a validation function that determines if a node matches the selector pattern. It handles various nth-child syntax forms (odd, even, an+b, etc.) and supports both regular nth-child and nth-last-child variants. The returned function checks if a given node's position in its siblings matches the parsed pattern.
10386	Apply each validator in validators to each node in obj and return nodes that match all validators.
10387	Sends ICMP echo requests to a destination host a specified number of times and returns a deferred that fires when all responses are received. The function configures ping parameters like count, interval, timeout, and packet size, then uses ICMPPort to handle the low-level networking operations. It starts listening for responses and returns a deferred that will be called back with the results once all ping operations complete.
10388	Summary: Makes an HTTP request to the specified URL using the given parameters and returns the response body. If no User-Agent header is provided, it sets a default "Tensor HTTP checker" User-Agent. The method delegates the actual request handling to the underlying `request` method.
10389	Expire cache items older than the specified age by removing them from both the cache and storage, then update the cache.
10390	Set a key `k` to value `v` in the store with timestamp, then persist the change.
10391	Returns the contents of a key and modifies the time, reading from storage if changed. Returns None if key doesn't exist.
10392	Return True if key `k` exists in the store, reloading the store if it has changed.
10393	Checks if a given timestamp fits into the chain by validating signatures and output values against previous and next records. Returns True if the chain integrity is maintained, False otherwise.
10394	Converts a JSON string representation of a NIST randomness beacon value into a NistBeaconValue object. Parses the JSON and validates that all required fields are present and non-null. Returns a new NistBeaconValue instance populated with the parsed data, or None if parsing fails or required fields are missing.
10395	Converts an XML string representing a NIST Randomness Beacon value into a NistBeaconValue object. Parses the XML, extracts required fields, and validates their presence before creating and returning a new NistBeaconValue instance with the extracted data. Returns None if XML parsing fails or required fields are missing.
10396	Returns a minified version of the javascript content, using either a pre-minified template or minifying the content if no minified template exists.
10397	Method `get_fn` processes log file lines by passing each parsed line to the provided function `fn`. It efficiently handles log file rotation and rollover by tracking file inode and size. The method starts reading from the last known position (`self.lastSize`) and continues until the end of file or specified maximum lines limit is reached. Each line is optionally parsed using a parser and then passed to the callback function `fn`. The method updates internal tracking variables after processing and returns control once done.
10398	Returns a list of all log lines since the last run, with an optional limit on the number of lines returned.
10399	Validate a secret link token by loading it and comparing expected data. Returns the token data if valid, None otherwise.
10400	Get cryptographic engine, creating it if necessary using SHA256 hash of SECRET_KEY as the Fernet key.
10401	Multiple algorithm-compatible token validation that iterates through supported digest algorithms and returns the first successful validation result.
10402	Create a secret link token using either a timed or regular serializer based on whether an expiration time is provided.
10403	32-bit counter aggregator with wrapping that calculates the difference between two 32-bit values (a and b) with proper handling of overflow conditions, returning the result divided by a specified delta. When b is less than a (indicating wraparound has occurred), it calculates the wraparound difference using the maximum 32-bit value (4294967295) minus a, then adds b and divides by delta. Otherwise, it simply returns the difference between b and a divided by delta.
10404	64-bit counter aggregator with wrapping that calculates the difference between two 64-bit values, handling wraparound when b < a by using the maximum 64-bit value (18446744073709551615) as the wrap point, and returns the result normalized by the provided delta.
10405	Method to calculate and format an average duration safely by dividing total duration by number of visits, handling edge cases where visits is zero or empty, and returning the result as a formatted string duration.
10406	Sets up output processors based on protocol (TCP/UDP) with default configurations, imports and instantiates output classes, and connects them using a reactor.
10407	Sets up source objects from the given configuration by iterating through sources, creating each source object, setting up triggers for each source, and adding the configured sources to the sources list.
10408	Method `sendEvent` handles incoming events from various sources. It updates the event counter based on the number of events received, aggregates events into a queue, and processes them if the source is critical or warning. The method also updates the timestamp of the last event for the source.

Key operations:
- Increments event counter (handling both single events and lists)
- Aggregates events using `_aggregateQueue`
- Routes events through `routeEvent` if queue exists
- Updates `lastEvents` timestamp for the source
- Sets states for critical/warning sources via `setStates`

Parameters:
- `source`: Event source identifier
- `events`: Either a single event or list of events

Returns: None
10409	**Method Summary:**

`sourceWatchdog` is a watchdog timer function that monitors sources for inactivity. It checks if sources have 'watchdog' enabled in their configuration and recreates sources that haven't generated events within 10 times their interval. The method stops inactive sources, removes them from tracking, and restarts them through the creation process.
10410	Parses a log format string into a regular expression pattern by:
1. Stripping whitespace and normalizing spaces
2. Splitting the format by spaces and processing each element
3. Handling quoted strings and special cases like Referer/User-Agent
4. Converting format specifiers to appropriate regex patterns
5. Building a complete regex pattern and compiling it
6. Extracting field names and types from the format
7. Raising ApacheLogParserError if regex compilation fails
10411	Parses a single line from a log file into a dictionary format. Takes a string line as input, strips whitespace, and uses a regular expression to match and extract log data. Returns a dictionary mapping field names to their parsed values (converted to specified types), with None for missing fields (represented by "-"). Raises ApacheLogParserError if the line cannot be parsed.
10412	Validates that the provided date is in the future and no more than 1 year ahead of the current date, but only when the form's accept data is true. Raises StopValidation with appropriate error messages if validation fails.
10413	Validates that a message is provided when a form rejection is submitted. Raises a validation error if the reject button is pressed but no message is entered.
10414	Verify token from request arguments, validate it using SecretLink, and store valid tokens in the session under 'accessrequests-secret-token' key. If no token is provided or invalid, silently handle the KeyError and do nothing.
10415	Return a basic meaningful name based on device type, using device name for mobile and tablet devices, or browser name for other devices.
10416	Summary: The `_warn_node` method filters out warnings for external images by checking if the warning message starts with 'nonlocal image URI found:'. If it does, the warning is suppressed; otherwise, the original warning behavior is preserved by calling `_warn_node_old`.
10417	Connects various receiver functions to corresponding signals for handling different request events, with specific ordering requirements for the request_accepted signal.
10418	Creates a secret link for an accepted request by generating a description template and associating it with the record title and expiration details.
10419	Sends an email notification to the request sender when their access request is accepted, including record details and optional message/expires_at information.
10420	Sends email notifications when an access request is confirmed - one to the request receiver and one to the request sender, using template files for the email content.
10421	Sends an email validation notification for access requests with a confirmation link that expires after a configured time period.
10422	Sends an email notification to the request sender when an access request is rejected, including record details and optional rejection message.
10423	Send an email notification by rendering a template with context and queuing it for delivery.
10424	Creates a new secret link with the given parameters, sets up its expiration date if needed, generates a token dependent on the object's ID and additional data, and sends a link created signal.
10425	Validate a secret link token by checking if the token is valid and the corresponding link is valid, only querying the database if the token format is correct.
10426	Revoke a secret link by setting its revoked_at timestamp to the current UTC time, sending a link_revoked signal, and returning True if successful. If the link is already revoked, return False without making changes.
10427	Creates a new access request with the specified parameters, sets appropriate status based on sender confirmation, and sends corresponding signals.
10428	Get access request for a specific receiver by request ID and user ID.
10429	Method that validates sender's email by transitioning request status from EMAIL_VALIDATION to PENDING, raising an error if the request is not in the expected state, and emitting a request_confirmed signal upon successful validation.
10430	Accepts a request by changing its status from PENDING to ACCEPTED, validates the current status, and sends a request accepted signal with optional message and expiration details.
10431	Rejects a request by changing its status to REJECTED if it's currently PENDING, then sends a request_rejected signal. Raises InvalidRequestStateError if the request is not in PENDING status.
10432	Creates a secret link using the provided title and optional parameters, associates it with the receiver and record ID, and returns the created link object.
10433	Computes a SHA512 hash for NistBeaconValue signature verification by encoding version string and packing binary data including frequency, timestamp, seed value, previous output, and status code into a hash object.
10434	Verify a NIST message hash and signature for a beacon value using timestamp-based verifier selection. Returns True if verification succeeds, False otherwise. Uses different verifiers based on timestamp ranges: pre-2013, 2013-2017, and post-2017. Returns False for unsupported timestamp ranges.
10435	Template filter to check if a record is currently embargoed based on access right being 'embargoed', having an embargo date, and the embargo date being in the future.
10436	Create an access request for a restricted record by validating user permissions, collecting form data, and processing the request with email verification if needed.
10437	Confirm an email address by validating a token and updating an access request's email confirmation status.
10438	Creates and returns a generic SSH endpoint connection using SSHCommandClientEndpoint.newConnection with the specified parameters including reactor, command, username, hostname, port, keys, password, and known hosts.
10439	Get reverse direction of ordering for a given column, returning the column name with appropriate ascending/descending prefix based on current selection state.
10440	Get the column name for ordering, prefixed with "-" if descending order is specified. Returns None if no column is selected.
10441	Get query with correct ordering, applying ascending or descending order based on the 'asc' attribute and '_selected' field. If 'asc' is True, orders by '_selected' in ascending order; if 'asc' is False, orders by '_selected' in descending order. Returns the query unchanged if no ordering criteria are specified.
10442	Open the file referenced in this object and scrape the version by searching for a magic line. Return the version string if found, otherwise return an empty string or any file exception messages encountered.
10443	Sets the version in a file by replacing the version string within a magic line, preserving the surrounding content.
10444	Initializes SSH client configuration by reading various SSH parameters from config, validates required settings, and creates/reuses SSH client connection with caching.
10445	Starts the timer for this source and establishes SSH connection if required.
10446	Called for every timer tick. Calls self._get which can be a deferred and passes that result back to the queueBack method. Returns a deferred.
10447	This function handles the main access requests and shared links page, listing pending access requests and active shared links. It supports filtering, sorting, and pagination of shared links, and allows users to revoke shared links through a delete form. The function returns a rendered template with the relevant data including paginated links, pending requests, and form for revoking links.
10448	Create a TCP connection to Riemann with automatic reconnection support, handling both TLS and non-TLS connections with failover capability.
10449	Stop this client by stopping the transport, factory, and disconnecting the connector.
10450	Remove all or up to self.queueDepth events from the queue, then send them through the protocol. If self.allow_nan is False, filter out events with None metrics before sending.
10451	Method: eventsReceived
Description: Receives a list of events and transmits them to Riemann
Parameters: events (list of `tensor.objects.Event`)
Functionality: Adds events to the internal events queue if the queue size limit hasn't been reached, ensuring the queue doesn't exceed the maximum allowed size.
10452	Create a UDP connection to Riemann server with specified IP and port, defaulting to 127.0.0.1:5555, and return a deferred object that will establish the connection when resolved.
10453	Creates an Elasticsearch client with configured server settings and starts a queue timer.
10454	Encodes an Event object into a Riemann protobuf Event by mapping event properties to protobuf fields, handling metric types (int/float) with appropriate field assignments, and converting attributes to protobuf attribute entries.
10455	Encodes a list of Tensor events into a protobuf message, filtering for events of type 'riemann' and returning the serialized byte string.
10456	Decode a protobuf message into a list of Tensor events
10457	Send a Tensor Event to Riemann by incrementing pressure and encoding/ sending the events message.
10458	Generate a preview for a given URL with specified options like metadata, width, height, and output format, then output the results.
10459	Retrieves preview results for a given ID and outputs the results using click.echo.
10460	Sends a message dictionary through a queue after checking if it can be pickled. If pickling fails, it provides detailed error information including offending keys and attributes to stderr.
10461	Loop through messages from a queue, execute tasks by running their `run()` method, send ACK, FINISHED, and ERROR messages back to the controller, and handle exceptions gracefully while maintaining a worker loop with dynamic sleep timing.
10462	Return True if it's time to log based on hot_loop status and time delta exceeding log interval.
10463	Send a response to a challenge with given payload, handling state transitions and protocol validation. Returns next state and payload tuple.
10464	Abort an initiated SASL authentication process, transitioning the state to failure. Raises RuntimeError if authentication hasn't started or is already complete.
10465	Performs the SASLprep stringprep mapping step by replacing characters in table C.1.2 with space and removing characters in table B.1, operating in-place on a list of unicode characters.
10466	A template tag that renders footer information based on authenticated user permissions, raising a TemplateSyntaxError if any arguments are provided.
10467	Builds payment parameters for Datatrans payment form including merchant ID, amount, currency, reference number, and signature.
10468	Builds payment parameters for Datatrans credit card registration form with zero amount and CHF currency.
10469	Charges money using Datatrans with a previously registered credit card alias. Takes an amount, alias registration ID, and client reference, validates the amount is positive, retrieves the alias registration, builds and sends an XML request to Datatrans, processes the response, saves and signals the charge response, then returns the payment result. Raises ValueError if amount is not positive.
10470	Return full version number including release candidate, beta, and other tags. For example: "2.0.0a1". If version parameter is not provided, uses the module's __version__ attribute. Handles version strings of length 4 by appending the fourth character (like 'a', 'b', 'rc') to the short version format. For other lengths, returns just the short version format.
10471	Constructs a widget with a layout containing a header with location combobox and up button, a splitter with bookmarks list view and filesystem table view, and a footer with cancel and choose buttons.
10472	Summary: Initialize the filesystem browser dialog by setting window title, sorting files, hiding bookmarks widget, configuring buttons and shortcuts, setting initial location, and connecting various signals to their handler methods.
10473	Adds a keyboard shortcut (Backspace key) for navigating up in the filesystem, connected to the navigate up button click handler.
10474	Handle item activation in file listing by checking if item is a file and updating location accordingly.
10475	Handle selection of item in listing by enabling accept button, clearing previous selection, getting the selected item's path from the filesystem widget model, and adding it to the selected list.
10476	Handle path segment selection by updating location when index is greater than 0.
10477	Sets the resource source and target paths for resource file processing.
10478	Method that runs the build process by executing pyside-rcc to compile resource files, with special handling for Windows platform where pyside-rcc needs to be located manually, and includes error handling for cases where pyside-rcc is not found or fails to execute.
10479	This method cleans up resource files by removing both the original resource file and its compiled version (.pyc). It first calculates the relative path of the resource target from the root path, then checks if the file exists and removes it if found. If the file doesn't exist, it logs a warning. It repeats this process for the compiled version (with 'c' extension) and finally calls the parent CleanCommand's run method to complete the cleaning process.
10480	Fetch and return new children if canFetchMore is True, otherwise return an empty list. Calls _fetchChildren() to get the children and sets _fetched to True. The caller is responsible for adding fetched children to the parent using Item.addChild.
10481	Reset all children and enable fetching for refetching.
10482	Return icon for the given index by mapping it to the source model and retrieving the icon from there.
10483	Runs an external command in a separate process, optionally daemonizing it. Forks a child process, redirects stdio to os.devnull by default, and returns the child's PID. If daemonize=True, the parent exits after forking. Uses subprocess.Popen to execute the command with provided arguments and options.
10484	Return the maximum file descriptor value by getting the soft limit for RLIMIT_NOFILE, using maxfd as fallback if the limit is infinite.
10485	Close a file descriptor if it is open, ignoring invalid file descriptor errors.
10486	Close all open file descriptors except those in the exclude list, iterating from the maximum file descriptor down to 0.
10487	Redirect a system stream to the provided target by duplicating the file descriptor, using /dev/null as target if None is provided.
10488	Sets HTML attributes on form field widgets, allowing dynamic attribute values through callable functions.
10489	Returns a module from a given app by its name, handling app config class paths and using autodiscover-like error bubbling strategy.
10490	Imports modules from registered apps using given module name and returns them as a list.
10491	**Summary:**

The `include_` function is a custom Django template tag that extends the built-in `include` tag by allowing template variables in the template name and supporting a fallback template. It checks if the template name contains variables (using `{{`), and if so, processes the template dynamically. If a fallback template is specified, it compiles the fallback template and creates a `DynamicIncludeNode` to handle the dynamic inclusion. Otherwise, it falls back to the standard `include` behavior. Requires Django 1.8+.
10492	Returns Gravatar image URL for a given string or UserModel with specified size and default image option.
10493	Returns a Gravatar image HTML tag for a given string or UserModel object, with specified size and default image type.
10494	Checks if the given path is a valid absolute filesystem directory. Returns True if the path is absolute, exists as a directory, and is not a file. Raises LocalPortValidationError if the path is invalid.
10495	Checks if a URL contains S3 references, but not an accurate validation. Skips URLs starting with 'source:' and raises RemotePortValidationError for invalid S3 locations.
10496	Returns the absolute path of a template file, converting relative paths to absolute paths using the current working directory.
10497	Get a list of keys from S3 bucket with optional folder path and full key data option.
10498	Builds a workflow definition JSON from a cloud_harness task, including task inputs/outputs, port handling, and optional S3 storage configuration.
10499	Execute a cloud_harness task by sending a POST request to the task URL with workflow JSON data, handle the response by extracting the task ID and refreshing the task status, or print error information if the request fails.
10500	Move active projects to the archive by validating folder existence and calling the archive function with the specified folder path, archive directory, and dry run flag.
10501	Creates directories recursively, equivalent to 'mkdir -p' shell command.
10502	List the contents of the archive directory by finding the intersection of all provided patterns, searching for files matching the patterns in the archive directory structure and printing the matching file paths.
10503	Restore a project from the archive by searching for the specified folder name in the archive directory. If found, move the most recent matching project from the archive to the current directory, after checking that no folder with the same name already exists.
10504	Create a new storage service client with the specified access token and environment, returning a Client instance.
10505	Lists entities directly under a given path, returning their names. Validates the path and entity type, then retrieves folder contents through API calls, formatting file and folder names appropriately. Raises exceptions for invalid arguments, forbidden access, not found errors, and other storage issues.
10506	Download a file from storage service to local disk.

Existing files on the target path will be overwritten.
The download is not recursive, as it only works on files.

Args:
    path (str): The path of the entity to be downloaded. Must start with a '/'.

Returns:
    None

Raises:
    StorageArgumentException: Invalid arguments
    StorageForbiddenException: Server response code 403
    StorageNotFoundException: Server response code 404
    StorageException: other 400-600 error codes
10507	Check if a certain path exists in the storage service.

Args:
    path (str): The path to be checked

Returns:
    True if the path exists, False otherwise

Raises:
    StorageArgumentException: Invalid arguments
    StorageForbiddenException: Server response code 403
    StorageNotFoundException: Server response code 404
    StorageException: other 400-600 error codes
10508	Get the parent entity of the entity pointed by the given path.

Args:
    path (str): The path of the entity whose parent is needed

Returns:
    A JSON object of the parent entity if found.

Raises:
    StorageArgumentException: Invalid arguments
    StorageForbiddenException: Server response code 403
    StorageNotFoundException: Server response code 404
    StorageException: other 400-600 error codes
10509	Creates a folder in the storage service at the specified path by validating the path, retrieving parent metadata, and calling the API to create the folder with the given name and parent UUID.
10510	Uploads a local file to a storage service destination. Validates the destination path and file name, creates a file container with specified metadata, uploads the file content, and returns the UUID of the created file entity. Raises various storage exceptions for invalid arguments, forbidden access, not found errors, and other server errors.
10511	Delete an entity from the storage service using its path. Raises StorageArgumentException if trying to delete non-empty folder, StorageForbiddenException if server returns 403, StorageNotFoundException if server returns 404, or StorageException for other 400-600 error codes. Returns the UUID of the deleted entity as string.
10512	Validate a string as a valid storage path. Raises StorageArgumentException if the path is invalid (empty, not a string, doesn't start with '/', or is just '/'). If projects_allowed is False, also raises StorageArgumentException if the path contains only one path element (indicating a project path).
10513	Creates a new cross-service client with a storage client initialized using the provided access token and environment.
10514	Creates a new storage service REST client with the specified access token and environment, configuring error handling for common HTTP status codes (403, 404, and other non-ok responses) and returning an ApiClient instance.
10515	Get generic entity details by UUID, returning a dictionary with entity information including collab_id, created_by, created_on, description, entity_type, modified_by, modified_on, name, and uuid. Raises StorageArgumentException for invalid UUID, and StorageException variants for various HTTP error codes.
10516	Set metadata for a specified entity by making an authenticated POST request to the metadata endpoint. Validates that the entity_id is a valid UUID and that metadata is provided as a dictionary. Replaces all existing metadata with the provided dictionary and returns the updated metadata as a dictionary. Raises appropriate storage exceptions for invalid arguments, forbidden access, not found, or other server errors.
10517	Get metadata of an entity by type and ID, validating the UUID and making an authenticated request to the metadata endpoint. Returns a dictionary of metadata key-value pairs. Raises StorageArgumentException for invalid UUID, and StorageException subclasses for various HTTP error codes.
10518	Update metadata for a specified entity identified by type and UUID. Existing non-modified metadata remains unaffected. Accepts entity type ('project', 'folder', 'file'), entity UUID, and metadata dictionary. Returns updated metadata as dictionary. Raises StorageArgumentException for invalid arguments, StorageForbiddenException for 403 errors, StorageNotFoundException for 404 errors, and StorageException for other HTTP error codes (400-600).
10519	Delete specified metadata entries from an entity by sending a DELETE request to the metadata endpoint. Validates the entity ID as a UUID and ensures metadata keys are provided as a list. Returns the updated metadata dictionary after deletion. Raises appropriate exceptions for invalid arguments, forbidden access, not found errors, or other server errors.
10520	List all projects the user has access to with optional filtering and pagination parameters. Returns a dictionary containing project count, pagination links, and project results. Supports filtering by HPC type, access level, name, and collab ID, with sorting options on name, created_on, and modified_on fields. Raises StorageException variants for different HTTP error codes.
10521	Get information about a specific project by its UUID, returning a dictionary with project details including collab_id, created_by, created_on, description, entity_type, modified_by, modified_on, name, and uuid. Raises StorageForbiddenException for 403 errors, StorageNotFoundException for 404 errors, and StorageException for other 400-600 error codes. Validates that the project_id is a valid UUID before making the request.
10522	Create a new project in the specified collaboration.

Args:
    collab_id (int): The ID of the collaboration where the project should be created.

Returns:
    dict: A dictionary containing the created project details with keys including 'collab_id', 'created_by', 'created_on', 'description', 'entity_type', 'modified_by', 'modified_on', 'name', and 'uuid'.

Raises:
    StorageForbiddenException: If server response code is 403.
    StorageNotFoundException: If server response code is 404.
    StorageException: For other 400-600 error codes.

The method makes an authenticated POST request to the 'project/' endpoint with the collaboration ID in the request body.
10523	Delete a project by UUID, recursively removing all content. Raises exceptions for invalid UUID, 403 Forbidden, 404 Not Found, or other HTTP errors.
10524	Creates a new folder with the specified name and parent entity. Returns details of the created folder including UUID, timestamps, and metadata. Validates that the parent UUID is valid and raises appropriate exceptions for invalid arguments, authorization errors, not found errors, or other HTTP errors.
10525	Get information about a specific folder by its UUID, returning a dictionary with folder details including creation/modification metadata, name, parent folder UUID, and entity type. Raises StorageArgumentException for invalid UUID, StorageForbiddenException for 403 errors, StorageNotFoundException for 404 errors, and StorageException for other HTTP error codes (400-600).
10526	Deletes a folder recursively by its UUID, raising appropriate exceptions for invalid arguments, forbidden access, not found errors, or HTTP errors.
10527	Uploads content to an existing file identified by file_id. Validates the file ID as a UUID and ensures either a source file path or content string is provided, but not both. Optionally verifies the file's current state using an ETag for optimistic concurrency control. Returns the ETag of the uploaded file. Raises exceptions for invalid arguments, file access errors, authentication issues, and server errors.
10528	Copy file content from a source file to a target file using HTTP PUT request with copy header.

Args:
    file_id (str): The UUID of the target file whose content will be written
    source_file (str): The UUID of the source file whose content will be copied

Returns:
    None

Raises:
    StorageArgumentException: If either file_id or source_file is not a valid UUID
    StorageForbiddenException: Server response code 403
    StorageNotFoundException: Server response code 404
    StorageException: Other 400-600 error codes
10529	Download file content by file ID, optionally using an ETag for conditional retrieval. Returns a tuple of (ETag, content) if content is retrieved, or (None, None) if content hasn't changed since the provided ETag. Raises various StorageException types for different error conditions.
10530	Get a signed unauthenticated URL for downloading file content that expires after 5 seconds.

Args:
    file_id (str): The UUID of the file to get the link for.

Returns:
    The signed url as a string

Raises:
    StorageArgumentException: Invalid arguments
    StorageForbiddenException: Server response code 403
    StorageNotFoundException: Server response code 404
    StorageException: other 400-600 error codes
10531	Inserts a formatted log record as a dictionary into the MongoDB collection.

The method takes a log record, formats it into a dictionary message, and inserts it into the specified MongoDB collection. If the formatted message is not already a dictionary, it attempts to parse it as JSON before insertion.
10532	Sets the service name and version for the request, targets the specified service and version, retrieves the service URL, strips trailing slashes, and returns the request builder instance for chaining calls.
10533	Adds headers to the request by merging given headers with existing headers, returning the request builder instance for method chaining.
10534	Adds parameters to the request params and returns the request builder instance to enable method chaining.
10535	Defines if an exception should be thrown after the request is sent based on a predicate. Takes an exception class and a predicate function that determines when to throw the exception. Returns the request builder instance to enable method chaining.
10536	Return a sequence containing the fields to be displayed on the changelist, with boolean fields replaced by switch fields.
10537	Spawns a tree of jobs to efficiently process large batches of samples by recursively partitioning them into smaller chunks (up to 100 partitions) to avoid overloading the job scheduler. For each partition, it either recursively spawns child jobs if the partition is large enough, or directly executes the provided function on individual samples.
10538	Runs GenotypeGVCFs on one or more gVCFs to perform joint genotyping, with optional annotations and configurable confidence thresholds. Supports unsafe mode for sequence dictionary incompatibility. Returns the resulting VCF file as a FileStoreID.
10539	Runs Oncotator to add cancer relevant variant annotations to a VCF file, returning an annotated VCF FileStoreID.
10540	Sorts the list in-place by timestamp by default (or by a custom function if provided), then returns the sorted list.
10541	Returns the timestamp portion of datapoints as a list of python datetime objects.
10542	Loads data from a ConnectorDB export folder by loading the data.json file located within the specified folder path.
10543	Shifts all timestamps in the datapoint array by the given number of seconds in-place. Takes a time shift value 't' and adds it to each timestamp in the array, modifying the original array directly. Returns self to allow for method chaining.
10544	Gets the sum of the data portions of all datapoints within the object by iterating through raw data and adding up the "d" values.
10545	Start the event loop to collect data from the serial device by either using the provided device parameter or retrieving it from configuration, and then initiate data collection. If no device is specified, print an error message and return.
10546	Create a new user with the given username by prompting for a password, creating a User object, adding it to the database session, and committing the transaction.
10547	Parse Visual Novel search pages and return a list of dictionaries containing VN names and IDs extracted from HTML table cells.
10548	Parse Releases search pages and return a list of dictionaries containing release information (date, ages, platform, and name) from the provided BeautifulSoup object.
10549	Parse a page of producer or staff results

:param soup: The BS4 class object
:return: A list of dictionaries containing a name and nationality.
10550	Parse a page of character results and return a list of dictionaries containing character name, gender, and their associated games with names and IDs.
10551	Parse a page of tag or trait results and return a list of tag strings from HTML table data.
10552	Parse a page of user results and return a list of dictionaries containing user names and join dates.
10553	Creates a gzipped tarball containing specified files with optional prefixing for tarball entries.
10554	Applies a given operation to each file in a list of absolute file paths, moving them to a specified output directory while preserving their base names. Raises a ValueError if any file path is relative instead of absolute.
10555	Copies a file from the file store to a specified output directory using a Toil job. Takes a job object, file name, file ID, and output directory as parameters, reads the file from the file store, and copies it to the destination directory.
10556	Creates a Spark Submit style job submission line with specified parameters, memory allocation, and argument handling.
10557	Method `docker_parameters` augments a list of Docker run arguments with a host mapping option when the notional Spark master address differs from the actual one. It adds '--add-host=spark-master:<actual>' to the docker parameters list if the current instance differs from the actual instance, returning the modified or original docker parameters list.
10558	Refresh reloads data from the server by reading metadata from the database at the object's path, raising an error if the metadata cannot be retrieved.
10559	Calls MuTect for variant analysis using provided BAM and reference files, then returns the MuTect output as a tarball FileStoreID.
10560	Creates a device with optional public/private setting and additional properties. Supports setting device metadata like nickname and description, and can create streams during device creation for faster setup. The schema for streams must be provided as a string. Returns the created device's metadata.
10561	Returns the list of streams that belong to the device by reading from the database and constructing stream objects with their metadata.
10562	Exports the device to a specified directory by creating a directory structure with device information and exporting all associated streams. Raises FileExistsError if the directory already exists.
10563	Searches vndb.org for a term and returns matching results of the specified type, raising appropriate exceptions for various error conditions including 404s, redirects, no results, and invalid search types.
10564	This method acts as a parsing dispatcher that routes BeautifulSoup objects to specific parsing functions based on the search type category. It handles different search types (v, r, p, s, c, g, i, u) and returns the parsed results from corresponding parsing functions. The method is asynchronous and awaits the completion of the parsing operations.
10565	Adds a stream to the query construction with optional interpolator and column naming. Supports Merge queries with custom column names. Raises exceptions for invalid column names or missing names.
10566	Invalidates the device's current API key, generates a new one, and updates the current authentication to use the new API key.
10567	Returns the list of users in the database by reading from the database and converting each user record into a user object with metadata.
10568	Creates BWA index files from a reference genome using Docker, returns FileStoreIDs for the index files.
10569	Returns the ConnectorDB object that the logger uses, establishing a connection if needed. Raises an error if connection fails.
10570	Adds a stream to the logger with optional schema creation. If the stream doesn't exist and a schema is provided, creates the stream with the specified schema and additional properties. If no schema is provided, attempts to load the existing stream from the database. Raises an exception if the stream doesn't exist and no schema is provided. Finally, calls addStream_force to add the stream to the logger.
10571	Adds a stream to the logger without verifying its existence in the ConnectorDB database. Inserts or replaces the stream in the database and updates the local streams dictionary with the provided schema. Use with caution as no validation is performed.
10572	Inserts a datapoint into the logger for the given stream name, validates it against the stream's schema, and caches it in the database for eventual synchronization with ConnectorDB. Raises an exception if the stream is not found.
10573	Syncs local cached data with the ConnectorDB server by iterating through streams, checking for newer timestamps to avoid conflicts, inserting data in chunks, and removing successfully synced datapoints from cache. Handles exceptions and calls sync failure callbacks if configured.
10574	Starts the logger's background synchronization service that automatically syncs with ConnectorDB at regular intervals, with an initial sync attempt and thread setup.
10575	Stops the background synchronization thread by canceling it if it exists and setting the reference to None.
10576	Downloads a file from a URL as a job and stores it globally, returning the global file ID.
10577	Uploads a file to S3 using s3am_upload function within a job context, handling file path resolution and core allocation.
10578	Writes all labels from a given ontology to a specified output file, one label per line.
10579	The `tree` function outputs parent-child relationships from an ontology to a specified file. It iterates through the hierarchy generated by `get_hierarchy` using the provided ontology and OLS base URL, then writes each parent-child pair to the output file in tab-separated format.
10580	Function to calculate the mean insert size from a BAM file using samtools via docker, filtering for proper pairs with insert size < 10000, returning the mean rounded to the nearest integer or 150 if no valid reads are found.
10581	Returns the Docker container ID of the current container by reading from /proc/1/cgroup, or raises NotInsideContainerError if not inside a container.
10582	Runs STAR alignment on FASTQ files to produce BAM output, with optional wiggle file generation. Handles both paired and single-end data, supports sorting and memory management for large samples. Returns file store IDs for transcriptome BAM, aligned BAM, log, and splice junction files, with optional wiggle file ID.
10583	Creates a stream with optional JSON schema and additional properties. Accepts schema as either string or dict, validates the schema, and stores the stream metadata.
10584	Exports the stream to a given directory by creating stream.json, data.json, and optionally downlink.json files. Raises FileExistsError if directory already exists.
10585	Returns the device that owns the given stream by extracting the device path from the stream path and creating a Device object.
10586	Returns an iterator over the labels of terms in the specified ontology using the OLS client.
10587	Returns an iterator over parent-child relationships in an ontology by creating an OLS client and calling its iter_hierarchy method with the specified ontology name.
10588	The `run` method prepares and executes a pipeline workflow by setting up necessary configurations, managing temporary directories, and executing the pipeline command. It handles argument parsing, configuration file creation, and ensures proper file ownership after execution. The method also supports restarting existing workflows and cleaning up temporary files upon completion.
10589	Populates an ArgumentParser object with arguments based on key-value pairs from config_data dictionary, recursively handling nested dictionaries by flattening their keys with dot notation.
10590	Returns the config file contents as a string by generating a temporary config file, reading its contents, and then deleting the file.
10591	Returns the mount point path of the current Docker container, raising exceptions if outside a container or if the Docker daemon is unreachable. This method is idempotent and stores the result for future calls.
10592	Add an argument to the given arg_parser with the given name, prefixed with '--'.
10593	Creates and returns an ArgumentParser object prepopulated with 'no clean', 'cores' and 'restart' arguments.
10594	Creates and returns a list representing a command for running the pipeline with specified arguments, work directory path, and configuration path, including optional restart flag.
10595	Sets the authentication header for the session using either user credentials or API key, with support for basic authentication. Updates both HTTP and WebSocket authentication with the provided credentials.
10596	Handles HTTP error codes for the given request, raising AuthenticationError for 4xx errors and ServerError for 5xx errors, returning the request on success.
10597	Method `ping` attempts to ping the server using current credentials and returns the path of the currently authenticated device by making a GET request with parameter "q" set to "this" and extracting the text response.
10598	Creates a POST request to the specified path with optional data, converting the data to JSON format.
10599	Send an update request to the specified path with given data converted to JSON.
10600	Delete an object from the CRUD API at the specified path by sending a DELETE request.
10601	Subscribe to the given stream with the callback and optional transform function.
10602	Creates a new user with the specified email and password, along with optional properties and device/stream initialization. Supports setting user role, public visibility, and creating an entire user tree including devices and streams in a single operation. Returns the created user metadata.
10603	Returns the list of devices that belong to the user by reading from the database and populating device metadata.
10604	Adapter trimming for RNA-seq data using CutAdapt tool. Takes paired or single-end FASTQ files and trims specified 3' adapters from reads. Returns FileStoreIDs of trimmed R1 and R2 files. For paired-end data, requires both forward and reverse adapter sequences. Uses CutAdapt version 1.9 via Docker container. Trims reads to minimum length of 35 bases.
10605	Creates a reference index file using SAMtools faidx command on a reference genome file, returning the FileStoreID of the created index file.
10606	Summarizes the SAMtools index operation that creates a BAM index file from an input BAM file using Dockerized SAMtools, returning the FileStoreID of the generated index file.
10607	Marks PCR duplicates in a BAM file using Sambamba and returns the sorted BAM file as a FileStoreID.
10608	Marks reads as PCR duplicates using SAMBLASTER tool, takes a SAM file as input, runs SAMBLASTER in a docker container to produce a deduplicated SAM file, and returns the FileStoreID of the output file.
10609	Runs Picard MarkDuplicates on a coordinate-sorted BAM file to mark duplicate reads, returning the processed BAM and BAI file IDs.
10610	Sorts a BAM file using Picard SortSam tool, with optional sorting by read name or coordinate, and returns the FileStoreID of the sorted BAM file.
10611	Creates a recalibration table for Base Quality Score Recalibration using GATK's BaseRecalibrator tool. Takes input BAM file, reference genome, and known variant files (dbSNP, Mills) to generate a recalibration table. Optionally runs GATK in unsafe mode to allow sequence dictionary incompatibility. Returns the FileStoreID of the generated recalibration table file.
10612	RNA quantification using Kallisto with optional paired-end or single-end input, returning a tarball of results.
10613	Runs RNA quantification with RSEM using a BAM file and RSEM reference tarball, returning FileStoreIDs for gene and isoform results.
10614	Prepare test set for C++ SAR prediction by finding all items users have seen before. Returns training data filtered to test users, sorted by user and item.
10615	Send a command through the websocket in a thread-safe manner using a lock.
10616	Subscribes to a stream with an optional transform and callback function. If the connection status is not connected, attempts to connect first. Sends a subscription command and stores the callback in subscriptions dictionary. Returns True if successful, False otherwise.
10617	Attempt to connect to the websocket and returns True if successful, False otherwise. Uses a lock to ensure thread safety and handles different connection states (connected, disconnecting, disconnected, reconnecting) appropriately.
10618	This method attempts to reconnect to a server when a connection is lost. It implements exponential backoff with randomization for reconnect delays, resetting the reconnect interval after 15 minutes of disconnection, and ensures the delay stays within configured minimum and maximum bounds. The actual reconnect attempt is scheduled using a daemon thread timer.
10619	Resubscribes to all existing subscriptions by sending subscribe commands, allowing connection recovery after a closed connection. Uses a lock to ensure thread safety while iterating through subscriptions.
10620	Called when the websocket is opened. Logs the event, adjusts reconnection timing, sets connection status to connected, initializes timing variables, and releases the connection lock.
10621	Called when the websocket is closed. Handles cleanup tasks like canceling the ping timer and managing connection state transitions. If the connection is already disconnected, it returns early to prevent double-processing. For active connections, it initiates a reconnect attempt.
10622	Handles websocket errors by logging the error and updating the connection status from "connecting" to "errored" if the connection was in progress.
10623	This method handles incoming websocket messages from the server, processing stream data based on subscriptions. It parses JSON messages, builds subscription keys considering transforms, and executes registered subscription functions when matches are found. For downlink streams, it automatically acknowledges received data by reinserting it into the corresponding non-downlink stream when the subscription function returns True. If no subscription is found for a stream, it logs a warning.
10624	Method `__ensure_ping` checks if the websocket connection is still alive by monitoring ping timeouts. It records ping timestamps and closes the websocket connection with reconnection attempt if no ping is received within the specified timeout interval. Otherwise, it schedules the next ping check using a daemon timer.
10625	Runs GATK SelectVariants to isolate a specific variant type (SNP or INDEL) from a VCF file, returning the FileStoreID of the filtered VCF.
10626	Filters a VCF file using GATK VariantFiltration with specified filter name and expression, then fixes quotation marks in the VCF header before returning the filtered file ID.
10627	Runs GATK VariantRecalibrator for SNP or INDEL variant quality score recalibration, using specified annotations and resource files. Supports SNP and INDEL modes with required resource files (hapmap, omni, phase, dbsnp, mills). Outputs recalibration table, tranches file, and plots file. Optionally runs in unsafe mode to allow sequence dictionary incompatibility.
10628	Applies variant quality score recalibration to a VCF file using GATK's ApplyRecalibration tool, filtering variants based on tranche thresholds. Takes input VCF, recalibration table, and tranches files along with reference genome data, and outputs a recalibrated VCF file. Supports SNP and INDEL modes with configurable sensitivity filtering and optional unsafe mode for sequence dictionary incompatibility.
10629	Merges VCF files using GATK CombineVariants with specified merge option, returning the FileStoreID of the merged VCF file.
10630	Performs a quick validation check on a BAM file using samtools quickcheck via Docker. Returns True if the BAM is valid, False if invalid or if the check fails.
10631	Loads handlers from a mapping dictionary by importing objects from dotted paths or using existing objects, and returns a dictionary mapping packet types to their corresponding handlers. Handles special wildcard '*' packet type and raises an error if a packet type already has a handler assigned.
10632	Helper function to write JSON configuration to a file with pretty formatting (indentation and sorted keys).
10633	Gets the project configuration from a JSON file, creating a default one if it doesn't exist. Returns the configuration as a dictionary.
10634	Gets the data for a given term from an ontology by making a GET request to a formatted URL and returning the JSON response.
10635	Searches the OLS with the given term and optional query fields, returning a JSON response containing the search results.
10636	Method: suggest
Parameters: self, name (str), ontology (list[str], optional)
Returns: dict
Description: Suggests terms from an optional list of ontologies by making a GET request to the ontology suggest endpoint with the provided name and optional ontology parameters. The method constructs query parameters with the search term and joins multiple ontologies with commas if provided, then returns the JSON response from the API call.
10637	Iterates over the descendants of a given term in an ontology, yielding terms one by one. Takes ontology name, term IRI, page size, and sleep time as parameters, with default page size of 500 and no sleep between pages. Returns an iterator of term dictionaries.
10638	Iterates over the labels for the descendants of a given term in an ontology, yielding labels one by one. Takes parameters for ontology name, term IRI, page size, and sleep time between pages, with defaults of 500 for page size and 0 for sleep time. Uses a helper function to iterate through labels.
10639	Iterates over the labels of terms in the specified ontology by wrapping the pager returned by the OLS. Returns an iterator of strings representing the labels. Takes optional parameters for page size (default 500) and sleep time between pages (default 0 seconds).
10640	Iterates over parent-child relationships in an ontology hierarchy, yielding pairs of parent and child term labels. For each term in the ontology, it fetches hierarchical children and produces label pairs. Returns an iterator of (parent_label, child_label) tuples.
10641	Runs FastQC on input FASTQ reads and returns a tarball of the results. Reads input files from file store, executes FastQC in Docker, combines outputs into a tarball, and writes the result back to file store. Handles both single-end and paired-end read inputs.
10642	Adds a stream to the query construction with optional time limits and transformations.
10643	Creates and configures a Flask application with database integration, login management, and administrative features. Initializes the app with default configuration, registers web and API blueprints, sets up user authentication via login_manager, configures database migrations, and initializes an admin interface. Returns the configured Flask app instance.
10644	Start Spark and HDFS master containers using Docker, setting up necessary environment variables and volume mounts. Returns the hostname of the system.
10645	Start Spark and HDFS worker containers, handling HDFS startup retries if necessary.
10646	Launches the Hadoop datanode by starting a Docker container with specified parameters and returns the container ID.
10647	Stop Spark and HDFS worker containers by executing docker commands to remove ephemeral directories, stop the containers, and remove them from the system, then log the stopping actions.
10648	Checks if Spark worker and HDFS datanode are still running by verifying their container statuses.
10649	A tokenizer function that generates a stream of tokens from text input, handling both string buffers and file objects with memory mapping. It processes input line-by-line, skipping non-XML comments, and yields tokens including text content, newlines, and end-of-file markers while tracking line numbers and positions. The function properly manages empty files and handles tokenization using regex patterns from a predefined tokens list.
10650	Look up a zone ID for a zone string.

Args: conn: boto.route53.Route53Connection
      zone: string eg. foursquare.com
Returns: zone ID eg. ZE2DYFZDWGSL4.
Raises: ZoneNotFoundError if zone not found.
10651	Fetch all pieces of a Route 53 config from Amazon by making iterative API calls to retrieve DNS records, handling pagination when results are truncated. Returns a list of ElementTrees containing the configuration data.
10652	Merge a set of fetched Route 53 config Etrees into a canonical form.

Args: cfg_chunks: [ lxml.etree.ETree ]
Returns: lxml.etree.Element
10653	Validate a changeset against Amazon's Route 53 API limits, returning a list of error messages for any violations found. Checks include minimum/maximum number of Change elements (1-100), maximum number of ResourceRecord elements (1000), and maximum total characters in Value elements (10000). Returns empty list if all limits are satisfied.
10654	Orders population members from highest fitness to lowest fitness by sorting the Member objects based on their fitness_score attribute in descending order.
10655	**Method Summary:**

The `fitness` method calculates and returns the average fitness score of all members in the population. It handles both single and multi-process scenarios by retrieving member data appropriately, then computes the mean fitness score. If the population is empty, it returns `None`.

**Key Details:**
- **Purpose:** Computes average fitness score of population members
- **Parameters:** None
- **Returns:** Average fitness score (float) or None (if population is empty)
- **Process:** 
  - Checks if population has members
  - Handles multi-process retrieval when applicable
  - Calculates sum of all fitness scores divided by member count
- **Edge Case:** Returns None for empty populations
10656	Returns the average cost function value across all members in the population. If there are no members, returns None. Uses multiprocessing if multiple processes are enabled, otherwise processes members sequentially.
10657	Returns the median cost function value across all members, or None if there are no members.
10658	Returns the average parameter values across all population members. Calculates the mean of each parameter across the entire population by summing individual member parameter values and dividing by the number of members. Returns None if the population is empty.
10659	Returns Member objects of population, handling both single and multi-process scenarios by checking the number of processes and extracting results from multiprocessing objects when necessary.
10660	Adds a parameter to the Population with specified name and value range.
10661	Generates the next population for evolutionary algorithm by selecting parents based on their fitness, performing crossover and mutation to create offspring, and evaluating their fitness. Uses parallel processing if multiple CPU cores are available. The selection probability follows a logarithmic distribution controlled by log_base parameter, favoring better performing individuals. Mutation is applied to offspring parameters with specified mutation rate and maximum mutation amount.
10662	Normalize dictionary keys by replacing underscores with hyphens and prefixing with '--' for long options.
10663	Returns a generator yielding environmental variables with prefix PIP_ as (key, value) tuples, where key is converted to lowercase with the prefix removed.
10664	Return True if the callable throws the specified exception, False otherwise. If no exception types are specified, returns True if any exception is thrown. Uses ExceptionTrap to catch exceptions and check if they match the specified types.
10665	Transforms a list of package versions from PYPI into a list of packages with their versions stored inline, sorted by score in descending order. Each package record contains the package name, summary, list of versions, and score. If multiple versions exist for a package, the record is updated with the summary and score from the highest version.
10666	Converts the result back into the input type by handling bytes and unicode types specifically, otherwise returns the result as-is.
10667	Converts HTML tags to XHTML by moving them to the XHTML namespace, iterating through all elements and prefixing their tags with the XHTML namespace URI.
10668	Convert XHTML tree tags to HTML by removing XHTML namespace from all elements.
10669	Return an HTML string representation of the document with various serialization options including pretty printing, metadata content type handling, encoding control, and doctype support.
10670	Opens an HTML document in a web browser by saving it to a temporary file and displaying its file URL. Takes an XML/HTML element or tree and optional encoding, writes the document to a temporary .html file, prints the file URL, and opens it in the default web browser. Note: the temporary file is not automatically deleted after use.
10671	Removes this element from the tree by:
1. Getting the parent element
2. Moving the element's tail text to either the previous sibling or parent's text
3. Removing the element from its parent

The method ensures text continuity by merging tail text with adjacent text content before removal.
10672	Remove the tag while preserving its children and text content, merging them into the parent element. The method handles text and tail content properly, ensuring that text from the removed tag is appended to appropriate sibling or parent text content, and children are moved to the parent's position in the tree structure.
10673	Get the first element in a document with the given id. If none is found, return the default argument if provided or raise KeyError otherwise. Note that there can be more than one element with the same id, and this isn't uncommon in HTML documents found in the wild. Browsers return only the first match, and this function does the same.
10674	Method that executes a CSS selector expression on this element and its children, returning a list of matching results. Uses lxml.cssselect.CSSSelector for the actual selection, with optional translator parameter (defaults to 'html'). Includes an import inside the method body to make the lxml dependency optional.
10675	Generator function that iterates through all logger handler attributes, yielding tuples containing (logger_name, handler, member_name, member_value) for use in testing scenarios where stderr/stdout need to be switched out.
10676	Returns test counts from environment variables, including classes, tests, and modules found by pyt.
10677	Returns True if only a single class or module is being run, or if no classes/modules are specified but tests are present. Returns False otherwise.
10678	Returns True if only a single module is being run, False otherwise. If no modules are detected, it checks if a single class is being run instead.
10679	Validates that the 'params' key in a request contains either a list or dictionary value. Raises an AssertionError with message 'Incorrect parameter values' if validation fails.
10680	Function to validate that a request contains a valid ID field, which must be of type string, int, or None. Raises an assertion error with message 'Incorrect identifier' if the ID field is invalid.
10681	Function `filesys_decode` ensures a given path is properly decoded using filesystem encoding or UTF-8. It returns the decoded string if successful, or None if decoding fails with both encodings. The function first checks if the path is already decoded, then attempts to decode using the filesystem encoding and UTF-8 in sequence.
10682	Helper function that escapes string values in a dictionary. It iterates through key-value pairs in an iterable, and for each value that has an '__html__' method or is a string type, it applies the escape function and updates the object with the escaped value. Returns the modified object.
10683	Return the Python codec name corresponding to an encoding, or None if the string doesn't correspond to a valid encoding. Handles both string and bytes input, normalizes the encoding name by removing ASCII punctuation and converting to lowercase, then looks up the canonical name in the encodings dictionary.
10684	Method `detectBOM` attempts to detect a Byte Order Mark (BOM) at the start of a stream to determine the file encoding. It checks for various BOM patterns (UTF-8, UTF-16 LE/BE, UTF-32 LE/BE) by reading up to 4 bytes from the beginning of the stream. If a BOM is found, it returns the corresponding encoding name; otherwise, it returns None. The method also adjusts the stream position to skip the BOM if one is detected, or resets to the beginning if no BOM is found.
10685	Selects the remote address from X-Forwarded-For header by taking the IP at the position determined by num_proxies parameter, defaulting to the last proxy's IP in the chain.
10686	Converts amount value from several types (Decimal, str, int, float) into Decimal, raising ValueError for unsupported types.
10687	Parses HTML string data into an Element tree using BeautifulSoup parser and returns the root <html> Element. Supports custom BeautifulSoup parser and Element factory function through keyword arguments.
10688	Parse a file into an ElementTree using the BeautifulSoup parser, with optional custom parser and element factory functions.
10689	Converts a BeautifulSoup tree to a list of Element trees, supporting HTML-like soup with multiple root elements. Returns a list of child elements instead of a single root Element. Accepts an optional Element factory function through the `makeelement` parameter.
10690	Get the current exception info as `Traceback` object. By default, system exceptions are re-raised unless `ignore_system_exceptions` is False. Optional parameters allow skipping frames and filtering hidden frames.
10691	Returns the string representation of an exception by formatting the exception type and value using traceback.format_exception_only, then strips and decodes the result appropriately for Python 2 or 3.
10692	Render the traceback for the interactive console, including optional title, frames, and exception description with appropriate HTML formatting.
10693	Returns a generator that yields a formatted traceback with file information, line numbers, function names, and the exception message.
10694	Helper function that returns source lines with additional information, including marking function definitions and the current line. It processes source lines to identify function boundaries using regular expressions and inspect module, then marks relevant lines with `in_frame` and `current` flags based on the code object's first line number and current line number. Returns a list of Line objects with annotated information.
10695	Render the source code by joining annotated lines with newline characters and formatting them using SOURCE_TABLE_HTML template.
10696	Function to parse version information from egg info strings, extracting version parts and validating against expected package names.
10697	Returns the locations of project URLs by checking index URLs and normalizing project names for compatibility with easy_install.
10698	Find all available versions for a given project name by searching through index URLs, find links, and dependency links, returning versions in priority order: local files, find links, page URLs, and dependency links.
10699	Finds an installation candidate for a given requirement, considering version specifiers, existing installations, and upgrade flags. Returns an InstallationCandidate or None, and may raise DistributionNotFound or BestVersionAlreadyInstalled exceptions.
10700	Returns elements of links in order, non-egg links first followed by egg links, while eliminating duplicates.
10701	Get the Content-Type header from a URL using a HEAD request, returning an empty string for non-HTTP schemes or when the header is missing.
10702	Returns a generator that yields Link objects for all anchors with href attributes found in the parsed HTML page. Each link is constructed using the base URL and cleaned using urljoin, with internal link determination based on the 'rel' attribute when API version is 2 or higher.
10703	Returns True if this link can be verified after download, False if it cannot, and None if we cannot determine. A link is verifiable if it comes from a trusted source and has a hash, or if it comes from a trusted source using API version 2 without a hash (not verifiable). Links from untrusted sources are not verifiable.
10704	Return filenames for package's data files in 'src_dir' by collecting files matching glob patterns from package_data and manifest_files, then excluding files according to exclude_data_files.
10705	Filters filenames for package data files in 'src_dir' by excluding patterns defined in exclude_package_data, removing duplicates and returning the remaining files.
10706	Parses a requirements file and yields InstallRequirement instances for each requirement found in the file. Takes parameters for file location, package finder, session, and other optional settings. Processes each line of the file to extract and yield individual package requirements.
10707	Joins lines that are continued on the next line with a backslash ('\') character.
10708	Strips and filters empty or commented lines from an iterator, returning only non-empty lines without comments.
10709	Returns a compiled marker function that evaluates whether an environment satisfies the marker conditions. The function accepts an environment dictionary and optional override values, using caching to avoid recompilation of identical markers. If the marker is empty, it returns True always. Otherwise, it parses, compiles, and evaluates the marker against the environment.
10710	Summary: This method validates that AST nodes in environment markers are allowed by checking if the node type is in the ALLOWED collection. If not allowed, it raises a SyntaxError with a caret pointing to the invalid node's position. Otherwise, it continues with normal AST node transformation.
10711	Flattens one level of attribute access by converting `obj.attr` into a string representation `"obj.attr"` while preserving the original node's location metadata.
10712	The `coerce` function attempts to convert a given value to a numeric type (float or int) by first trying to parse it as JSON. If successful and the parsed result is a number, it returns the numeric value. Otherwise, it returns the original value unchanged. The function handles exceptions gracefully and uses JSON parsing to detect valid numeric representations.
10713	A decorator that captures and preserves the current request context for use in greenlets. When applied to a function, it creates a copy of the current request context and pushes it when the decorated function is called, allowing the function to access Flask's request context variables even when executed in a separate greenlet. Raises a RuntimeError if used outside of a request context.
10714	Binds the application context to the current context, increments the reference counter, pushes the context onto the stack, and sends an appcontext_pushed signal.
10715	Pops the application context from the stack, decrements the reference counter, and calls teardown handlers if the context is fully removed. Sends a signal after popping.
10716	Creates a copy of this request context with the same request object, useful for moving request contexts between greenlets. Returns a new instance of the same class with the same app, environ, and request.
10717	Method `match_request` attempts to match the current request URL against registered URL rules using the URL adapter. It retrieves the matching rule and view arguments, storing them in the request object. If no match is found, it catches the HTTPException and stores the routing exception in the request object for further handling.
10718	Binds the request context to the current context, ensuring proper application context management and session handling.
10719	Make a filename relative to another path by finding their common directory and creating appropriate parent directory references.
10720	Returns True if the given distribution is installed in editable mode, False otherwise. Checks the distribution's editable status by creating a FrozenRequirement object and examining its editable attribute.
10721	Registers a function as URL value preprocessor for this blueprint. The function is called before view functions and can modify the URL values provided. Returns the original function.
10722	Adds a default value function for URL generation in this blueprint, updating URL default functions in the application's registry.
10723	Registers an error handler for this blueprint only, similar to Flask's errorhandler decorator but scoped to the blueprint. The handler applies to error codes or exceptions within the blueprint's scope, with special handling for 404 and 500 errors.
10724	# Summary: `stream_with_context` Function

The `stream_with_context` function is a Flask utility that preserves request context when using streamed responses. Due to efficiency reasons, request contexts are typically lost when response streaming begins, which can cause issues with generators that need access to request-bound information.

## Key Features:
- **Context Preservation**: Keeps the request context active throughout the streamed response generation
- **Decorator Support**: Can be used as a decorator or applied directly to generators
- **WSGI Compatibility**: Handles both generator functions and WSGI-level iterators
- **Memory Safety**: Includes cleanup logic to prevent memory leaks

## Usage Patterns:
1. **As Decorator**: `@stream_with_context` applied directly to generator functions
2. **As Function**: `stream_with_context(generate())` wrapped around specific generators

## Important Notes:
- Requires an active request context; raises RuntimeError if none exists
- Automatically handles cleanup of generators with close methods
- Works with both synchronous generators and WSGI iterators
- Added in Flask version 0.9

The function ensures that streamed responses can access request data (like `request.args`) even when the response is being generated incrementally, making it essential for dynamic streaming scenarios.
10725	Creates a Flask response object from view function return values, allowing addition of headers. It handles different argument cases: no arguments (creates empty response), one argument (passes to Flask's make_response), or multiple arguments (passes as tuple to Flask's make_response). Useful for view decorators and when headers need to be added to response objects.
10726	Generates a URL for a given endpoint with optional parameters. Supports query arguments, external URLs, anchors, and HTTP methods. Handles blueprint shortcuts and raises BuildError for invalid endpoints. Can be customized with a build error handler.
10727	Safely joins a directory path and filename while preventing directory traversal attacks. Normalizes the filename path, checks for invalid separators and absolute paths, and raises NotFound exception if the resulting path would fall outside the specified directory. Returns the joined path if validation passes.
10728	Returns the absolute path to a package or module, or the current working directory if neither can be found. First checks if the module is already imported, then attempts to use a loader, falling back to importing the module if necessary. The path returned corresponds to the directory containing the module or package file.
10729	Returns the Jinja loader for this package bound object, using FileSystemLoader with the joined root_path and template_folder if template_folder is not None.
10730	This method prints shell completion code for a specified shell. It checks if the provided shell option is valid, retrieves the corresponding completion script, and prints it formatted with base completion template. If the shell is invalid, it writes an error message listing valid shell options to stderr.
10731	Returns the appropriate cookie domain for session cookies based on app configuration, falling back to SERVER_NAME if SESSION_COOKIE_DOMAIN is not set, with special handling for .localhost and subpath scenarios.
10732	Return a directory to store cached wheels for a given link, using a hashed key based on the link's URL and hash to ensure unique caching.
10733	Return True if the extracted wheel in wheeldir should go into purelib by checking for "root-is-purelib: true" in the WHEEL file.
10734	Yields all uninstallation paths for a distribution by reading its RECORD metadata file, including both regular files and their corresponding .pyc files for Python source files.
10735	Checks wheel version compatibility and raises errors/warnings for incompatible versions. Raises `UnsupportedWheel` if wheel version is major version ahead of pip's compatible version, otherwise issues a warning for minor version ahead.
10736	Builds a single wheel file from a requirement and moves it to the specified output directory. Returns the path to the built wheel file or None if the build fails. Uses a temporary directory for the build process which is cleaned up afterward.
10737	The `iter_symbols` function is a generator that traverses a code object and its nested code objects to yield all symbol names and string constants. It works by:

1. Iterating through `code.co_names` to yield all variable names and attribute names used in the code
2. Iterating through `code.co_consts` to yield:
   - String constants directly
   - Recursively traversing nested code objects (when `const` is of type `CodeType`) to yield their symbols

The function handles nested code objects by recursively calling itself on embedded code objects, making it capable of extracting symbols from complex nested structures like nested functions or classes. This is useful for code analysis, static analysis tools, or dependency tracking in Python bytecode.
10738	Decorator for Backend that ensures rates are fresh within last 5 minutes by checking if the last update time is older than 5 minutes and refreshing if necessary before executing the decorated function.
10739	Adds egg-info file paths from an external egg-base directory to the manifest, prefixing paths with egg_base to ensure proper inclusion during the build process.
10740	Writes a pip delete marker file to the specified directory with a delete marker message.
10741	Return True if running inside a virtualenv, False otherwise by checking for sys.real_prefix or different sys.prefix and sys.base_prefix.
10742	Returns the effective username of the current process, using different methods for Windows and Unix-like systems.
10743	Return a distutils install scheme with optional user, home, and root directories, handling isolated installations and virtual environment paths.
10744	Parse cache control headers and return a dictionary with directive values.
10745	Return a cached response if it exists in the cache and is fresh enough, otherwise return False. Handles cache control headers, freshness calculation, and validates cached responses based on HTTP caching rules.
10746	Caches HTTP responses based on cache-control headers and response status codes. Returns early for non-cacheable status codes (206, and others). Handles etag-based caching, 301 redirects, and max-age/expires header logic. Removes cached entries when no-store directive is present.
10747	Updates the zipimporter cache for a given normalized path by processing all sub-path entries and optionally replacing cache entries based on an updater function.
10748	Loads a template script from the setuptools package, with an option to load a development version, and returns it as a UTF-8 decoded string.
10749	Make sure there's a site.py in the target directory, creating or updating it if needed. If a site.py already exists and is not a setuptools-generated file, raise an error. Otherwise, write the setuptools site.py patch to the target directory.
10750	Save changes to a .pth file on disk, writing relative paths and handling file creation/deletion appropriately.
10751	Convert values to appropriate types by replacing dicts, lists, and tuples with their converting alternatives, and converting strings based on conversion format patterns.
10752	Adds filters to a filterer by iterating through a list of filter names and attempting to add each filter from the configuration. Raises a ValueError with details if any filter fails to be added.
10753	Configure a logging handler from a dictionary configuration, handling formatters, levels, filters, and special cases for memory, SMTP, and syslog handlers.
10754	Add handlers to a logger from a list of handler names, raising a ValueError if any handler cannot be added.
10755	Configures a logger with common settings shared by root and non-root loggers, including level setting, handler management, and filter configuration.
10756	Executes a Python script file by reading it, compiling it with proper line ending handling for different Python versions, and executing the compiled code within the specified global and local namespaces.
10757	Summary: A context manager that temporarily overrides the system's temporary directory path with a specified replacement path, ensuring the replacement directory exists and restoring the original path upon completion.
10758	Method that processes Git repository URLs by prefixing stub URLs with 'ssh://' for proper parsing, then removes the prefix from the returned URL. Handles both SSH-based URLs and regular URLs, ensuring correct URL formatting for Git operations while preserving the original URL structure.
10759	Get an item or attribute of an object, preferring item access over attribute access. If both fail, return an undefined object.
10760	Internal hook method that can be overridden to customize the generation process, calling the external `generate` function with the provided parameters.
10761	Compiles all templates found by the loader and stores them in a target directory or zipfile. Supports optional error handling, logging, and Python bytecode compilation. Templates are compiled using the loader's source and filename, with options for deflate or stored zip algorithms. If py_compile is True, .pyc files are written instead of .py files. Errors during compilation are logged by default but can be made fatal by setting ignore_errors to False.
10762	**Summary:**

The `get_default_cache()` function determines the default cache location for Python eggs. It first checks the `PYTHON_EGG_CACHE` environment variable. If not set, it uses platform-specific default locations: on Windows, it looks for an "Application Data" directory and returns a "Python-Eggs" subdirectory; on other systems, it returns "~/.python-eggs". The function includes multiple fallback strategies for finding the appropriate application data directory on Windows and raises a RuntimeError if no suitable location can be determined.
10763	Find eggs in zip files; possibly multiple nested eggs. Returns distributions from PKG-INFO metadata and recursively finds nested eggs in zip archives, excluding wheel files which don't support this finder.
10764	Function that yields distributions accessible on a sys.path directory by scanning for .egg, .egg-info, and .dist-info files and directories, handling different file types and locations including unpacked eggs, egg-info directories, and egg-link files.
10765	Declares that a given package is a namespace package by updating namespace package tracking and handling path items appropriately.
10766	Returns the method resolution order (MRO) for a given class, handling both new-style classes (with `type`) and classic classes by temporarily creating a new class that inherits from both the original class and `object`.
10767	Return an adapter factory for object `ob` from the given `registry` by searching through the object's method resolution order (MRO) for a matching type.
10768	Ensure that the parent directory of `path` exists by creating it if it doesn't already exist.
10769	Yields entry point objects from a specified group, optionally filtered by name, across all distributions in the working set. If no name is specified, all entry points in the group are yielded; otherwise, only entry points matching both the group and name are yielded in distribution order.
10770	Returns whether a distribution is acceptable for this environment based on platform and Python version compatibility requirements.
10771	Find distribution best matching `req` and usable on `working_set`. Calls `working_set.find(req)` to check if suitable distribution is already active. If not found, returns newest distribution in environment that meets `Requirement` in `req`. If no suitable distribution is found and `installer` is supplied, calls `self.obtain(req, installer)` to download/install.
10772	Evaluates a PEP 426 environment marker on CPython 2.4+, returning a boolean result. Raises SyntaxError for invalid markers. Uses the 'parser' module for implementation, which is not available in Jython and has been superseded by 'ast' in Python 2.6+.
10773	Evaluate a PEP 426 environment marker using markerlib and return a boolean result. Raises SyntaxError for invalid markers. Translates Metadata 1.2 environment marker variables to Metadata 2.0 format before evaluation.
10774	Formats log record with indentation based on current indentation level.
10775	Return formatted currency value according to the specified currency, locale, and formatting options.

This function formats a numeric value as a currency string, taking into account:
- Currency code and its natural decimal places
- Locale-specific formatting rules (thousands separators, decimal separators, symbol placement)
- Optional custom format patterns
- Format type (standard, accounting, etc.)
- Decimal quantization behavior

The function handles various scenarios including:
- Default locale-based formatting
- Custom format string specification
- Currency-specific decimal digit handling
- Format type selection
- High-precision number quantization control

Example usage:
- format_currency(1099.98, 'USD', locale='en_US') returns '$1,099.98'
- format_currency(1099.98, 'EUR', locale='de_DE') returns '1.099,98'
- format_currency(1099.98, 'JPY', locale='en_US') returns '1,100' (rounded to currency's natural precision)

Parameters:
- number: the numeric value to format
- currency: the 3-letter currency code
- format: optional custom format pattern
- locale: locale identifier or Locale object
- currency_digits: whether to use currency's natural decimal digits
- format_type: type of currency format to use
- decimal_quantization: whether to truncate/round high-precision numbers

Returns formatted currency string respecting all specified parameters and locale conventions.
10776	Parse a number format pattern into its components including positive/negative prefixes/suffixes, integer/fraction precision, grouping, and exponent information.
10777	Return the minimal quantum of a number defined by the given precision, which is 10 raised to the power of negative precision.
10778	Return the maximum precision of a decimal instance's fractional part by extracting the absolute value of the exponent from its normalized tuple representation.
10779	Returns normalized scientific notation components (value, exponent, exponent sign) of a given decimal value with locale-specific formatting.
10780	This function converts a timedelta object to total seconds, providing Python 2.6 compatibility. It first checks if the timedelta object has a `total_seconds()` method (available in Python 2.7+), and if so, uses it. Otherwise, it manually calculates the total seconds using the microseconds and seconds components of the timedelta object.
10781	Parse a string or iterable of strings into Requirement objects, handling version specifications and extras.
10782	Returns the original distutils class by traversing base classes to avoid re-patching, raises AssertionError if distutils has already been patched by another extension.
10783	Verifies that the `install_requires` parameter contains valid requirements specifiers. Raises `DistutilsSetupError` if the value is not a string or list of strings with valid project/version requirement specifiers.
10784	Fetches an egg dependency needed for building by either using an existing egg fetcher command or creating a new one with easy_install, then installs the requested package.
10785	Roll n-sided dice and return each result and the total
```
10786	Converts string prices to Price objects, leaving non-string objects unchanged.
10787	**Summary:**

The `price` function is a factory function that creates an `attr.ib` field specifically designed for price-related attributes. It sets default values and converters, and ensures the field contains a `PriceClass` instance through validation.

**Key Features:**
- Sets default value to 'USD 0.00' if not provided
- Uses `price_converter` as the converter function
- Validates that the field contains an instance of `PriceClass`
- Accepts additional arguments and keyword arguments for `attr.ib`
- Supports custom validators through the `validator` parameter

**Usage Example:**
```python
@attr.s
class Test:
    price: Price = fields.price(default='USD 5.00')
```

This function simplifies creating price fields in attrs-based classes with proper default values, conversion, and type validation.
10788	Validates a JSON-RPC request by checking its version, method, parameters, and ID. Raises an invalid_request error if any validation fails.
10789	Get request method for service application, raises method_not_found if method key is not found in app dictionary.
10790	Apply application method with error handling, executing method with parameters from args dictionary.
10791	Returns the name of the current module if the request was dispatched to an actual module. This functionality is deprecated - use blueprints instead. Issues a deprecation warning and returns the blueprint name if the request was to an old module.
10792	Returns the name of the current blueprint by extracting the part before the last dot in the URL rule endpoint.
10793	Attaches an enctype error multidict to a request object by monkeypatching the files object to raise a DebugFilesKeyError when a key is not found in form data but exists in files.
10794	Factory function that creates an abstract distribution object based on the type of requirement:

- For editable requirements: returns an IsSDist object
- For wheel links: returns an IsWheel object  
- For non-editable requirements with source directory: returns an IsSDist object

Returns a concrete DistAbstraction instance based on the requirement type.
10795	Add a requirement to the installation set, handling markers, duplicates, and dependencies. Returns additional requirements to scan or empty list if requirement is not applicable.
10796	Walks through all pending requirements and calls a handler for each one, potentially discovering additional requirements along the way.
10797	Check if a requirement should be skipped based on whether it's already installed and user options. Returns a skip reason or None.
10798	Create installation order using topological sorting, installing dependencies before requiring packages while preserving user-specified order where possible.
10799	Return sorted list of all package namespaces by iterating through namespace packages and adding all parent namespaces.
10800	Convert QuerySet objects to their list counterparts by serializing Django model instances to dictionaries and QuerySet objects to JSON format, falling back to the parent encoder for other types.
10801	Tokenize a document and add an annotation attribute to each token.
10802	Merge annotations from old tokens to new tokens based on matching sequences, copying annotations only for equal token sequences.
10803	Copy annotations from source tokens to destination tokens, ensuring both lists have equal length and transferring each source token's annotation to the corresponding destination token.
10804	Combine adjacent tokens with shared annotations when no HTML tags exist between them, merging them using `compress_merge_back` while preserving tokens that have HTML tags or different annotations.
10805	Serializes a list of tokens into text chunks with annotations by applying a markup function to each token's HTML content, including handling pre-tags, post-tags, and trailing whitespace.
10806	Generator that yields text chunks from tokens, including pre-tags, token HTML content (with trailing whitespace if present), and post-tags, optionally skipping tokens with hide_when_equal flag when equal=True.
10807	The `locate_unbalanced_end` function handles end tags in HTML/XML document processing, similar to `locate_unbalanced_start` but for closing tags. It works by:

1. Iterating through unbalanced end tags (from outer to inner)
2. For each unbalanced end tag, it finds the corresponding closing tag in `pre_delete` (which contains tags in reverse order)
3. If a matching closing tag is found, it removes both from their respective lists and adds the closing tag to `post_delete`
4. If an unmatched tag is found, it breaks the loop
5. It can't move into `ins` or `del` tags when searching
6. It continues until all unbalanced end tags are processed or no more matching tags can be found

The function moves the processing point earlier in the document by removing matched tags from `pre_delete` and adding them to `post_delete`.
10808	This function processes a list of text chunks (tokens, tags, etc.) and converts them into a list of properly formatted tokens with appropriate pre-tags and post-tags. It handles different chunk types including image tags, hyperlinks, regular words, and HTML tags, maintaining proper formatting and structural information throughout the processing.
10809	Generates text chunks from an lxml element including start tags, words, and end tags. Returns HTML escape sequences for text content and optionally yields href values for anchor tags. If skip_tag is True, only yields content without the outermost container tag.
10810	Splits text into words, including trailing whitespace, using a regular expression pattern. Returns an empty list for empty or whitespace-only input.
10811	Returns the text representation of the start tag for an XML/HTML element, including the tag name and all attributes with proper HTML escaping.
10812	Returns the text representation of an end tag for a given element, including trailing whitespace when the element's tail content starts with whitespace.
10813	Serializes an lxml element as HTML string, optionally skipping the outermost tag. Returns the HTML representation including element tails, with optional removal of the outer tag when skip_outer=True.
10814	Function that fixes ins/del tags in an lxml document by moving non-block-level content inside block elements and removing the tags.
10815	Extracts the constant value of a symbol from Python code. Returns the constant if symbol is bound to one, returns default if symbol is bound to an expression, and returns None if symbol is not found. Only considers STORE_NAME and STORE_GLOBAL opcodes for global variables.
10816	Creates a cached URL for the given query parameters by combining operation, service, version, and additional keyword arguments with the appropriate service domain.
10817	Autolink URLs in HTML elements by converting matching text into hyperlinks. The function recursively processes elements, skipping specified elements, classes, and hosts, and transforms text content using provided regex patterns while preserving existing structure.
10818	Removes IE conditional comments from the document that could embed hidden HTML content, by identifying and killing comment elements that match the conditional comment pattern.
10819	Parse a whole document into a string using the specified HTML parser, with optional character encoding guessing.
10820	A decorator that validates API response status codes and ensures JSON response format. It checks if the returned HTTP status code is one of the allowed codes and verifies that the response is a JsonResponse. In debug mode, it returns 400 Bad Request on validation failures, while in production it logs warnings unless explicitly configured otherwise. The decorator allows defining acceptable return codes and their documentation through a dictionary parameter.
10821	Get a TreeWalker class for various types of tree with built-in support.

Supported tree types are: "dom", "pulldom", "etree", "lxml", and "genshi".
The implementation parameter applies to the "etree" tree type only.
Returns the requested TreeWalker class or None if not found.
10822	Exports the SVN repository to the specified destination location, removing any existing directory at that location first.
10823	Return the maximum revision for all files under a given location by walking through directories and checking SVN entries.
10824	Wraps a method to check if it's called after the first request has been handled in debug mode, raising an AssertionError with a helpful message if the condition is met. Used to detect improper usage where setup functions are called too late in the application lifecycle.
10825	Returns the name of the application, usually derived from the import name. When the import name is '__main__', it guesses the name from the main module's filename. This name is used as a display name by Flask and can be overridden.
10826	Returns the value of the `PROPAGATE_EXCEPTIONS` configuration value if set, otherwise returns `True` if either `testing` or `debug` is `True`, `False` otherwise.
10827	Method `auto_find_instance_path` automatically determines the instance path when not provided during application initialization. It locates a folder named 'instance' next to the main file or package. If the package prefix cannot be determined, it returns the instance folder path relative to the package path. Otherwise, it returns a path in the format 'prefix/var/app_name-instance' where app_name is the application name.
10828	Updates the template context with commonly used variables including request, session, config, and g, along with values from template context processors, while ensuring original context values take precedence.
10829	Handles HTTP exceptions by invoking registered error handlers, falling back to returning the exception itself if no handler is found. Returns the exception unchanged if it has no error code.
10830	Method `trap_http_exception` determines whether an HTTP exception should be trapped or allowed to propagate. It returns `True` if either `TRAP_HTTP_EXCEPTIONS` is enabled in the configuration, or if `TRAP_BAD_REQUEST_ERRORS` is enabled and the exception is a `BadRequest`. Otherwise, it returns `False`, allowing the exception to be handled by error handlers. This helps with debugging by letting certain exceptions show up in the traceback instead of being caught by HTTP error handlers.
10831	Handles exceptions that occur during request processing. In debug mode, re-raises exceptions immediately; otherwise logs them and uses the 500 error handler. If no 500 handler exists, returns a default 500 error message. Supports exception propagation based on configuration.
10832	Method that handles routing exceptions during request processing. In non-debug mode or for GET/HEAD/OPTIONS requests, it re-raises the original routing exception. In debug mode, it raises a special FormDataRoutingRedirect exception for redirect requests to aid debugging, while preserving the original exception for other request methods.
10833	Dispatches the request with pre/post-processing and handles exceptions, then processes and returns the response.
10834	Creates a default OPTIONS HTTP response by detecting allowed methods from the URL adapter and setting them in the response's Allow header. Falls back to legacy Werkzeug behavior for older versions and handles various HTTP exceptions during method detection.
10835	Creates a URL adapter for the given request, handling both request-specific and application-level URL binding scenarios.
10836	Injects URL defaults for a given endpoint into the values dictionary. Gets default functions for the endpoint and blueprint, then calls each function to modify the values in place. Used internally during URL building operations.
10837	Yields unique values from an iterable while preserving their original order. Uses a set to track seen values for efficient lookup.
10838	Handle runtime requirements from pkg_info and place them into metadata, organizing packages by conditional requirements and extras.
10839	Converts requirement version specifications into PEP 345 formatted requires_dist string with version predicates wrapped in parentheses.
10840	Converts .egg-info directory with PKG-INFO to Metadata 1.3 format, handling requirements, extras, and description processing.
10841	Return modules that match module_name by iterating through paths, attempting to import each module, and handling exceptions gracefully while temporarily modifying sys.path.
10842	Method `classes` returns an iterator of TestCase classes that match a specified naming pattern. It inspects modules to find classes, applies regex filtering based on `class_name` attribute (supporting wildcard matching with "*"), and yields classes that inherit from `unittest.TestCase` while excluding the base `TestCase` class itself. The matching is case-insensitive.
10843	Returns the actual test methods that match self.method_name by iterating through classes and their methods, applying regex pattern matching based on method_prefix and method_name criteria.
10844	Method `_find_basename` searches for a given name within a list of basenames, checking for matches with optional prefixes and postfixes. It supports glob pattern matching (when name starts with "*") and can operate in prefix mode to match against module prefixes or postfixes. The method returns the first matching basename found, or an empty string if no match is found. The search considers both exact matches and pattern-based matches with test module naming conventions.
10845	Returns True if the given path is a test module path, False otherwise. A path is considered a test module path if its filename (without extension) starts with any of the module prefixes or ends with any of the module postfixes defined in the instance.
10846	Walk all directories under basedir except hidden directories, filtering out system directories if applicable.

The method behaves like `os.walk` but excludes:
- Dot directories (starting with '.')
- Private directories (starting with '_')
- System directories (when a system directory is detected)

It returns a generator yielding tuples of (root, dirs, files) for each directory walk.
10847	Generate test module paths recursively from a base directory, yielding file paths for modules that match specified naming conventions, including support for module prefixes, postfixes, and direct file paths.
10848	Summary: Sets default arguments for JSON dump functions based on the current application configuration, falling back to default values when no app context is available.
10849	Injects default arguments for load functions by setting the JSON decoder class in kwargs based on the current application context.
10850	Sets multiple keys and values from a mapping, returning True if all keys were set successfully.
10851	Increments the value of a key by `delta`, initializing it with `delta` if it doesn't exist. This operation is atomic for supporting caches. Returns the new value or None if there's a backend error.
10852	Dumps an object into a string for redis storage, encoding integers as ASCII strings and pickle serializing all other types with a '!' prefix.
10853	This method extracts query string parameters from an editable URL and returns them as a dictionary. It uses a regular expression to find all key-value pairs in the URL's query string or fragment identifier, then validates that no duplicate parameter names exist. If valid parameters are found, it returns a dictionary mapping parameter names to their values; otherwise, it returns None.
10854	Method `populate_link` attempts to find and set a link for the current object using a finder, but only if no link already exists. If an upgrade is requested or the requirement is not installed, it will search for the appropriate link. The method allows `self.link` to remain `None` when `upgrade=False` and the requirement is already installed.
10855	Ensure that a source_dir is set by creating a temporary build directory if needed. If self.source_dir is None, it calls build_location with the provided parent_dir to set it, then returns the source_dir.
10856	Remove temporary source files and build directories if they exist and are marked for deletion.
10857	Return a pkg_resources.Distribution built from self.egg_info_path by creating PathMetadata from the egg info directory and using it to construct a Distribution object with the appropriate project name.
10858	Reads buffered incoming data from client into one bytestring with optional caching, text decoding, and form data parsing support.
10859	Returns modified WSGI headers for a given environment, ensuring proper location URLs, handling content length automatically, and applying other necessary adjustments based on the response status code.
10860	Converts a unicode-based IRI to an ASCII URI by encoding non-ASCII characters using URL encoding. Handles special cases like international domain names (IDNA) and supports safe conversion mode that avoids conversion when the input is already valid ASCII. Returns the converted URI as a native string.
10861	Returns the full path to the user-specific cache directory for an application, with platform-specific default locations:
- macOS: `~/Library/Caches/<AppName>`
- Linux: `~/.cache/<AppName>` (XDG default)
- Windows: `C:\Users\<username>\AppData\Local\<AppName>\Cache`

The function constructs the path by appending the application name and "Cache" directory to the appropriate platform-specific base directory.
10862	Returns the full path to the user-specific data directory for an application, with platform-specific paths for Windows, macOS, and Unix-like systems.
10863	Returns the full path to the user-specific log directory for an application, with platform-specific paths:
- Mac OS X: ~/Library/Logs/<AppName>
- Unix: ~/.cache/<AppName>/log
- Windows: <user_data_dir>/<AppName>/Logs
10864	Return full path to the user-specific config directory for an application, handling different platforms according to their conventions (Windows and macOS use user_data_dir, Unix follows XDG spec with $XDG_CONFIG_HOME or defaults to ~/.config/<AppName>).
10865	Return a list of potential user-shared config dirs for this application based on the operating system platform. For Windows, returns the Common Application Data directory path. For Mac OS X, returns the Application Support directory path. For Unix-like systems, returns paths from $XDG_CONFIG_DIRS environment variable plus the default '/etc' directory.
10866	This function iterates over all loaded Python modules and yields the file paths of relevant Python files. It handles edge cases where module files might not exist or be in unusual locations by traversing up the directory structure until a valid file is found. The function specifically looks for .pyc and .pyo files and converts them to their .py counterparts before yielding the filename.
10867	Spawn a new Python interpreter with the same arguments to restart the application with reloader thread, handling environment variables and Windows Unicode issues, returning the exit code if restart is not triggered.
10868	Converts input to text type, handling None values by returning empty string (or None if blank_if_none=False).
10869	Return an existing CA bundle path, or None by checking Windows certificate file, common certificate paths, and finally certifi package resources.
10870	Parses HTML content from a string or file-like object into a tree structure using the specified tree builder and encoding options.
10871	Parse a HTML document into a well-formed tree and return the document object.
10872	Parse a HTML fragment into a well-formed tree fragment using the specified container element and return the resulting fragment.
10873	Method: translate
Parameters: self, word
Returns: A sorted list of tuples containing non-zero transmission matches for the given word, sorted in descending order by value
Raises: NoMatchError if the word is not found in self.transmissions
Description: Looks up a word in the transmissions dictionary and returns all non-zero transmission matches sorted by their values in descending order
10874	Converts input data file into tokens and token dictionary. Reads lines from file, strips whitespace, splits lines into tokens, removes duplicates, and returns both the original lines list and the unique token list.
10875	Bind and activate HTTP server by initializing HTTPServer with host, port, and HTTPRequestHandler, then update port with actual server port.
10876	Method `report` outputs startup information to stdout using a formatted message template with service, host, and port details.
10877	Loads bytecode from a file or file-like object by verifying the magic header and checksum, then marshals the code. If verification fails, resets the instance.
10878	Returns a copy of paramsDict updated with kwargsDict entries, wrapped as stylesheet arguments, ignoring any None values in kwargsDict.
10879	Run a VCS subcommand by wrapping call_subprocess, adding the VCS command name to the command list, checking if the VCS is available, and handling cases where the VCS executable is not found.
10880	Return the Python implementation version by first trying to get it from sysconfig, and falling back to constructing it from sys.version_info if the first attempt fails.
10881	Returns a list of egg or source distribution objects based on the given basename and location. Handles various file extensions including .egg, .egg.zip, .exe, .zip, .tgz, etc., and uses appropriate parsing functions to interpret the distribution names. Returns an empty list if no matching extensions are found.
10882	Find rel="homepage" and rel="download" links in a webpage, yielding the complete URLs by parsing HTML tags and extracting href attributes.
10883	Function `local_open(url)` reads local files or directories, returning either a URL opener for files or an HTTP error for non-existent paths. If the path is a directory, it lists its contents with links, showing `index.html` if present or generating a directory listing otherwise.
10884	Process a URL for potential downloading and parsing. If the URL has already been scanned or retrieval is not requested, return early. Handle URLs without schemes as filenames. For URLs with schemes, check if they contain downloadable distributions. If so, add them to the list. If the URL is not already fetched, attempt to fetch and parse the HTML content, extracting links to process recursively. If the URL is an index page, process it accordingly.
10885	Remove duplicate entries from sys.path and convert them to absolute paths, filtering out duplicates including case-insensitive file systems.
10886	Returns a set containing all existing directory entries from sys.path, with each directory path converted to a canonical case-insensitive form.
10887	Adds a new path to known_paths by combining sitedir and name, or executes sitedir if it starts with 'import'. Reads a file at the combined path, processes its lines (skipping comments and handling imports), and adds valid directory paths to sys.path and known_paths. Returns the updated known_paths.
10888	Add a site directory to sys.path and process .pth files in that directory. If the directory is not already in sys.path, it will be added. The function also handles Python package files (with .pth extension) in the specified directory by calling addpackage() for each one. Returns the updated known_paths dictionary.
10889	Check if user site directory is safe for inclusion by verifying command line flags, environment variables, and process permissions. Returns None if disabled for security reasons, False if disabled by user, True if safe and enabled.
10890	Add a per user site-package to sys.path by determining the appropriate user site-packages directory based on the operating system and environment variables, then adding it to the Python path if it exists.
10891	Summary: The `setquit()` function defines new built-in `quit` and `exit` objects that display helpful exit instructions. It determines the appropriate EOF key combination based on the operating system separator (`os.sep`) and creates a `Quitter` class that provides descriptive output when called or repr'ed, along with proper system exit functionality.
10892	On Windows systems, this function aliases locale-specific codepage encodings (like "cp1252") to "mbcs" when they're not natively supported by Python. It checks if the current platform is Windows, gets the default locale encoding, and if it starts with "cp" (indicating a codepage), it attempts to look up the encoding. If the lookup fails, it adds an alias from the unknown encoding to "mbcs" in Python's encoding cache and aliases, making these encodings available for use.
10893	Sets the string encoding used by the Unicode implementation, with 'ascii' as default. Supports optional locale-aware encoding and can switch off string to Unicode coercion, but only works in Unicode builds.
10894	Force easy_installed eggs in the global environment to be placed in sys.path after virtualenv packages, ensuring virtualenv packages always mask global packages for least surprise behavior.
10895	Adjusts the classpath entries in sys.path for Jython to follow the base virtualenv lib directories.
10896	Open a subprocess without blocking. Return a process handle with output streams replaced by queues of lines from that stream. Uses threading to capture output asynchronously.
10897	Return True if Cython or Pyrex can be imported.
10898	Convert .pyx source files to target language extensions (.c or .cpp) when Cython is not available, allowing pre-converted sources to be used while preferring .pyx files when Cython is present.
10899	Debugs an application by running it and preserving traceback frames for error reporting. If an exception occurs, it captures the traceback, stores frame information, and renders a full error page with debugging information. Handles cases where response headers may have already been sent.
10900	Return a static resource from the shared folder by constructing the file path, checking if the file exists, determining its MIME type, reading the file content, and returning it as a response with appropriate MIME type, or returning a 404 Not Found response if the file doesn't exist.
10901	Return a string representing the user agent with details about pip version, Python version, implementation, and system information.
10902	Returns True if the input string looks like a URL by checking if it contains a colon and has a valid scheme (http, https, file, ftp, or any VCS scheme).
10903	Unpacks a file from a given link to a specified location. If the link points to a local directory, it copies the directory recursively. If the link contains a hash, it verifies the file hash. When a download directory is provided, it checks if the file is already downloaded and valid; if not, it downloads and copies the file to the download directory. The file is then unpacked to the build directory location regardless of whether it was downloaded or not.
10904	Download a file from a URL into a temporary directory using a provided session, handling content type and filename detection from HTTP headers.
10905	Check if a file already exists in the download directory with the correct hash. If it does, return its path; otherwise, return None. If the file exists but has an incorrect hash, remove it and return None.
10906	Handles currency formatting subdirectives by registering currency information through context action.
10907	Handles exchange subdirectives by registering an exchange action with the given parameters.
10908	Decodes the input data using the stored decoder if content decoding is enabled, handles decoding errors by raising a DecodeError with the content-encoding information, and optionally flushes the decoder to process any remaining data.
10909	Default template context processor that injects request, session, and g objects into the template context.
10910	Renders a template with the given context and fires a template_rendered signal.
10911	Renders a template from the template folder with the given context, handling either a single template name or a list of template names where the first existing one will be rendered.
10912	Renders a template from a given source string using the application's Jinja environment and provided context variables.
10913	Returns a version parser object that can parse version strings, prioritizing pkg_resources.parse_version and falling back to distutils.version.LooseVersion if pkg_resources is not available.
10914	Check if a name is declared in this or an outer scope by verifying its presence in locally declared names, parameter names, or overall declared names.
10915	This method handles name node visits during AST traversal, tracking identifier declarations and usage. It adds names to different sets based on their context: 
- 'store' context (assignments) are added to declared_locally
- 'param' context (function parameters) are added to declared_parameter  
- 'load' context (usages) that aren't previously declared are added to undeclared

This implements basic static analysis for identifier scoping and undeclared variable detection.
10916	Handles template inclusion by generating code to fetch and render templates, with support for context handling and missing template suppression.
10917	Visits named imports by getting a template from the environment, creating a module from it, and handling variable assignments and exports within the given frame. It processes import aliases, handles missing names with undefined values, and updates context variables and exported variables accordingly.
10918	Creates a .whl file archive from files in base_dir, placing .dist-info files at the end of the archive. Returns the name of the created wheel file.
10919	Decorates a function with a reentrant lock to prevent simultaneous execution from multiple threads.
10920	Create a service factory that instantiates a service and starts a server using the provided parameters, then serves it forever.
10921	URL escapes a string or object for URL safety, handling both unicode and byte strings with specified charset encoding.
10922	**Function:** `matches_requirement(req, wheels)`

**Summary:** 
Returns a list of wheels that satisfy a given requirement by matching the wheel's package name and version against the requirement. Uses `pkg_resources` to parse requirements and distribution metadata for comparison.

**Parameters:**
- `req`: A string representing the requirement to satisfy
- `wheels`: A list of wheel objects to search through

**Returns:**
- List of wheel objects that match the requirement

**Dependencies:**
- `pkg_resources` (imported as `Distribution` and `Requirement`)
- Requires `pkg_resources` to be available in the environment

**Error Handling:**
- Raises `RuntimeError` if `pkg_resources` is not available
10923	Populates a requirement set by adding requirements from command line arguments, editable requirements, and requirement files. Raises a warning if no requirements are found.
10924	Exports the Bazaar repository to a destination location by temporarily unpacking it and using the bzr export command.
10925	Lookup an Amazon product by ASIN(s) and return either a single AmazonProduct instance or a list of AmazonProduct instances. Raises LookupException if the lookup fails due to invalid request, or AsinNotFound if the ASIN(s) are not found. Uses the ItemLookup operation from the Amazon API with the specified ResponseGroup and additional keyword arguments.
10926	**Summary:** A generator method that iterates through Amazon search result pages, yielding lxml root elements for each page. It automatically stops when NoMorePages exception is raised, typically when Amazon limits the number of available pages.
10927	Returns the immediate ancestor browse node in the browse node tree, or None if no ancestor exists.
10928	Returns a list of child browse nodes in the browse node tree by extracting Children data from the element and creating AmazonBrowseNode objects for each child.
10929	**Method Summary:**

`_safe_get_element` safely retrieves a nested child element from an lxml element structure using a dot-separated path. It navigates through multiple levels of child elements, returning `None` immediately if any intermediate element in the path doesn't exist, preventing AttributeError exceptions. The method accepts an optional root element (defaults to `self.item` if not provided) and a path string, returning the final element if found or `None` if the path is invalid anywhere along the way.

**Parameters:**
- `path` (str): Dot-separated path string (e.g., 'Items.Item.Offers.Offer')
- `root` (lxml element, optional): Starting element; defaults to `self.item`

**Returns:**
- lxml element or None: The final element if found, otherwise None

**Behavior:**
- Splits path by '.' and traverses levels sequentially
- Returns None if any intermediate element is missing
- Safely handles missing elements without raising exceptions
10930	Safe get element text.

Get element as string or None,
:param root:
    Lxml element.
:param path:
    String path (i.e. 'Items.Item.Offers.Offer').
:return:
    String or None.
10931	Returns element date from XML path as datetime.date or None. Safely parses date string in 'YYYY-MM-DD' format, returns None if parsing fails or element is not found.
10932	Get offer price and currency by checking sale price, regular price, and lowest new price in that order, returning a tuple of (price as float, currency code) or (None, None) if no price is available.
10933	Returns the list price as a tuple of (price float, currency code string) by extracting from ItemAttributes.ListPrice.Amount and ItemAttributes.ListPrice.CurrencyCode elements, with price converted from cents to dollars. Returns (None, None) if no price is available.
10934	Send a request using the cache control adapter, checking for cached responses and conditional headers, then delegate to the parent class implementation.
10935	Builds a response by making a request or using cache, handling 304 Not Modified responses by updating cached content, caching 301 responses, applying heuristics to other responses, and managing cache invalidation for invalidating HTTP methods.
10936	Returns a callable that looks up the given attribute from a passed object with the rules of the environment, supporting dot notation for nested attribute access and integer indexing.
10937	Return a titlecased version of the string where words start with uppercase letters and all remaining characters are lowercase.
10938	Sort an iterable in ascending order by default, or descending if reverse=True. Optionally control case sensitivity for string comparisons (case_sensitive parameter) and sort by a specific attribute of the items (attribute parameter). Uses Python's built-in sorted() function with a custom key function that handles case conversion and attribute extraction. The attribute parameter was added in version 2.6.
10939	Groups a sequence of objects by a specified attribute, returning tuples of (grouper, list) where grouper is the common attribute value and list contains all objects with that attribute value. Supports dotted notation for nested attribute access.
10940	Applies a filter on a sequence of objects or looks up an attribute, useful for extracting specific values from lists of objects. Can map on attributes or invoke filters on sequences.
10941	Creates a custom logger for an application that adjusts its effective logging level based on the application's debug flag, removes any existing handlers, and configures a debug handler that only emits records when debug mode is enabled.
10942	Returns True if two strings are equal, False otherwise, with constant-time comparison to prevent timing attacks. Uses C implementation if available, otherwise implements constant-time comparison using XOR operations on byte arrays.
10943	Verifies that the provided signature matches the expected signature by comparing it with a generated signature using constant-time comparison for security.
10944	This method derives a key using different key derivation methods based on the configuration. It supports four methods: 'concat' (concatenates salt and secret key), 'django-concat' (adds 'signer' prefix), 'hmac' (uses HMAC with the secret key), and 'none' (returns the secret key directly). If an unknown method is specified, it raises a TypeError. The method is intended for internal use in key derivation processes and recommends using large random secret keys rather than deriving them from short passwords.
10945	Returns the base64-encoded signature for the given value by deriving a key and applying the algorithm's signature method.
10946	Function `sign` takes a value as input and returns the value concatenated with a separator and its signature. The separator is converted to bytes using `want_bytes` function, and the signature is obtained by calling `self.get_signature` method with the value as argument.
10947	Verifies the signature for a given value using a derived key and the specified algorithm, returning True if valid or False if invalid or if decoding fails.
10948	Unsigns a given string by splitting it at the separator, verifying the signature against the value, and returning the original value if the signature is valid. Raises BadSignature if the separator is not found or if the signature doesn't match.
10949	Signs the given string by attaching timestamp information and a signature, returning the combined result.
10950	Validates a signed value by checking if its signature is valid. Returns True if the signature exists and is valid, False otherwise.
10951	Returns a signed string serialized with the internal serializer, with the return value being either bytes or unicode string depending on the serializer format.
10952	Creates a JSON-RPC server error response with the specified request ID and error details, then raises a ServiceException with HTTP 500 status and the serialized response.
10953	Return a list of all Python packages found within a directory, with options to include or exclude specific packages using wildcard patterns.
10954	Exclude packages that don't include their parents, e.g., exclude 'foo.bar' if 'foo' is not present.
10955	Return all directories in base_path, relative to base_path.
10956	Verify Vary headers match and construct a urllib3 HTTPResponse object from cached response, handling special case of '*' Vary value and potential Python 2/3 compatibility issues with body data.
10957	Remove RECORD.jws from a wheel by truncating the zip file, ensuring it's at the end of the archive and the zip is an ordinary archive with compressed files and directory in the same order.
10958	Unpacks a wheel file to a specified destination directory. The wheel content is extracted to a subdirectory named {name}-{ver} where {name} is the package name and {ver} is the version. Returns the destination path where the wheel was unpacked.
10959	Regenerate entry_points console_scripts for the specified distributions using setuptools and pkg_resources, with error handling for missing setuptools dependency.
10960	Sets the _draw_ and _ldraw_ attributes for each graph sub-element by processing the xdot format of the graph through parsing and building the graph structure.
10961	Redraws the canvas by parsing Xdot attributes from all graph components (nodes and edges) and adding them to a new canvas.
10962	Returns a node given an ID or None if no such node exists. First checks the parent graph's nodes, then searches through all graphs in the collection.
10963	Sets the connection string for all edges based on the 'new' parameter, using "->" for True and "--" for False.
10964	Handles graph edge list changes by ensuring edge nodes exist in the graph and initializing edge node lists.
10965	Handles component changes by removing the old component from the canvas and adding the new component to the canvas.
10966	Handles left mouse button double-click events in 'normal' state by opening a Traits UI view on the component's element trait, setting the current tool as active during the view duration.
10967	Handles diagram canvas changes by adding tools to the canvas. When the diagram canvas is set, it iterates through all tools and appends each tool (instantiated with the canvas) to the canvas tools list, printing a message for each tool added.
10968	Clears all components from the diagram canvas by creating a new canvas with the same background color and axis drawing properties, then updates the viewport and requests a redraw.
10969	Handles domain model changes for a diagram by unmapping the old model and mapping the new model when they are not None.
10970	Maps a domain model to the diagram by creating nodes for contained elements, styling them, and associating them with diagram nodes while adding tools to relevant nodes.
10971	Removes listeners from a domain model by iterating through node mappings and removing trait change listeners from the old model's containment traits.
10972	Handles mapping and unmapping of diagram elements to/from diagram components, including styling, tool attachment, and canvas updates.
10973	Styles a node by setting its shape, fixed size, width, height, color, fill color, and styles based on dot attributes.
10974	Parses xdot data using a predefined parser and returns the parsed components as a result. If no data is provided, it returns an empty list.
10975	Sets the font using the provided size and bold flag from tokens, then returns an empty list.
10976	Returns an Ellipse component with specified parameters from tokens and fill status.
10977	Returns the components of a polygon by extracting points from tokens and creating a Polygon object with the specified pen, points, and fill status.
10978	Returns the components of a polyline by extracting points from tokens and creating a Polyline object.
10979	Returns a Text component object configured with the provided token parameters (x, y, j, w, b) and the instance's pen.
10980	Returns the components of an image by processing the input tokens, currently raises NotImplementedError.
10981	Renders a GridFS file as an HTTP response with proper headers and range support. Sets content type, length, MD5 checksum, and last modified time from GridFS metadata. Handles range requests efficiently by using either direct file streaming or chunked iteration based on client capabilities. Includes diagnostic information in development mode.
10982	Saves an object to a file using its save_dot method, ensuring the file descriptor is properly closed in finally block.
10983	Load the file by parsing a dot file and return the parsed object, ensuring the file descriptor is properly closed in the finally block.
10984	Test if a point is within this ellipse by checking if the normalized squared distances from the center sum to less than 1.0.
10985	Draws the component bounds as a rectangle using the graphics context for testing purposes.
10986	**Summary:** The `perform` method creates and opens a `NewDotGraphWizard` dialog. If the user successfully completes the wizard (clicks OK), it sets the wizard's `finished` attribute to `True`.
10987	Constructs SQLAlchemy engine and session factory, tests connection, and assigns engine to database alias in context.
10988	Parses the dot_code string using GodotDataParser and replaces the current model with the parsed graph if parsing is successful.
10989	Handles the new Graph action by confirming with the user if they want to replace an existing graph, and if confirmed, creates a new Graph model.
10990	Handles the open action by opening a file dialog to select a Graphviz file, parsing the selected file using GodotDataParser, and setting the parsed model as the current model if parsing is successful.
10991	Saves the current model to the last saved file. If the file doesn't exist, it calls save_as() to create it. Otherwise, it opens the existing file in binary write mode and writes the string representation of the model to it, ensuring the file descriptor is properly closed in all cases.
10992	Handles saving the current model to a file by opening a save dialog, writing the model's dot code to the selected file, and updating the saved file path. Displays an error message if saving fails.
10993	Handles display of graph dot traits by opening an edit_traits dialog with a live view when the info is initialized.
10994	**Method Summary:**

`configure_nodes(self, info)` - Handles the display of the nodes editor by showing the nodes view as a live trait editor when the model is initialized, using the provided UI control as the parent container.
10995	Configures and displays the edges editor view when the UI is initialized, using live editing mode with a specified edges view.
10996	**Method Summary:**

`about_godot(self, info)` - Displays a modal view with information about Godot when the application is initialized. This method checks if the application is properly initialized and if so, opens a live modal dialog using the `about_view` configuration, showing details about the Godot engine.

**Parameters:**
- `self`: The instance of the class containing this method
- `info`: An object containing initialization status and UI information

**Functionality:**
- Validates if the application is initialized (`info.initialized`)
- If initialized, opens a live modal traits dialog showing about information
- Uses `about_view` for the dialog content and `info.ui.control` as parent window
10997	Adds a new node to the graph by creating a unique ID, appending the node to the graph's nodes list, and displaying an editable dialog. If the user cancels the dialog, the node is removed from the graph.
10998	Adds an edge to the graph by creating appropriate nodes and displaying an dialog. Returns early if the info is not initialized or if no graph is found. Handles different cases based on the number of existing nodes (0, 1, or 2+) to determine tail and head nodes, then appends the new edge to the graph if editing is confirmed.
10999	Adds a subgraph to the main graph by creating a new Subgraph instance, displaying an editable dialog, and appending the subgraph to the graph's subgraphs list if the dialog is confirmed.
11000	Adds a Cluster to the main graph by creating a cluster dialog, validating the graph, and appending the cluster to the graph's clusters list if the dialog is confirmed.
11001	Displays a graph selection dialog when multiple graphs exist and a graph is not already selected, returning the selected graph or None if canceled.
11002	Handles display of the options menu by showing a live modal dialog with the options view when the application is initialized.
11003	Handles display of the dot code in a text editor by setting the dot_code attribute from the model and opening a live modal dialog with the dot_code_view.
11004	Handles user attempting to exit Godot by showing confirmation dialog if prompt_on_exit is enabled, then calls close handler.
11005	Moves components to origin by adjusting their coordinates so that the bottom-left corner is at (0,0). For Ellipses, adjusts origin points; for Polygons/BSplines, translates all points by subtracting minimum x/y values; for Text, sets text position to origin.
11006	Save the object to a given file-like object in the specified format by calling the appropriate save method.
11007	Loads an object from a file-like object using the specified format, raising ValueError for unknown formats.
11008	Save the object to a file with the specified filename, automatically deriving the format from the file extension if no format is provided, and using the save_to_file_like method to perform the actual saving operation.
11009	Load an instance of the class from a file, automatically detecting the format from the file extension if not specified.
11010	Creates a property alias to another trait by delegating get/set operations to the referenced trait name.
11011	Generator function that parses a file line by line and yields individual words. Takes a filename and optional encoding parameter, opens the file, splits each line into words, and yields them one at a time.
11012	Returns a cached list of starting words for sentence generation, which are uppercase words not ending in sentence-final punctuation.
11013	Add a Markov chain to the current shelve file with the specified name and order, raising an error if a chain with that name already exists.
11014	Remove a chain from the current shelve file by name, raising a ValueError if the chain doesn't exist.
11015	Builds a Markov chain from a source iterable, extending an existing chain by learning transitions from the source data. For each group of tokens in the source (with size based on the chain's order), it updates the chain's transition probabilities, then clears the chain's cache.
11016	Generate a sentence using a Markov chain with weighted random selection, starting with a randomly chosen start word and continuing until a sentence-ending punctuation mark is reached.
11017	Creates and returns a graph representation using Graphviz layout program. Writes graph to temporary dot file, processes it with specified program/format, and returns output string on success or None on failure.
11018	Adds a node to the graph. If node_or_ID is not a Node instance, converts it to a string ID and either reuses an existing node with that ID or creates a new Node. If node_or_ID is already a Node instance, either uses the existing node or adds the new node to the graph. Sets any additional keyword arguments on the node and returns the node.
11019	Removes a node from the graph by accepting either a Node object or node ID, retrieving the node if an ID is provided, and then removing it from the graph's nodes list. Raises a ValueError if the node does not exist.
11020	Returns the node with the given ID or None.
11021	Removes an edge between two nodes in the graph and returns the deleted edge object, or None if the edge doesn't exist. The method accepts either node objects or node IDs as parameters for both tail and head nodes.
11022	Adds an edge to the graph between two nodes, creating the nodes if they don't exist. The edge can be directed or undirected based on the graph's properties, and supports additional keyword arguments for edge configuration. Handles both strict and non-strict graph modes, though strict mode implementation is incomplete.
11023	Adds a subgraph to the graph. Takes either a subgraph object or ID string, creates appropriate subgraph/cluster object if needed, sets default node/edge properties, and appends to corresponding list (subgraphs or clusters) before returning the subgraph.
11024	Handles Graphviz layout program selection changes by validating that the specified program exists and is a valid file. Logs warnings if the program is not found or if the path does not point to a valid executable file.
11025	Maintains each edge's list of available nodes by assigning the graph's nodes to each edge's _nodes attribute.
11026	Parses a DOT file and returns a Godot graph using GodotDataParser.
11027	Returns a graph given a file or a filename by reading the file data and parsing it with parse_dot_data method. Handles both file objects and filename strings, with proper file closing and error handling.
11028	Builds a Godot graph instance from parsed tokens, extracting graph properties like strict mode, type, and name, then constructs and returns a Graph object with the parsed data.
11029	Builds a Godot graph by processing tokens that define nodes, edges, subgraphs, and attributes. Supports adding nodes, edges with ports, subgraphs (including clusters), and setting default attributes for graphs, nodes, and edges. Returns the constructed graph.
11030	Returns the appropriate time units and multiplier for displaying a duration in seconds by finding the best fit from a predefined units table.
11031	Formats a number of seconds using the best time units (e.g., "2.500 seconds", "1.200 minutes") by determining appropriate units and multiplier, then returns a formatted string with 3 decimal places.
11032	Handles file path changes by updating the name attribute with the basename of the new path and reloading the graph from the editor input.
11033	Creates a toolkit-specific UI control for the graph editor by loading the graph from editor input, creating a view with a graph tree editor, and returning the created UI with live editing capabilities.
11034	Split a sequence into pieces of length n, discarding any remaining elements that don't fit evenly into groups of size n. Returns a list of tuples, where each tuple contains n consecutive elements from the input sequence. For strings, this results in tuples of individual characters.
11035	Summary: A sliding window iterator that creates sublists of a specified length from an iterable, with optional overlap and padding. Takes an iterable and returns sliding windows of specified length, where successive windows overlap by the specified amount. If padding is enabled and the final window is shorter than the specified length, it fills the remaining positions with None values.
11036	Summary: The `main()` function initializes and runs a Godot application with a set of core plugins including CorePlugin, PuddlePlugin, WorkbenchPlugin, ResourcePlugin, and GodotPlugin.
11037	Gets the object's children by collecting and returning subgraphs, clusters, nodes, and edges.
11038	Appends a child object to the appropriate collection (subgraphs, clusters, nodes, or edges) based on the child's type, ignoring invalid types.
11039	Inserts a child object into the specified index position within the appropriate collection (subgraphs, clusters, nodes, or edges) based on the child's type.
11040	Deletes a child object at the specified index from its parent object's children collections based on the child's type (Subgraph, Cluster, Node, or Edge).
11041	Sets up or removes a listener for children being replaced on a specified object by subscribing to changes in "subgraphs", "clusters", "nodes", and "edges" traits with fast_ui dispatch.
11042	Sets up or removes a listener for children being changed on a specified object by connecting to multiple trait change events (subgraphs_items, clusters_items, nodes_items, edges_items) with fast_ui dispatch.
11043	Gets the label to display for a specified object. If label starts with '=', returns the label without the first character. Otherwise, retrieves the label from the object using xgetattr, and if a formatter is provided, applies it to the label.
11044	Sets the label for a specified object by storing the label value in the object's attribute specified by self.label, but only if the label name doesn't start with '='.
11045	Sets up or removes a listener for label changes on a specified object, but only if the label doesn't start with '='.
11046	Initializes the editor by creating the underlying toolkit widget and setting up the graph visualization interface.
11047	Updates the editor when the object trait changes externally to the editor by graphing the new object and adding listeners.
11048	Adds event listeners for a specified object's node and edge children, registering callbacks for replacement and change events on canvas nodes and edges. Raises ValueError if graph canvas is not set.
11049	Handles a list of nodes being set by deleting the old nodes and adding the new nodes.
11050	Handles addition and removal of nodes by deleting removed nodes and adding added nodes from the event.
11051	Adds nodes to the graph for each feature in 'features' using the editor factory's GraphNodes, then arranges all nodes.
11052	Handles a list of edges being set by deleting the old edges and adding the new edges.
11053	Handles addition and removal of edges by deleting removed edges and adding added edges from the event.
11054	Adds edges to the graph for each feature in 'features' using GraphEdges from the editor factory, then arranges all graph elements.
11055	This method parses Xdot drawing directives and processes graphical components by:
1. Using XdotAttrParser to parse raw drawing data into components
2. Calculating the absolute coordinates of the drawing container relative to the graph origin
3. Adjusting component positions so they're relative to the container's origin rather than the graph
4. Handling different component types (Ellipse, Polygon, BSpline, Text) by translating their coordinates
5. Creating a Container with the processed components and assigning it to either self.drawing or self.arrowhead_drawing based on the directive name

The method essentially converts Xdot drawing instructions into positioned graphical components relative to their container's coordinate system.
11056	Handles the containers of drawing components being set by adjusting positions relative to graph origin and updating component positions accordingly.
11057	Creates new nodes with unique IDs, either derived from existing graph nodes or generated as random hex strings.
11058	Creates a new edge with unique ID by connecting nodes from a graph, using the first two nodes as tail and head, or creating new nodes if needed.
11059	Attaches the connection's default database to the provided context using the specified alias.
11060	Parses xdot drawing directives and updates node components by:
1. Parsing xdot data into components using XdotAttrParser
2. Calculating maximum dimensions and minimum positions from components
3. Moving components to origin using move_to_origin()
4. Creating a Container with auto_size=True and blue background
5. Adding all components to the container
6. Assigning the container as self.drawing

The method handles positioning calculations and container setup for drawing directives, though bounds assignment is commented out.
11061	Parses a label drawing directive by parsing xdot data, positioning components relative to the object's position, creating a container with red background, and storing the result in self.label_drawing.
11062	Handles the change of drawing components container by removing the old component, adding the new component, and updating the component's position and redraw request.
11063	Handles the position of the component changing by updating the component's position based on its bounds.
11064	Handles Graphviz position attribute changing by updating component position based on new coordinates and requesting redraw.
11065	Handles right mouse button click in 'normal' state by opening a context menu with menu items from parent component tools that implement MenuItemTool interface.
11066	This function outputs CSS styles for code highlighting by:
1. Listing all available Pygments styles
2. Displaying the CSS style definitions for a specified style
3. Using click for colored terminal output to show available styles and CSS
4. Utilizing pygments.formatters.HtmlFormatter to generate style definitions

The function takes a context object and style name as parameters, then outputs formatted information about available styles and the CSS for the selected style to the terminal.
11067	Draws a closed polygon using the object's points, fill color, stroke color, and line width properties. The polygon is either filled or stroked based on the 'filled' attribute, and the drawing is performed within a saved graphics context state.
11068	Test if a point is within this polygonal region by checking if the given point (point_x, point_y) lies inside the polygon defined by self.points using the specified inside_rule (winding number or even-odd rule). Returns True if the point is inside, False otherwise.
11069	Draws the Bezier component by rendering a path with cubic Bzier curves based on the component's points, using the specified graphics context and pen properties.
11070	Broadcasts an event to all database connections registered by calling the event method on each engine if it exists.
11071	Method that runs in the Worker thread, processing items from in_queue by applying func and placing results in out_queue until stopper is set.
11072	Returns the full external URL for a given page number with optional URL scheme, constructing the URL using request context and URL routing parameters.
11073	Render the rel=prev and rel=next links to a Markup object for injection into a template
11074	Render SEO links including canonical, prev, and next links to a Markup object for template injection.
11075	The function `_content_type_matches` checks if a candidate content type exactly matches or is a subtype of a given pattern. It uses a helper function `_wildcard_compare` to compare content type and subtype components, allowing wildcard matching with '*'. The function returns True if both the content type and subtype match (either exactly or via wildcard), False otherwise.
11076	Selects the best content type for proactive content negotiation according to RFC 7231. Takes requested and available content types, returns the best match and its pattern. Raises NoMatch if no suitable match is found. Uses a prioritization system based on match type and parameter specificity to determine the optimal content type.
11077	Modifies a given URL by applying specified changes to its components (scheme, host, port, path, query, fragment, user, password) and returns the updated URL. Supports various query parameter formats (mapping, sequence of pairs, or string) and handles IDN encoding for hostnames. Raises ValueError for invalid port values.
11078	Removes authentication credentials (username and password) from a URL, returning both the extracted credentials and the sanitized URL. The function parses the URL to extract authentication information and uses a helper function to remove the credentials from the URL. It returns a named tuple containing the authorization tuple (username, password), the username, the password, and the sanitized URL.
11079	Generate the user+password portion of a URL by encoding special characters and combining them with a colon separator if both are present, or just the user if password is absent or None.
11080	Normalize a host for URL inclusion by encoding it with IDNA or percent-encoding, and validate its length.
11081	Discovers Python modules by scanning a directory tree for packages (directories containing __init__.py files) and returns a list of module names as strings. Returns an empty list if the directory doesn't exist or contains no valid packages.
11082	Function `rdiscover_modules(directory)` recursively searches a directory tree for Python modules by looking for `__init__.py` files and returns a list of discovered module names as strings. It examines each directory entry and only processes directories that contain an `__init__.py` file, using a helper function `_search_for_modules()` to find modules within those directories. The function returns a list of candidate module names found in the directory tree.
11083	Function `rlist_modules(mname)` recursively discovers submodules under a given module by:

1. Importing the specified module using `import_module()`
2. Checking if the module has a valid `__path__` attribute
3. Determining the module's path either from `__path__` or by scanning `sys.path`
4. Searching for submodules recursively in the module's path using `_search_for_modules()`
5. Returning a list of fully qualified submodule names joined with the module path separator

The function handles both standard modules in default paths and modules from extended paths via `sys.meta_path` hooks, and raises an `ImportError` if the module cannot be loaded.
11084	Lists all classes within a specified module, optionally filtered by a provided filter function. Returns a list of classes that meet the filter criteria.
11085	Function `rlist_classes` recursively lists all classes within a given module namespace and its submodules. It takes a module and an optional class filter function as parameters. The filter function is called for each class to determine whether it should be included in the results. The function returns a list of classes that pass the filter criteria. The function works by first getting all module names through `rlist_modules`, then iterating through each module and collecting classes using `list_classes` with the provided filter.
11086	Ensure that a needed directory exists, creating it if it doesn't exist. If the directory cannot be created and doesn't already exist, raise an exception. Log the directory creation attempt.
11087	Store text contents in a blob service using the specified key for later retrieval.
11088	The `luhn_check` function validates a credit card number using the Luhn algorithm (mod-10 checksum). It processes each digit from left to right, doubling every second digit starting from the right, subtracting 9 if the result exceeds 9, and summing all digits. The function returns `True` if the total sum is divisible by 10, indicating a valid card number according to the Luhn checksum, and `False` otherwise.
11089	Return the git hash as a string by executing 'git rev-parse HEAD' command in the directory containing the current file, with minimal environment setup. If the command fails, return 'Unknown'.
11090	Loads a module by its name, validates it against the loader's expected module, and sets up the module's hidden variables according to PEP302. Returns the loaded module object.
11091	Adds a path to the list of searchable paths if it's not already present.
11092	Method: `find_module`
Parameters: 
- `module_name` (str): the full name of the module to find
- `path` (str, optional): set to None when searching for top-level modules - otherwise set to package.__path__ for submodules and subpackages (unused)

Returns: `ModuleLoader` object if module is found, otherwise `None`

Description: Searches through configured paths to locate a module by its full name. The method constructs the module path by splitting the module name using a module path separator, then searches each configured path root for the module. If the module path corresponds to a directory, it looks for an `__init__.py` file to identify it as a package. If the path corresponds to a file, it appends `.py` to the path. When a matching file is found, it returns a `ModuleLoader` object containing the module's path information. If no matching module is found in any search path, it returns `None`.
11093	Splits a line of text into multiple lines based on indentation and length constraints, inserting line breaks at spaces to maintain readability. The function preserves leading whitespace and recursively processes the remainder of the line until all segments fit within the specified maximum length. Returns a list of lines, with each line respecting the minimum and maximum length parameters. If no suitable split point is found, the original line is returned as a single-element list.
11094	Removes all XML namespaces from an lxml.etree document by stripping namespace prefixes from element tags and cleaning up namespace declarations.
11095	Checks that versions are consistent across different sources. Returns an error message if inconsistencies are found, otherwise returns an empty string. Can optionally check against a desired version or include/exclude the 'package' version in the consistency check.
11096	Creates a new instance of a rule from YAML configuration by updating the class dictionary with provided kwargs, called during default configuration file parsing.
11097	Merges a dictionary into the Rule object by extracting and adding actions, then updating the object's attributes with the remaining dictionary items.
11098	Executes a series of actions in the specified working directory by first running global actions and then iterating through and executing each action in order using subprocess.
11099	Creates a new instance of a rule by merging configuration dictionaries from defaults and kwargs, handling token and directory parameters specifically while deep copying the defaults dictionary.
11100	Add extra details to a message by appending Flask request information (URL, method, endpoint, and formatted form data with obscured password fields) and session data, handling exceptions gracefully.
11101	Method `emit(self, record)` formats and sends email messages with rate limiting. It maintains a rate limiter list to track emails sent within the last minute, allowing only a maximum number of emails per minute (defined by `max_sends_per_minute`). The method:

1. Cleans up the rate limiter by removing entries older than 60 seconds
2. Checks if the number of recent emails is below the threshold
3. If under threshold, adds current timestamp to rate limiter and sends email
4. If over threshold, logs warning instead of sending email
5. Handles exceptions by calling `handleError(record)`

The method uses `format()` and `add_details()` to prepare the email message, then sends it via `send_text_mail()` if rate limits permit.
11102	Summary: The `get_context` method extends the parent class's context by adding an `image_rendition` key. This key is set to either the configured rendition's image_rendition value or defaults to 'original' if not specified. The method then returns the updated context dictionary.
11103	Logs an attempt against a key, tracking attempts and locking the account if maximum attempts are exceeded.
11104	Adds a URL to the download queue if both music and drive services are properly initialized, otherwise logs an error message.
11105	Starts worker processes for a pipeline with specified workers per task, sets up graceful shutdown handling, and begins execution of all workers.
11106	Set or update a key-value pair in the database via PUT request to the specified endpoint. Raises KVStoreError if the request fails.
11107	Get the value of a given key from the KV store, with optional waiting for changes. Raises KeyDoesNotExist if key doesn't exist, KVStoreError for other HTTP errors. Returns decoded value or empty string if value is None.
11108	Recursively retrieves all key-value pairs from the KV store under a given key, with optional blocking wait functionality. Uses HTTP GET request to fetch tree data with recurse=true parameter, handles 404 and other error status codes, and decodes base64-encoded values. Returns dictionary mapping keys to their decoded values, with empty strings for keys with no value. Supports optional wait timeout and index parameters for blocking operations.
11109	Get the current index of a key or subtree for Consul long polling requests. If recursive=True, includes all keys in the subtree. Returns the X-Consul-Index header from the response.
11110	Delete a key from the key-value store, with optional recursive deletion of all keys below it. Sends a DELETE request to the specified endpoint and raises an exception if the operation fails.
11111	Plot a clustered heatmap showing feature importance grouped by classes. Takes feature data and labels, computes feature importance, selects top N features, and creates a clustered heatmap with optional clustering metrics and methods. Returns a seaborn clustermap object with color-coded class labels.
11112	Adds a specified number of months to a given timestamp, handling edge cases where the resulting date would have an invalid day (like February 30th) by adjusting to the last day of the target month or first day of next month as appropriate.
11113	Add a specified number of months to a given date, handling edge cases where the resulting date would be invalid (such as February 30th) by adjusting to the last valid day of the month or the first day of the next month.
11114	**Summary:** The `is_christmas_period()` function determines if the current date falls within the Christmas period, defined as between December 15th and December 27th inclusive. It returns `True` if the current date is within this range, otherwise `False`.
11115	Sets the current music service to the specified service_name, initializing it with the provided API key if necessary. Supports 'youtube' and 'soundcloud' services, with logging for unrecognized service names.
11116	Sets the current storage service to the specified service_name and connects to it. Supports 'google drive', 'dropbox', and 'local' services. For 'google drive', creates a new GoogleDrive instance and connects. For 'local', creates a LocalStorage instance with the provided custom_path and connects. Logs errors for unsupported services or unrecognized service names.
11117	Read dataset from CSV file, extract features and labels, and return them as dictionaries and list respectively.
11118	Reads dataset from JSON file (supports gzip compression) and returns transposed data as list of lists.
11119	Writes dataset to JSON file in gzip or regular text format, zipping labels with features.
11120	Filter items from dataset by label condition. Returns items with matching label if reverse=False (default), or items with non-matching label if reverse=True. Uses zip and filter operations to maintain correspondence between features and labels.
11121	Calculates the average values for dictionary features in a dataset that match a given reference label, returning a defaultdict with feature averages.

**Parameters:**
- X: List of dictionaries representing the dataset
- y: List of labels corresponding to each data point
- ref_label: The reference label to filter data by

**Returns:**
- defaultdict(float): Dictionary with feature names as keys and their average values as floats for the filtered data

**Process:**
1. Filters the dataset X and labels y by the reference label using filter_by_label()
2. Converts the filtered data to a pandas DataFrame
3. Calculates the mean of all numeric columns
4. Converts the result back to a dictionary
5. Wraps the result in a defaultdict with float default values
11122	Provides feature significance report using ANOVA with multiple hypothesis testing correction. Returns DataFrame with F-values and p-values for each feature, sorted by specified criterion.
11123	Method: `restore_data(self, data_dict)`

Summary: Updates the Flask session and the object's internal data dictionary with the provided data dictionary.

Parameters:
- `data_dict`: Dictionary containing the data to be restored

Behavior: 
- Stores the input `data_dict` in the Flask session under the key `self._base_key`
- Updates the object's `_data_dict` attribute with the value from the session

Note: This method assumes `self._base_key` is properly initialized and `session` is available in the context.
11124	Recursively merge two dictionaries destructively, where dictionary 'b' is merged into dictionary 'a'. If a key exists in both dictionaries and both values are dictionaries, they are merged recursively. Otherwise, the value from 'b' overwrites the value in 'a'. Returns the merged dictionary 'a'.
11125	A decorator that creates a dispatch function for multiple implementations based on a dispatch value returned by a provided dispatch function. The decorator maintains a registry of implementations mapped to dispatch keys and selects the appropriate implementation at runtime. If no matching implementation is found, it either uses a default implementation or raises an exception. The dispatch function and registered implementations are stored as attributes on the decorated function.
11126	A decorator function that registers dispatch functions for a given dispatch key in a multiple dispatch system. If no dispatch key is specified, it sets the function as the default dispatch function; otherwise, it registers the function in the dispatch function's multi-dispatch dictionary under the specified key.
11127	Auto-discover INSTALLED_APPS registered_blocks.py modules and fail silently when not present. This forces an import on them thereby registering their blocks.

This is a near 1-to-1 copy of how django's admin application registers models. For each installed app, it attempts to import the app's registered_blocks module to register its blocks. If the module doesn't exist, it silently fails. If the module exists but causes import errors, it resets the block_registry to its previous state and only re-raises the error if the app actually has a registered_blocks module.
11128	Verifies a block prior to registration by checking:
1. If the block type is already registered (raises AlreadyRegistered if so)
2. If the block is an instance of Block class (raises InvalidBlock if not)
11129	Registers a block to a specified block type in the registry after verification.
11130	Removes a block type from the registry. Raises NotRegistered if the block type is not found.
11131	Converts a file to MP3 format using FFmpeg, returning the new filename and adding the original to a delete queue. If the file is already MP3, returns the original filename. Handles conversion errors by retrying and logs conversion timing.
11132	Method `reasonable_desired_version` determines if a proposed version is a reasonable next version by:

1. Parsing the desired version and extracting major, minor, and patch components
2. Getting existing tag versions from the repository
3. Comparing the desired version against the maximum existing version:
   - Returns empty string if no tags exist (any version is legal)
   - Returns error message if desired version is less than current version
   - Checks for version skipping using `skipped_version` helper
4. Returns appropriate error messages for invalid updates or empty string for valid updates

The method supports optional parameters to allow equal versions or patch skips, and uses version comparison to ensure semantic versioning compliance.
11133	Handle SSL redirect checks for routes based on SSL requirements and configuration, redirecting between HTTP and HTTPS as needed while allowing static routes to be served on both protocols.
11134	Initializes Celery with Flask app context support and configures logging. Sets up a ContextTask class that automatically includes the Flask application context when executing Celery tasks, then returns the configured Celery instance.
11135	Add a mail to the queue to be sent.

WARNING: Commits by default!

:param to_addresses: The names and addresses to send the email to, i.e. "Steve<steve@fig14.com>, info@fig14.com"
:param from_address: Who the email is from i.e. "Stephen Brown <s@fig14.com>"
:param subject: The email subject
:param body: The html / text body of the email
:param commit: Whether to commit to the database
:param html: Is this a html email?
:param session: The sqlalchemy session or None to use db.session
:returns: The queued email object
```
11136	Parses an HTTP accept-like header into a list of ContentType instances sorted by quality preference in decreasing order. The function processes the header value by splitting it into individual content types, extracting quality parameters (q-values), and sorting the results based on these quality values while maintaining proper ordering semantics for equal quality items. Each ContentType instance includes a 'quality' property representing its associated preference value as a float.
11137	Parse a `Cache-Control` header into a dictionary of key-value pairs, handling both directives with values and boolean directives without values. Returns a dictionary where parameterless directives like 'public' or 'no-cache' are set to True if present, and directives with values are parsed into appropriate types (int or string).
11138	Parse a content type header string into its components (type, subtype, suffix, and parameters) returning a ContentType data structure. Supports optional case normalization for parameter values and handles MIME content suffixes.
11139	Parse RFC7239 Forwarded header into a list of dictionaries containing parameter values. Supports optional strict parsing to reject non-standard parameters.
11140	Parse a comma-separated list header by splitting on commas while preserving quoted segments that may contain commas. Returns a list of header elements as strings, with quoted segments properly handled and commas within quotes replaced with a null character for temporary storage before final comma replacement.
11141	Parse a named parameter list in the "common" format, returning name-to-value pairs with optional normalization of parameter names and values to lowercase, and strip quotes from values.
11142	Resize an image to fit a specified width while maintaining the original aspect ratio. Takes a PIL.Image object and desired width as input, returns a new PIL.Image object with the resized dimensions.
11143	Add a new value to the list with validation according to RFC 5988 sections 5.3 and 5.4. If strict mode is enabled, validate against RFC values and raise MalformedLinkValue for invalid cases. Handle special cases for 'media', 'type', 'title', and 'title*' parameters.
11144	Downloads the first available MP4 or WebM file associated with a YouTube video URL, logs the download progress and duration, and returns the local filename. If the URL is invalid, logs an error and returns None.
11145	Creates a connection to Google Drive API, sets up the connection attribute for making requests, and ensures the 'Music' folder exists by creating it if necessary.
11146	Uploads a file to Google Drive in the Music folder and returns the original filename.
11147	Initializes the connection attribute with the path to the user home folder's Music folder, and creates it if it doesn't exist.
11148	Writes sky parameters to a text file for skytool_Free to generate sky radiance distribution, including verbose mode, band count, wavelength data, partition type, viewing angles, sky type, and image settings.
11149	Method Summary:
**update_filenames()** - Currently does nothing but may be needed for future functionality. This method would generate and set a sky file path based on input parameters including sky state, zenith, azimuth, number of bands, and dataset code, though the current implementation is incomplete or unused.
11150	Reads phytoplankton absorption data from a CSV file and stores it in self.a_phi, with error handling that sets self.a_phi to -1 if reading fails.
11151	Scale the spectra by multiplying by linear scaling factor

:param scale_parameter: Linear scaling factor
11152	Read pure water absorption data from a CSV file, handling potential read errors with exception logging.
11153	Read pure water scattering data from a CSV file and store it in self.b_water attribute. Handles exceptions during file reading with logging.
11154	Generic IOP reader that reads IOP data from a CSV file and interpolates it to common wavelengths. Reads wavelength and IOP values from file, converts to float, then uses scipy.interp to interpolate IOP values to the wavelengths defined in the class constructor. Returns interpolated IOP values or -1 on error.
11155	Writes a numpy array to a file, one element per line, with logging information.
11156	Calculates total back-scattering by dividing the sum of back-scattering from sea water and particle scattering by a given scattering fraction, defaulting to 0.01833.
11157	Builds total absorption by summing water, CDOM, and phytoplankton absorption components.
11158	Method `build_c` calculates the total attenuation by summing total absorption and total scattering values. It computes c = a + b and stores the result in `self.c`. The method logs the operation with the message 'Building total attenuation C'.
11159	Meta method that executes all build operations (a, bb, b, c) in proper sequence for IOP-based construction.
11160	Stores input parameter lists as class properties for batch processing.
11161	Loads a text file to a Python dictionary using '=' as the delimiter, stripping whitespace from values and keys.
11162	Converts a comma-separated string representation of numbers into a list of floats, handling both space-separated and non-space-separated values.
11163	Reads a PlanarRad generated report file and parses its contents into a Python dictionary, extracting single line parameters, theta/phi tables, and L_w/L_it band data. Returns the populated data dictionary.
11164	Sets handlers for a list of signals, with each signal configured to use the specified handler (defaulting to the default signal handler).
11165	**Summary:** A pseudo signal handler that logs warning messages when duplicate signals are received while the system is already processing a previous signal. It captures the signal number and current execution frame for debugging purposes.
11166	Default handler for signal processing that manages different signals by calling appropriate methods:
- HUP signal: Restarts python process
- TERM/INT/QUIT signals: Cleanup and exit with error code
- STOP/TSTP signals: Pause execution
- CONT/USR1 signals: Resume execution
- INFO signals: Print status information
- USR2 signals: Abort and exit with error code
- Unhandled signals: Log error and raise exception
11167	Pause execution for a specified number of seconds or until a resume signal is received, then execute a callback function. Returns True if timer expired, False otherwise.
11168	Handles abort signal by running all abort tasks, then exit tasks, then terminates with error status.
11169	**Summary:**

The `status` method handles status signal requests by executing all registered status callback functions, removing non-persistent callbacks, and then resuming operations. It logs each callback execution, applies the callback with its arguments, retains persistent callbacks for future use, and finally calls the resume queue handler.
11170	Removes a registered event from the event list without triggering it, with comprehensive error handling for logging and removal failures.
11171	Fetch time series data from OpenTSDB with specified metric, time range, tags, and aggregation settings, returning a dictionary mapping timestamps to data points.
11172	Fetch and sort time series data from OpenTSDB, returning (timestamp, value) tuples sorted by timestamp.
11173	Collects values from an iterable into a list, optionally limiting the number of items collected.

Args:
    iterable: An iterable yielding values for the list
    n: An optional maximum number of items to collect (default: None)

Returns:
    List of values from the iterable

If n is specified, collects at most n items using itertools.islice().
If n is None, collects all items from the iterable.

Example:
    >>> pfcollect(n=5)([1, 2, 3, 4, 5, 6, 7])
    [1, 2, 3, 4, 5]
11174	Prints an item to the specified file with optional end character.

**Parameters:**
- item: The item to print
- end: String to append to the end of printed output (default: '\n')
- file: File to which output is printed (default: sys.stdout)

**Returns:** None

**Example:**
```python
>>> from operator import add
>>> fn = pfreduce(add, initial=0) >> pfprint
>>> fn([1, 2, 3, 4])
10
```
11175	Prints each item from an iterable using pfprint, with optional end string and file parameters.
11176	Extracts function signature information including arguments, default values, and special argument flags.
11177	Extract function signature from an existing partial instance by copying its argument lists, default arguments, and variable arguments attributes.
11178	Calculate new argv and extra_argv values by adding specified positional and keyword arguments, handling both regular parameters and variable arguments. Returns a tuple of (new_argv, new_extra_argv) where new_argv is a copy of the current argv with new values added, and new_extra_argv contains any additional positional arguments that don't fit in regular parameters. Raises TypeError for unexpected keyword arguments or too many positional arguments.
11179	Returns True if the given filename matches any of the specified META-INF files that should be ignored to prevent multiple signatures in XPI signing, False otherwise. The ignored files include manifest.mf and various signature files (.sf, .rsa, .dsa) plus ids.json.
11180	Function to generate sort keys for XPI file names, prioritizing specific files (install.rdf, chrome.manifest, icon.png, icon64.png at the beginning, licenses at the end) and sorting alphabetically ignoring case. Returns a tuple of priority number and lowercase filename split into directory and base name.
11181	Read one VLQ-encoded integer value from an input data stream, handling little-endian byte order and variable-length encoding.
11182	Reads a table structure from binary data where each value is prefixed by a 2-byte header (index and key) followed by a variable-length quantity. Returns a dictionary of field names to their corresponding values, with unknown fields discarded. The actual values are halved during parsing.
11183	Parse the user data header portion of a StarCraft II replay file, extracting version information and duration, and return it as an OrderedDict.
11184	Transforms a duration in seconds into a human-readable string format (e.g., "2h 30m 45s").
11185	Print a summary of the game details including map, duration, version, and team player information with formatted columns for team, name, race, and color.
11186	```python
def data(self):
    """
    Retrieves and stores all user input data from the UI widgets into instance variables.
    Collects various parameter values including batch names, spectral parameters, 
    coordinate values, path information, CPU settings, and report parameters.
    """
    # Text input values
    self.batch_name_value = self.ui.batch_name_value.text()
    self.saa_values = self.ui.saa_values.text()
    self.sza_values = self.ui.sza_values.text()
    self.p_values = self.ui.p_values.text()
    self.x_value = self.ui.x_value.text()
    self.y_value = self.ui.y_value.text()
    self.g_value = self.ui.g_value.text()
    self.s_value = self.ui.s_value.text()
    self.z_value = self.ui.z_value.text()
    self.wavelength_values = self.ui.wavelength_values.text()
    self.verbose_value = self.ui.verbose_value.text()
    
    # Path values
    self.phytoplankton_path = self.ui.phyto_path.text()
    self.bottom_path = self.ui.bottom_path.text()
    self.executive_path = self.ui.exec_path.text()
    
    # Other settings
    self.nb_cpu = self.ui.nb_cpu.currentText()
    self.report_parameter_value = str(self.ui.report_parameter_value.text())
```
11187	Method: search_file_result

Summary: Displays file data and associated graphics when a file is found. Sets up UI elements, processes data, and displays graphics when in normal mode.
11188	This method creates a BatchFile object with various configuration parameters and writes the batch file to disk with a filename based on the batch name value.
11189	This function processes data from a file to separate wavelength values from other data for curve plotting. It reads the file line by line, splits each line by commas, and identifies the column containing "wave length (nm)" to determine the separation point. The data is then organized into two arrays: one for information (all columns except wavelength) and one for wavelength values and data to be plotted. The wavelength column is converted from strings to floats, and the data is split so that the first line contains wavelength values and subsequent lines contain the data for plotting curves. The function also handles error cases where the wavelength column cannot be found.
11190	```python
def display_the_graphic_connection(self):
    """
    Connects the slider to the display_the_graphic function by creating a parameterless wrapper.
    This allows the slider to trigger the graphic display function which requires multiple parameters.
    """
    self.display_the_graphic(self.num_line, self.wavelength, self.data_wanted, self.information)
```
11191	This function displays curve information by setting text values for multiple labels and result fields in a graphical user interface. It takes a curve index and an information array containing both label headers and data rows. The function first populates eight column labels with header information from the first element of the information array, then displays the corresponding data values for the specified curve index in the result fields. The implementation uses hardcoded references to column labels and results (column1_label through column8_label and column1_result through column8_result) to show the information in a tabular format within the UI.
11192	Displays an error message with warning image and red text when invalid input is detected.
11193	Hide error message by setting scaled contents to False and hiding error text label.
11194	Executes planarRad using a batch file, handling error checking and process management. The method validates input data, writes parameters to file, and launches the planarrad.py script as a subprocess with the specified batch file. It also manages progress bar updates and displays graphics upon completion.
11195	This function cancels the PlanarRad application by terminating its process if it's currently running in normal mode. It shows a confirmation dialog before cancellation and resets the progress bar upon successful cancellation. The function includes a warning that it needs testing.
11196	Method: quit(self)
Summary: This method handles the quitting of PlanarRad application by first checking if it is currently running. If PlanarRad is running, it displays a warning message asking the user to stop the application before quitting. If PlanarRad is not running, it prompts the user with a confirmation dialog asking if they are sure they want to quit. If the user confirms, the application is terminated using QtGui.qApp.quit().
11197	Saves the currently displayed figure as a PNG file with an incrementing name to avoid overwriting previous figures, storing it in the "Artists_saved" folder within the "planarradpy" directory.
11198	Opens and displays the PlanarRad log file in a UI text edit widget.
11199	Opens and displays the local documentation file in a new window using QWebView.
11200	Initializes GUI by hiding error messages, disabling UI elements, setting default paths and parameters, and resetting the progress bar.
11201	Method: click(self, event)
Summary: Intercepts mouse right-click events to capture cursor position and display a graphic context menu when in normal mode.
11202	Method `mouse_move(self, event)` handles mouse movement events on the canvas by:

1. Checking if the current tab is in normal mode
2. Capturing the mouse coordinates (xdata, ydata) from the event
3. Updating the stored position coordinates (posX, posY)
4. Calling `graphic_target()` to render graphics at the current mouse position

The method acts as a mouse tracking handler that updates position data and triggers graphical updates when the mouse moves over the canvas in normal mode.
11203	Updates the mouse coordinate display with the given x,y coordinates when authorized display is enabled, and refreshes the graphic display.
11204	Creates a genesis signing lockset with a single vote from any validator to avoid complex bootstrapping.
11205	Method: sign
Description: Signs the current object using a provided private key and updates the object with signature components (v, r, s). 
Parameters: 
- privkey: The private key to use for signing, which can be in different formats (raw binary or 64-character string)
Returns: The modified object with signature components set
Raises: 
- InvalidSignature: If the object is already signed or if the private key is invalid (zero value)
Process:
1. Checks if object is already signed
2. Validates private key is not zero/empty
3. Calculates SHA3 hash of RLP-encoded object (excluding v, r, s fields)
4. Converts private key to binary format if needed
5. Generates ECDSA signature using the private key
6. Extracts signature components and converts to appropriate formats
7. Sets v, r, s fields and resets sender cache
11206	Returns the keccak hash of the RLP-encoded transaction, excluding the 'v', 'r', 's' fields and including the sender. Raises MissingSignatureError if the sender is None.
11207	Method `check` validates the state of quorum conditions. It returns `True` if the object is invalid or if exactly one of the three quorum states (quorum, noquorum, or quorumpossible) is set to a non-None value. The method uses an assertion to ensure exactly one quorum state is active and returns `True` in all cases.
11208	Issues new funds by allocating amount to sender's balance and tracking issuance with RTGS hash.
11209	Returns the highest lock on height by iterating through rounds (sorted highest to lowest) and returning the first non-None lock found.
11210	Returns the last block proposal that was voted on, where the proposal matches the locked vote in the same round.
11211	Returns the highest valid lockset on height, iterating through rounds until a valid lockset is found, or None if none exists.
11212	Sets up a timeout for waiting for a proposal based on current round and timeout parameters, returning the delay amount.
11213	Method called when a proposal is received from a synced peer. Validates the proposal against the current chain state and updates the last active protocol reference.
11214	Creates private keys that support color coding by ensuring each key corresponds to an address with a specific color index, where the color is determined by the address hash modulo the number of colors.
11215	Computes the total delay for packet transmission between sender and receiver, accounting for bandwidth limitations, base latencies, and optional additional delay.
11216	Delivers a packet between sender and receiver with a delay equal to the consensus round timeout, asserting that the timeout is positive and printing a debug message.
11217	Creates a proxy object for a contract on a chain that forwards method calls to the contract via ABI encoding/decoding, using test_call to execute methods and returning decoded outputs.
11218	Converts an address to its corresponding native contract class by:
1. Validating the input address is 20 bytes and is a valid instance address
2. Deriving the native contract address prefix by combining the native contract prefix with the last 4 bytes of the address
3. Returning the native contract class from the native_contracts dictionary using the derived address
Returns the contract class._on_msg_unsafe method with the class as im_self attribute
11219	Registers NativeContract classes by validating the contract is a subclass of NativeContractBase, has a valid address length and prefix, and the address is not already taken. If the contract is not already registered, it stores the contract's _on_msg handler in native_contracts dictionary with the contract address as key.
11220	Method `update(data)` adds data to a filter list if it's not already present, maintaining a maximum number of items by removing the oldest item when necessary. It returns `True` if the data was added (unknown), and `False` if the data was already in the filter (known).
11221	Method `on_receive_transactions` handles incoming RLP-decoded transactions by spawning a separate greenlet to process and add each transaction to the local chain. It logs the number of received transactions and the remote peer ID for debugging purposes.
11222	Decondition an image from the VGG16 model by:
1. Transposing dimensions from (C, H, W) to (H, W, C)
2. Adding VGG16 dataset mean values to each color channel
3. Converting BGR to RGB format
4. Returning the deconditioned image
11223	Condition an image for VGG16 model by converting RGB to BGR format, subtracting ImageNet mean values, and transposing dimensions from HWC to CHW format.
11224	Creates a function that returns the output of a specified layer given the network input and learning phase.
11225	Get symbolic output of a specified layer by name, caching the result for future use.
11226	Get feature outputs from specified layers for input x.
11227	Creates a new encryption key file at the specified path with read-only permissions, generating a random initialization vector and using the system's time for key generation. The function writes the base64-encoded key to the file and sets file permissions to 0o400 (read-only) with Windows compatibility notes.
11228	Finishes the load job by performing cleanup and validation operations. Returns the exit code from applying rows to the table. Raises TeradataPTError if the job finishes with a non-zero exit code. The method ensures proper cleanup by ending acquisition and applying rows if any were processed, and performs checkpointing before finalization.
11229	Load data from a file into a target table, handling compression, encoding, and date parsing. Supports text and giraffez archive files with automatic delimiter detection and null value handling. Returns the result of the load operation.
11230	Loads a single row into the target table with error handling. Returns the row status and updates counters. Raises exceptions for encoding errors or connection problems based on panic parameter.
11231	Method `release` attempts to release the target mload table. It raises `GiraffeError` if the table has not been set via constructor, `TeradataBulkLoad.table`, or `from_file`. If table is set, it logs the release attempt and calls `self.mload.release(self.table)`.
11232	Returns a list of four table names derived from the target table by adding suffixes "_wt", "_log", "_e1", and "_e2". Raises GiraffeError if the target table has not been set.
11233	Summary: The `fix_compile` function is a monkey-patch helper that modifies the default compiler behavior in Python's distutils module. It removes specified compiler flags from the default compilation process by overriding the `compile` method of `CCompiler` class. This allows for custom compiler flag management during the build process.
11234	Finds the Teradata install directory based on the platform, checking default paths for Windows (32-bit/64-bit), Linux, and macOS, with a fallback to the Linux default path if no platform match is found. Returns None if no installation is found at the default locations and TERADATA_HOME is not explicitly set.
11235	Retrieve the decrypted value of a key in a giraffez configuration file, automatically prefixing keys with "secure." if they don't start with "secure." or "connections.", and return None for non-string values.
11236	Sets a decrypted value by key in a giraffez configuration file, automatically prefixing the key with "secure." if not already present, then writes the configuration to disk.
11237	Method `do_table(self, line)` controls table output formatting. It accepts a line parameter and enables/disables table display based on whether the line is "on" or "off" (case-insensitive). If no parameter is provided, it logs the current table output state. The method updates the `self.table_output` boolean flag and writes corresponding log messages.
11238	Execute SQL commands using CLIv2 with various options for formatting, parsing, and error handling, returning a cursor over the results.
11239	Retrieve a value from the configuration based on its key, supporting nested keys separated by '.'. If nested is True, the key is split and traversed through the settings dictionary. Optionally decrypts the value if decrypt is True. Returns the default value if key is not found.
11240	Writes a default configuration file with specified name or default location (~/.girafferc), overwriting existing content. Returns the written content.
11241	Sets the column names to be used for iteration and retrieval operations. Validates that each column name exists and isn't duplicated, raising a GiraffeTypeError if invalid names are provided. When names is None, all columns are included.
11242	Writes export archive files in Giraffez archive format using a Writer, yielding row counts as chunks are written.
11243	Sets the current encoder output to Python string format and returns a row iterator with specified delimiter and null value representation.
11244	Converts a string with optional k, M, G, T multiplier to a float value. Parses the numeric portion and applies the corresponding multiplier if present, raising ValueError for invalid inputs or unknown multipliers.
11245	Converts a string representation of amplification element gains into a dictionary mapping element names to their float values. Splits the input string by commas to separate individual gain entries, then splits each entry by '=' to separate the amplifier name from its value, converting the value to float and storing in a dictionary. Returns an empty dictionary if input string is empty.
11246	Convert string with SoapySDR device settings to dict
11247	Wrap text to terminal width with default indentation using TextWrapper.
11248	Detects and returns available SoapySDR devices, returning both a list of devices and formatted text listing them, or indicates if no devices are found.
11249	Sets the center frequency and initializes PSD state data, including frequency array calculation and clearing averaged power data. Returns a dictionary containing PSD state information with update lock and futures list.
11250	Return frequency array and averaged PSD for given center frequency, with optional cropping, normalization by repeats, and log scaling.
11251	Wait for all PSD threads to finish and return the aggregated result. If multiple futures exist, wait for all using concurrent.futures.wait(). If only one future exists, block on that future's result. Finally, return the computed result using the class's result() method.
11252	Computes PSD from input samples using Welch's method and updates the running average PSD estimate for a given frequency bin. Uses a lock to ensure thread-safe updates to the PSD state, handling DC removal if specified. The method accumulates power spectral density values across multiple calls, initializing the accumulator on first use.
11253	Reads data from a file-like object, validates magic bytes, parses header information, and extracts a power array of float32 values. Returns a tuple containing the parsed header and the power array, or None if end of file is reached. Raises ValueError if magic bytes don't match expected value.
11254	Writes data to a file-like object including magic header and power array data.
11255	Submits a callable to be executed with the given arguments and tracks the maximum work queue size reached in ThreadPoolExecutor.max_queue_size_reached.
11256	Convert integration time to number of repeats based on device sample rate and bins.
11257	Returns a list of frequencies for frequency hopping within the specified range, calculating hop sizes and positions based on sample rate, bin size, and overlap parameters, with optional detailed logging of the frequency plan calculation.
11258	Creates a buffer for reading samples with specified parameters, calculating optimal buffer size based on bins, repeats, and base buffer size, while respecting maximum buffer size limitations. Returns tuple of (buffer_repeats, buffer_array) with logging information about the buffer configuration.
11259	Setup method prepares sample buffer and starts streaming from device with specified parameters including buffer configuration, PSD calculation settings, and output writer initialization.
11260	Stop streaming samples from device and delete samples buffer by stopping the device stream, closing the writer, and clearing all buffer and related attributes.
11261	Method `psd` tunes to a specified center frequency and computes the Power Spectral Density. It first checks if streaming is initialized, then performs frequency tuning by deactivating and reactivating the stream if necessary, with optional delay after tuning. It acquires samples multiple times based on buffer repeats, updates the PSD computation asynchronously, and returns the PSD future result along with acquisition start and stop timestamps.
11262	Sweep spectrum using frequency hopping over a specified frequency range, acquiring PSD data at each frequency point, and writing results asynchronously while managing system resources and time limits.
11263	Sets the I2C address for the device if it differs from the current address, using the SMBUS.I2C_SLAVE ioctl command.
11264	Summary: The `run_cmake` function is designed to configure and build the zql project using CMake. It first checks if CMake is installed and exits with an error message if it's not available. It then creates a build directory, changes to it, and runs CMake with the provided arguments, followed by running `make clean` and `make` to compile the project. If any errors occur during the build process, it prints helpful error messages and exits.
11265	Filter a set of datetimes to return approximately `number` units of time before `now`, keeping only the first datetime of each unit and preserving future datetimes.
11266	Return a datetime with the same value as ``dt``, to a resolution of days by setting time components to zero.
11267	Returns a datetime rounded to the nearest week boundary, where the week starts on the specified firstweekday (default Saturday). The returned datetime has time set to 00:00:00.000000.
11268	Return a set of datetimes that should be kept based on time filters, keeping up to specified years, months, weeks, days, hours, minutes, and seconds in the past, with optional reference point and weekday preference for weeks.
11269	Return a set of datetimes that should be deleted from the input set, based on the specified time offsets. The function calculates which datetimes should be removed by subtracting the datetimes that should be kept (determined by to_keep) from the original set of datetimes.
11270	Return a set of dates that should be kept, out of ``dates``, based on the specified time intervals (years, months, weeks, days) and weekday criteria.
11271	Return a set of dates that should be deleted from the input dates set, based on the specified time-based filtering criteria (years, months, weeks, days) and weekday constraints. The function determines which dates to keep using the `dates_to_keep` function and returns the difference from the original dates set.
11272	Returns an SPI control byte for the MCP23S17 slave device by combining fixed bits (0x40), hardware address bits, and read/write command bits into a single byte.
11273	Returns the specified bit value from the given address by reading the address and applying a bit mask.
11274	Writes a specified value to a particular bit position at the given memory address by using bitwise operations with a generated bit mask.
11275	Returns the lowest bit number from a given bit pattern, or None if no bits are set. The function shifts the bit pattern right until it finds the first set bit (1), counting the positions shifted to determine the bit number. If no bits are set, it returns None. If the bit number exceeds 7, it resets to 0 and breaks.
11276	Waits for port events on a specified GPIO port, detecting interrupts from an MCP23S17 chip and adding corresponding events to a queue. Handles keyboard interrupts gracefully based on a flag and uses epoll for efficient event waiting. The function continuously monitors interrupt flags and captures interrupt data to create InterruptEvent objects, which are then added to the provided event queue.
11277	Waits for events on the event queue and calls registered functions that match each event. Returns when the terminate signal is received. Uses function_maps to determine which functions to call for each event based on event_matches_function_map.
11278	Bring a GPIO interrupt pin into Linux userspace by exporting it if not already exported, then waiting for the device file to be created.
11279	Set the GPIO interrupt edge configuration with retry logic until timeout.
11280	Wait until a file exists by continuously attempting to open it with a timeout limit. Raises a Timeout exception if the file doesn't exist within the specified time limit.
11281	Registers a pin number and direction to a callback function with optional settle time for event handling.
11282	De-registers callback functions from the pin function maps. If no pin number is provided, all functions are de-registered. If a pin number is provided, all functions for that pin are de-registered. If a direction is also specified, only functions matching both the pin number and direction are de-registered.
11283	Enables GPIO interrupts by bringing the GPIO interrupt into userspace and setting the GPIO interrupt edge. Raises InterruptEnableException with detailed error message if a Timeout occurs during the process.
11284	Sends bytes via the SPI bus and returns the bytes received from the SPI device.

**Parameters:**
- `bytes_to_send` (bytes): The bytes to send on the SPI device.

**Returns:**
- bytes: Returned bytes from SPI device.

**Raises:**
- InitError: If SPI device is not initialized.
11285	Renders a tabbed interface by processing form fields and their associated tabs, generating both tab links and content sections, and returning the rendered HTML using a specified template. The method handles tab activation, unique ID generation for accordion groups, and passes the form instance to each tab's render_link method.
11286	Check if any field in the form's errors exists in the current object's fields.
11287	Render the link for the tab-pane using a template, updating CSS class with 'active' if needed.
11288	Extract package version from installed distribution or setup.cfg configuration file if not installed.
11289	Pass template pack argument by updating form kwargs with foundation version pack information.
11290	Check the status of the incoming response and raise appropriate exceptions based on the status code. Raises BadRequestException for 400, PermissionDeniedException for 403, FileNotFoundException for 404, UnavailableForLegalReasonsException for 451, BandwidthUsageExceeded for 509, and ServerErrorException for 500 and above status codes. Returns None.
11291	**Summary:**

The `_get` method performs a GET request to the specified URL with optional parameters. It automatically includes authentication credentials (login and key) in the request parameters, sends the request using the `requests` library, and processes the JSON response through the `_process_response` method before returning the results.

**Key details:**
- **Purpose:** Makes authenticated GET requests to API endpoints
- **Parameters:** 
  - `url` (str): Relative API endpoint path
  - `params` (dict, optional): Additional parameters to include in request
- **Returns:** Processed JSON response from the GET request
- **Authentication:** Automatically adds login and key credentials to all requests
- **Error handling:** Relies on `_process_response` for handling response processing and potential errors
11292	Requests direct download link for a file using a preparation ticket. Makes a GET request to 'file/dl' endpoint with ticket and file_id parameters, and optionally includes captcha_response if provided. Returns a dictionary containing file information and download URL.
11293	Makes a request to prepare for file upload, returning upload URL and expiration time. Optionally specifies folder ID, expected SHA1 hash, and HTTP-only protocol. If no folder ID provided, uploads to Home folder. Returns dictionary with 'url' and 'valid_until' keys.
11294	Uploads a file to a specified folder using the OpenLoad service. Calls upload_link internally to obtain the upload URL, then performs a POST request with the file content. Returns detailed information about the uploaded file including its ID, name, size, content type, SHA1 hash, and download URL. If no folder_id is provided, uploads to the Home folder. Supports optional SHA1 validation and HTTP-only upload links.
11295	Method: `remote_upload`

Description: Initiates a remote file upload to openload.co by downloading a file from a provided URL.

Parameters:
- `remote_url` (str): Direct link of the file to be remotely downloaded and uploaded
- `folder_id` (str, optional): Folder ID where the file should be uploaded (defaults to "Home" if not provided)
- `headers` (dict, optional): Additional HTTP headers for the request (e.g., Cookies, Authentication)

Returns: Dictionary with keys "id" (uploaded file ID) and "folderid" (folder ID)

Example return value:
```json
{
    "id": "12",
    "folderid": "4248"
}
```

Implementation: Sends a GET request to 'remotedl/add' endpoint with parameters including the remote URL and optional folder ID and headers.
11296	Checks the status of remote file uploads with optional limits and specific upload ID filtering, returning a dictionary of upload information including status, progress, and metadata.
11297	Lists files and folders in a specified folder, or the Home folder if no folder_id is provided. Returns a dictionary with "folders" and "files" keys containing respective lists of folder and file information.
11298	Shows running file conversions by folder.

Args:
    folder_id (str, optional): ID of the folder to list conversions for. If not provided, uses the Home folder.

Returns:
    list: List of dictionaries containing file conversion information including name, ID, status, progress, and links.
11299	Calculates relative humidity using the formula from weatherwise.org based on temperature and dewpoint inputs. Converts Fahrenheit to Celsius, then applies the humidity calculation formula. Returns the relative humidity value.
11300	This function calculates the dew point temperature in Fahrenheit using a formula from weatherwise.org. It takes temperature in Fahrenheit and humidity percentage as inputs, converts Fahrenheit to Celsius, applies the dew point calculation formula with multiple polynomial terms, then converts the result back to Fahrenheit before returning it.
11301	Method to perform HTTP session transmission of defined weather values by calling internal publish method with args, server, and URI parameters.
11302	Calculates and returns the CRC value from raw serial data using a lookup table approach.
11303	Function `verify` performs a CRC check on input data and returns `True` if the CRC is valid (equals zero), `False` otherwise. It handles empty data by returning `False` and logs CRC status.
11304	Unpacks a packed storm date field into 'YYYY-MM-DD' string format by extracting 7 bits for year (plus 2000), 5 bits for day, and 4 bits for month from the given integer date value.
11305	Method `_use_rev_b_archive` determines whether a weather station returns Rev.B archives by examining the 'RecType' field in unpacked archive data. It first checks if the archive revision has already been determined (cached in `self._ARCHIVE_REV_B`). If not, it unpacks data from the given records at the specified offset using `ArchiveBStruct`, checks the `RecType` field, and sets the revision accordingly (0 indicates Rev.B, otherwise Rev.A). The method caches and returns the result, logging the detected revision level.
11306	Method `_wakeup` sends a wakeup command to a device to exit standby mode. It writes newline characters to the port 3 times, reads the acknowledgment response each time, and checks if it matches the expected wakeup acknowledgment string. If the correct acknowledgment is received within 3 attempts, the method returns successfully. If not, it raises a `NoDeviceException` indicating the weather station cannot be accessed. The method logs the wakeup command sent and the raw data read during the process.
11307	Send a command to the device with optional arguments, expecting either an ACK or OK response. Returns if successful, raises NoDeviceException if communication fails after 3 attempts.
11308	Method: `_dmpaft_cmd`

Summary: Issues a command to read archive records from a device after a specified timestamp. The method sends a 'DMPAFT' command followed by a timestamp and CRC, then reads back pre-amble data and page records. It verifies CRC checksums for each data block, handles acknowledgments, and collects valid archive records into a list. The method returns a list of archive records that have valid date and time stamps.

Parameters:
- `time_fields`: A tuple of 2 unsigned shorts representing the timestamp fields

Returns:
- List of archive records with valid date/time stamps, or None if communication fails

Side effects:
- Sends commands and data through serial port
- Reads data from serial port
- Logs raw data transmission and reception
- Logs informational messages about reading pages and records
- May send ESC and ACK commands during error handling
11309	Returns a dictionary of fields from the newest archive record in the device, or None if no new records are available. Raises NoDeviceException if weather station cannot be accessed.
11310	Method that reads and parses data from console input, processes it through multiple helper methods, and stores the resulting fields in the instance variable.
11311	Function `weather_update(station, pub_sites, interval)` serves as the main execution loop that queries weather data from a station, performs sanity checks, calculates wind gust values, and posts the weather information to multiple online publishing sites. It parses the station data, validates temperature readings, computes wind gust and direction using `WindGust.get()`, then iterates through each publishing site to set the weather data fields and publish to the service. If any publishing attempt fails, it logs a warning message but continues attempting the remaining publishers. The function includes error handling to ensure all publishers are attempted even if one fails, and raises a `NoSensorException` if temperature readings exceed 200F.
11312	Initialize system logging with specified verbosity level, setting up both syslog and optional console output with configurable debug level.
11313	Creates publication service instances using configuration options, returning a list of configured service objects.
11314	Return gust data if it exceeds the threshold and is within the reporting window period, otherwise return no value.
11315	Method: set
Summary: Sets weather data parameters for publishing to a server. Accepts various weather metrics like pressure, temperature, humidity, wind speeds/directions, rain measurements, and cloud cover. Parameters not explicitly set will be reset and excluded from server transmission. Unknown keyword arguments are silently ignored to accommodate different publisher field support. Uses the Weather Underground PWS upload protocol format.
11316	Stores keyword arguments to be written to output file by assigning them to self.args and logging the arguments.
11317	Writes output file by iterating through arguments, formatting each key-value pair, and appending formatted values to the file.
11318	Helper decorator for transitioning to user-only requirements that passes request context internally to requirements, intended only for transitional use until flask-allows 1.0.
11319	Initializes the Flask-Allows object against the provided application by setting up extensions and registering before/after request handlers to manage context overrides and additional data.
11320	Checks if the provided or current identity meets all the given requirements, taking into account additional and overridden requirements where overrides take precedence. Returns True if all requirements are met, False otherwise.
11321	Pushes an override to the current context, optionally combining it with parent overrides. If `use_parent` is True and there's a current override, creates a new combined override; otherwise uses the provided override directly. The override is then pushed onto the context stack.
11322	Pops the latest override context from the stack, raising a RuntimeError if the context was not pushed by this manager.
11323	A context manager method that temporarily pushes an override context, yields the new context to the following block, then pops the context.
11324	Pushes an additional onto the context stack, optionally combining it with the current additional from the parent context.
11325	Pops the latest additional context from the stack, raising a RuntimeError if the context was not pushed by the current manager.
11326	A context manager method that temporarily adds additional context, yields the new context, then restores the previous context.
11327	Append a number to duplicate field names to make them unique.
11328	Generates a string summarizing the results of a Cypher query execution, showing either the number of rows affected or detailed statistics including update counts and other metrics.
11329	Extracts valid JSON serializable parameters from user namespace for Neo4j queries, filtering out non-serializable values.
11330	Executes a Cypher query against a Neo4j database and returns results in various formats (raw data, ResultSet, DataFrame, or NetworkX graph) based on configuration options. Handles connection management, parameter extraction, and supports auto-conversion to pandas DataFrames or NetworkX graphs.
11331	Returns a Pandas DataFrame instance built from the result set, raising ImportError if Pandas is not installed.
11332	Returns a NetworkX multi-graph instance built from the result set, with optional directed or undirected graph creation.
11333	Generates a pie chart from the result set using matplotlib. Takes numerical values from the rightmost column and uses other columns for labels. Requires matplotlib to be installed and properly configured for IPython notebooks. The chart can be customized with a title and additional matplotlib parameters. Raises ImportError if matplotlib is not available.
11334	Generates a pylab plot from the result set using matplotlib. Takes the first and last columns as X and Y values, with columns between ignored. Requires matplotlib to be installed. Additional keyword arguments are passed through to matplotlib.pylab.plot. Returns the plot object. Raises ImportError if matplotlib is not available.
11335	Generates a pylab bar plot from the result set using matplotlib. Requires matplotlib installation and IPython Notebook inlining. Uses the last quantitative column as Y values and other columns for X-axis labels. Accepts customizable title and separator for labels, plus additional matplotlib keyword arguments. Raises ImportError if matplotlib is not available. Returns the plot object.
11336	Generates CSV formatted results, writing to a file if filename is provided or returning as string otherwise. Uses UnicodeWriter with specified format parameters and includes field names as header row.
11337	A re-implementation of the permission_required decorator that respects application settings. If DASHBOARD_REQUIRE_LOGIN is False, it always returns True; otherwise, it checks for the specified permission. It can either raise a PermissionDenied exception or return False (which typically triggers a login redirect) when permissions are insufficient.
11338	Adds ``is_rendered`` flag and widget context data to the template context, indicating whether the AJAX view has been called and signaling that full widget rendering is occurring.
11339	Returns the widgets sorted by position as a list of tuples containing (widget_name, widget, position).
11340	Returns all widgets that need an update by checking each widget's should_update() method. Scheduled to run every minute via crontab.
11341	Registers a widget class that must inherit from DashboardWidgetBase, validates it's not already registered, and stores it with its name as key. Raises ImproperlyConfigured if widget_cls doesn't inherit DashboardWidgetBase, or WidgetAlreadyRegistered if widget with same name already exists.
11342	Unregisters a widget class by removing it from the widgets dictionary using its instance's name as key.
11343	Gets or creates the last update object for this widget by retrieving or creating a DashboardWidgetLastUpdate instance based on the widget's name.
11344	Returns the setting value for this widget from the database by looking up the setting name, or returns the provided default value if the setting doesn't exist.
11345	Saves a setting value to the database, creating a new record if it doesn't exist or updating the existing record if it does. Returns the setting object.
11346	Checks if an update is needed by comparing the time since last update with the configured update interval. Returns True if an update is overdue, False otherwise.
11347	Create a spark bolt array from a local array by distributing it along specified axes using Spark RDD.
11348	Create a spark bolt array of ones with specified shape, context, axis distribution, data type, and number of partitions.
11349	Concatenates two BoltArray objects along a specified axis, where at least one array must be a Spark array. Takes a tuple of two arrays (at least one being a BoltArraySpark) and an optional axis parameter, returning a BoltArraySpark object. Raises ValueError if inputs are invalid or if neither array is a Spark array, and NotImplementedError if more than two arrays are provided.
11350	Check that arguments are consistent with spark array construction, verifying conditions: (1) positional argument is SparkContext, (2) keyword arg 'context' is SparkContext, (3) argument is BoltArraySpark, or (4) nested list containing BoltArraySpark.
11351	Formats target axes given an array shape by converting int, list, or iterable axes to a tuple and validating that all axes are within the valid range [0, len(shape)-1]. Raises ValueError for invalid axes specifications or out-of-bounds axes.
11352	Wrap an existing numpy constructor in a parallelized construction by creating a distributed RDD of arrays with specified shape and dtype.
11353	Align local bolt array so that specified axes for iteration are moved to the front of keys, transposing and reshaping the underlying array to ensure functional operators can be applied over the correct records. Returns a new BoltArrayLocal with aligned axes.
11354	Converts a BoltArrayLocal into a BoltArraySpark by using the provided SparkContext to create a distributed array, parallelizing across the specified axis.
11355	Converts a BoltArrayLocal into an RDD by creating a BoltArraySpark object and calling its tordd method.
11356	Stacks records from an RDD into lists of keys and ndarrays along a new dimension, with optional batching by size.
11357	Apply a function to each subarray and return a new StackedArray with the transformed data.
11358	Split values of distributed array into chunks along specified axes with optional padding, returning a new distributed array with chunked data structure.
11359	Apply a function to each subarray of a ChunkedArray, potentially changing the shape of unchunked dimensions while preserving chunked dimensions. The method validates that chunked dimensions maintain their size and that no dimensions are dropped. It returns a new ChunkedArray with the transformed data and updated shape information.
11360	Apply a generic function to each subarray, returning a BoltArraySpark with object dtype where blocked dimensions are replaced with block ID indices.
11361	Identifies an optimal chunking plan for array dimensions based on specified size constraints and padding requirements. Returns a tuple containing the chunk plan and padding array.
11362	Remove padding from chunks along specified axes based on padding scheme and chunk index.

Parameters:
- idx: tuple or array-like, the chunk index
- value: ndarray, the chunk data
- number: ndarray or array-like, number of chunks along each dimension
- padding: ndarray or array-like, padding scheme
- axes: tuple, optional, axes along which to remove padding (default: all axes)

Returns:
- ndarray, chunk with padding removed along specified axes
11363	Get the number of chunks for given chunk plan and array shape by calculating how many chunks fit along each dimension.
11364	Function `getslices` calculates slice objects for chunking arrays with specified padding. It takes three parameters: `plan` (chunk sizes per dimension), `padding` (overlap sizes per dimension), and `shape` (dimensions of the array to be chunked). The function returns a list of slice lists, where each inner list contains the slices needed to extract chunks along a specific dimension, accounting for padding between chunks. For each dimension, it computes the number of full chunks and handles any remainder elements separately, ensuring proper overlap between adjacent chunks.
11365	Get a binary mask of length n with specified indices set to True.
11366	Repartition the underlying RDD to the specified number of partitions and return a new instance with the repartitioned RDD.
11367	Aggregates records of a distributed array into a StackedArray object for improved vectorized operation performance, with optional size parameter to control stacking granularity.
11368	Align spark bolt array so that specified axes for iteration are moved to keys. Validates axes and swaps key/value axes accordingly before functional operations. Returns self if no swapping needed, otherwise returns result of swap operation.
11369	Return the first element of an array by getting the first value from the RDD, sorting by key if the array is not ordered.
11370	Compute a statistic over a specified axis using either a custom function or a named statistic. Supports reduction operations across specified axes and can maintain dimensions of the result.
11371	Return the mean of the array over the given axis.
11372	Return the variance of the array over the given axis.
11373	Returns the standard deviation of the array over the given axis, with options to specify which axis to compute over and whether to keep dimensions.
11374	Return the sum of the array over the given axis. Parameters: axis (tuple or int, optional, default=None) - Axis to compute statistic over, if None will compute over all axes; keepdims (boolean, optional, default=False) - Keep axis remaining after operation with size 1. Returns: Sum of the array over the specified axis.
11375	Return the maximum of the array over the given axis.
11376	Return the minimum of the array over the given axis. Parameters: axis (tuple or int, optional, default=None) - Axis to compute statistic over, if None will compute over all axes; keepdims (boolean, optional, default=False) - Keep axis remaining after operation with size 1. Returns the minimum value(s) along the specified axis.
11377	Chunks records of a distributed array by breaking them into subarrays with specified chunk sizes along given axes, supporting both explicit chunk tuples and kilobyte-based sizing with optional padding overlaps between chunks.
11378	Swap axes between keys and values in a Spark BoltArray, moving specified axes from keys to values and/or values to keys. Supports chunked data operations with configurable chunk sizes. Returns a new BoltArray with the axis swap applied. Raises ValueError if swap would consolidate all data to a single key.
11379	Transpose an array by rearranging its axes according to the specified permutation, handling key/value axis swaps efficiently.
11380	Return the array with two axes interchanged by swapping their positions in the axis order and transposing accordingly.
11381	Return an array with the same data but a new shape, supporting independent reshaping of keys, values, or both, while raising NotImplementedError for reshaping between keys and values for BoltArraySpark.
11382	Check if a requested reshape can be broken into independent reshapes on keys and values. Returns the index in the new shape separating keys from values if possible, otherwise returns -1.
11383	Remove single-dimensional axes from the array along specified dimensions.
11384	Cast the array to a specified type.

Parameters
----------
dtype : str or dtype
    Typecode or data-type to cast the array to (see numpy)
casting : str, optional
    Casting rule (default is 'unsafe')

Returns
-------
Series or DataFrame
    Same type as caller with values cast to specified dtype
11385	Clip values above and below the specified minimum and maximum thresholds, broadcasting arrays as needed.
11386	Returns the contents as a local array by collecting RDD values and reshaping to the object's shape. May cause memory issues for large objects.
11387	Convert singletons, lists, and ndarrays to tuples while preserving existing tuples. Returns None for None input, wraps single non-container items in tuples, and converts lists/ndarrays to tuples. Iterable objects (except strings) are also converted to tuples, while existing tuples are returned unchanged.
11388	Coerce a list of arguments to a tuple, handling nested tuples, iterables, and basic sequences. If the first argument is a tuple, list, or ndarray, it uses tupleize to convert it. If it's an iterable (but not a string), it converts it to a list first then to a tuple. Otherwise, it directly converts the arguments to a tuple.
11389	Checks if specified axes are valid for a given array shape, raising ValueError if any axis is out of bounds.
11390	Test that arrays a and b are close and match in shape, returning True if both shape and value closeness conditions are met.
11391	Converts a list of integer indices into a flattened array and validates that all indices are within specified bounds. Raises ValueError if indices are not integers or exceed the given dimension limits.
11392	Force a slice to have defined start, stop, and step from a known dimension. Converts integers to slices and handles negative indices and boundary overflow conditions. Returns a normalized slice object with proper bounds enforcement.
11393	Check if a proposed tuple of axes is a valid permutation of an old set of axes by verifying length, axis repetition, and bounds.
11394	Check if a proposed tuple of axes is a valid reshaping of the old axes by ensuring they have the same total size.

Parameters:
- new: tuple of proposed axes
- old: tuple of old axes

Raises:
- ValueError: if total size of new keys must remain unchanged

Returns:
- None (raises exception if validation fails)
11395	Function that reconstructs an original ndarray from its chunked components by recursively concatenating nested lists of arrays along specified axes.
11396	Expand dimensions by iteratively appending empty axes.

Parameters:
----------
arry : ndarray
    The original array
extra : int
    The number of empty axes to append

Returns:
-------
ndarray
    The array with additional empty axes appended iteratively
11397	Returns a tuple of (count, RDD) where each element in the RDD is paired with its global index, with eager count calculation. The function efficiently computes the starting index for each partition and maps each element to (value, global_index) pairs across all partitions.
11398	A decorator function that enhances docstrings by appending information about local and spark implementations. It extracts function signatures including default arguments and formats them into the docstring, showing how the function behaves in both local and spark contexts. The decorator retrieves argument specifications using `inspect.getargspec()`, processes default values, and constructs formatted parameter strings for both `ConstructLocal` and `ConstructSpark` classes.
11399	Function that routes constructor based on arguments by checking keyword arguments and applying constructor-specific checks.
11400	Reshape the keys of a BoltArraySpark to a new dimensionality while preserving the values, returning a new BoltArraySpark with the specified shape. The operation maps each key to its new position in the reshaped array structure.
11401	Transpose the keys of a BoltArraySpark by rearranging their dimensions according to the specified axes, returning a new BoltArraySpark with transposed keys while preserving the values structure.
11402	Reshapes the values of a BoltArraySpark to a new shape and returns a new BoltArraySpark object with the reshaped data.
11403	Transpose the values of a BoltArraySpark by rearranging axes and return a new BoltArraySpark with the specified axis ordering.
11404	Create a local bolt array filled with ones using specified shape, data type, and order parameters.
11405	Create a local bolt array filled with zeros, similar to numpy's zeros function but wrapped in a BoltArrayLocal object.
11406	Join a sequence of arrays together along a specified axis.

Parameters:
- arrays: tuple of array-like objects to be joined
- axis: int, optional (default=0) - the axis along which to join

Returns:
- BoltArrayLocal: the concatenated array

Raises:
- ValueError: if arrays is not a tuple

Example:
```python
# Concatenating arrays along axis 0 (default)
result = concatenate((array1, array2, array3))

# Concatenating arrays along axis 1
result = concatenate((array1, array2), axis=1)
```
11407	Computes the log-likelihood for a discrete power-law distribution using Equation B.8 from Clauset et al. Given data, minimum value (xmin), and scaling parameter (alpha), it calculates the likelihood to be maximized. Requires scipy for the zeta function computation.
11408	Returns the alpha value that maximizes the likelihood for given data and xmin by evaluating the likelihood function across a range of alpha values and selecting the one with maximum likelihood.
11409	Method: discrete_alpha_mle

Purpose: Computes the Maximum Likelihood Estimator (MLE) of the scaling parameter alpha for discrete data following the method described in Clauset et al. 2009 (Equation B.17).

Parameters:
- data: array-like, input data values
- xmin: float, minimum value threshold for data

Returns: float, the estimated alpha parameter, or 0 if insufficient data points (less than 2) remain after applying the xmin threshold

Process: 
1. Filters data to include only values greater than or equal to xmin
2. Checks if at least 2 data points remain; returns 0 if not
3. Applies the MLE formula:  = 1 + n  (log(x/(xmin-0.5)))
4. Returns the calculated alpha value

Note: Uses the discrete case formula with a correction term (xmin-0.5) to account for discrete probability mass functions.
11410	Function to find the optimal alpha parameter for discrete data by maximizing the likelihood function within a specified range around the MLE estimate, using the Kolmogorov-Smirnov distance as the optimization criterion. Returns the best alpha value, corresponding xmin, KS distance, and likelihood value.
11411	Finds the maximum likelihood estimate of alpha for discrete data by minimizing the Kolmogorov-Smirnov distance between the empirical and theoretical distributions. It can use either an approximate or exact approach to determine the optimal alpha value within a specified range, with optional finite-size corrections and verbose output. Returns the best alpha, xmin, ksD statistic, and likelihood value.
11412	Plots power-law predicted values against real values to diagnose fit quality, with optional logarithmic scaling.
11413	Method: `lognormal(self, doprint=True)`

Summary: This method fits a lognormal distribution to the data using maximum likelihood estimation. It utilizes Scipy's lognormal fitting function to calculate the best-fit parameters and computes the negative log-likelihood. The method also performs a Kolmogorov-Smirnov test to assess the goodness-of-fit and calculates a likelihood ratio statistic to compare the lognormal fit against a power law distribution. When `doprint` is True, it outputs the KS test statistics, p-values, and likelihood ratio information. The method stores various statistical measures including the fitted distribution, KS test results, and likelihood values as instance attributes.
11414	Sanitizes HTML by removing unallowed tags and attributes, keeping only specified allowed tags and attributes. Returns the cleaned HTML as unicode.
11415	Configures Yandex Metrika analytics counter with given ID and optional parameters, appending the configuration to the analytics list.
11416	Generates a list of tuples containing tag names and their corresponding CSS classes ("selected taggit-tag" for previously selected tags, "taggit-tag" for others) by iterating through all model objects and checking if each tag name exists in the provided tags list.
11417	Calculate MD5 fingerprint of decoded key and return it in SSH fingerprint format (MD5:xx:xx:...).
11418	Calculate SHA256 fingerprint of decoded key and return as UTF-8 string with "SHA256:" prefix.
11419	Calculates the SHA512 fingerprint of the decoded key and returns it as a base64-encoded string prefixed with "SHA512:".
11420	Parse long integer from bytes data, handling two's complement calculation with Python 2/3 compatibility.
11421	Decodes a base64 encoded public key content into binary format, raising MalformedDataError if decoding fails.
11422	Parses an SSH options string into a dictionary format, handling quoted values and validating option names and values based on strict mode settings. Returns a dictionary mapping option names to their values, raising various exceptions for invalid syntax or unknown options.
11423	Parses SSH RSA public keys by unpacking and parsing the exponent and modulus, creating an RSA public key object and validating its bit length against configured minimum and maximum bounds based on strict mode settings.
11424	Parses SSH DSA public keys by unpacking and validating DSA parameters (p, q, g, y), checking bit lengths against configured constraints, and constructing a DSAPublicNumbers object from the parsed values. Raises appropriate exceptions for invalid key parameters, too short keys, or too long keys based on strict/loose mode settings. Returns the final position in the data buffer after processing.
11425	Processes ECDSA-SHA public keys by parsing curve information and key data, validating the curve type, extracting the verifying key, and storing the key and bit size information.
11426	Parses ed25519 keys by unpacking the verifying key from the given data, validating that the key is positive and exactly 256 bits long, and returns the current position after unpacking. Raises InvalidKeyError for negative keys and InvalidKeyLengthError for incorrect key lengths.
11427	Validates SSH public key data and populates key type, bits, and raw key fields. Supports both SSH1 and SSH2 key formats. Throws exceptions for invalid keys or mismatched key types. Returns None on successful validation.
11428	Performs a single step in the GSSAPI context establishment process as an initiator. It takes an optional input token from the acceptor, processes it using `gss_init_sec_context`, and returns the next token to send to the acceptor. The method should be called repeatedly until the context is established. It handles buffer management, error handling, and cleanup of GSS resources. Returns the output token or None if no further communication is needed, and raises GSSException on errors.
11429	Performs a single step in establishing a GSS context as an acceptor by processing an input token from the initiator and returning the next token to send, or None if no further communication is needed. Raises GSSException on error and handles cleanup of resources regardless of success or failure.
11430	Returns the set of mechanisms supported by the credential, loading them if necessary. The result is cached in `self._mechs` for subsequent calls.
11431	Stores this credential into a credential store, either the default one or a specified mechanism-specific store. Returns the set of mechanism OIDs for which credential elements were successfully stored and the usage of the stored credential. Raises GSSException on storage errors and NotImplementedError if the required C functions are not supported.
11432	Imports and runs setup function with given properties by calling init with options and custom_options, then applying the result to properties.
11433	Imports and returns a setup function with optional configurations for markdown README, stdeb packaging, and distribute support.
11434	Creates and returns a file handle for recording audio, setting up stereo channels, 16-bit samples, and default input sample rate. The file is automatically closed when done.
11435	Returns HTML5 Boilerplate CSS file as an HTML link tag, using the specified version or default settings.
11436	Returns a normalized CSS file for HTML5 Boilerplate, with an optional version parameter. If no version is specified, it uses the default version from settings (DJFRONTEND_NORMALIZE). The function returns an HTML link tag referencing the normalize.css file from the djfrontend CSS directory.
11437	Returns Font Awesome CSS file based on version and debug settings, using either full or minified version.
11438	Returns Modernizr JavaScript file based on version number, using either the full or minified version depending on TEMPLATE_DEBUG setting.
11439	Returns jQuery JavaScript file based on version number, using either local file (in debug mode) or Google CDN with local fallback.
11440	Returns jQuery UI plugin file based on version number. In debug mode returns full file, otherwise returns minified file from Google CDN with local fallback.
11441	Returns the jQuery DataTables plugin script tag based on version and debug settings, using either the full or minified version.
11442	Returns the jQuery DataTables CSS file according to version number, using either the provided version, a setting value, or the default version if none specified.
11443	Returns the jQuery DataTables ThemeRoller CSS file according to version number, using either a provided version, settings configuration, or default version, and formats it as an HTML link tag with the appropriate static URL and version path.
11444	Returns the jQuery Dynamic Formset plugin file URL based on version number and TEMPLATE_DEBUG setting. In debug mode, returns the full JavaScript file path; otherwise returns the minified version from CDN with fallback to local file.
11445	Returns the jQuery ScrollTo plugin file based on version number, using either the full or minified version depending on TEMPLATE_DEBUG setting.
11446	Returns the jQuery Smooth Scroll plugin file based on version number, using either the full or minified version depending on TEMPLATE_DEBUG setting.
11447	Returns Twitter Bootstrap CSS file. If TEMPLATE_DEBUG is True, returns the full CSS file; otherwise returns the minified version. Uses the specified version or falls back to default settings.
11448	Returns Google Analytics asynchronous snippet based on settings configuration for tracking.
11449	Render CodeMirrorTextarea by generating JavaScript code to initialize CodeMirror editor from textarea element with specified options.
11450	Generate authentication hashes for a user with a specified purpose that expire at midnight of the minute they're valid for.
11451	Returns the expiration time for an auth_hash by adding minutes_valid + 1 minutes to the current time and rounding down to the nearest minute.
11452	Return login token info for given user, including token ID, token string, and expiration time.
11453	Serialize a user object according to Meteor accounts format, including username, emails, profile, and permissions while removing sensitive data and handling creation date and email fields appropriately.
11454	Deserialize user profile fields into concrete model fields, handling only 'name' key with optional prefix and pop functionality.
11455	Updates user data by modifying profile fields and saving the changes to the database.
11456	**Summary:**

The `auth_failed` function provides a consistent authentication failure response that prevents attackers from gaining information about the authentication system. It optionally notifies about failed login attempts and raises a MeteorError with a 403 status code and "Authentication failed" message. The function cleans the provided credentials before sending the notification and handles both authenticated and unauthenticated scenarios uniformly to maintain security.
11457	Validates an authentication token by decoding it, resolving the associated user, and checking if the token hash is valid for the given purpose and time window, returning the user object if validation succeeds.
11458	Function `check_secure()` checks if a request is secure (using SSL) or from a local connection. It returns `True` if the request is secure or from localhost/127.0.0.1, otherwise it raises a `MeteorError` with a 403 status code indicating authentication refusal without SSL.
11459	Retrieve username from user selector, handling string usernames, dict lookups by username, email, or ID, and raising MeteorError for invalid inputs.
11460	Creates a new user account by sending a create_user signal, authenticating the user, logging them in, and returning a resume login token. Raises NotImplementedError if no handler is registered for create_user.
11461	Logs in a user by setting user ID and DDP ID, subscribing to LoggedInUser publication, updating subscriptions, and sending user logged in signal.
11462	Logout a user by silently unsubscribing from LoggedInUser pub, deleting user subscription ID, updating subscriptions to None, sending user logged out signal, and clearing user ID and DDP ID from the session.
11463	Method to handle user login by checking for password or resume token in parameters and calling appropriate login method, or triggering authentication failure if neither is present.
11464	Authenticate user with username and password, verify credentials, and return token if successful.
11465	Login with existing resume token, validating the token and returning a new user token. Raises ValueError("Login failed.") for invalid tokens.
11466	Change a user's password by authenticating with the old password and setting a new one, sending a password changed signal upon successful update.
11467	Request password reset email for a given username, generate a reset token, and send a password reset signal with token and expiry information.
11468	Reset password using a token and log the user in.
11469	**Summary:**

The `dict_merge` function performs a recursive merge of two dictionaries. It combines the contents of two dictionaries (`lft` and `rgt`), where if both dictionaries contain a key with dictionary values, the function recursively merges those nested dictionaries. Otherwise, it replaces the value from the left dictionary with the value from the right dictionary. The function uses `deepcopy` to avoid modifying the original dictionaries.
11470	Read encoded contents from specified path or return default value if path is invalid or file cannot be read. Handles IO errors gracefully by returning the default value or re-raising the exception.
11471	Returns an Alea ID for the given object by checking for AleaIdField uniqueness, falling back to ObjectMapping model lookup if needed.
11472	Return Alea ID mapping for all given ids of specified model, handling cases where primary key is an AleaIdField or when there are unique AleaIdFields in the model's local fields. For objects without existing meteor IDs, generate new ones using get_meteor_id function.
11473	Returns an object ID for the given meteor_id by checking if it's a primary key, finding unique AleaIdField, or looking up in ObjectMapping. Raises TypeError if trying to map ObjectMapping instances through themselves.
11474	Return all object IDs for the given meteor_ids by querying either unique AleaIdField fields or ObjectMapping table based on model configuration.
11475	Returns an object for the given meteor_id by checking if the model's primary key is an AleaIdField, if so uses it directly as the primary key. If not, it looks for unique AleaIdFields and uses the first one found. If no unique AleaIdField exists, it delegates to get_object_id to retrieve the object.
11476	Sets default AleaIdField values for existing model instances by updating each record with a generated meteor ID.
11477	Sets default reverse for AleaIdField by getting meteor ID for each object in the model.
11478	Truncates tables for the specified models in the given app label by executing TRUNCATE TABLE statements with RESTART IDENTITY CASCADE options.
11479	Method `database_forwards` applies forward changes to the database schema using the provided schema editor. It takes parameters including the application label, schema editor instance, current state, and target state. The method specifically truncates data using the `truncate` method with `truncate_forwards` as the truncation strategy.
11480	Method `database_backwards` applies reverse schema changes using the provided schema_editor. It calls the `truncate` method with the app_label, schema_editor, and truncate_backwards parameter to reverse the changes defined in the migration.
11481	Sets default values for command options including meteor executable path, debug flag, build directories, and build configurations.
11482	Update command options by setting undefined options from 'build' and 'build_py' commands, then call parent class finalize_options method.
11483	This method performs a Meteor application build process for multiple packages. For each package, it:

1. Determines source and target directories
2. Constructs an output directory path
3. Builds a command line for the meteor build command with appropriate arguments
4. Executes the meteor build command in the project directory
5. Optionally prunes unnecessary npm dependencies from the build output

The method handles debug mode, extra arguments, and cleanup of unused npm packages if configured.
11484	Converts a UNIX-style path into platform-specific directory specification by joining path arguments and splitting the last argument using POSIX path separator.
11485	Seeds the internal state of the object using the provided values. If no values are supplied, generates a secure seed using system time and random data. Initializes three internal state variables (s0, s1, s2) using a Mash hash function and updates them based on the input values to ensure proper randomization.
11486	Return internal state as a dictionary with keys 'c', 's0', 's1', and 's2', useful for testing purposes.
11487	Return a string of specified length by randomly choosing elements from the given alphabet.
11488	Decorator to mark a method as an API endpoint for later registration, with optional path specification and decorator application.
11489	Iterator over all API endpoint names and callbacks, yielding tuples of combined API paths and their corresponding callbacks from both the object's attributes and its API providers.
11490	Clears the API path map cache by setting the internal cache to None and calling the clear method on each API provider that implements it.
11491	Debug print function that outputs a formatted name and value pair, where the value is pretty-printed with indentation and line wrapping for better readability.
11492	Validates keyword arguments against a function's signature, checking for missing required arguments and extra unknown arguments, while handling reserved keyword names by translating trailing underscore variants. Raises MeteorError with descriptive messages for validation failures.
11493	Handle new websocket connection by initializing request, setting up message buffering, tracking remote connections, and sending initialization messages.
11494	Handle closing of websocket connection by cleaning up connection resources and sending finish signal.
11495	Process a message received from remote by parsing DDP frames and emitting request finished signal.
11496	Parse a raw WebSocket message containing DDP messages, validate the EJSON format, and yield individual DDP message payloads while handling parsing errors and yielding control to other greenlets between messages.
11497	Process a single DDP message by extracting the message and dispatching it, handling any exceptions that occur during dispatch and responding accordingly with appropriate error messages or results.
11498	Dispatches incoming messages to appropriate handler methods, enforcing that 'connect' is called first for non-connect messages, validating method calls with required 'method' and 'id' arguments, looking up handler methods with 'recv_' prefix, validating handler arguments, and executing the handler with provided keyword arguments.
11499	Handles DDP connect requests by establishing a new connection session, validating version and support parameters, creating a connection record in the database, and sending back a connection confirmation with session ID.
11500	DDP ping handler that responds with 'pong' message, optionally including the provided id_ in the response.
11501	DDP sub handler that calls the API subscription method with the provided parameters.
11502	DDP unsub handler that unsubscribes from a specific ID if provided, otherwise replies with 'nosub'.
11503	Handles DDP method calls by setting random seed if provided, executing the method through the API, and sending an update reply with the method ID.
11504	Returns WebSocket connection information to the client, including WebSocket support status, allowed origins, cookie requirement status, and random entropy value for security purposes.
11505	Function `serve` spawns greenlets to handle websockets and PostgreSQL calls with specified listening addresses, verbosity level, and SSL options. It sets up signal handlers for graceful shutdown on SIGINT and SIGQUIT, and optionally starts a debug backdoor server.
11506	This function serves as the main entry point for the `dddp` command, setting up command-line argument parsing for Django and HTTP/SSL configurations. It defines argument groups for Django options (verbosity, debug port, settings), HTTP options (listening addresses), and SSL options (version, certificate files, ciphers, CA certificates, key files). After parsing arguments, it sets the Django settings module from the command-line argument if provided, then calls a `serve` function with the configured parameters to start the server with specified listening addresses, debug port, SSL settings, and verbosity level. If no listening addresses are provided, it defaults to listening on localhost port 8000.
11507	Prints a formatted message if the verbosity level is set to 1 or above.
11508	Stop all green threads by setting a stop event, stopping each server in the servers list and DDPLauncher.pgworker, then waiting for all threads to complete their shutdown process.
11509	**Summary:** The `run` method executes the DDP greenlets by starting the process, waiting for a stop event, and then ensuring all threads and the PostgreSQL worker complete execution before clearing the threads list.
11510	Spawn sub tasks, wait for stop signal. Establishes a PostgreSQL connection with async support and application name, handles connection errors by ignoring invalid parameters, listens for "ddp" channel notifications, and waits for stop event while polling the connection. Closes the connection and cursor upon termination.
11511	Polls the database connection socket to process asynchronous tasks and notifications. When notifications are received, it processes them by reconstructing chunked data based on sequence numbers and forwards the complete data to connected websockets. Handles poll states for read/write operations and logs errors appropriately.
11512	Patches threading and psycopg2 modules to enable green threads support using gevent. Prevents double patching, warns if threading module is already loaded, applies monkey patching to all modules, attempts to use psycopg2 with fallback to psycopg2cffi, and finally patches psycopg to work with gevent's green threads.
11513	Generate a random ID string of specified length using either a thread-local random stream (if no name provided) or a named random stream, containing only characters from METEOR_ID_CHARS.
11514	Imports all `ddp` submodules from `settings.INSTALLED_APPS` and registers them with the API.
11515	Return an error dictionary containing the error, reason, and details from self.args, plus any additional keyword arguments.
11516	Get attribute, creating it with the provided factory if it doesn't exist. If the factory's `update_thread_local` flag is True (or if the attribute doesn't exist), the created object is stored in the instance. Returns the existing or newly created attribute.
11517	Emits a formatted log record via DDP by checking if subscription exists, formatting the record, generating a random ID, and sending the log data with typecasted attributes through a meteor connection.
11518	A middleware function that selects an appropriate renderer based on request content negotiation and renders handler data accordingly, returning a properly formatted aiohttp response with the correct content type.
11519	Context manager that provides a function for adding multiple routes to a web application from a given module, with optional URL and name prefixing.
11520	Add routes by an resource instance's methods.

Parameters:
- path: route path. Should be started with slash ('/').
- resource: A "resource" instance. May be an instance of a plain object.
- methods: Methods (strings) to register.
- names: Dictionary of 'name' overrides.
11521	Runs an `aiohttp.web.Application` using gunicorn with optional reloading and custom configuration.
11522	Sends a push notification to this device via GCM with the specified message and additional data.
11523	Sends an APNS notification to multiple registration IDs in bulk. Takes a list of registration IDs, notification alert message, and optional keyword arguments. Uses a socket connection to send notifications sequentially and checks for errors after sending all messages. The alert parameter should be a string, or None for silent notifications.
11524	Queries APNS server for inactive device IDs since last fetch by connecting to feedback service, receiving registration IDs, and returning them hex-encoded.
11525	Sends a single GCM notification using the provided registration ID and data through a GCMMessenger instance.
11526	Method to send bulk GCM notifications using a GCMMessenger instance. Takes registration IDs, notification data, and optional encoding/kwargs, then returns the bulk send result.
11527	Sends a JSON GCM message with optional registration IDs and data payload, handles failures by deactivating unregistered devices, and returns the push result.
11528	Sends a GCM message with the specified content type by creating an HTTP request with appropriate headers and returning the decoded response.
11529	Returns the instance of the given module location by dynamically importing the module and retrieving the specified class from it.
11530	Fast forward selection algorithm for reducing the number of scenarios while preserving their representative characteristics. The algorithm iteratively selects scenarios based on their distances and probabilities to create a reduced set. It returns the reduced scenarios, their updated probabilities, and the original scenario numbers in the reduced set. If the desired number of reduced scenarios is greater than or equal to the input scenarios, the original set is returned unchanged.
11531	Creates a Giphy API wrapper and calls its search method with the specified parameters, returning a generator of search results.
11532	Creates a Giphy API wrapper instance and calls its translate method with the provided parameters.
11533	Creates a Giphy API wrapper and returns a generator of trending GIFs with optional limit, rating, and strict parameters.
11534	Returns a Giphy API wrapper instance configured with the specified API key and strict mode settings, then calls its gif method with the provided gif_id parameter.
11535	Creates a Giphy API wrapper with the specified API key and calls the screensaver method, optionally filtering by tag.
11536	Uploads a file to Giphy with the specified tags and optional parameters using the Giphy API wrapper.
11537	Normalizes image data by converting specified string values to integers. Converts 'frames', 'width', 'height', and 'size' fields from strings to integers if possible, ignoring conversion errors. Returns the modified data dictionary.
11538	Method `_fetch` is a wrapper for making API requests to the Giphy API. It takes an endpoint name and optional parameters, adds the API key to the parameters, sends a GET request to the specified endpoint, validates the response status, checks for errors in the API response metadata, and returns the JSON data from the response.
11539	Translate a term or phrase into an animated GIF by retrieving a single image from the Giphy API. The method accepts either a term or phrase (but not both) and supports optional parameters for strict mode and rating limits. If no results are found and strict mode is enabled, a GiphyApiException is raised. The phrase parameter should have spaces replaced with dashes, and punctuation is ignored in the search. Returns a GiphyImage object if successful, otherwise raises an exception.
11540	Method to retrieve currently trending GIFs with optional rating filtering and result limiting.
11541	Retrieves a specific gif from Giphy based on unique ID. Returns a GiphyImage object if found, raises GiphyApiException if not found and strict mode is enabled.
11542	Uploads a GIF file to Giphy with specified tags and optional username, returning a GIF object.
11543	Prepares extension elements for YouTube video access control settings, supporting private and unlisted access levels, returning a tuple of extension elements.
11544	Authenticates a user with optional email, password, and source parameters, falling back to settings if parameters are not provided. Raises BadAuthentication exception for incorrect credentials.
11545	Method: upload
Description: Initiates a browser-based video upload by creating video metadata and returning upload parameters
Parameters:
- title (string): Video title (required)
- description (string): Video description (optional, default: "")
- keywords (string): Comma-separated keywords (optional, default: "")
- developer_tags (tuple): Developer tags (optional, default: None)
- access_control (AccessControl): Access control settings (optional, default: AccessControl.Public)
Returns: Dictionary containing 'post_url' and 'youtube_token' for upload
Throws: ApiError - when authentication is required but not provided
Authentication: Required - raises ApiError if not authenticated
Process: Creates media group with provided metadata, applies access control, builds video entry, gets upload token from YouTube service, and returns upload URL and token for browser upload form construction
11546	Checks the video upload status for a given video ID. Returns True if video is available, otherwise returns a dictionary containing the upload state and detailed message. Requires authentication.
11547	Updates a video entry with the specified parameters. Requires authentication and returns the updated video entry on success, None otherwise. Supports updating title, description, and access control settings.
11548	Deletes a video from YouTube.

**Parameters:**
- `video_id`: The ID of the video to delete

**Returns:**
- `True` if deletion is successful

**Raises:**
- `ApiError`: If the user is not authenticated
- `OperationError`: If the video cannot be deleted from YouTube

**Authentication:** Required
**Service:** YouTube Data API
11549	Checks video availability status and returns JSON response indicating whether the video is available or not based on its upload status.
11550	Displays a video in an embed player by checking video availability and rendering appropriate templates based on the video's upload state. If the video is unavailable or has failed/rejected status, it shows error pages. Otherwise, it renders the video player page.
11551	Displays a list of videos for a specified user. If no username is provided and the user is not authenticated, raises a 404 error. Retrieves videos belonging to the user and renders them using the 'django_youtube/videos.html' template.
11552	Direct upload method that handles video upload to server and then to YouTube. Takes a video file from POST request, saves it locally, uploads to YouTube via API, extracts video ID from YouTube response, creates Video instance with YouTube metadata, sends video_created signal, deletes temporary upload, and returns either JSON response with video_id or redirects to video display page. Includes error handling and supports optional 'only_data' parameter for JSON response.
11553	Displays an upload form and creates an upload URL and token from YouTube API for video upload. Handles API errors by redirecting to homepage with error message. Returns a form with token, post URL, and next URL for the upload process.
11554	**Method Summary:**

`upload_return` handles the YouTube upload completion page, saving successful uploads and redirecting users accordingly. It processes the upload status and video ID from the request parameters, creates a new video entry in the database for successful uploads, sends a signal, and redirects to either a configured redirect URL or the video page. For failed uploads, it displays an error message and redirects back to the upload page.
11555	Removes a video from YouTube and database, requires POST request, redirects to upload page or specified page after deletion.
11556	Method: `entry`
Description: Connects to YouTube API and retrieves the video entry object
Parameters: None
Returns: `gdata.youtube.YouTubeVideoEntry`
Implementation: Creates an Api instance, authenticates it, then fetches a video entry using the instance's video_id attribute
11557	Save video information by synchronizing with YouTube API, handling both new instance creation (fetching details from API and saving thumbnails) and updates (pushing changes to YouTube with authentication).
11558	Deletes a video from YouTube by authenticating with the API and sending a deletion request, then calls the parent class's delete method. Raises OperationError if deletion fails.
11559	Generic method for updating a resource's metadata via API PUT request to the resource's metadata endpoint, accepting metadata parameters and returning the API response.
11560	Generic method to update a resource's metadata field via API PUT request, supporting devices, distributions, and collections. Takes a field name and value as parameters and returns the API response. Raises HTTPError for request failures.
11561	Generic method for updating resource details via API endpoint, updating instance data with response and returning the updated data.
11562	Loads a list of trees from a Newick formatted string by splitting on semicolons and parsing each node with optional comment stripping.
11563	Serialize a list of trees in Newick format.

**Parameters:**
- trees: List of Node objects or a single Node object.

**Returns:**
- Newick formatted string.
11564	Loads a list of trees from an open Newick formatted file by reading the file contents and parsing them with the loads function, optionally stripping comments enclosed in square brackets.
11565	Loads a list of trees from a Newick formatted file by reading the file and parsing it with the load function, optionally stripping comments and passing additional keyword arguments to Node.create.
11566	Parse a Newick formatted string into a Node object, with optional comment stripping and additional keyword arguments passed to Node.create.
11567	Create a new `Node` object with specified properties and descendants.

**Parameters:**
- `name` (str, optional): Node label
- `length` (float, optional): Branch length from node to parent  
- `descendants` (list, optional): List of descendant nodes to add
- `**kw`: Additional keyword arguments passed to `Node.__init__`

**Returns:**
- `Node` instance

**Behavior:**
- Creates a new node with given name and length
- Adds all descendants from the descendants list using `add_descendant()`
- Returns the fully constructed node object
11568	Returns the Newick format representation of the Node, including its label (name and branch length) and descendants in parentheses.
11569	Return a unicode string representing a tree in ASCII art fashion with optional strict ASCII characters and internal node visibility control.
11570	Method `get_node` searches for a node with the specified label/name within the tree structure and returns the node object if found, otherwise returns None. The method iterates through all nodes in the tree using the `walk()` iterator and compares each node's name attribute with the provided label.
11571	Remove nodes from the tree structure based on a list of leaves, either pruning specified nodes or their complement depending on the inverse flag, while ensuring the root node remains untouched.
11572	Resolves polytomies in a tree by inserting additional zero-length nodes to convert the tree into a fully resolved binary tree where all non-leaf nodes have exactly 2 descendants.
11573	Remove internal node names by setting them to None.
11574	Remove all leaf node names in the subtree by setting them to None.
11575	Decorator that protects methods with HTTP authentication by requiring valid authentication before executing the decorated function.
11576	Clear all comments in a JSON string by removing JS-style comments like // and /**/, while preserving string literals and handling escape sequences correctly. Returns the cleaned string with comments removed.
11577	**Summary:** Checks if a required application setting is defined, raising an exception with a descriptive message if the setting is missing. The method takes two parameters: `name` (the setting name to check) and `feature` (optional description of the feature requiring the setting) and raises an `Exception` if the setting is not found in `self.settings`.
11578	Returns the value of the argument with the given name, raising an HTTP 400 exception if it's missing and no default is provided. If the argument appears multiple times, returns the last value. The returned value is always unicode.
11579	Returns a list of arguments with the given name from request parameters, decoding and optionally stripping each value. Returns empty list if argument not present. All returned values are unicode strings with control characters removed.
11580	Obsolete - catches exceptions from the wrapped function. This function is unnecessary since Tornado 1.1. Returns the callback unchanged, or a partial callback with args/kwargs prepended if provided.
11581	Gets the value of the cookie with the given name, else returns the default value. Asserts that the cookie monster is set.
11582	Deletes the cookie with the specified name using the cookie monster.
11583	Returns the authentication URL for this service and redirects to it. The URL includes parameters for OpenID authentication and requests specified user attributes (name, email, language, username by default) via OpenID Attribute Exchange. After authentication, the user will be redirected back to the provided callback URI.
11584	Gets the OAuth authorized user and access token on callback. This method should be called from the handler for your registered OAuth Callback URL to complete the registration process. We call callback with the authenticated user, which includes the 'access_key' attribute containing the OAuth access token for authorized requests on behalf of the user.
11585	Returns the OAuth parameters as a dictionary for a given request, including base OAuth arguments and a calculated signature.
11586	Authenticates and authorizes access to Google resources using OAuth2 redirect. Allows authorization for various Google services like Gmail, Calendar, and Finance by specifying resource URLs separated by spaces. Uses OpenID Connect endpoint for authentication flow.
11587	Makes a Facebook API REST request with automatic inclusion of API key, signature, and other required parameters, handling the response asynchronously through a callback.
11588	Handles Facebook user login by exchanging an authorization code for an access token and returning user information. Takes redirect URI, client ID/secret, authorization code, and callback function as parameters, then fetches user data from Facebook's Graph API using the obtained access token.
11589	Concatenate a URL with a dictionary of query arguments, handling existing query parameters correctly by adding '?' or '&' as needed, and using urllib.urlencode to format the arguments.
11590	Parse a Content-type like header and return the main content-type and a dictionary of options.
11591	Adds a new value for the given key, normalizing the key name and handling duplicate keys by concatenating values with commas.
11592	Returns all values for the given header as a list.
11593	Updates the dictionary with a single header line, handling both continuation lines (starting with whitespace) and new header lines (split by colon). For continuation lines, it appends the content to the last header value. For new lines, it splits the line at the first colon and adds the name-value pair to the headers.
11594	Returns a dictionary from HTTP header text by parsing each line and adding the key-value pairs to a new HTTPHeaders instance.
11595	Converts a name to Http-Header-Case by capitalizing words separated by hyphens and caching the result. Returns the normalized header name, using a cache to avoid repeated processing of the same name.
11596	Converts a string argument to a byte string using UTF-8 encoding. If the argument is already a byte string or None, it is returned unchanged. Otherwise, it must be a unicode string and is encoded as UTF-8.
11597	Converts a string argument to a unicode string. If the argument is already a unicode string or None, it is returned unchanged. Otherwise it must be a byte string and is decoded as utf8.
11598	Converts a string argument to a subclass of basestring, handling the difference between byte and unicode strings in Python 2 vs Python 3 by decoding byte strings to UTF-8 unicode strings.
11599	Walks a simple data structure, converting byte strings to unicode.
Supports lists, tuples, and dictionaries.
11600	Method `setup` checks for conflicting authentication plugins by iterating through installed plugins and raising a PluginError if another AuthPlugin with the same keyword argument is found.
11601	Generator over all subclasses of a given class, in depth-first order. Raises TypeError if called with old-style classes. Uses a set to track seen classes to avoid duplicates. Returns subclasses in depth-first order, starting with direct subclasses and recursively yielding their subclasses.
11602	Selects a policy based on matching strategy and origin, returning a tuple of policy name and origin. Supports "firstmatch" and "verbmatch" strategies, checks method compatibility, and determines appropriate origin based on policy rules. Returns None for origin if no matching policy is found.
11603	Returns a vector with the occupancy count for each grid point based on the proximity of given points within a specified spacing threshold.
11604	Write a GRO file with the specified title, atoms, and box dimensions to the given output stream.
11605	Write a PDB file with the given title, atoms, and box parameters to the specified output stream.
11606	Determine molecule numbers based on total quantity, absolute numbers, and relative proportions. If only relative numbers are provided, distributes the total according to relative weights. If both absolute and relative numbers are provided, uses absolute numbers as fixed values and fills remaining quantity with relative distribution. If only absolute numbers are provided, returns them directly. Returns a list of tuples pairing molecule names with their calculated numbers.
11607	Resize and adapt the periodic boundary conditions (PBC) box size to accommodate lipids in both leaflets of a bilayer, considering absolute and relative lipid numbers, protein areas, and hole sizes. The function modifies the PBC in place and raises an exception if there is insufficient information to determine the box size. It calculates scaling factors based on lipid areas and available space to adjust the box dimensions accordingly.
11608	Writes a basic TOP file with specified molecules and title. If outpath is provided, writes to file including header and martini.itp include; if outpath is empty, writes only added molecules (excluding Protein) to stderr without header.
11609	Return a stream for a given resource file in the module, yielding each line as a UTF-8 decoded string.
11610	Send a message to a particular user by storing it in cache with message level information.
11611	Send a message to a group of users by iterating through each user in the queryset and calling message_user on each one.
11612	Fetch messages for a given user from cache. Returns the cached messages if they exist and are valid, otherwise returns None. If messages are found in cache, they are immediately deleted from cache before being returned.
11613	Process response by checking for user messages and adding them to the response using Django's messages framework.
11614	Checks config.json file for default settings and auth values, verifies profile name, retrieves data from config, handles authentication retrieval if needed, and updates config data and password if save flag is set.
11615	Verifies that a profile name exists in the configuration data, raising an UnknownProfileError if the profile is not found.
11616	Updates message attributes with values from configuration profile only if the attribute is None and exists in config data.
11617	Retrieve authentication password from configuration based on message type and profile, then set it in msg.auth attribute as either a string or tuple.
11618	Updates a profile's configuration data with values from a message object, overwriting existing values while excluding the "auth" attribute.
11619	Updates a configuration password entry by storing authentication values from a message object. If the message's auth attribute is a sequence or tuple, it joins the values with " :: " separator; otherwise, it stores the auth value directly. The key is formatted using the message's profile and type.
11620	Creates a configuration profile for the specified message type by validating the message type, displaying required items, getting user confirmation, and then collecting profile information including name, data, and authentication details to configure the profile.
11621	Display required configuration items and authentication credentials needed to set up a profile for a specified message type, showing settings and authorization requirements in a formatted list.
11622	Get required settings from user input and return as a dictionary.
11623	Get authentication credentials from user input for a specified message type and return them as an OrderedDict.
11624	Create a profile configuration entry with specified message type, profile name, settings data, and authentication parameters, then print confirmation with file location.
11625	Writes configuration data by creating a nested structure in the config object under the specified profile and message type.
11626	Writes authentication settings to the config's pwd section by formatting a key from profile name and message type, then joining authentication parameters with " :: " separator.
11627	Add attachments to the message by converting them to a list if needed, then formatting each attachment as a dictionary with "image_url" and "author_name" keys. If additional parameters are provided, update each attachment with those parameters.
11628	Send a message via HTTP POST request with optional JSON or URL encoding, handling authentication errors and printing debug information if verbose mode is enabled.
11629	The `send` function constructs and sends messages of various types (like Email, Twilio, etc.) either synchronously or asynchronously. It takes a message type string and optional arguments for message configuration, then uses a factory to create the appropriate message object. The function supports both synchronous and asynchronous sending through the `send_async` parameter, and handles sending errors gracefully by exiting with an error message. The function accepts keyword arguments that vary depending on the message type being sent.
11630	Factory function that creates and returns message instances based on the specified message type. Takes a message type string and optional arguments, looks up the appropriate message class in the message types dictionary, and instantiates it with the provided arguments. Handles errors for unknown profiles, invalid message input, and unsupported message types by either exiting with an error message or raising appropriate exceptions.
11631	A credential property factory that creates properties with obfuscated getters and private attribute setters for message classes.
11632	A property factory that creates a validated property descriptor. The returned property uses a getter to retrieve values from the instance's `__dict__` and a setter that validates input using `validate_input` before assigning the value. The validation ensures critical parameters maintain specific types based on the class and attribute names.
11633	Function `validate_input` validates input values based on message type by dispatching to specific validation functions. It takes `msg_type`, `attr`, and `value` as parameters, looks up the appropriate validation function in a dictionary, and returns 0 for valid input or 1 for invalid input. If an invalid message type is provided, it catches the KeyError and returns 1.
11634	Twilio input validator function that checks if 'from_' or 'to' attributes contain valid phone numbers and 'attachments' attribute contains valid URLs.
11635	Function that validates SlackPost input attributes, ensuring 'channel' and 'credentials' are strings and 'attachments' are valid URLs.
11636	Validates WhatsApp input attributes, specifically handling 'from_', 'to' phone numbers (stripping 'whatsapp:' prefix and validating as integers) and 'attachments' (validating as URLs).
11637	Creates a coroutine that continuously receives message instances and sends them asynchronously using a thread pool executor, with exception handling for completed futures.
11638	Add a message to the futures executor by sending it through the coroutine, raising an UnsupportedMessageTypeError if the coroutine is not properly initialized.
11639	Reads message body from a file specified by filepath and sets it as the body while clearing the file parameter.
11640	Removes None values and specified keys from kwargs dictionary, converts certain keys to lists.
11641	Summary: The `send_message` function performs final preprocessing on a message before sending it. If a file is specified in the keyword arguments, it retrieves the message body from that file. It then trims the arguments and sends the message synchronously using the specified message type and processed keyword arguments.
11642	Lookup chat_id of username if chat_id is unknown via API call. Returns the chat ID if found, otherwise returns None.
11643	Send content via HTTP POST request with error handling and optional verbose logging.
11644	Send a message with optional attachments, print debugging information if verbose mode is enabled, and display a confirmation message upon completion.
11645	Return an SMTP server name guess from an outgoing email address. If an address is provided, extract the domain and look up the corresponding SMTP server in SMTP_SERVERS. If the domain is not found in the lookup table, return a default SMTP server with the format "smtp.domain" on port 465. If no address is provided, return (None, None).
11646	Method `_generate_email` combines email components by creating a MIMEMultipart message and coordinating the addition of header, body, and attachments through helper methods.
11647	Add email header information including From, Subject, To, Cc, and Bcc fields to the message.
11648	Add the plain text body content to the email message if it exists.
11649	Add required attachments to the message object. Returns the number of attachments successfully added.
11650	Starts a session with the email server using SSL or TLS based on the port number, then logs in with the provided credentials, raising a MessageSendError if login fails.
11651	Returns an SMTP_SSL session using the server and port attributes with default SSL context.
11652	Get an SMTP session with TLS encryption by creating an SMTP connection, performing EHLO handshakes before and after starting TLS negotiation.
11653	Send an email message by generating the email content, establishing a session with email servers, sending the message to all recipients (to, cc, bcc), and then closing the session. The method includes verbose logging options to display debugging information, including timestamped messages about message creation, login success, logout, and final message sent confirmation. Recipients are handled as either single values or sequences (lists/tuples) and are properly flattened into a single list before sending.
11654	Save metadata tags to a file. If no filename is provided, uses the instance's filename. Issues a deprecation warning if a filename is specified explicitly. Raises ValueError if no tags exist in the file. Returns the result of the tags' save operation.
11655	Releases renderer resources associated with this image by calling the unload function from the library and sets the handle to -1.
11656	Returns a new Image object representing a rectangular region of this image without copying the underlying data. The returned image shares the same underlying data as the original, so modifications to the region will affect the original image. The region is defined by its top-left (x1, y1) and bottom-right (x2, y2) coordinates.
11657	Validate keys and values in Vorbis metadata. Checks that all keys are valid Vorbis keys and all values are valid Unicode or UTF-8 strings. Raises ValueError for invalid keys or values. In Python 3, requires all keys and values to be strings. Returns True if validation passes.
11658	Clear all keys from the comment by removing each internal key from the _internal collection.
11659	Return a string representation of the data with optional framing bit. Validates data first, then encodes vendor and tag-value pairs into a byte string. Each tag-value pair is prefixed with its length in little-endian format. If framing is True, appends a framing bit (0x01) at the end. Returns the complete byte string.
11660	Reads chunk data from the file object starting at data_offset with size data_size, storing the result in self.data.
11661	Method deletes a chunk from file and adjusts parent chunk size if exists.
11662	Update the size of the chunk by writing the new data size to the file and recursively adjusting the parent chunk's size if necessary.
11663	Inserts a new chunk with the specified ID at the end of the IFF file, updating file position and chunk metadata accordingly.
11664	Save ID3v2 metadata to an AIFF file by preparing frame data, updating the ID3 chunk with new header and data, and expanding the chunk if necessary to accommodate the new data size.
11665	Deletes the ID3 chunk from an AIFF file and clears the current instance data.
11666	Parses a C source file and adds its blocks to the processor's list by processing each line, handling normal lines, block ends, and column lines according to the current format, and managing block creation and line recording.
11667	Process a normal line and check if it starts a new block. If so, add current block lines, update format and line number, then append line to current lines.
11668	Adds the current accumulated lines as a new SourceBlock and creates a new empty block.
11669	Draws a string using the specified font and parameters, rendering text with given alignment and positioning. The text is rendered with the left edge and baseline at the specified coordinates (x, y), though text alignment and word-wrapping are not yet implemented. The method creates a glyph layout based on the provided parameters and draws it using an internal drawing function.
11670	Parses an ISO 8601 time string into a timezone-aware UTC datetime object. Handles both millisecond-precision and second-precision timestamps, converting them to UTC timezone.
11671	Converts a series of simple words into HTML text by quoting each word and joining them with spaces.
11672	The `make_html_word` method processes a single word to convert it into HTML format by handling cross-references, italics, and bold formatting. It first checks if the word matches a cross-reference pattern (e.g., `[word]`) and attempts to link it to a corresponding block identifier. If the cross-reference is undefined, it reports a warning and returns the word wrapped in question marks. Next, it checks for italic and bold formatting patterns and wraps the matched text accordingly. If none of these patterns match, the word is escaped for HTML safety using `html_quote` and returned as-is.
11673	Converts a list of words into tagged HTML text with paragraph formatting, handles cross-references, converts quotations to proper HTML entities, and replaces tildes with non-breaking spaces.
11674	Converts a sequence of code lines into HTML format by wrapping each line with HTML quotes and adding header and footer.
11675	Converts a field's content into valid HTML by processing items into code blocks or paragraphs.
11676	Save metadata to the given filename by rendering atoms and updating existing or new metadata structure.
11677	Updates all parent atoms in the file with the new size by adjusting their stored size values to reflect the given delta change.
11678	Starts the game loop by creating and showing the window, then enters the main event loop where game events are processed until the game exits. Sets up various event handlers for window resizing, keyboard input, mouse input, and controller input, and registers a tick callback for game updates. If a game is already running, it replaces the current game instance. Properly cleans up event handlers and resets global state when the game ends.
11679	Register a controller mapping for a specific vendor and product ID, replacing any existing mapping for controllers not yet connected.
11680	Find a controller mapping in the registry using the controller's vendor_id and product_id as the key. Returns the matching ControllerMapping object if found, otherwise returns None.
11681	Register a text key for MP4 freeform atoms by creating a custom getter, setter, and deleter functions that handle UTF-8 encoding/decoding and register the key with the class using the provided key name and atom identifier constructed from the mean and name parameters.
11682	This method implements HMAC-based authentication for Route53 API requests by signing a given string with the user's secret access key using SHA256 hashing and returning the Base64-encoded result.

Parameters:
- string_to_sign (str): The timestamp string to be signed

Returns:
- str: Base64-encoded HMAC signature using SHA256 digest of the input string signed with the AWS secret access key
11683	Returns the request headers for Route53 API calls, including authentication headers generated using AWS secret access key and current timestamp.
11684	Sends HTTP requests through transport methods, handling GET, POST, and DELETE operations with appropriate headers and data handling.
11685	Sends a GET request to the Route53 endpoint with specified path, parameters, and headers, then returns the response body.
11686	Sends a POST request to the Route53 endpoint with the specified path, data, and headers, then returns the response body as a string.
11687	Sends a DELETE request to the Route53 endpoint with the specified path and headers, returning the response body as a string.
11688	Creates APEv2 tag values with specified type, handling text encoding and returning appropriate value objects based on the kind parameter (TEXT, BINARY, or EXTERNAL).
11689	Sends an HTTP request to the Route53 API using the specified path, data, and method, then parses the XML response using lxml and returns the root element.
11690	A method that handles autopaginating API calls by repeatedly requesting pages of results until all records are retrieved, yielding parsed records one at a time. It uses XPath to find pagination markers and adjusts request parameters accordingly, supporting optional additional parser arguments and handling special cases for resource record sets.
11691	Lists all hosted zones associated with the connection's account using pagination, returning a generator of HostedZone instances.
11692	Creates a new hosted zone with the specified name, caller reference, and comment. Returns a tuple containing the HostedZone instance and change information. The hosted zone details cannot be changed after creation.
11693	Method that lists a hosted zone's resource record sets by Zone ID using pagination, returning a generator of ResourceRecordSet instances with optional filtering by type, identifier, and name.
11694	Method `_change_resource_record_sets` sends a ChangeSet to the Route53 API to modify DNS resource record sets. It converts the ChangeSet into XML format using `change_resource_record_set_writer`, sends it as a POST request to the Route53 API endpoint for the specified hosted zone, and parses the response to return change information. The method raises a `Route53Error` if the API request fails.
11695	Draw an image on the screen with optional scaling and flipping capabilities by specifying corner coordinates.
11696	Draw a rectangular region of an image by mapping coordinates from texel-space (ix1, iy1) to (ix2, iy2) onto screen-space (x1, y1) to (x2, y2). For example, to draw the left half of a 100x100 image at coordinates (x, y), use: bacon.draw_image_region(image, x, y, x + 50, y + 100, 0, 0, 50, 100).
11697	Total frame size calculation including header overhead and packet data.
11698	Replace old pages with new pages within a file object by rewriting the data, adjusting offsets, and renumbering pages as needed.
11699	Find the last page of a specific stream in an Ogg file. For non-multiplexed streams, it quickly locates the last page by seeking near the end of the file. For multiplexed streams, it reads through the entire stream to find the last page belonging to the specified serial number. Returns the last OggPage object or None if not found.
11700	Sets the current section during parsing by creating a new DocSection if the section doesn't exist, or retrieving the existing section from the sections dictionary.
11701	Add a new markup section by creating a DocMarkup object from current markup and markup_lines, then appending it to the markups list while clearing the current markup state.
11702	Process a block of content and return a list of DocMarkup objects corresponding to it. The method parses through each line, identifies markup tags using regular expressions, and organizes the content into markup sections. It handles the creation and accumulation of markup content, ultimately returning a list of all processed markup objects.
11703	Returns the DocMarkup object corresponding to a given tag name in a block, or None if not found.
11704	Creates an XML string for Route53 API to create a new hosted zone with specified parameters including name, caller reference, and optional comment.
11705	Locks a file object using fcntl.lockf() if available, with graceful fallback to False if fcntl is not supported or locking fails. Returns True if successful, False otherwise.
11706	Inserts a specified number of bytes of empty space into a file at a given offset, using memory mapping when possible for efficiency or falling back to a slower but more compatible method.
11707	Delete bytes from a file by shifting remaining data left and truncating. Uses memory mapping as a fast method, falling back to buffered copying if mmap fails. The operation is atomic and handles file locking when needed.
11708	Convert a basestring to a valid UTF-8 str. If the input is bytes, decode it from UTF-8 and re-encode to UTF-8. If the input is unicode, encode it to UTF-8. Raise TypeError for other types.
11709	Adds a change to this change set by appending a tuple of (action, record_set) to either creations or deletions list based on the action parameter. Raises Route53Error if action is not 'CREATE' or 'DELETE'.
11710	Parses a ChangeInfo XML element into a dictionary containing request status and timestamps. Returns None if input is None. Extracts status and submitted_at fields, converting the timestamp from ISO 8601 format.
11711	Calculates the width of a given string in pixels using text rendering operations. Takes a string parameter and returns a float representing the width in pixels.
11712	Returns True if the record set has been modified since last retrieval or save, False otherwise. Compares current attribute values with initial values to detect modifications.
11713	Deletes this record set by creating a change set with DELETE operation and applying it through the connection.
11714	Saves changes to a record set by creating a DELETE and CREATE change pair within a ChangeSet, then updates the initial attribute values to reset modification tracking.
11715	Parse an ID3v1 tag from data and return a dictionary of ID3v2.4 frames. Returns None if the tag is invalid or not found. The function handles special cases like out-of-spec year fields and properly decodes strings using latin1 encoding. It extracts title, artist, album, year, comment, track number, and genre information, converting them to appropriate ID3v2.4 frame types. Track number is only included if it's not padded with spaces, and genre is only included if it's not the default value (255).
11716	Converts an ID3v2.4 frame dictionary to an ID3v1.1 tag string, handling title, artist, album, comment, track number, genre, and year fields with proper encoding and padding.
11717	Reads a specified number of bytes from the source file, validating the requested size against file boundaries and tracking total bytes read.
11718	Delete all tags of a given kind; if key exists, delete it, otherwise delete all keys that start with key followed by ":".
11719	Method `loaded_frame` is deprecated and should be replaced with the `add` method. It processes a tag by converting 2.2-style tags to 2.3/2.4 format if necessary, then stores the tag in the object using its HashKey as the dictionary key.
11720	Updates common to both v23 and v24 updates, including cleaning up TCON genres format and handling APIC frame conversions from v2.2 to v2.3+ while removing incompatible LNK frames.
11721	Convert older ID3 tags to ID3v2.4 format by updating frames like TYER to TDRC, TORY to TDOR, and IPLS to TIPL, while removing obsolete frames.
11722	Release all resources associated with the sound by unloading it through the library function and reset the handle to -1.
11723	Play the sound as a one-shot with optional gain, pan, and pitch control. If no parameters are specified, plays at default settings. If any parameters are provided, creates a Voice instance with the specified settings and plays it.
11724	Set the loop points within the sound by specifying start and end sample numbers. The sound must have been created with loop=True, and the default parameters set the loop points to the entire sound duration. Uses the system's SetVoiceLoopPoints function to apply the loop settings.
11725	Function `adobe_glyph_values()` returns two lists containing Adobe glyph names and their corresponding Unicode values by parsing a glyph list string, where each line contains glyph information separated by semicolons and Unicode values separated by spaces.
11726	Filters a list of glyph names by removing all names that appear in the filter list, returning the remaining names.
11727	Dumps a given encoding to a file as a formatted C array of unsigned shorts, with values organized in lines of 16 elements each.
11728	Dumps a given array to a write function in C static array format with hexadecimal values, 16 values per line, handling line wrapping for long arrays.
11729	main() generates a PostScript glyph names header file with standard names, Macintosh encoding extras, and Adobe Glyph List (AGL) in compressed form, including a lookup function for Unicode values. It also includes unit test code for verification.
11730	The `file_exists` function checks if a given file exists and is accessible. It attempts to open the file in read mode and returns 1 if successful, or None if the file cannot be accessed (e.g., doesn't exist or lacks permissions). In case of failure, an error message is written to stderr indicating the file that couldn't be accessed.
11731	Builds a list of input files from command-line arguments, handling wildcards and filtering out non-existing files.
11732	Parses an XML HostedZone element from Route53 API response and returns a HostedZone object. Extracts field values from XML tags, handles special cases like Comment nested under Config and Id path stripping, maps XML tag names to keyword arguments using a predefined mapping, and instantiates a HostedZone object with the extracted parameters.
11733	Parses a DelegationSet XML element and populates the nameservers attribute of a HostedZone instance with the extracted nameserver values.
11734	Function `writeblocks` renders metadata blocks as a byte string by:
1. Creating a list of [block_code, block_data] pairs from input blocks
2. Setting the highest bit of the last block's code to indicate end-of-blocks
3. For each block:
   - Converts code to byte
   - Validates datum length doesn't exceed 2^24 bytes
   - Packs length as 3-byte big-endian value
   - Concatenates byte + length + datum
4. Returns concatenated byte string of all blocks
11735	Consolidates FLAC padding metadata blocks by merging multiple padding blocks into a single padding block. Removes all existing padding blocks from the input list and replaces them with one padding block whose size equals the sum of all removed padding sizes plus 4 bytes per removed header (minus 4 bytes for the original header). The overall rendered block size remains unchanged, but adds several bytes of padding for each merged block.
11736	Remove Vorbis comments from a file by deleting VCFLACDict metadata blocks and saving the changes. If no filename is provided, uses the most recently loaded file.
11737	Save metadata blocks to a file, handling padding and optional ID3 header/footer removal. If no filename is provided, uses the most recently loaded file. Ensures proper file structure by adjusting padding and writing metadata blocks. Removes ID3v2 tags if requested and truncates ID3v1 tags if present.
11738	Parses an Alias tag beneath a ResourceRecordSet, extracting the HostedZoneId and DNSName values. Returns a tuple containing (alias_hosted_zone_id, alias_dns_name).
11739	Parses resource record values from XML elements and returns them as a list of strings.
11740	Parses an XML element representing a ResourceRecordSet and returns the appropriate ResourceRecordSet object based on its type. Takes an etree element, connection object, and zone ID as input, extracts relevant fields including type, alias information, and resource records, then instantiates and returns the correct ResourceRecordSet subclass.
11741	Deletes the hosted zone, with optional force deletion that removes all record sets first. Returns change information from the deletion request.
11742	Adds a new resource record set to a hosted zone by creating the record set with specified parameters and submitting a CREATE change request to the DNS service. Returns the created record set instance and the change information.
11743	Creates and returns an A record attached to this hosted zone with the specified parameters including name, values, TTL, and optional routing configuration.
11744	Creates an AAAA record attached to this hosted zone with the specified parameters and returns the created record set along with change information.
11745	Creates a CNAME record in the hosted zone with specified parameters and returns the created record set along with change information.
11746	Creates an MX record in the hosted zone with the specified name, values, and TTL, returning the created record set and change information.
11747	Creates an NS record attached to the hosted zone with specified name, values, and TTL, returning the created record set and change information.
11748	Creates a PTR record attached to this hosted zone with the specified name, values, and TTL, returning the created record set and change information.
11749	Creates an SPF record in the hosted zone with the specified name, values, and TTL, returning the created record set and change information.
11750	Creates an SRV record attached to the hosted zone with specified parameters and returns the created record set along with change information.
11751	Creates a TXT record attached to this hosted zone with the specified parameters and returns a tuple containing the created record set and change information.
11752	Register a user-defined text frame key in the format TXXX:desc for use with ID3 tags, allowing storage of freeform description-based metadata like barcode information.
11753	This function processes change values for DNS record operations by returning a dictionary of attribute values based on the action type. For 'CREATE' actions, it retrieves current values from the resource record set's attributes, while for other actions (like deletions), it returns the initial values stored in the `_initial_vals` dictionary. The function abstracts away the difference between attributes and dictionary key-value pairs to provide a consistent dictionary interface for writing change requests.
11754	Creates an XML element representing a DNS change operation with action and resource record set details including name, type, TTL, and optional alias or routing configuration.
11755	Creates an XML string for Route53 API requests to change resource record sets, including deletions and creations in the specified order, with optional comment support.
11756	Initialize log file with timestamped name and basic configuration including timestamp format and INFO level logging, then log the start message with versions.
11757	Gets an item by its alias by looking up the alias in the alias dictionary to get the identifier, then using that identifier to retrieve the item from the items dictionary.
11758	Freezes a dictionary into a sorted tuple of key-value pairs, making it hashable. Takes a dictionary as input and returns a tuple containing its items sorted by keys. This allows dictionaries to be used in contexts requiring hashable types, such as set elements or dictionary keys.
11759	Joins a dictionary of HTML attributes into a template string and corresponding values tuple. The template string contains placeholders for the attribute values, and the values are returned in the same order as the attributes. This prevents XSS attacks when used with markupsafe.Markup. Returns a 2-tuple of (template, ordered_values).
11760	Initializes an app to work with this extension by connecting app-level signals and integrating with Jinja template context.
11761	Initializes all bound navigation bars by calling their respective initializers on the current instance.
11762	Binds a navigation bar to the extension instance by storing it in the bars dictionary using the bar's name as the key.
11763	Returns the arguments that will be passed to ``url_for`` as a dictionary. If ``self._args`` is None, returns an empty dict. If ``self._args`` is callable, calls it and converts the result to a dict. Otherwise, converts ``self._args`` directly to a dict.
11764	Returns the final URL of this navigation item by either generating it using the endpoint and args for internal links, or returning a pre-defined URL for external links.
11765	Returns ``True`` if the current request has the same endpoint and view arguments as the item, False otherwise. Raises ``RuntimeError`` if used outside a bound request context. External URLs always return False.
11766	Validates that a metric class has required attributes 'label' and 'widget'. Raises ImproperlyConfigured exception if either attribute is missing.
11767	Fetches a statistic by its class name from the registered gadgets' statistics. If 'ALL' is specified, returns all statistics models. Otherwise, searches for and returns the matching statistic model, raising an exception if not found.
11768	Calculates statistics for registered gadgets by iterating through provided statistics and frequencies, printing calculation progress, and executing the calculate method on each statistic with the corresponding frequency.
11769	Auto-discover INSTALLED_APPS gadgets.py modules and fail silently when not present. This forces an import on them to register any gadgets they may want.
11770	Returns a CSV dump of specified metric's counts and cumulative counts with date/time, count, and cumulative count columns.
11771	Command handler for the "metrics" command that processes different metric operations based on keyword arguments: lists statistics, calculates latest statistics, resets statistics, or recalculates statistics with specified frequency settings.
11772	Returns the GET array's contents for the specified variable, or an empty list if the variable is not found and fail_silently is True. Raises an exception if the variable is not found and fail_silently is False.
11773	Extracts a boolean variable from a request's GET parameters, returning a default value if the variable is not found. The function interprets the first character of string values ('t' for True, otherwise False).
11774	Returns the next colour from the Geckoboard colour list in a cyclic manner, maintaining internal state to track the current colour index.
11775	Returns the default GET parameters for a Geckoboard view request, parsing various query parameters from the request with default fallback values.
11776	Returns a number widget displaying the cumulative total for a specified metric, along with the previous period's value for comparison. Handles cases where historical data may be unavailable by returning appropriate default values.
11777	Returns a tuple of metric results for RAG widget display based on GET parameters.
11778	Returns line chart data for a specified metric including counts, dates, and metric title.
11779	Returns a Geck-o-Meter control for the specified metric by retrieving the latest count with given parameters and returning it along with min/max values.
11780	Returns a funnel chart for the specified metrics, including items with their counts and titles, along with chart configuration parameters like type, percentage, and sorting options.
11781	Returns all unique active statistics from all currently registered gadgets.
11782	Registers a gadget object in the registry, raising AlreadyRegistered if the gadget is already present.
11783	Get the context for this view, including gadgets registry, columns, rows, and their ratios, then update with any additional keyword arguments.
11784	Method: error(self, message, code=1)
Summary: Prints an error message to stderr and terminates the program with the specified exit code (defaults to 1).
11785	A decorator factory that creates validation wrappers using a specified schema. It validates input data against the schema and raises appropriate exceptions (InvalidParams for validation errors, InternalError for schema errors) if validation fails. The decorator extracts the 'params' field from the input data, validates it, and passes the validated parameters to the wrapped function.
11786	Get a multi-line string as input with optional limits on number of lines and line length. Prompts user for input until EOF is encountered, joining all lines with newline characters. Supports optional maxlines and maxlength parameters to constrain input length.
11787	Get a list of strings as input from user, with optional maximum items and string length limits. Returns a list of strings entered by the user until EOF is encountered.
11788	Function `outfile_input` prompts user for a file name and handles file creation or overwrite scenarios. It validates file extensions, checks if files exist, and manages user choices for overwriting or creating files. The function ensures proper file permissions and handles various error cases including permission denied and directory not found errors. It returns the validated filename.
11789	Gets schedule information for a team-season.

**Parameters:**
- year: The year for which we want the schedule.

**Returns:**
- DataFrame of schedule information.
11790	Returns the team ID of the winning team. Returns None if a tie.
11791	Returns the year ID of the season in which this game took place, adjusting for January games by subtracting 1 from the year when the month is less than or equal to 3.
11792	Returns a DataFrame containing starter player information from PFR, including player ID, name, position, team, home/away status, and offense/defense classification for both home and visiting teams.
11793	Returns the playing surface type from game info, or np.nan if not available.
11794	Gets information relating to the opening coin toss, including which team won and whether they deferred. Returns a dictionary with 'wonToss' (team ID) and 'deferred' (boolean) keys, or None if no coin toss information is available.
11795	Returns a dictionary containing weather information including temperature, wind chill, relative humidity, and wind speed. Parses weather data from a sports game info table using regex, with default values for dome stadiums when weather data is unavailable.
11796	Gets a dictionary of ref positions and the ref IDs of the refs for that game by parsing the officials table from the document.
11797	Returns a DataFrame of schedule information for NBA games in a season, filtered by regular season ('R') or playoffs ('P') games. The method collects game data from monthly schedule pages, concatenates them into a single DataFrame, determines the number of regular season games, and returns the appropriate subset based on the `kind` parameter. Defaults to regular season games ('R') if no parameter is provided.
11798	Returns a DataFrame containing combined East and West conference standings information, including team details, win records, seeding, and gameback metrics.
11799	Helper function that extracts team statistics tables from season pages and returns them as a DataFrame with team_id as the index.
11800	Returns a DataFrame containing information about ROY (Rookie of the Year) voting by scraping the NBA awards page for the specified year and parsing the ROY table data.
11801	Returns the linescore for the game as a DataFrame with team data.
11802	Returns the year ID of the season in which this game took place. For games starting in September or later, returns the next year; otherwise returns the current year.
11803	Returns a DataFrame containing player statistics from a game by parsing tables for both away and home teams, cleaning the data by setting zero minutes played to zero for all stats, adding team and positioning information, and combining all player data into a single DataFrame.
11804	A decorator that switches to a specified directory before executing a function and then returns to the original directory.
11805	A caching decorator that stores HTML responses in a user-specific cache directory, checking cache validity based on time and sport-specific expiration rules before either serving cached content or fetching new data.
11806	Returns a unique identifier for a class instantiation by creating a tuple of object IDs from the class and its arguments, sorted for consistency.
11807	A decorator for memoizing functions that caches results based on function arguments. Only works with simple arguments (strings, numbers, etc.) and raises TypeError for complex arguments like lists or dictionaries. Uses a cache dictionary to store previously computed results and returns cached results when the same arguments are encountered again. Includes error handling for type errors during memoization and respects a 'memoize' option from sportsref configuration.
11808	Returns the age of the player on a given date by calculating the difference between the specified date and the player's birth date, returning the age in years as a float.
11809	Gets a stats table from the player page based on the specified table ID and season type, returning the data as a DataFrame. Supports regular season ('R'), playoff ('P'), or both ('B') tables, with optional summary formatting.
11810	Returns a DataFrame containing per-game box score statistics for the specified statistic type and summary level.
11811	Returns a DataFrame containing total box score statistics organized by season, with options to specify statistic kind and summary format.
11812	Returns a DataFrame containing per-36-minutes statistics by retrieving the appropriate stats table using the 'per_minute' interface with specified kind and summary parameters.
11813	Returns a DataFrame containing per-100-possession statistics for the specified metric.
11814	Returns a DataFrame containing advanced statistics by retrieving data from the advanced stats table with specified kind and summary options.
11815	Returns a DataFrame containing shooting statistics by default, with options to specify stat type and summary output.
11816	Returns a DataFrame of play-by-play stats by calling the internal `_get_stats_table` method with 'advanced_pbp' as the table parameter.
11817	Returns a DataFrame containing a player's basic game-by-game stats for a specified season, with options to filter for regular season, playoffs, or both.
11818	Memory Session Object Demo: This method retrieves and displays session data with key "sv". If the key exists, it shows the current value and then deletes it from the session. After deletion, it confirms the value is empty. If the key doesn't exist initially, it displays "Session data not found". The method includes a warning that this approach should not be used in production environments.
11819	Expands the details column of the given dataframe by parsing play details and returns a DataFrame with new columns from play-by-play parsing, including error handling and feature cleaning.
11820	Adds 'team' and 'opp' columns to a DataFrame by iterating through rows in game order, handling kickoff scenarios manually to determine possession, and filling missing values using forward and backward fill methods.
11821	Adds convenience features based on teams with and without possession, including distance to goal, win probability (WP), win probability added (WPA), and team/opp scores. Creates columns for team and opponent WP/WPA based on home/away status, calculates distance to goal considering field side, and populates team scores using boxscore data.
11822	Returns the initial win probability of a game given its Vegas line, where the line is from the home team's perspective (negative means home team is favored). The function calculates the probability using a normal distribution with a standard deviation of 13.86, and returns a float in the range [0., 100.] representing the win probability.
11823	Gets yearly passing stats for the player.

**Parameters:**
- ``kind``: One of 'R', 'P', or 'B'. Case-insensitive; defaults to 'R'.

**Returns:** Pandas DataFrame with passing stats.
11824	Returns a list of years for a simple award (like Pro Bowls or First-Team All-Pro) by parsing the corresponding table from the HTML document using the specified award ID.
11825	Returns the full name of a franchise by parsing the team ID from a web document. Extracts the team name from the header of the main document by splitting the text content, finding the position of "Franchise", and joining all words before that position.
11826	Gets list of BoxScore objects corresponding to the box scores from that year. Returns np.array of strings representing boxscore IDs.
11827	Returns a PyQuery object containing info from the meta div at the top of the team year page that matches the given keyword. Raises ValueError if keyword not found or no p tags exist.
11828	Returns an array of head coach IDs indexed by game for a given season, where each coach ID appears as many times as the number of games they coached during that season.
11829	Returns a DataFrame with schedule information for the given year, including game outcomes, weeks, and additional flags for wins, losses, ties, byes, and overtime games.
11830	Returns the coach ID for the team's Offensive Coordinator in a given year. If no OC is found or an error occurs, returns None.
11831	Returns the coach ID for the team's Defensive Coordinator in a given year by parsing the year info HTML, extracting the href attribute from the anchor tag, or returns None if not found.
11832	Returns the stadium ID for the team's home stadium in a given year by parsing the year-specific information page and extracting the stadium identifier from the href attribute of the anchor tag.
11833	Returns the name of the offensive scheme the team ran in the given year by parsing the offensive scheme text from year-specific information.
11834	Returns the name of the defensive alignment the team ran in the given year by parsing the defensive alignment text from year-specific information.
11835	Returns a DataFrame of offensive team splits for a given season by parsing HTML tables from the corresponding year's splits page.
11836	Gets HTML content from a URL with request throttling and error handling. Includes rate limiting to ensure minimum delay between requests, raises ValueError for 4xx status codes, and removes HTML comments from response.
11837	Flattens relative URLs within table cell HTML to IDs and returns the result. Helper function `_flatten_node` processes text content and href attributes, converting relative URLs to IDs using `rel_url_to_id`. Removes span.note elements before processing. Returns empty string for recursive calls or None for top-level calls with no text content.
11838	Converts a relative URL to a unique ID by matching against multiple regex patterns. Returns the ID associated with the URL or the original URL if no match is found.
11839	Converts keyword arguments to a query string by processing and mapping various parameter names and formats, such as boolean values, team IDs, year ranges, positions, and draft positions, then joins them into a URL-encoded query string.
11840	Main function for processes that read from an HDF5 file, handling cyclic or linear reading with synchronization. It reads data blocks from a specified HDF5 node, manages buffer writes with optional ordering, and supports wrapping around dataset boundaries when cyclic mode is enabled. The function uses a stop event to control execution and a barrier for synchronizing read cycles.
11841	```python
def put_direct(self):
    """
    Allows direct access to the buffer element.
    Blocks until there is room to write into the buffer.

    :return: A guard object that returns the buffer element.
    """
    return self.Guard(self.read_queue, self.arys, self.__put_idx)
```

Summary: Returns a guard object for direct buffer access, blocking until write room is available. The guard manages access to buffer elements through the read queue and array storage using the current put index.
11842	Returns a guard object that provides direct access to buffer elements, blocking until data is available for reading. The guard holds the read index and releases it back to the write queue when disposed. Returns QueueClosed if the queue is closed.
11843	Close the queue by signaling that no more data can be put into the queue, using QueueClosed sentinel values in both read and write queues.
11844	Get a block of data from the specified HDF5 node path, with optional length parameter and last batch flag. Returns a numpy array copy of the requested data block.
11845	Get the remainder elements from an HDF5 dataset that won't be read in direct queue access mode, returning them as a numpy array copy.
11846	Returns a queue for direct access to an internal buffer, allowing parallel reading of HDF5 dataset blocks with options for cyclic reading, ordering, and block sizing.
11847	Returns a generator that iterates over rows in the dataset from the specified path. The generator first yields all rows from the main dataset using an iterator, then yields any remaining rows from the remainder. Additional arguments are forwarded to get_queue. The generator ensures proper cleanup by closing the queue in a finally block.
11848	Parse a stream of protobuf messages.

Args:
    ifp (string or file-like object): input stream
    pb_cls (protobuf.message.Message.__class__): The class object of the protobuf message type encoded in the stream

Yields:
    protobuf.message.Message: parsed protobuf message objects
11849	Writes protobuf message objects to a stream (file or file-like object).

Args:
    ofp (string or file-like object): output stream/file path
    pb_objs (*protobuf.message.Message): variable number of protobuf message objects to write
    **kwargs: additional arguments passed to open()

Writes all protobuf objects to the output stream in binary mode, handling both file paths (strings) and file-like objects automatically.
11850	Read a varint from file, parse it, and return the decoded integer.
11851	A generator that parses and yields protobuf object data from a stream, reading variable-length integers to determine object counts and sizes, handling group delimiters, and raising EOFError for unexpected end-of-file conditions.
11852	Close the stream by flushing and closing the underlying file descriptor if it exists.
11853	Writes protobuf objects to file with buffering support. Objects are stored in an internal buffer and flushed to disk when the buffer size threshold is reached or when explicitly flushed. Supports multiple protobuf messages as arguments.
11854	Write buffer contents to file by encoding and writing object count, followed by each object's serialized string with length prefixes, then clear the buffer.
11855	Returns the joined game directory path relative to Steamapps. Raises RuntimeError if game directory cannot be determined without username. On Windows/Cygwin, converts the directory name to lowercase.
11856	Emulates keyboard input for text fields by sending key-down, key-up, and control key events in sequence to work around limitations in user interaction emulation, particularly for auto-suggest functionality.
11857	Generate a 2D fake fluorescence movie with specified parameters including number of frames, mask shape, background intensity, and calcium dynamics. Returns simulated fluorescence data, calcium concentration, spike train, and model parameters.
11858	Evaluates traits and returns a list of descriptions for traits that are not true. If LAZY_EVALUATION is False, all traits are evaluated before returning; otherwise, evaluation stops at the first false trait.
11859	Waits until the specified condition returns True or a non-None value, with a timeout. Returns the condition's result when met, otherwise raises TimeoutException. Handles ignored exceptions during polling with debugging logging.
11860	Waits until all traits are present on the given element, polling at regular intervals. Returns True when all traits are present, or raises a TimeoutException if the timeout is exceeded while traits are still missing.
11861	Sets a list of exceptions to be ignored inside the wait loop by adding them to the internal _ignored_exceptions tuple and returns self for chaining.
11862	Execute Main.Volume command and return the volume level as an integer. Returns None if the command fails or returns an invalid value.
11863	Execute Main.Source and return an integer result, or None if conversion fails.
11864	Send a command string to the amplifier via socket connection with retry logic, optionally read and return the reply with timeout handling.
11865	Return the status of the device including volume, power, muted state, and source.
11866	Power off the device if it is currently on, by sending a power save off command.
11867	```python
def power_on(self):
    """Power the device on."""
    status = self.status()
    if not status['power']:
        self._send(self.CMD_ON, read_reply=True)
        sleep(0.5)
```

Summary: Sets the device power status to on by sending an ON command if the device is currently powered off, with a 0.5 second delay after sending the command.
11868	Sets the device volume level using an integer value between 0-200, converts it to hexadecimal format, and sends the command to the device.
11869	Selects a source from the list of available sources, but only if the device is powered on and the requested source is different from the current source to prevent hanging the NAD7050 device.
11870	Deobfuscates a URL by decrypting the provided key, resolving the resulting path to a view function, and returning the HttpResponse from that view. Handles decryption errors and URL resolution failures by returning a 404 response. Fixes up the request environment to match the resolved path and query string, then creates a new request object with the corrected information. Copies missing request attributes from the original request to the patched request. Marks the patched request as obfuscated and calls the view function with the patched request. If juice parameter is provided and the response doesn't already have a Content-Disposition header, sets the Content-Disposition header to include a friendly filename. Returns the response from the view function.
11871	Generates a CRC32 checksum of the input plaintext, ensuring the result is within a 32-bit integer range by applying modulo 2147483647 and bitwise AND with 0xffffffff.
11872	Template filter that obfuscates text (typically URLs) by encrypting it and returning a reverse URL. When UNFRIENDLY_ENABLE_FILTER is False, returns the original value. Optional SEO-friendly text can be included via the 'juice' parameter.
11873	Method: missing_schema

Purpose: Prints a list of downloadable songs when a specified song is not found

Parameters: 
- self: Instance reference
- html: HTML content to parse
- song_name: Name of the song that was not found

Functionality: 
1. Parses HTML content using BeautifulSoup
2. Creates a combined song name string from the song_name parameter
3. Prints a "not found" message with the song name
4. Prints a header indicating downloadable songs are available
5. Finds all anchor tags with class 'touch' 
6. Extracts and prints text content from these tags by removing HTML markup using regex

Output: Displays a message about the missing song and lists alternative downloadable songs from the HTML content.
11874	Method: `list_of_all_href(self, html)`

Summary: This method extracts all hyperlinks and their corresponding names from an HTML page, specifically targeting links with the class "touch". It parses the HTML using BeautifulSoup, finds all anchor tags with the "touch" class, extracts the href attribute and cleans up the link name by removing HTML tags and numbering prefixes, then returns a list of [link, name] pairs.

Parameters:
- `html`: The HTML content to parse

Returns:
- List of lists containing [href, name] pairs for each hyperlink found

Example output format: 
```
[['http://example.com/file1', 'Movie Title 1'], ['http://example.com/file2', 'Movie Title 2']]
```
11875	Method: check_if_song_name(self, html)

Summary: This method parses HTML content to determine if the page contains song download options and returns the appropriate download link. It searches for specific text indicators ('download in 48 kbps', 'download in 128 kbps', 'download in 320 kbps') within the HTML to identify the highest available quality download link. 

The method returns a tuple where the first element is a boolean indicating whether the page contains song download options (False if found, True if not), and the second element is the href attribute of the download link (or 'nothing' if no song names are found). It prioritizes 320 kbps, then 128 kbps, then 48 kbps quality downloads.
11876	Method: Parse(self, url, song_name, flag)

Summary: This method processes a given URL to either download a song at a specific bitrate or return a list of available songs for download. When flag is False, it parses the HTML response to find download links for the specified song, prioritizing 320 kbps, then 128 kbps, then 48 kbps. If no suitable download option is found, it calls missing_schema and exits. When flag is True, it checks if the song name exists in the page, returns all available download links if found, or downloads the song directly if not found. The method returns either a single download URL or a list of URLs depending on the flag value.
11877	Returns a Google search URL by combining song name and website parameters with appropriate URL encoding.
11878	Parses Google HTML response to extract and return the first URL from the search results.
11879	Parses song information from a website to find the download URL. Takes a list of song names and a website string, constructs a Google search URL, downloads the HTML content, parses the Google search results to extract the actual website URL, and returns the URL where the music file can be downloaded.
11880	Method: `get_html_response(self, url)`

Summary: Downloads an HTML page from the specified URL and returns the page content. The method includes error handling for SSL errors and other request exceptions, with a timeout of 50 seconds. If SSL errors occur, it attempts to download without SSL verification. If other request errors occur, it prints the error message and terminates the program. The method prints a download status message before attempting the request.
11881	Downloads a file from a given URL using the requests module with progress tracking. The method first checks if the file already exists, then attempts to download the file with error handling for SSL and other request exceptions. It uses streaming to download large files in chunks while displaying a progress bar using tqdm. The downloaded file is saved with its original name from the URL.
11882	Downloads a file from the specified URL using the wget utility with options for continued downloads, timeout handling, retries, and SSL certificate checking disabled.
11883	Lookup AQI database for station codes in a given city. Returns a list of station codes if successful, empty list otherwise.
11884	Function to look up weather observations using latitude and longitude coordinates, returning parsed observation data or empty dict if request fails.
11885	Parse AQICN observation response JSON into a Python object with idx, city, aqi, dominantpol, time, and iaqi data.
11886	Function to fetch observation data from a weather station API using a station code and authentication token. Makes a GET request to the API endpoint with the station code and token as parameters. If the request is successful (status code 200 and API status "ok"), it parses the response data using `parse_observation_response()` and returns the parsed data. Otherwise, it returns an empty dictionary.
11887	The `search_paths` method returns a list of logical paths used to search for an asset. It starts with the asset's original path and, if the path doesn't end with 'index', it also includes a path to an 'index' file in the same directory with the same suffix. This is useful for finding assets that might be located in an index file within a directory structure.
11888	Returns a list of compilers used to build the asset by mapping compiler extensions to their corresponding compiler objects from the environment.
11889	Returns the MIME type of the asset by checking the environment's mimetypes dictionary with the format extension, falling back to compiler_mimetype, and defaulting to 'application/octet-stream' if neither is found.
11890	Returns the implicit MIME type of the asset based on its compilers, checking in reverse order and returning the first compiler's result MIME type, or None if not found.
11891	Returns the file extension corresponding to the compiler's mimetype by searching through the environment's mimetypes dictionary. Returns None if no matching extension is found.
11892	Register a processor for a specific mimetype, appending it to the list of processors for that mimetype if it's not already registered.
11893	Remove the specified processor for the given mimetype from the registry. If either the mimetype or processor is not found, the operation silently does nothing.
11894	Returns the list of search paths built from registered finders that have a 'paths' property, useful for compilers to resolve internal dependencies.
11895	Register default compilers, preprocessors, and MIME types by calling the register_defaults methods on mimetypes, preprocessors, and postprocessors collections.
11896	Function to import Qt core bindings, prioritizing IDA's Qt bindings when running under IDA, otherwise falling back to system Qt installations. It handles both PyQt5 and PySide fallbacks and manages sys.path modifications to ensure proper binding loading.
11897	Get the netnode used to store settings metadata in the current IDB by creating a netnode with a formatted name based on organization and application settings.
11898	Adds a plugin name to the list of registered plugin names in the current IDB, avoiding duplicates by using a set to track existing names.
11899	Remove a plugin name from the list of registered plugin names in the current IDB's metadata netnode.
11900	Imports settings from a configuration file into a settings instance.

The function reads all key-value pairs from an INI format configuration file at the specified path using Qt's QSettings, and copies them to the provided settings instance. The settings instance must implement the IDASettingsInterface, and the configuration file path should be a string. Keys from the source configuration are copied directly to the target settings instance using dictionary-style assignment.
11901	Exports the given settings instance to the specified file system path using QSettings in INI format.
11902	Returns the IDASettings instance for the current plugin with directory scope, initializing it if necessary.
11903	Enumerate the keys found at any scope for the current plugin, yielding unique keys from multiple sources (idb, directory, user, system) while handling permission and environment errors gracefully.
11904	A simple error handler that processes different types of exceptions and returns appropriate HTTP responses with error messages and status codes. It handles API exceptions with custom headers, HTTP 404 errors, and permission denied errors, returning None for unhandled exceptions which triggers a 500 error.
11905	Returns a table object for a given table name and user authentication, with optional eager loading.
11906	Returns a list of table objects for the given user by connecting to DynamoDB and retrieving all tables.
11907	Fetch packages and summary from Crates.io based on the specified category and date.

This method retrieves items from Crates.io either as crates (if category matches CATEGORY_CRATES) or as summary data, using the provided from_date parameter to filter results. It returns a generator yielding the fetched items. The method acts as a dispatcher that calls either __fetch_crates() for crate data or __fetch_summary() for summary data based on the category parameter.

Parameters:
- category: the category of items to fetch
- from_date: date filter for the backend query

Returns:
- Generator of items from Crates.io
- Items are either crates or summary data depending on the category parameter
11908	Extracts identifier from item based on its type - returns string id for crates items or timestamp string for other items.
11909	Extracts the update time from an item by checking its metadata category and converting the corresponding timestamp field ('updated_at' or 'fetched_on') to UNIX timestamp format.
11910	Get the team owner of a crate by fetching its 'owner_team' attribute from the client and parsing the JSON response.
11911	Get crate user owners by fetching and parsing owner_user attribute from the crate.
11912	Fetch crate versions data from the client and parse JSON response.
11913	Get crate version downloads by fetching raw data from the client and parsing it from JSON format.
11914	Fetches crate data by ID from the client and returns the crate information from the JSON response.
11915	Get Crates.io summary from the category summary API endpoint.
11916	Get crates in alphabetical order from the crates API endpoint, starting from the specified page.
11917	Get a crate by its ID from the crates API endpoint.
11918	Get crate attribute by ID and attribute name from the crates API.
11919	Fetch items from Crates.io API with pagination, yielding raw content for each page until all items are retrieved.
11920	Fetch questions from the Kitsune URL by calling the parent class's fetch method with the specified category and offset parameters, returning a generator of questions.
11921	Fetch questions from the Kitsune API url, handling pagination, errors, and yielding questions with their answers. It processes questions in pages, drops extra questions from partial pages, and continues to the next page on 500 errors while logging relevant information.
11922	Retrieve questions from oldest to newest based on update time, starting from a given offset, yielding pages of questions until all questions are fetched.
11923	Fetch items from the ReMo URL for a given category with optional offset, returning a generator of items.
11924	Extracts the update time from a ReMo item by checking for 'end', 'date_joined_program', or 'report_date' fields and converts the timestamp to UNIX format. Raises ValueError if no update field is found.
11925	Extracts the category from a ReMo item by checking for unique fields: 'estimated_attendance' for events, 'activity' for activities, or 'first_name' for users. Raises TypeError if category cannot be determined.
11926	Retrieves all items for a given category using pagination, yielding raw items from the API. Supports events, activities, and users categories, with automatic pagination handling through page numbers extracted from API response URIs.
11927	Returns the buffer list this instance operates on, but only when not in AIOBLOCK_MODE_POLL mode. Raises AttributeError if in poll mode. Note that buffer list changes aren't fully applied until next submission since the kernel may still be using the original buffer list.
11928	Returns the IO priority for this instance, or None if IO priority is not set.
11929	Closes the AIO context by canceling pending IO operations, waiting for non-cancellable IO blocks to complete, and de-initializing the AIO context.
11930	Submits a list of IO blocks to the kernel for asynchronous I/O operations. Takes a list of AIOBlock objects, passes them to the kernel via io_submit ioctl, and tracks successfully submitted blocks in the internal _submitted dictionary. Returns the count of successfully submitted blocks. The method handles partial submission errors gracefully by only updating the submission tracking for blocks that were successfully submitted.
11931	Cancel an IO block and return its event data, or None if kernel returns EINPROGRESS.
11932	Cancel all submitted IO blocks, wait for all transfers to finalize, and return list of cancellation results. Throws exception for invalid operations.
11933	Returns a list of event data from submitted IO blocks, with optional minimum count, maximum count, and timeout parameters. Each event is a 3-tuple containing the completed AIOBlock instance and two file-object-type-dependent values.
11934	Fetch events from the MozillaClub URL by retrieving data from a Google spreadsheet via feed API REST, returning a generator of events for the specified category.
11935	Retrieve all cells from the spreadsheet by calling the API and returning the raw text response.
11936	Parse MozillaClub spreadsheet feed cells JSON and yield events, skipping invalid events with missing date or club name.
11937	Returns a sorted list of export formats for a given pid_type, caching the results internally.
11938	Load default permission factory, importing it if necessary.
11939	Creates an Invenio-Records-UI blueprint with URL routes for each endpoint and error handling for tombstones.
11940	Creates a Werkzeug URL rule for a specific endpoint with support for persistent identifier resolution, permission checking, and custom view rendering. Returns a dictionary suitable for Flask's Blueprint.add_url_rule method.
11941	Displays a record view by resolving PID and record, checking permissions, and calling a view method. Handles various PID resolution errors and redirects accordingly. Renders a template with pid and record context.
11942	Display default view.

Sends record_viewed signal and renders template.

:param pid: PID object.
:param record: Record object.
:param template: Template to render.
:param **kwargs: Additional view arguments based on URL rule.
:returns: The rendered template.
11943	Record serialization view that exports records in specified formats using configured serializers and renders a template with the serialized data.
11944	Send a Timer metric calculating duration of execution of the provided callable and return the result.
11945	Close the socket to free system resources. After closing, further operations will fail. Multiple calls have no effect.
11946	Remove a client from the socket's users. If no clients remain, close the socket automatically.
11947	Increment a Counter metric by the specified count and rate, sending the metric request only if the metric should be sent based on the rate threshold.
11948	Send a Timer metric with the specified duration in milliseconds, but only if the metric should be sent based on the given rate. The duration is converted to an integer before being sent in a request.
11949	Send a Timer metric calculating the duration from the start time, where start_time can be either a datetime object or numeric timestamp, and the duration is converted to milliseconds before being sent with the specified rate.
11950	Send a Gauge metric with the specified value, applying rate limiting and type conversion if necessary.
11951	Send a GaugeDelta metric to change a Gauge by the specified value.
11952	Set a metric value with the specified name and value, sending it only if the metric should be sent based on the given rate. The value is converted to a string before being sent.
11953	Overrides the parent method to buffer metric data instead of sending immediately. Takes a string input, converts it to bytearray with newline termination, prepares batches for storage based on data length, and appends the formatted data to the last batch in the batches list.
11954	Return a batch client with the same settings as the current client, configured with the specified batch size.
11955	Return a new client instance with the same settings as the batch client, configured with the same host, port, and prefix.
11956	Send buffered metrics in batch requests using socket communication, clearing the batches queue and returning the BatchClient instance.
11957	Creates a permission checker that validates if a record has 'open' access level by retrieving the record and checking its 'access' field value.
11958	Return a TCP batch client with the same settings as the TCP client.
11959	Send buffered metrics in batch requests over TCP by iterating through batches, sending each batch via socket, and removing it from the batch queue, then return the client instance.
11960	Return a TCPClient with same settings of the batch TCP client
11961	Creates a user with specified permissions and groups, setting default active, non-superuser, non-staff status if not specified. Supports custom password, active status, superuser status, staff status, groups, and permissions. Returns the created user instance.
11962	Converts Python objects to OpenMath objects for building OM objects in DSL embedded in Python, handling integers, floats, strings, functions (converted to OMBinding with lambda), and existing OM objects.
11963	Converts a term into OpenMath format using a converter if available, otherwise falls back to interpretAsOpenMath method. First checks if the term is already OpenMath or a helper object, then attempts conversion through the provided converter, and finally uses interpretAsOpenMath as a fallback.
11964	Converts an OpenMath object to Python by handling different object types through class-specific overrides, symbol lookup, or application evaluation. Raises ValueError for unsupported object classes.
11965	Converts a Python object to OpenMath format by trying registered conversion functions, then checking for a __openmath__ method, and raising ValueError if conversion fails.
11966	Register a conversion from Python to OpenMath by adding a converter function or OpenMath object for a specific Python class (or all classes if py_class is None) to the conversion list. Converters are called in reverse order of registration.
11967	Register a conversion from OpenMath to Python. Supports two forms: three-arguments (cd, name, converter) for registering conversions for specific symbols, and two-arguments (cd, name) for overriding default conversions for basic OpenMath types.
11968	Initializes redis with app object by setting default redis URLs in app config and registering a before_request handler.
11969	Return list of choices's keys by iterating through the choices dictionary and extracting keys from nested lists/tuples.
11970	Splits model keyword arguments into model fields and nested field arguments.

This function takes a dictionary of keyword arguments and separates them into two categories:
- Model fields: keys without double underscores
- Nested field arguments: keys with double underscores, where the part before '__' becomes the field name and the part after becomes a subfield

Returns a tuple of (model_fields_dict, nested_fields_dict) where nested_fields_dict is a defaultdict of subfield dictionaries.

Example: {'name': 'John', 'address__street': '123 Main St'} becomes ({'name': 'John'}, {'address': {'street': '123 Main St'}})
11971	Register a form field data function for a given field type. Can be used as a decorator.
11972	Creates and returns a value instance based on the provided arguments and registry mapping. Raises TypeError if no object instance is provided or no matching function is found in the registry.
11973	Returns a tuple containing form data and files for a given form class, populating fields with provided kwargs or default values.
11974	A decorator that conditionally returns None for optional form fields with 10% probability, otherwise delegates to the original function. When a field is not required, there's a 10% chance the wrapper will return None instead of processing the field normally.
11975	Returns a decorator that wraps a function to select random valid choices from a field's widget choices attribute, falling back to the original function if no choices are available.
11976	Return random value for DecimalField based on field validators and constraints, ensuring the generated decimal falls within the specified range defined by min_value, max_value, max_digits, and decimal_places. The function respects Django's MinValueValidator and MaxValueValidator, adjusts max_value based on decimal field limits, and uses xunit.any_decimal to generate the random decimal string.
11977	Return random email address string for EmailField with length constraints based on min_length and max_length attributes.
11978	Return random date value for DateField using specified date range and format.
11979	Return random datetime value formatted as string for DateTimeField using optional date range and format parameters.
11980	Return random float value for FloatField within specified min/max bounds, using Django field validators or provided kwargs for precision.
11981	Return random integer value for IntegerField within specified min/max bounds, using field validators or default range 0-100.
11982	Return random time value formatted according to the field's input formats.
11983	Return random value for ChoiceField by selecting a valid choice from the field's choices, or 'None' if no choices are available.
11984	Return random value for MultipleChoiceField by selecting random choices from valid options and joining them with spaces.
11985	Return a random choice from the first ten items in a model field's queryset, or raise TypeError if no items are available.
11986	Encodes an OpenMath element into bytes by first converting it to an XML node and then to a string representation.
11987	Method: publish

Summary: Deploys the application to PYPI by executing a series of build and upload operations. The method first runs tests to ensure success, then creates source distribution and binary distribution packages using setup.py, and finally uploads the distributions to PYPI using twine. A git tag is created upon successful upload.

Parameters: msg (str, optional) - Description for the commit message, defaults to "checkpoint: publish package"

Returns: None (executes deployment operations)
11988	Deploy a version tag by creating a git tag with the specified version number and pushing it to the remote repository. If the tagging is successful, the tag is pushed to the remote repository.
11989	**Summary:**

The `any_field_blank` decorator wraps a function to optionally return `None` based on two conditions: when the `isnull` keyword argument is `True`, or when a randomly generated number is less than 0.1 and the field has a `blank` attribute set to `True`. This decorator is useful for simulating optional field values in data generation or testing scenarios where fields might be empty or null.
11990	Load a global Python object from a module by name, handling Python 2/3 compatibility for the built-in module. Returns the object from the specified module.
11991	Initialize an instance from state using the setstate protocol or direct attribute assignment.
11992	Convert a list of OM objects into an OM object representing a Python list.

This method takes a list of OpenMath objects and wraps them in an OMApplication that represents a Python list. The resulting OM object uses the 'list' symbol from the 'Python' content dictionary.

Args:
    l (list): A list of OM objects to be converted

Returns:
    OMApplication: An OM object representing the list with elements from the input list

Example:
    >>> converter.OMList([om.OMInteger(2), om.OMInteger(2)])
    OMApplication(elem=OMSymbol(name='list', cd='Python', id=None, cdbase='http://python.org/'),
             arguments=[OMInteger(integer=2, id=None),
                        OMInteger(integer=2, id=None)],
             id=None, cdbase=None)
11993	Convert a tuple of OM objects into an OM object by creating an OMApplication with a tuple symbol and the given arguments.
11994	Decodes PackBit encoded data by processing header bytes and either copying literal bytes or repeating bytes according to the PackBit compression algorithm. Handles both positive headers (copy next N+1 bytes) and negative headers (repeat next byte -N+1 times), with special handling for header -128 which does nothing. Returns the decompressed byte string.
11995	Encodes data using PackBits encoding algorithm, handling both raw and run-length encoded sequences. Returns bytes containing the encoded data, where raw sequences are prefixed with length-1 followed by the bytes, and repeated bytes are encoded as 256-(count-1) followed by the repeated byte. Handles edge cases of empty or single-byte input data.
11996	Method: to_fixed(self, value, precision)
Purpose: Implements fixed-point decimal arithmetic to handle floating-point rounding issues, particularly useful for accounting and finance applications.

Behavior: 
- Adjusts precision according to system settings
- Uses multiplication, rounding, and division to achieve accurate decimal representation
- Returns a formatted string with specified decimal precision
- Addresses binary floating-point representation problems (e.g., 0.615 formatted to 2 decimal places becomes "0.61" instead of "0.62")

Note: The return statement appears to have a bug - it uses the original 'value' parameter instead of the computed rounded result, and the format string construction seems incorrect.
11997	Formats a number with comma-separated thousands and custom precision/decimal places, handling recursive formatting for lists and supporting localization through configurable separators and precision settings.
11998	Formats a number into currency representation with specified formatting options including symbol, precision, thousands separator, and decimal separator.
11999	Converts a blosc compressed array into a numpy array by unpacking the data. Takes a blosc packed numpy array as input and returns the corresponding numpy array. Raises a ValueError with details if the unpacking process fails.
12000	Exports a numpy array to a blosc compressed array format and returns the compressed bytes. Raises ValueError if compression fails.
12001	Add a workspace entry to the user config file with the specified name and path, raising errors if the path doesn't exist or if a workspace with that name already exists.
12002	Remove a workspace from the config file by name, raising an error if it doesn't exist, then write the updated configuration.
12003	List all available workspaces and return a dictionary with workspace information.
12004	Get workspace information by name, returning None if workspace doesn't exist.
12005	Return True if the specified workspace contains the given repository name. First checks if the workspace exists, then verifies if the repository is listed in that workspace's repositories. Returns False if the workspace doesn't exist.
12006	Synchronizes a workspace's repositories by scanning the workspace directory, identifying valid repositories, updating the configuration with repository paths, and logging the repository names. Returns the updated repositories list and writes the configuration to disk.
12007	Clone a repository from the given URL to the specified path using the appropriate adapter based on the URL scheme. Supports Git, Svn, Bzr, and Hg repositories. Raises RepositoryAdapterNotFound if no suitable adapter is found for the URL scheme.
12008	Check if the current ndio version is up to date by comparing with the latest version on PyPI. Returns the latest version string and prints an update message if a newer version is available.
12009	Converts a boolean numpy array to a list of voxel coordinates (n-tuples) representing the indices where the array values are True.
12010	Converts a list of voxel coordinates into a binary numpy array where populated voxels are marked with 1s.
12011	Execute update subcommand by printing specific workspace or all workspaces based on provided arguments.
12012	Prints a colored repository update message and attempts to update the repository at the specified path, logging any errors that occur during the update process.
12013	Sets up a console handler for logging with optional debug level control, using a custom formatter.
12014	Execute a command using subprocess.Popen and return the process object with captured output and error streams.
12015	Loads a PNG file into a numpy array.

Arguments:
    png_filename (str): A string filename of a png datafile

Returns:
    A numpy array with data from the png file

Raises:
    ValueError: If the file cannot be loaded for conversion
12016	Exports a numpy array or binary PNG string to a PNG file. Takes a filename and numpy array (or binary string) as input, saves the data as a PNG file, and returns the expanded filename. Raises ValueError if save fails due to invalid data or formatting issues.
12017	Saves a numpy array as a series of PNG files, with each 2D slice stored in a separate file. Takes a filename template (e.g., "image-*.png") and numpy data, returning a list of generated filenames. Each file is named by replacing the asterisk with zero-padded layer indices starting from the specified value.
12018	Prints the status of workspaces matching the given name. Returns False if no matches are found, otherwise prints status for each matching workspace.
12019	Prints the status of a repository with colored logging output. Takes a repository name and path as input, logs the repository information in green color, attempts to get and display the repository status, and handles any repository errors gracefully by logging them and continuing execution. Includes a blank line print at the end for formatting.
12020	Returns the XYZ block size for a given token at a specified resolution. If no resolution is provided, uses the minimum available resolution. The block size is determined from the dataset's cube dimensions metadata.
12021	Method `_post_cutout_no_chunking_blosc` uploads cutout data to a remote server using Blosc compression. It accepts data in zyx format, expands the data dimensions, compresses it with Blosc, constructs a URL with spatial coordinates and resolution parameters, and sends a POST request to upload the data. The method returns `True` on successful upload or raises a `RemoteDataUploadError` if the upload fails.
12022	Loads a TIFF file into a numpy array. Takes a filename string as input and returns the image data as a numpy array. Raises a ValueError if the file cannot be loaded.
12023	Export a numpy array to a TIFF file.

Arguments:
    tiff_filename:  A filename to which to save the TIFF data
    numpy_data:     The numpy array to save to TIFF

Returns:
    String. The expanded filename that now holds the TIFF data
12024	Load a multipage TIFF file into a single 3D array in xyz format, converting data to specified dtype and handling proper dimension ordering.
12025	Writes configuration data to a file using YAML format. Takes the configuration data (expected to be a dict) and writes it to the specified configuration file with proper YAML formatting.
12026	Clone a repository from the specified URL using the git executable, creating a new branch with the repository's path as the destination.
12027	Get version from package resources by parsing the "yoda" requirement and returning the provider's version.
12028	Function that takes a name and optional greeting and yell parameters, creates a greeting message, and prints it in either regular or uppercase with punctuation based on the yell parameter.
12029	A decorator function that creates a command-line option handler with customizable greeting and yelling behavior. Takes a name, greeting message, and boolean flag to determine output format, printing either a formatted greeting or an all-caps exclamation.
12030	Reserves a specified quantity of IDs from the server by making a GET request to a reservation endpoint. Takes a token, channel, and quantity as parameters, validates the response, and returns a list of consecutively numbered IDs starting from the first available ID granted by the server. Raises RemoteDataNotFoundError if the reservation request fails.
12031	Merge RAMON objects by ID through RESTful endpoint, optionally deleting merged objects. Returns True on success.
12032	Propagates a token-channel pair to a remote server by setting its propagate status to 1. Returns True on success, raises RemoteDataUploadError on failure. If the token-channel already has propagate status '0', the function returns early without making a remote request.
12033	Lists projects related to a specified dataset by making a GET request to the dataset's project endpoint and returns the JSON response containing the projects found. Raises RemoteDataNotFoundError if the request fails.
12034	Returns information about a specific dataset by fetching it from a remote API endpoint. Takes a dataset name as input and returns a dictionary containing the dataset details. Raises RemoteDataNotFoundError if the dataset cannot be found (status code other than 200).
12035	Lists datasets in resources based on the get_global_public parameter. If True, retrieves all public datasets in the cloud; if False, retrieves only the user's public datasets. Returns datasets in JSON format.
12036	Parse show subcommand that displays workspace details with mutually exclusive options for showing all workspaces or a specific workspace by name.
12037	Execute show subcommand, displaying specific workspace if name provided or all workspaces if --all flag is used.
12038	Show specific workspace with its path, number of repositories, and detailed repository information including repository name, path, and SCM type. Raises ValueError if workspace doesn't exist.
12039	Show details for all workspaces by iterating through each workspace and displaying its information with spacing between each workspace.
12040	Method: url
Description: Constructs and returns the base URL of the Remote by combining the protocol, hostname, and optional endpoint.
Arguments: Takes an optional endpoint parameter (default: empty string).
Returns: A string representing the complete base URL.
Behavior: If the endpoint doesn't start with '/', it prepends a '/' to the endpoint before combining it with the protocol and hostname.
12041	Guesses the appropriate data type from a file extension by looking through FILE_FORMATS to find matching formats. Returns the format string if exactly one match is found, or False if no match or multiple matches (ambiguous) are found.
12042	Opens a file from disk and returns it as a numpy.ndarray. Supports image formats like PNG, JPG, TIFF, and JPEG. Raises NotImplementedError for unsupported formats.
12043	Converts a file from one format to another, guessing formats when not explicitly specified. Verifies input file exists and output file doesn't. Determines input and output formats either from parameters or file extensions. Imports data using the appropriate loader based on input format, then exports it using the appropriate saver based on output format. Returns the output filename. Raises IOError if input file doesn't exist, or ValueError if formats cannot be determined. Handles special case where input and output formats are identical by copying the file.
12044	Builds a graph using the graph-services endpoint with specified parameters. Takes project, site, subject, session, scan, and size as required arguments, along with optional settings for email, invariants, fiber file, atlas file, threading, and callback. Validates inputs and either runs the graph building process in the foreground or background using threads. Returns an HTTP response or None depending on threading usage. Raises ValueError for invalid inputs and RemoteDataNotFoundError for server processing issues.
12045	Compute graph invariants from a GraphML file using remote grute services. Supports background execution with threading and callbacks. Validates input format, invariants, and file existence. Raises ValueError for invalid inputs, RemoteDataUploadError for upload issues, and RemoteError for server computation problems. Returns HTTP response when not using threads, otherwise returns None.
12046	Convert a graph file from one format to another, with optional email notification and threading support. Raises RemoteDataUploadError, RemoteError, or ValueError on issues. Returns HTTP response when not using threads, otherwise runs in background.
12047	Converts a RAMON object list to a JSON-style dictionary indexed by ID. Takes a list of RAMON objects (or single object) and returns a dictionary where each RAMON is stored under its ID, with fields for id, type, and metadata. The flatten parameter is not implemented.
12048	Returns the class type based on input string or integer parameter, with different lookup tables for Python 2 and 3 compatibility.
12049	Deletes a channel given its name, project name, and dataset name. Returns True if successful, False otherwise.
12050	Adds a new dataset to the ingest with specified parameters including name, image size, voxel resolution, and optional configurations for offset, time range, scaling levels, and scaling method.
12051	Generate ND json object by creating a dictionary with dataset, project, metadata, and channels information, then return it as a JSON string with sorted keys and indentation.
12052	Generate a dataset dictionary with the specified parameters including dataset name, imagesize, voxelres, and optional parameters like offset, timerange, scalinglevels, and scaling.
12053	Generate a channel dictionary with the specified parameters including channel name, data type, channel type, data URL, file format, file type, and optional fields like exceptions, resolution, window range, and read-only status.
12054	Generate a project dictionary with project name, token name (using project name as default if empty or None), and public status.
12055	Method: `identify_imagesize`

Summary: This method determines the dimensions of an image file by loading it using appropriate library functions based on the image type. It supports PNG and TIFF/TIFF image formats, returning the image dimensions in reverse order. The method constructs the full file path using the provided image type and path, then attempts to load and retrieve the image dimensions. If the image type is unsupported or the file cannot be accessed, appropriate exceptions are raised.

Parameters:
- `image_type` (str): The type of image file ('png', 'tif', or 'tiff')
- `image_path` (str): The base path where the image file is located (default: '/tmp/img.')

Returns: 
- `tuple`: Image dimensions in reverse order (height, width)

Exceptions:
- `ValueError`: Raised when an unsupported image type is provided
- `OSError`: Raised when the image file cannot be accessed at the specified path
12056	Method: `put_data(self, data)`

Summary: Attempts to post JSON data to a server endpoint for automatic ingestion. The method constructs a URL path using the instance's `oo.url("autoIngest/")` method, sends a POST request with the provided data (serialized to JSON format), and verifies the response status code is 200. On successful submission, it prints the server's response content. If the request fails or returns a non-200 status code, it raises an OSError with details about the failure including the response status code. The method bypasses SSL certificate verification during the HTTP request.

Parameters:
- `data`: A dictionary or object containing the data to be posted to the server

Returns: None

Raises:
- `OSError`: When the POST request fails or returns a status code other than 200
12057	Find path for given workspace and/or repository, returning a dictionary mapping path names to their respective paths.
12058	Get a list of public tokens available on this server.

Returns:
    str[]: list of public tokens
12059	Return project information for a given token by making a GET request to the project info endpoint and returning the JSON response.
12060	Sets metadata for a given token in the OCP database by making a POST request. Raises RemoteDataUploadError if upload fails.
12061	Get a response object for a given url with authentication token. Raises ValueError for access denied errors. Returns the response object on success.
12062	Method: `post_url`
Summary: Sends an HTTP POST request to a specified URL with optional authentication token, JSON data, or form data. Returns a POST request object.

Parameters:
- `url` (str): The URL to send the POST request to
- `token` (str): Optional authentication token (defaults to instance's user token if empty)
- `json` (dict): Optional JSON data to send in request body
- `data` (dict): Optional form data to send in request body
- `headers` (dict): Optional additional headers to include

Returns: A requests.post() object representing the HTTP POST request

The method automatically adds authorization headers using the provided token and handles three request types: JSON payload, form data, or no payload. SSL verification is disabled for all requests.
12063	Returns a DELETE request object for the specified URL with optional authentication token.
12064	Loads an HDF5 file into a numpy array by accessing the 'image/CUTOUT' dataset path within the file.
12065	Save a numpy array to an HDF5 file format. Takes a filename and numpy array as input, exports the array to HDF5 format, and returns the expanded filename. Raises ValueError if saving fails.
12066	Adds a character matrix to DendroPy tree and infers gaps using Fitch's algorithm to determine placement of gaps in sequences at ancestral nodes.
12067	```python
def nvim_io_recover(self, io: NvimIORecover[A]) -> NvimIO[B]:
    '''calls `map` to shift the recover execution to flat_map_nvim_io'''
    return eval_step(self.vim)(io.map(lambda a: a))
```

Summary: This method performs a recover operation on NVim IO by mapping the input to shift execution to `flat_map_nvim_io` through `eval_step`.
12068	Installs custom gettext and ngettext functions into Jinja2's environment by creating a Translation class that wraps the ugettext and ungettext functions, then calls jingo.env.install_gettext_translations() with this translation object.
12069	A central unsafe function that executes a thunk with exclusive access to a guarded state, using a lock to ensure thread safety. It acquires the guard, runs the thunk with the current state, ensures failure handling with release, updates the state in-place, releases the guard, and returns the response.
12070	Calculate a percentage by dividing a part value by a total value and multiplying by 100, rounded to 1 decimal place. Returns 0 if division by zero occurs.
12071	Get cache statistics information from memcached servers, calculating percentages for bytes usage and get hit/miss rates. Returns statistics for all servers or a specific server if server_name is provided.
12072	Get slabs info from memcached client, optionally filtering by server name. Returns a dictionary mapping server names to their slab information, or just the slab information for a specific server if server_name is provided.
12073	Adds admin global context for Django 1.7 compatibility by merging site context with provided data, falling back to just data if site context is unavailable.
12074	Return the status of all servers by rendering server_status.html template with cache statistics and slabs availability information.
12075	Show the memcache dashboard, displaying cache statistics if memcached is configured and reachable, otherwise show an error message.
12076	Displays server statistics for a given server name by retrieving cache statistics and rendering them in a template.
12077	Show server slabs by rendering the 'memcache_admin/slabs.html' template with context data containing the page title and cache slabs for the specified server.
12078	Converts a byte value into a human-readable format, returning the size in bytes (B), kilobytes (KB), megabytes (MB), or gigabytes (GB) with 2 decimal places.
12079	Find a config in the children to fill in variables in other children with its data. First checks for a 'config' kwarg, then looks through other kwargs and directories for Config objects. Returns the first found Config object, prioritizing named 'config' over others.
12080	Add objects to the environment by creating Directory instances for string values and assigning them to _children dictionary with proper configuration and preparation.
12081	Replace config tokens in file path with config values using the provided applicator.
12082	Get the path to the file relative to its parent. If the file has a parent, joins the parent's path with the file path; otherwise, returns the file path directly.
12083	Read and return the contents of the file.
12084	Writes data to a file using the specified mode, defaulting to write mode.
12085	Configure the Python logging module for this file by creating a file handler with optional formatting and adding it to specified loggers or the root logger.
12086	Create a file at the specified path if it doesn't already exist, otherwise raise an exception.
12087	Apply configuration tokens to the path and recursively apply configuration to all children nodes using the provided applicator function.
12088	Return the full path to this directory by joining parent path, base name, and additional path components.
12089	Remove the directory, with optional recursive deletion and error handling.
12090	Prepare the directory for environment use by creating it if needed and recursively preparing child elements.
12091	Cleans up child elements and removes the directory if the cleanup flag is set.
12092	Returns the full path by joining the current directory path with the given path component.
12093	List the contents of the directory by returning a list of File objects for each item in the directory path.
12094	Write data to a file in the directory using the specified mode.
12095	Read a file from the directory and return its contents.
12096	Add objects to the directory, supporting both keyword arguments (as File objects or strings) and positional arguments (as File objects or strings). Returns the added File object when a single file/filename is provided for convenience.
12097	Save the object's state to a file using YAML serialization.
12098	Load a saved state file from the specified path, parsing it with YAML and replacing tabs with 4 spaces, storing the result in self.d.
12099	Clean up the saved state by removing the file at the specified path if it exists.
12100	Loads Python plugins from a directory recursively. Searches for .py files and loads modules that contain subclasses of the Plugin class. Handles both files and subdirectories by recursively traversing the directory structure.
12101	Recursively merges values from a source dictionary into a target dictionary, updating nested dictionaries while preserving existing keys.
12102	Return a ConfigNode object representing a child node with the specified relative path.
12103	Returns a tuple containing a reference to the last container in the path and the last component in the key path, allowing direct access to the item referred to by the key path. Traverses the nested structure based on the path components, creating missing containers if the create flag is True. Handles both dictionary and list access, converting string keys to integers when possible for array indexing. Raises IndexError for invalid list indices and KeyError for invalid dictionary keys.
12104	Get the value represented by this node, returning None if the path cannot be resolved or key/index is missing.
12105	Update the configuration with new data and/or options. The `options` parameter accepts keypath/value pairs similar to CherryPy's config mechanism (e.g., 'server.port': 8080), while `data` accepts nested dictionaries of actual configuration data. Both parameters are optional and can be used together. Options are applied first, followed by merging the data dictionary. If data is a ConfigNode, it's converted to its value before merging.
12106	Load configuration data from files and initialize the config object with defaults and loaded data.
12107	Apply the config to a string by replacing config variable placeholders in the format `{config:variable_name}` with their corresponding values from the configuration. The method splits the string on config delimiters, processes each token to identify and replace config variables, and returns the resulting string with all valid config variables substituted. If a config variable is not found or there's a parsing error, the original string is returned unchanged.
12108	Build Twilio callback URL for confirming message delivery status by constructing an absolute URL using either a configured domain or request object.
12109	Method called when socket is read-ready to process input data, handling exceptions by logging errors and closing connections, then processes the connection with current timestamp.
12110	Method `send_output` is called when a socket is ready for writing. It attempts to write output data using `pyngus.write_socket_output` and handles any exceptions by logging the error, closing the output connection, and closing the connection entirely. Finally, it processes the connection with the current timestamp.
12111	Send an RPC call request message with the specified method, address, and reply-to information.
12112	Reads input data from a socket connection, processes it through the connection handler, and returns the number of bytes processed or EOS if connection is closed. Handles blocking and non-blocking sockets with appropriate exception handling for timeouts, interrupts, and other socket errors. Returns 0 for retryable errors, EOS for connection closure, or re-raises exceptions for fatal errors.
12113	Writes data to network layer through socket connection, handling both blocking and non-blocking sockets. Returns number of bytes sent or EOS when done. Handles socket timeouts, blocking errors, and other socket errors appropriately, with fatal errors re-raised to caller. Manages connection state changes when socket is closed.
12114	Decorator that prevents callbacks from calling into link methods that are not reentrant. Raises RuntimeError if a link method is invoked from within a callback.
12115	Return a map containing the settle modes as provided by the remote, skipping any default values.
12116	Configure link addresses, properties, and modes.

Sets up the target and source addresses for a link, handling both static and dynamic addresses. Configures distribution, send settle, and receive settle modes from properties. For dynamic addresses, sets up the appropriate properties and clears existing ones when dynamic properties are provided.

Parameters:
- target_address: Target address for the link
- source_address: Source address for the link  
- handler: Handler function for the link
- properties: Dictionary of link properties including distribution modes and dynamic node properties
12117	Return the authoritative source address of the link, using local address for senders or remote address for receivers.
12118	Return the authoritative target address of the link, using the local target for receivers or the remote target for senders.
12119	When the remote session closes, this method handles the link's response based on its current state. If the link is still active remotely, it simulates receiving a close event. If the link was never initialized remotely (locally created), it marks the link as failed with a "Parent session closed" error.
12120	Create a new sender link and return a request sender object.
12121	Creates and returns a SenderLink object from a request link, adding it to the connections links collection.
12122	Create a new receiver link and return the requested receiver.
12123	Creates a ReceiverLink from a request and adds it to the connections links.
12124	When a link is destroyed, it is removed from the internal links collection. If no links remain, the session is closed and freed, and session references are set to None.
12125	Method `_ep_need_close` is called when a peer closes its end of a session. It logs a debug message indicating the session close request, creates a copy of the session's links to avoid modification issues during iteration, and then calls the `_session_closed` method on each link to notify them of the session closure.
12126	Processes endpoint state change events by transitioning through a finite state machine, handling invalid events by setting an error state, and executing associated state change callbacks when transitions occur.
12127	Modifies inline patterns to add a mark tag pattern for text highlighting functionality.
12128	Method called when a receiver link is closed remotely. Logs the close condition, closes the receiver link, and sets the done flag to True.
12129	Method `receiver_failed` handles protocol errors by logging the error, closing the receiver link, and marking the process as done.
12130	Parse the hostname and port from an AMQP server address string, returning a tuple of (host, port) where port is None if not specified.
12131	Creates a TCP socket connection to a specified host and port, with optional non-blocking behavior. Returns the connected socket object.
12132	Creates a TCP listening socket for a server with the specified host, port, and backlog settings, setting it to non-blocking mode.
12133	Returns a triple of lists (readers, writers, timers) containing connections that need network reading, writing, and connections waiting for pending timers to expire (sorted by expiration time).
12134	Decorator that prevents callbacks from calling into methods that are not reentrant by checking if a callback lock is active before allowing the method to execute.
12135	Process connection state by handling SASL authentication, timer events, and proton events, while managing connection lifecycle and invoking appropriate callbacks for SASL completion, connection failures, or closure.
12136	Get a buffer of data that needs to be written to the network. Returns None if no data is available or if an error occurs during data retrieval.
12137	Creates a new Sender link with the specified parameters, configures it with the given address and properties, and returns the configured sender object. Raises a KeyError if a sender with the same identifier already exists.
12138	Rejects a SenderLink by its handle and destroys the link. Raises an exception if the link handle is invalid. The link is rejected with an optional condition and then destroyed immediately since it was not made available to the application.
12139	Creates a new Receive link using the provided parameters and adds it to the receiver links dictionary. Raises KeyError if a receiver with the same identifier already exists. Returns the newly created receiver link.
12140	Clean up and log connection failure error, storing it in self._error if not already set.
12141	**Method Summary:**

`_ep_active` - Handles the event when both ends of an endpoint become active, logs connection status, and notifies the handler through a callback mechanism.

**Key Details:**
- **Purpose:** Manages endpoint connection activation state
- **Actions:** Logs "Connection is up" message, invokes handler's connection_active callback if handler exists
- **Thread Safety:** Uses callback lock to ensure thread-safe handler invocation
- **Trigger:** Called when both endpoint ends are active

**Parameters:** None
**Returns:** None
12142	Method `_ep_need_close` is called when the remote end of a connection closes. It logs a debug message indicating the connection was remotely closed and notifies the handler through a callback, passing along the remote connection condition. The method uses a callback lock to ensure thread-safe execution of the handler's callback.
12143	Method `_ep_error` handles protocol errors in the endpoint state machine by calling the parent class's `_ep_error` method and then triggering a connection failure with a "Protocol error occurred" message.
12144	A decorator that provides helpful shortcuts for writing Twilio views by ensuring requests are from Twilio, exempting views from CSRF checks, and allowing views to return TwiML or Verb objects instead of manual HttpResponse objects.
12145	Returns Adobe output string for defining colors based on color type and color values. For device colors ('d'), returns either grayscale 'G' or RGB 'RG' format. For fill ('f') or text ('t') colors, returns either grayscale 'g' or RGB 'rg' format. Uses 0.000 format for values.
12146	Method `get_ttf` searches through a given directory path to find all files with '.ttf' extension. It processes each .ttf file by extracting its name, normalizing spaces and style indicators (bold, italic, oblique), and storing the file paths in a dictionary with normalized names as keys. The method populates `self.font_dict` with font names and their corresponding file paths, and `self.families` with the list of font families found. It specifically handles font names that start with English letters differently from those that don't, and correctly processes various style indicators to create standardized font naming conventions.
12147	Sets the compression property to a boolean value. Raises TypeError if value is not boolean.
12148	Adds an object to the PDF document's object array at the specified position, creating a new object with given flag or appending to the end, and outputs the object reference to the buffer.
12149	Stores PDF code in a buffer, either globally or in a specific page's buffer if page object is provided.
12150	Creates a PDF text stream by writing 'stream', the provided stream content, and 'endstream' in sequence.
12151	Helper function for PDFText to add a new page and retry adding large blocks of text that would otherwise be too long for a single page.
12152	Sets the color scheme for drawing, filling, and text elements. If no colors are specified, defaults to black for all elements. Initializes draw_color, fill_color, and text_color attributes with appropriate PDFColor objects.
12153	Sets the default font by creating a new PDFFont object, setting its index, adding it to the fonts list and its font_key to fontkeys list.
12154	Adds a new page to the document, either creating a default page or using a provided page object, and initializes its properties and font settings.
12155	Sets the font size to the specified value, only updating if the size has actually changed.
12156	Adds text to a PDF page with optional cursor position and justification. Handles both single lines and multi-line text by processing each line separately. Text is automatically cleaned of multiple whitespace characters, and sequential calls print without additional whitespace. Uses the page's current cursor position and justification settings by default.
12157	**Method Summary:**

`add_newline(self, number=1)` - Moves cursor to a new line position on the document page. Accepts an optional integer parameter `number` to specify how many line breaks to create (default is 1). If the specified number of lines exceeds the current page capacity, it automatically creates a new page. Raises `TypeError` if the `number` parameter is not an integer, and handles `ValueError` internally by triggering page creation when necessary.
12158	Adds a pie chart to the PDF with specified data and formatting options, preserving current color settings during chart creation.
12159	Creates PDF page objects and their content streams, handling orientation changes and compression. For each page, it generates the page object with media box, resources, and content references, then creates the content stream with optional compression.
12160	Returns a list of page indices that have orientation changes by iterating through all pages and collecting those with orientation_change set to True.
12161	**Summary:**

The `_output_fonts` method is responsible for creating font objects in a PDFLite document. It saves the current object number, outputs encoding differences and font files, then iterates through all fonts to add each font as a new object in the session, sets its object number, and outputs the font data.

**Method signature:** `_output_fonts(self)`

**Returns:** None

**Side effects:** 
- Saves object number in session
- Outputs encoding differences and font files
- Adds font objects to session
- Sets object numbers on fonts
- Outputs font data for each font in `self.fonts`

**Called by:** PDFLite object during PDF creation process
12162	Creates reference images that can be drawn throughout the document by adding objects to the session and setting image numbers.
12163	**Summary:**

The `_output` method generates the PDF object representation of an image by writing image properties such as dimensions, color space, bits per component, and compression filters to the PDF session. It handles different color spaces (including Indexed and DeviceCMYK), transparency masks, soft masks, and palettes. Additionally, it writes the image data as a stream and outputs associated objects like color palettes and soft mask images. The method manages the complete PDF image object structure, including necessary headers, stream data, and end object markers.
12164	This method applies a 2D transformation matrix to the current graphics state by multiplying the current transformation matrix with a new transformation matrix defined by parameters a, b, c, d, e, f. It updates the internal `_currentMatrix` with the resulting transformation and outputs the new matrix values in PDF coordinate matrix format (cm command) to the session output. The transformation affects how subsequent graphics elements are rendered on the page.
12165	Returns the absolute position of coordinates (x,y) in user space relative to the default user space by applying the current transformation matrix.
12166	Sets the text style for the object, accepting 'B' for bold, 'U' for underline, 'I' for italic, or empty string for no style. Symbol and zapfdingbats fonts disable all styling. Underline style is determined by presence of 'U' in style string.
12167	Rotates a point relative to the mesh origin by the angle specified in the angle property, using trigonometric calculations to compute the new position based on the angle and distance from the origin.
12168	Summary: Sets document information properties (title, subject, author, keywords, creator) with optional values, preserving existing values and creating new attributes only when needed.
12169	Set the default viewing options with specified zoom and layout modes, validating that the provided values are supported. Raises exceptions for invalid zoom or layout display modes.
12170	Closes the document by generating PDF code and saving it to the specified destination. This method orchestrates the complete PDF generation process by calling various internal methods to output headers, pages, resources, information, catalog, and trailer objects. It then writes the final output to either an IO object, a string, or a file based on the destination parameter, and returns the output when appropriate.
12171	Writes the standard PDF header line followed by compression marker if compression is enabled.
12172	Summary: The `_put_pages` method handles the creation and output of PDF page objects. It first processes orientation changes and outputs individual pages through the document object. Then it creates a "Pages" object that references all page objects through their Kids list, setting up the page structure with media box dimensions and page count. Finally, it outputs the Pages object to the PDF session.
12173	Creates PDF reference to resource objects including fonts and images.
12174	This method creates a PDF Information object that stores metadata about the document. It adds metadata fields such as Producer, Title, Subject, Author, Keywords, Creator, and CreationDate to the PDF. The method uses the session object to add the information object and write the appropriate PDF syntax with the metadata values. The CreationDate is automatically set to the current date and time in the format 'D:YYYYMMDDHHMMSS'.
12175	Method `_put_catalog` generates a PDF catalog object that defines document structure and settings. It adds the catalog object to the session, sets the document type and pages reference, configures zoom behavior based on the zoom_mode attribute (supporting fullpage, fullwidth, real, or numeric zoom values), and applies page layout settings (single, continuous, or two-column) using PDF dictionary entries. The method concludes by finalizing the object definition with 'endobj'.
12176	Method `_put_trailer` performs final PDF trailer calculations and writes end-of-file reference. It:
1. Calculates the startxref position from buffer length
2. Writes cross-reference table
3. Generates MD5 hash using timestamp and document metadata (title, subject, author, keywords, creator)
4. Outputs trailer dictionary with:
   - Size (object count)
   - Root object reference
   - Info object reference
   - ID array with MD5 hash
5. Writes startxref position and EOF marker

The method finalizes the PDF structure by adding metadata and references needed for PDF readers to navigate the document.
12177	Floyd's Cycle Detection algorithm implementation that uses the tortoise and hare approach to detect cycles in sequences. Takes two iterators or a function/starting state pair, yields values until a cycle is detected, then raises CycleDetected exception with cycle parameters (first=offset, period=duration).
12178	**Summary:**

The `naive` function is a cycle detector that iterates through a sequence and raises a `CycleDetected` exception when a duplicate value is found, based on a key function for comparison. It maintains a history of previously seen values and their positions, and when a cycle is detected, it provides the first occurrence position and the period of the cycle. The function can work with different interfaces including direct sequences or finite state machines defined by a function and starting state.
12179	Gosper's cycle detector implementation that yields values from a sequence until a cycle is detected. Uses a table-based approach to track seen values and raises CycleDetected when a cycle is found, computing the cycle period but not the starting position. The algorithm uses bit manipulation tricks for efficient cycle detection.
12180	Brent's Cycle Detection algorithm implementation that detects cycles in sequences generated by either two iterators or a function/starting state pair. Uses the tortoise and hare approach to efficiently find cycles with O(n) time complexity. When a cycle is detected, it raises a CycleDetected exception containing the cycle's period and starting offset. When used with a function and starting state, it can identify the exact cycle parameters (first occurrence position and period) rather than just detecting the cycle's existence.
12181	Test if the line has enough space for the given length.
12182	Method `y_fit` checks if there is sufficient vertical space on the page to accommodate a given text height starting from the current y-position. It returns `False` if the test length would exceed the maximum y-coordinate (`self.ymax`), otherwise it returns `True`.
12183	Method to compare if the x coordinate of the current object is greater than the x coordinate of a test ordinate object. Returns True if self.x > test_ordinate.x, False otherwise. Includes validation to ensure the test_ordinate has a valid coordinate.
12184	Method to compare the y-coordinate of this object with another coordinate object. Returns True if this object's y-coordinate is greater than the test object's y-coordinate, False otherwise. Includes coordinate validation before comparison.
12185	Create a copy of the current cursor object with the same position, bounds, and deltas, and return the new copy.
12186	Mutable x addition method that adds a delta value to x. If no argument is provided, it uses the stored self.dx value; otherwise, it adds the provided dx value to self.x.
12187	Method `y_plus` performs mutable y-coordinate addition with an optional delta parameter. When no parameter is provided, it adds the stored delta value (`self.dy`) to the current y-coordinate (`self.y`). When a parameter `dy` is provided, it adds this value directly to the current y-coordinate. This allows for both incremental updates using stored deltas and direct value additions.
12188	Summary: The `_draw` method is an internal drawing method that compiles table data and executes the complete drawing sequence including row advancement, border setting, filling, border drawing, text drawing, and final cursor positioning. This method is intended to be called internally by `document.draw_table` rather than directly.
12189	Creates a new label with the specified name, description, and color, then returns the API response. If no description is provided, the name is used as the description. If no color is provided, a random color is assigned. The method uses the `/tags/` endpoint internally to create the label.
12190	Get all current labels from Logentries API.

Returns: list of dict containing the API response tags
Raises: ServerException if there is an error from Logentries
12191	Get labels by exact name match from the existing labels list. Returns a list of dictionaries containing label data where the name matches exactly, or an empty list if no matches found. Raises ServerException if there is an error from Logentries API.
12192	Update a Label with the provided data and return the result of the POST request.

**Parameters:**
- `label` (dict): Must include keys 'id', 'appearance', 'description', 'name', 'title'

**Returns:**
- dict: Result from the API POST request

**Example:**
```python
Labels().update(
    label={
        'id': 'd9d4596e-49e4-4135-b3b3-847f9e7c1f43',
        'appearance': {'color': '278abe'},
        'name': 'My Sandbox',
        'description': 'My Sandbox',
        'title': 'My Sandbox',
    }
)
```
12193	Delete the specified label by sending a DELETE request to the API endpoint with the given label ID.

Parameters:
- id (str): the label's ID

Returns:
- Result of the POST request to the DELETE endpoint

Raises:
- ServerException: if there is an error from Logentries
12194	Create a new tag using the provided label ID by making a POST request to the actions endpoint with predefined tag configuration data.
12195	Get all current tags

:return: All tags
:rtype: list of dict

:raises: This will raise a
    :class:`ServerException<logentries_api.exceptions.ServerException>`
    if there is an error from Logentries

Filters and returns only items with 'type' equal to 'tagit' from the API response actions list.
12196	Get tags by a label's sn key.

:param label_sn: A corresponding label's ``sn`` key.
:type label_sn: str or int

:return: A list of matching tags. An empty list is returned if there are not any matches
:rtype: list of dict

:raises: ServerException<logentries_api.exceptions.ServerException> if there is an error from Logentries
12197	Create a hook with specified name, regexes, tag IDs, and optional logs by sending a POST request to the hooks API endpoint.
12198	Get all current hooks from Logentries API.

Returns a list of hook dictionaries. Raises ServerException if there is an error from Logentries.
12199	Update a hook by sending hook data through a POST request to the hooks API endpoint.

**Parameters:**
- `hook` (dict): Hook data containing keys 'id', 'name', 'triggers', 'sources', 'groups', and 'actions'

**Returns:**
- dict: Response from the API post request

**Example:**
```python
Hooks().update(
    hook={
        'id': 'd9d4596e-49e4-4135-b3b3-847f9e7c1f43',
        'name': 'My Sandbox',
        'triggers': ['host = you.example.com'],
        'sources': ['4d42c719-4005-4929-aa4a-994da4b95040'],
        'groups': [],
        'actions': [
            '9f6adf69-37b9-4a4b-88fb-c3fc4c781a11',
            'ddc36d71-33cb-4f4f-be1b-8591814b1946'
        ],
    }
)
```
12200	Create a new alert with specified configuration and frequency settings, sending the alert to the provided alert configurations. The method accepts parameters for occurrence and alert frequencies, defaulting to 1 hour periods if not specified. It returns the server's response as a dictionary.
12201	Get alerts matching a specific type and optional arguments.

This method filters alerts by type and arguments, returning all alerts that match the specified alert type and have the provided arguments as a subset of their actual arguments.

Parameters:
- alert_type (str): The type of alert to filter by (must be one of 'pagerduty', 'mailto', 'webhook', 'slack', or 'hipchat')
- alert_args (dict, optional): Arguments that must be a subset of the alert's actual arguments

Returns:
- list: A list of alert dictionaries matching the criteria, or empty list if no matches found

Raises:
- ServerException: If there is an error from the Logentries server
12202	Update an alert by sending the provided alert data to the API endpoint. The alert data must include keys such as id, rate_count, rate_range, limit_count, limit_range, type, schedule, and args. The method constructs a data dictionary with these fields and makes a POST request to the UPDATE action endpoint with the constructed parameters. Returns the response from the API call.
12203	Initialize Sphinx extension with todo, mathjax, intersphinx, and extlinks extensions, configure intersphinx mapping for Python and Sage documentation, and set the HTML theme to 'sage'.
12204	Returns the absolute path to the 'themes' directory located within the same package as this module.
12205	A wrapper for making POST requests to the Logentries API. Takes a request type, URI endpoint, and optional parameters, constructs the request data with account credentials, sends a POST request to the Logentries API, and returns the JSON response. Raises ServerException if the response indicates an error.
12206	Get all log sets from Logentries API.

Returns a dictionary mapping hostnames/log sets to lists of log keys.

Raises ServerException if the API request fails.
12207	Get a specific log or log set by making a GET request to the API endpoint. Takes a log_set parameter specifying the log or log set to retrieve (e.g., 'app' or 'app/log'), and returns the JSON response. Raises ServerException if the API returns an error status code.
12208	Find a slider attacker by checking if any slider piece in piece_bb can attack the target position pos, considering occupancy constraints in occ_bb and excluding sliders in target_bb. Store valid attacking positions in dest_list.
12209	The `duration` method calculates the approximate transit duration for a planetary transit, accounting for eccentric orbits. It computes the transit duration based on orbital parameters including eccentricity, impact parameter, and planetary radius ratio, while adjusting for orbital eccentricity effects. The method handles both circular and eccentric orbits by deriving eccentricity and other parameters when needed, and returns the transit duration in days.
12210	Update the transit keyword arguments with validation and automatic ldmodel detection based on provided parameters.
12211	**Summary:** Computes the light curve model by calling the low-level _Compute function with transit, limb darkening, settings, and arrays parameters. Raises an error if the computation fails.
12212	Bins the light curve model to the provided time array using the _Bin function with transit, limbdark, settings, and arrays parameters. Raises an error if the binning process fails.
12213	Frees all dynamically allocated C arrays by calling _dbl_free on each array member and resetting their allocation flags to 0.
12214	Reads data from socket with specified size, raises NNTPError on timeout/failure, writes received data to internal buffer.
12215	Generator that reads lines of data from a server by first checking an internal buffer, and if needed, requesting more data from the server to fulfill line reads. Yields lines of data as they become available.
12216	Generator that reads data blocks from server, first checking internal buffer then requesting more data if needed. Yields data blocks of specified length (or default buffer size if length=0), handling partial reads by continuing until sufficient data is available.
12217	Reads and parses an NNTP command response status line, returning a tuple of status code and message while raising appropriate exceptions for error codes and parsing failures.
12218	Dispatcher for info generators that selects the appropriate generator based on compression flags in the message or explicit compression parameter, returning the corresponding info generator function.
12219	Returns the complete content of a textual info response by joining all elements from the info_gen generator method.
12220	Call a command on the server with optional arguments, handling authentication if needed. Returns a tuple of status code and message. Raises NNTPSyncError if command is issued while generator is active. Handles temporary errors (480) by attempting authentication before retrying the original command.
12221	**Summary:**

The `capabilities` method sends a CAPABILITIES command to an NNTP server to determine its supported features. It accepts an optional keyword parameter (though unused by servers per RFC3977) and returns a list of server capabilities, with VERSION always appearing first. The method raises `NNTPReplyError` if the server response code is not 101 (indicating success). The result is parsed from the server's informational response using `info_gen`.
12222	MODE READER command that instructs a mode-switching server to switch modes, returning True if posting is allowed (code 200) or False if not (code 201), raising NNTPReplyError for other codes.
12223	QUIT command implementation that closes the NNTP connection gracefully. Sends QUIT command to server, validates successful response (code 205), and closes the underlying socket. Raises NNTPReplyError if server returns unexpected response code. After calling this method, no other NNTPClient methods should be invoked. The method is intended for graceful shutdown and should not be used within generators (use close() instead).
12224	Returns the UTC time according to the server as a datetime object by executing the DATE command. Raises NNTPReplyError if the server response code is not 111, and NNTPDataError if the timestamp cannot be parsed.
12225	HELP command that provides a short summary of commands understood by the NNTP server, returning help text from the server.
12226	Generator for the NEWGROUPS command that yields newsgroups created since a specified timestamp, handling timezone conversion and parsing response lines.
12227	Generator for the NEWNEWS command that yields message-ids for articles created since a specified timestamp in newsgroups matching a given pattern. Converts timezone-aware timestamps to GMT and raises NNTPReplyError for non-230 response codes.
12228	NEWNEWS command that retrieves a list of message-ids for articles created since a specified timestamp for newsgroups matching a given pattern.
12229	Generator for the LIST ACTIVE command that yields active newsgroups matching an optional pattern, returning tuples of newsgroup name, low water mark, high water mark, and status.
12230	Generator for the LIST ACTIVE.TIMES command that yields tuples containing newsgroup name, creation date as datetime object, and creator string. Raises NNTPReplyError for non-215 response codes and NNTPDataError for invalid data format.
12231	Generator for the LIST NEWSGROUPS command that yields tuples of newsgroup names and descriptions, optionally filtered by a pattern. Raises NNTPReplyError if the command fails.
12232	Generator for the LIST OVERVIEW.FMT command that yields tuples of (name, is_full) by parsing the response lines and validating the format. Raises NNTPReplyError for non-215 response codes and NNTPDataError for invalid formats.
12233	Generator for the LIST EXTENSIONS command that yields stripped lines from the command output. Raises NNTPReplyError if the command fails.
12234	Generator for LIST command that yields elements from various list sub-commands based on the keyword parameter, including ACTIVE, ACTIVE.TIMES, DISTRIB.PATS, HEADERS, NEWSGROUPS, OVERVIEW.FMT, and EXTENSIONS, raising NotImplementedError for unsupported keywords.
12235	LIST command implementation that wraps all list commands. Returns a list of results from list_gen based on the specified keyword and argument. Supports keywords: ACTIVE, ACTIVE.TIMES, DISTRIB.PATS, HEADERS, NEWSGROUPS, OVERVIEW.FMT, and EXTENSIONS. Raises NotImplementedError for unsupported keywords.
12236	GROUP command implementation that retrieves and parses group information from NNTP server, returning total, first, last, and group name. Raises NNTPReplyError for non-211 status codes and NNTPDataError for invalid response format.
12237	NEXT command implementation that retrieves the next article number and message ID from an NNTP server. Returns a tuple of (article_number, message_id) on successful response (code 223), raises NNTPReplyError for non-223 status codes, and raises NNTPDataError for invalid response format.
12238	ARTICLE command implementation that retrieves and processes news articles. Takes optional message ID/article parameter, sends ARTICLE command to server, validates response, parses article number and headers, handles yEnc decoding when required, and returns article number, headers, and body content.
12239	HEAD command implementation that retrieves article headers. Takes an optional msgid_article parameter, sends HEAD command to server, validates response code (must be 221), and returns parsed headers. Raises NNTPReplyError for invalid response codes.
12240	BODY command implementation that retrieves and processes article body content, optionally decoding yEnc encoded data. Returns the complete article body as a string.
12241	XGTITLE command implementation that sends a pattern argument to the server and handles the response, raising an exception if the expected return code (282) is not received.
12242	XHDR command implementation that retrieves header information from an NNTP server. Takes a header name and optional message ID range, sends the XHDR command, and returns the header information if successful. Raises NNTPReplyError if the server returns an error code.
12243	XZHDR command that retrieves header information for articles. Takes an optional message identifier/range parameter and returns compressed header information. Raises NNTPReplyError for non-success responses.
12244	Generator for the XOVER command that returns overview database information for specified articles. Takes an optional range parameter specifying article numbers or range, and yields parsed fields for each available article in the specified range. Raises NNTPReplyError if no such article exists or current newsgroup is invalid.
12245	Generator for the XPAT command that yields parsed response lines.
12246	XPAT command implementation that returns a list of results by consuming the generator output from xpat_gen method.
12247	XFEATURE COMPRESS GZIP command that optionally includes a TERMINATOR argument. Returns True on success, raises NNTPReplyError if the response code is not 290.
12248	POST command that sends headers and body to a newsgroup server. Raises NNTPDataError for binary characters in body. Returns True if posting succeeded, or the message-id if available. Converts '\n' line terminators to '\r\n'. Raises NNTPReplyError for invalid server responses. Handles illegal characters by truncating the message and raising an error.
12249	Parse timezone to offset in seconds.

Args:
    value: A timezone in the '+0000' format. An integer would also work.

Returns:
    The timezone offset from GMT in seconds as an integer.
12250	Parse a datetime string to a unix timestamp, using fast custom parsing for common formats or slow dateutil parser for others.
12251	Parse a datetime string to a datetime object using fast custom parsing for common formats or slow dateutil parser for other formats. Supports formats like "1 Feb 2010 12:00:00 GMT", "Mon, 1 Feb 2010 22:00:00 +1000", "20100201120000", and epoch timestamps. Returns a datetime object.
12252	**Summary:** A convenience method for making POST API requests that handles response validation and error handling, returning JSON data or raising a ServerException for non-successful responses.
12253	Convenience method for deleting resources via API calls, handling responses and raising ServerException for non-successful status codes.
12254	Convenience method for making GET requests with API headers, raising ServerException for non-success responses, and returning JSON data.
12255	List all scheduled queries and return them as a list of dictionaries. Raises ServerException if there is an error from Logentries.
12256	List all tags for the account, returning a list of tag dictionaries that may include scheduled query IDs for anomaly alerts. Raises ServerException if there is an error from Logentries.
12257	Get alert by name or id, returning a list of matching tags based on id or name comparison.
12258	Create an inactivity alert with specified parameters including name, patterns, logs, trigger configuration, and alert reports, then return the API response.
12259	Delete the specified InactivityAlert with the given tag ID by making a DELETE request to the Logentries API endpoint. Raises ServerException if there is an error from Logentries.
12260	Create a scheduled query with the given parameters and return the API response.
12261	Creates an anomaly alert by first creating a scheduled query and then setting up the alert with specified parameters including name, query, scope, threshold settings, trigger configuration, logs, and alert reports. Returns the API response from the alert creation.
12262	Delete a specified anomaly alert tag and its associated scheduled query by making two API requests to remove the tag and corresponding query. Returns early if the tag ID is not found. Raises ServerException if there is an error from Logentries.
12263	Unparses a range argument into a string format suitable for NNTP commands. Handles both single integers (representing a single article) and tuples (representing article ranges). Valid formats include: single integer like 4678, tuple with no start like (,5234), tuple with no end like (4245,), and full ranges like (4245, 5234). Returns string representation of the range.
12264	Parse a newsgroup info line to python types.

Args:
    line: An info response line containing newsgroup info.

Returns:
    A tuple of group name, low-water as integer, high-water as integer and posting status.

Raises:
    ValueError: If the newsgroup info cannot be parsed.

Note:
    Posting status is a character is one of (but not limited to):
        "y" posting allowed
        "n" posting not allowed
        "m" posting is moderated
12265	Parse a header line returning None for end of headers, continuation line for continuations, or (name, value) tuple for regular headers. Raises ValueError for unparsable lines.
12266	Function `unparse_headers(hdrs)` converts a dictionary of headers into a string format suitable for NNTP POST requests. It takes a dictionary `hdrs` where keys are header names and values are header values, processes each header using `unparse_header()` function, joins them together with newlines, and appends a carriage return and newline (`\r\n`) at the end. The result is a properly formatted headers string.
12267	Handles POST requests from Boundary Url Action by reading request data and printing client information, headers, path, and request body.
12268	Run tests using the provided reporter, with optional stop_after limit. Returns the reporter instance.
12269	Return a docstring from a list of defaults.
12270	A decorator that adds default keyword arguments documentation to a function's docstring. It takes a defaults dictionary and a decorator function that appends formatted default arguments documentation to the original function's docstring, preserving existing documentation.
12271	Add the default values to the class docstring by calling the defaults_docstring function with the class defaults attribute.
12272	Set the value after invoking type-checking and bounds-checking hooks.
12273	Method `check_type` performs type-checking during assignment by comparing a given value against an expected data type. It raises a `TypeError` if both the value and expected dtype are present but mismatched, otherwise it allows the assignment. The method returns early if either the value or expected dtype is None, effectively skipping type checking in those cases.
12274	Return the current value, caching it if not already cached by first checking if `self.__value__` is None. If not cached, invoke the `loader` function to compute the value and cache the result. Raise AttributeError if loader is not defined or TypeError if loader returns incorrect type.
12275	Method `check_type` performs type-checking during assignment by converting values to scalars using `asscalar`. It allows size 1 numpy arrays and lists, but raises `TypeError` if the value cannot be cast to a scalar. The method calls the parent class's `check_type` with the scalar value after successful conversion.
12276	Return the symmetric error from error estimates. If no error estimate is available, returns 0. For scalar error values, returns the error directly. For asymmetric errors, returns the average of the low and high error estimates.
12277	Set parameter error estimates, handling None input by clearing errors or converting errors to scalar values if provided.
12278	Sets the value, bounds, free, and errors attributes based on keyword arguments, invoking type-checking and bounds-checking hooks implemented by subclasses. Handles bounds, free, errors, and value parameters through their respective setter methods.
12279	Method `import_metrics` handles the process of importing metrics by:
1) Getting command line arguments
2) Reading and parsing JSON metrics data 
3) Creating or updating metric definitions through API calls
4) Looping through metrics to process each one for creation/update

The method handles both v2 and non-v2 metric formats, constructs proper metric objects with names, and calls `create_update` for each metric to persist them.
12280	Extract required fields from an array of metrics and return a dictionary mapping metric names to their extracted fields.
12281	Filter metrics based on a filter expression. If a filter expression is provided, it searches for matching metric names and keeps only those that match. If no filter expression is provided, all metrics are kept. The filtered metrics are then processed through an extraction method to create a new metrics dictionary.
12282	**Method Summary:**

`_call_api` - Establishes a TCP connection to a meter using JSON RPC protocol, sends an encoded RPC message, receives and stores the response data, then closes the connection. The method handles socket communication, message encoding, and data reception for API calls to a remote meter device.

**Key Operations:**
- Creates and connects TCP socket to specified host/port
- Encodes and sends RPC message 
- Receives JSON RPC response data
- Stores received data in rpc_data list
- Properly closes socket connection

**Parameters:** Uses instance variables self.rpc_host, self.rpc_port, self.rpc_message, and self.MAX_LINE

**Returns:** None (modifies self.rpc_data in-place)
12283	expression_terminal matches one of several possible terminal expression types: identifier, terminal, option_group, repetition_group, grouping_group, or special_handling.
12284	Method `operator` attempts to match one of the operators: "|", ".", ",", or "-". It uses the `alternation` function to try each operator in sequence and returns the matched operator with `TokenType.operator` type.
12285	op_add = "+" ; returns a terminal token for addition operator "+" with TokenType.op_add
12286	Initializes properties by tracking required properties and setting up derived property loaders.
12287	Return a list of Parameter objects, either all parameters or specifically those with the given names.
12288	Return an array with the parameter values for specified parameter names or all parameters if no names are provided.
12289	Return an array with the parameter errors for specified parameters or all parameters if none are specified. The output is a N x 2 array containing the parameter errors.
12290	Reset the value of all Derived properties to None

This method iterates through all parameters and clears the value of any Derived properties by calling their clear_value() method. It's typically called by setp and __setattr__ methods to reset derived property values.
12291	Validates that the provided HTTP method value is supported before assignment, raising an AttributeError if not found in the implemented methods.
12292	Gets configuration from environment variables, setting default API host if not specified.
12293	Encode URL parameters by converting the _url_parameters dictionary to a query string, returning an empty string if no parameters exist.
12294	HTTP Get Request using requests library with url, data, headers, and basic authentication credentials.
12295	HTTP Delete Request using requests library with authentication headers and data payload.
12296	Method that performs an HTTP POST request with specified URL, data, headers, and authentication credentials.
12297	HTTP Put Request implementation that sends a PUT request to the specified URL with provided data, headers, and authentication credentials.
12298	Make an API call to get the metric definition, log request details, and handle response errors.
12299	Check scene name and whether remote file exists. Raises WrongSceneNameError if the scene name is wrong.
12300	Method that verifies satellite type and returns corresponding satellite ID and stations. Takes a satellite parameter ('L5', 'L7', or 'L8') and returns a dictionary containing the satellite ID and list of stations. Raises ProductInvalidError for invalid satellite types.
12301	Gets the filesize of a remote file from the given URL by making an HTTP request and returning the Content-Length header value. If an HTTP error occurs, it logs the error, reconnects to EarthExplorer, and retries the operation.
12302	Download remote .tar.bz file and extract TIFF images from it, returning a list of image file paths and their sizes.
12303	Validates that the bands parameter is a list containing only valid band identifiers (bands 1-11 and 'BQA'). Raises TypeError if bands is not a list, and InvalidBandError if any band in the list is not valid.
12304	Method: `connect_earthexplorer`

Summary: Establishes a connection to Earth Explorer website using provided user credentials. Attempts to authenticate by logging into https://ers.cr.usgs.gov/login with the stored username and password. If authentication fails, raises an AutenticationUSGSFailed exception. On successful connection, logs the user information and returns. Handles exceptions during the connection process and logs errors appropriately.

Parameters: None (uses instance variables self.user and self.password)

Returns: None (implicitly)

Throws: AutenticationUSGSFailed - when authentication with USGS fails
        Exception - when there are connection errors during the authentication process
12305	Returns a callable that checks if a name starts with the given prefix, useful for filtering objects by name prefix.
12306	Return a datetime.tzinfo implementation for the given timezone. Raises UnknownTimeZoneError if passed an unknown zone.
12307	Normalize a datetime by correcting its timezone information, raising ValueError if the datetime is naive (no timezone info set).
12308	Join an iterable by a delimiter, replacing instances of delimiter in items with escape + delimiter.
12309	Returns a list of positions in the text where newline characters occur.
12310	Function `point_to_source` highlights a specific position in source code by displaying the target line with a pointer and surrounding lines. It takes the source text, a position tuple (line_number, character_number), and optional formatting parameters. The function returns a formatted string showing the context around the specified position, with line numbers and a visual pointer character.
12311	Dump relay output results in textual format with timestamp, type, and message information.
12312	Method `_filter` applies filtering criteria to remove specified data fields (metrics, control, plugins) from relay information based on the presence of corresponding flags (_metrics, _control, _plugins). It operates on the 'relays' data structure within self._relays['result']['relays'] and deletes the designated fields from each relay's data when the respective filtering flags are enabled.
12313	Initialize a class instance from a list of fortune files, loading each file and accumulating their counts. Returns self with files, count, and keys attributes set. Raises ValueError if all files are invalid.
12314	Initialize a class instance with fortune files and their associated chances, distributing any remaining probability mass among files with zero chance. The method processes a list of (filename, chance) pairs, loads the corresponding fortunes, and calculates cumulative probabilities for efficient random selection. Files with non-zero chances are added directly, while those with zero chances receive remaining probability mass either equally (if equal=True) or proportionally to their entry count. The final distribution is normalized to a fixed count (65536) for efficient random indexing with cumulative probability bounds.
12315	The `main` function serves as the entry point for running tests using the virtue testing framework. It accepts a context object and keyword arguments, then executes tests through the `run` function with the provided arguments. The function exits the context with a failure code (non-zero) if any tests fail, or success code (zero) if all tests pass. The function's docstring indicates it's designed to discover and execute tests from various test objects like packages, modules, or individual objects.
12316	This method defines a parsing rule that matches a grammar rule structure consisting of an identifier, followed by an equals sign, an expression, and a semicolon. It uses concatenation to combine these elements with whitespace ignored and returns the result with a rule token type.
12317	special_handling = "?" , identifier , "?" ;
12318	Returns the parsed grammar tree from the source input, parsing it only once and caching the result.
12319	Returns the AST rules by parsing grammar children and converting expressions to ASN format.
12320	The `comments` method returns a list of AST comments by filtering children of the grammar that match the `TokenType.comment` type. It uses lazy loading, initializing the comment list only when first accessed and caching it for subsequent calls.
12321	Returns the directives parsed from comments, caching the result in self._directives.
12322	Returns the Python source code of the generated parser. If the source hasn't been compiled yet, it compiles it first and caches the result.
12323	Returns the Python source code for the generated parser by formatting a template with current date, imports, token type enum, and class definition.
12324	Returns source code for custom imports by reading import directives and joining their values, or empty string if no import directives exist.
12325	Builds Python source code for a Parser TokenType enum class with values generated from self.rules.
12326	Builds and returns the class definition string for the parser, including the class declaration, docstring, entry point, and all rule definitions formatted with proper indentation.
12327	Gets the entry_point value for the parser by finding the "entry_point" directive and returning its value, or returns the name of the first rule if no entry_point directive is found.
12328	Generates the source code for a rule by formatting a function definition with the rule's name, documentation, attempt tracking, and rule definition. Handles terminal shorthand conversion and applies proper indentation to the final source code.
12329	Gets the variable part of the source code for a rule by extracting the relevant portion from the input source, stripping trailing whitespace, and indenting it with specified depth while skipping the first line.
12330	This method determines how to transform a given rule based on its directive configuration. It returns the appropriate source code text for transforming the rule, which can be either "retype", "compress", or "identity" (no transformation). For "retype", it returns code to retyped the rule to a specified type. For "compress", it returns code to compress the rule, either with a specified type or as identity compression. For "identity", it returns an empty string indicating no transformation is needed.
12331	Convert an expression to an Abstract Syntax Tree Node by transforming children to ASN nodes and converting infix notation to optimized tree structure.
12332	Convert a parse tree node into an abstract syntax tree node based on its token type, handling various node types like identifiers, terminals, groups, special handling, numbers, and operators by creating corresponding AST node objects.
12333	Flattens a list of optree operands by recursively expanding elements that satisfy a predicate, commonly used to simplify nested concatenation or alternation operations into a single flat list.
12334	Removes grouping groups from an optree by hoisting their expressions up to parent nodes, replacing GroupingGroup objects with their underlying expressions while preserving the tree structure.
12335	Convert an abstract syntax tree node to Python source code by dispatching to specific conversion methods based on node type.
12336	Convert an abstract syntax operator tree node to Python source code by dispatching to specific handler methods based on the node's operator type.
12337	Convert an AST terminal to Python source code, returning either a shorthand value or a formatted "terminal(value)" string based on the use_terminal_shorthand flag.
12338	Convert an AST option group to Python source code by creating a formatted string with proper indentation and structure.
12339	Convert an AST repetition group to Python source code by generating a `zero_or_more()` function call with indented expression and ignore_whitespace parameter.
12340	Convert an AST special handling to python source code by returning either "PB.{ident}" for special handling identifiers or "self.{ident}" for others.
12341	Convert an AST alternate operation to Python source code by hoisting operands and formatting them in an alternation structure.
12342	Convert an AST concatenate operation to Python source code by hoisting operands and formatting them into a concatenation function call with ignore_whitespace parameter.
12343	Convert an AST exclude operation to Python source code by formatting the left and right operands with an 'exclusion(' prefix and ')' suffix, properly indented and comma-separated.
12344	Converts an AST multiplication operation to Python source code by creating a repeated() function call with formatted parameters.
12345	Convert an AST repeat operation to Python source code by creating a `one_or_more()` function call with indented operands and ignore_whitespace parameter.
12346	Finds all directives that match a given predicate - either by exact name match (if predicate is string) or by passing a custom predicate function.
12347	Custom flattening method for parse tree that returns True when child node should be flattened into parent expression based on type matching.
12348	Extracts and yields directive definitions from a comment's text content, where directives are lines starting with '!' in the comment.
12349	Handle the results of the API call by processing only non-200 HTTP status codes and printing the colored JSON response.
12350	Get a new ID if the provided one is None, otherwise return the provided ID. If a new ID is generated, log the generation.
12351	Remove a global hotkey from the specified control by unregistering the hotkey event and removing it from the internal hotkeys dictionary.
12352	Add command line arguments for API host, email, API token, and curl output options.
12353	Configures logging based on command line options by setting the logging level if provided, and logs the set level.
12354	Validates command line arguments for CLI by checking that both email and API token are provided. Returns False and sets error message if either is missing, otherwise returns True.
12355	Convert a list of nodes from infix order to postfix order using operator precedence and associativity rules, with optional recursive processing of specified node types.
12356	Convert a list of nodes in postfix order to an Optree by repeatedly reducing the nodes until only one remains, then validate and return the resulting tree structure.
12357	Finds the first operator in a list of nodes, converts it and its operands into an OptreeNode, and returns a new list with the operator and operands replaced by the new OptreeNode. Raises OperatorError if no operator is found or if there are insufficient operands.
12358	Add specific arguments for the CLI including metric name, display names, description, aggregation method, unit, resolution, type metadata, and enable/disable status.
12359	Load a plugin manifest file by reading and parsing its JSON content into a dictionary format.
12360	Looks up and returns a metric definition by name from the cached API definitions.
12361	Gets the maximum length of each column (name and description) in the field table by iterating through all fields and comparing string lengths. Returns a tuple containing the maximum lengths for name and description columns.
12362	Gets the maximum length of each column in the metrics data, returning a tuple of (max_display_name_length, max_description_length).
12363	Escapes underscores in metric names to ensure proper markdown formatting by replacing "_" with "\_".
12364	Outputs field definitions to standard out by getting column lengths, printing headers, and then printing the fields with proper formatting.
12365	**Method Summary:**
`outputMetricMarkdown()` - Outputs metric definitions in Markdown format to standard output by first escaping underscores, then calculating column lengths, and finally printing the formatted metric header and data.

**Key Steps:**
1. Escapes underscores in metric data
2. Calculates optimal column lengths for metrics and descriptions
3. Prints formatted Markdown header using calculated lengths
4. Prints formatted Markdown metric data using calculated lengths

**Purpose:** Generates and displays metric definitions in a readable Markdown table format.
12366	Method that generates Markdown documentation by calling four helper methods: generateMetricDefinitions(), generateFieldDefinitions(), generateDashboardDefinitions(), and outputMarkdown().
12367	Attempt to parse source code by calling the entry point method, raising a ParserError if parsing fails due to a DeadEnd exception.
12368	Keeps track of the furthest point in the source code that the parser has successfully processed by updating the maximum consumed character count.
12369	Add command line arguments for API metric retrieval including format, name, aggregate, sample rate, source, time range, and date formatting options.
12370	Parses a string into a datetime object, fallback to epoch timestamp conversion on parse error.
12371	Outputs query results in CSV format with timestamp, metric, aggregate, source, and value columns. Takes JSON text input, parses it, prints CSV header, then iterates through aggregates to print each timestamp with its associated source/value pairs.
12372	Method: output_json(self, text)
Summary: Converts input JSON text into a structured output format by parsing aggregated data, extracting timestamp, metric name, and source-value pairs, then formats and prints the result as indented JSON with colorization.
12373	Outputs results in raw JSON format by loading the input text as JSON, sorting keys, formatting with indentation, and printing with colorization.
12374	Method: output_xml(self, text)

Summary: Converts JSON formatted measurement data into XML format with proper structure including timestamp, metric, source, and value elements. The method creates an XML document with aggregates and measurements nodes, parses the input JSON payload, and iterates through timestamp aggregates to generate individual measure nodes for each source-value pair. The output is formatted with proper XML indentation and includes a comment header indicating the source of the generated XML.
12375	Returns True if the node is a ParseNode and is either empty or a terminal node type.
12376	Pretty prints a parse tree with proper indentation and formatting, showing node types, positions, and values while recursively printing child nodes with increased indentation.
12377	Returns a partial function that wraps `_get_repetition` with specified extractor and bounds, optionally ignoring whitespace.
12378	Checks if text starts with a given value and returns a terminal ParseNode if matched, otherwise raises DeadEnd.
12379	Tries to repeatedly extract text using the given extractor within specified bounds. Returns a ParseNode with type "repetition" if the number of successful extractions is at least the lower bound, otherwise raises DeadEnd. The bounds parameter defines the minimum and maximum number of repetitions allowed, with None indicating no upper limit. Used to implement optional matches, zero-or-more, one-or-more, and exact repetition patterns.
12380	Returns the extractor's result if the exclusion does not match. If exclusion matches (doesn't raise DeadEnd), raises DeadEnd. If exclusion raises DeadEnd (doesn't match), returns the extractor's result.
12381	Returns the number of whitespace characters at the beginning of text.
12382	Calls an extractor on text, handling both string extractors (which are passed to `_get_terminal`) and callable extractors (which are called directly).
12383	**Method Summary:**

`position()` - Retrieves the text position of a ParseNode, checking its own position first and falling back to its first child if needed. Throws an exception for 'Value Nodes' (terminals) that don't have their own position.

**Key Details:**
- Returns the node's own position if available
- If no position exists, searches the first child node for position data
- Value nodes must have their own position to avoid exceptions
- Returns `None` if no position can be determined
- Uses `isinstance(ch1, ParseNode)` to verify child is a ParseNode before accessing its position property
12384	Returns True if this node has no children, or if all of its children are empty ParseNode instances.
12385	Add ignored text to the node and update the consumed property with the ignored text length.
12386	Returns True if the node's type matches the given value. If value is a tuple, returns True if the node's type matches any member of the tuple.
12387	Flattens a ParseNode by recursively hoisting child nodes up to ancestor nodes when a predicate function returns True. If a node is a value node, it returns itself unchanged. For each child node, if the child is empty it's skipped. Otherwise, the child is recursively flattened and either hoisted (its children are added to the new children list) or appended to the new children list based on the predicate result. Returns a new ParseNode with the flattened children structure.
12388	Trim a ParseTree by removing nodes that satisfy the given predicate.

This method recursively traverses the parse tree and removes any child nodes (or subtrees) for which the predicate function `pred` returns True. The predicate is called with the child node and its parent node as arguments. Nodes that do not satisfy the predicate are kept in the resulting tree.

The method creates a new ParseNode with the same type, consumed text, position, and ignored flags as the original, but with only the non-trimmed children retained. Child nodes that are ParseNode instances are recursively trimmed themselves.

Args:
    pred: A predicate function that takes (child_node, parent_node) as arguments and returns True if the node should be trimmed

Returns:
    A new ParseNode with trimmed children according to the predicate function
12389	Returns a new ParseNode with merged children from this node and another node, preserving node type and combining consumed text while handling ignored text from this node.
12390	Returns a new ParseNode with the same contents as self but with the specified new node type.
12391	Compresses the node into a value node by concatenating all its children's string values. If `include_ignored` is True, ignored portions are included in the concatenation. Returns a new ParseNode with the concatenated value.
12392	Returns the current cursor position as a Position object containing index, line number, and column offset.
12393	Returns the position of the deepest character that has been read, represented as a Position object containing the maximum index, line, and column values.
12394	Moves the cursor to the next character position, updating column offset and tracking maximum positions reached.
12395	Sets cursor to the beginning of the next line by appending current position to end-of-line list, incrementing line number, and resetting column offset to 0.
12396	Sets cursor to the end of the previous line by popping the last end-of-line position from the `_eol` stack and assigning it to `self.position`. If no previous line exists (empty `_eol`), cursor remains unchanged.
12397	Returns the last read line content for error message computation by finding the line boundaries around the current cursor position.
12398	Increment the cursor position by the specified length and return the new index. Raises ValueError if length is negative. Handles newline characters by stepping to the next line when encountered.
12399	Save current position to contexts stack and return True.
12400	Restore the cursor position to the previously saved context and return False.
12401	Return a Fmt representation of Translator for pretty-printing, including type translation information and notification content.
12402	Sets the name of the object and updates internal signal names. Initializes the object's name attribute and refreshes the internal signal dictionary by reconstructing it from existing signal objects using their internal names.
12403	Count variables defined by this scope.
12404	Count the number of functions defined by this scope by iterating through `_hsig` values and checking for the `is_fun` attribute.
12405	Update internal counters by setting _ntypes, _nvars, and _nfuns with the respective counts from count_types(), count_vars(), and count_funs() methods.
12406	Updates the Set with values from another Set, handling namespace relationships and scope states.
12407	Create a new Scope produced by the union of two Scopes.
12408	Update this set with the intersection of itself and another set, keeping only common elements and their values from the other set.
12409	Create a new Scope produced by the intersection of two Scopes.
12410	Remove values common with another Set and return self.
12411	Create a new Scope by subtracting another Scope from this Scope.
12412	Method: symmetric_difference_update

Description: Removes common elements between this set and another set, then updates this set with elements that are unique to the other set.

Parameters: 
- oset (Scope): Another Scope object to compare and update from

Returns: 
- Scope: Returns self after performing the symmetric difference update operation

Operation:
1. Identifies common keys between this set and the other set
2. Adds keys from the other set that are not common to this set
3. Removes all common keys from this set
4. Returns the modified set
12413	Create a new Scope with values present in only one of the two scopes (symmetric difference operation).
12414	Adds a Signature object to the Set, setting its state to EMBEDDED if it's a Scope, generating an internal name, setting parent relationship, handling namespace-specific naming, checking for duplicates, and updating the count. Returns True upon successful addition.
12415	Remove a signature from the set and raise KeyError if not found. Returns True if successful.
12416	Remove a signature from the internal hash table if present, updating its state to LINKED if it's a Scope, and return True if removal was successful.
12417	Returns all signature values from the current scope, including parent scope values if in EMBEDDED state.
12418	Retrieve the first Signature ordered by mangling descendant by sorting the keys of _hsig and returning the value at the first key position.
12419	Retrieve the last Signature ordered by mangling descendant by sorting the keys of _hsig and returning the value at the last key position.
12420	Get a signature instance by its internal_name. Returns the signature if found, otherwise returns the default value (or None if not specified).
12421	Retrieve a Scope containing all signatures with the given symbol name, searching recursively in parent scopes if not found in current scope.
12422	Retrieve the unique Signature of a symbol by its name, raising KeyError if multiple candidates exist in scope.
12423	```python
def get_all_polymorphic_return(self) -> Scope:
    """Collects all polymorphic return types from symbol values and creates a linked scope.
    
    This method identifies symbols with polymorphic return types (tret.is_polymorphic),
    encapsulates them in EvalCtx for meta-variable resolution, and constructs a
    Scope containing these polymorphic types. The resulting scope inherits type/translation
    from the parent scope and is set to LINKED state.
    
    Returns:
        Scope: A linked scope containing all polymorphic return types from symbols
    """
    lst = []
    for s in self.values():
        if hasattr(s, 'tret') and s.tret.is_polymorphic:
            lst.append(EvalCtx.from_sig(s))
    rscope = Scope(sig=lst, state=StateScope.LINKED, is_namespace=False)
    rscope.set_parent(self)
    return rscope
```
12424	Method `callInjector` handles translator injection by checking if an injector is defined in the current scope. If not, it forwards the call to the parent scope recursively until either an injector is found or a TypeError is raised if no injector exists in the entire scope chain. If an injector is found, it executes the injector with the provided old Node and Translator arguments.
12425	Normalize an AST node by replacing built-in containers (dict, list, tuple) with referencable subclasses and recursively normalizing their contents. Returns the normalized node.
12426	Sets the node's class to another node's class and copies all its attributes and values.
12427	A generator method that yields data values in reverse order from a doubly-linked list, starting from the current node and traversing backwards using the prev pointer.
12428	Check if a hit's charge is within specified limits, returning False if charge is below minimum or above maximum (when maximum is not zero), True otherwise.
12429	Compute a signature using resolution by mapping type components through resolution table, handling both regular and variadic parameters, then transforming the result into the appropriate signature class.
12430	Process the signature to find definitions for types by collecting all types that need resolution, then attempt to resolve each component type by looking it up in the parent context, storing the resolved type or marking it as unresolved if not found.
12431	Returns a list of resolved type names by substituting components of the given TypeName using the context's resolution mapping. For each component in the TypeName, looks up its resolution, calls it if it's callable, and appends the resulting name to the result list. Raises an exception if a component is not found in resolution.
12432	Sets the resolved name for a type by mapping a type name to its reference value in the resolution dictionary.
12433	Deletes the specified file from the local filesystem if it exists.
12434	Deletes a specified file from an S3 bucket using the provided filename and bucket name. Handles both Key objects and string filenames, constructs the proper S3 path, and attempts to delete the key from the bucket. Silently ignores S3 response errors during deletion.
12435	Deletes a file either locally or from S3 based on storage type. If no storage type is specified, deletes locally. If storage type is 's3', deletes from the specified S3 bucket. Raises ValueError for unsupported storage types.
12436	Saves a file to the local filesystem by copying from a temporary file, creates necessary directories, sets file permissions, and optionally updates an object's filesize attribute.
12437	Saves a file to the configured S3 bucket by creating a new key with the specified filename, setting its contents from the temporary file, and updating the object's filesize attribute if configured. Returns the filename.
12438	Saves a file to either S3 or local filesystem based on storage configuration, updates object fields with storage metadata, and returns the saved file reference.
12439	Finds files in an S3 bucket by listing objects with a specified prefix path.
12440	Creates an enum type with forward and reverse mapping capabilities, allowing both name-to-value and value-to-name lookups.
12441	A decorator that validates argument and return types of a function based on type annotations. It checks that all arguments match their specified types (including default values) and that the return value matches the declared return type. Supports regular arguments, *args, and **kwargs type checking. Raises ValueError with descriptive messages for type mismatches.
12442	Adds a mapping with key `thing_name` for `callobject` in `chainmap` with namespace handling, creating nested namespace entries from the split key.
12443	Attaches a method to a class by setting it as an attribute with the method's name.
12444	Attach a method to a parsing class and register it as a parser hook, with optional custom hook name and erase functionality.
12445	Attach a method to a parsing class and register it as a parser rule, with optional custom rule name and erase functionality.
12446	Attaches a class to a parsing class and registers it as a parser directive. The class is registered with its name unless directname is provided. Returns a wrapper function that sets the namespace name and registers the class.
12447	A decorator factory that registers parsing decorators to a global decorator list. It takes an optional directname parameter to specify the registration name, defaults to the function's __name__ if not provided. The wrapper function attaches the decorator class to the global _decorators list and sets the namespace name attribute on the decorated function.
12448	**Summary:** The `bind` method creates an alias for a node by mapping a destination name (`dst`) to a source node (`src`). It searches through rule node maps to find an existing key matching `dst` and replaces its value with `src`. If the key is not found, it raises an exception indicating the key was not found. This functionality is useful for creating aliases similar to how `':>'` works by default.
12449	Return True if the parser can consume an EOL byte sequence (CRLF), False if EOF is reached or if only CR is found without LF.
12450	Push context variable to store rule nodes. Returns True.
12451	Pop the context variable that stores rule nodes by moving to parent contexts and return True.
12452	Return the text value of the node by looking up its id in caches and retrieving the corresponding value from the value cache.
12453	Pushes a new Stream into the parser, making it the active stream for subsequent parsing operations until popStream is called.
12454	Save the current stream index under the given name in tag_cache and return True.
12455	Extracts the string between saved and current index, sets the end index of the tag cache, and returns True.
12456	Sets rules for a class by merging internal rules with given rules, handling rule name namespace resolution, and returns True.
12457	Merge internal hooks with given hooks by updating the class's hook dictionary with new hook points, automatically constructing full module.class.hook_name keys when needed, and return True upon successful completion.
12458	Merges internal directives with given directives and attaches working directives to dsl.Parser class. Returns True upon successful completion.
12459	Evaluates a rule by name and returns the resulting Node. Creates a context node, checks if the rule exists, and executes the rule if found. If the rule doesn't exist, it notifies an error and raises a diagnostic exception. Returns the result of the rule evaluation or None if unsuccessful.
12460	Evaluates a hook by its name, checking if it exists in the class hooks dictionary, notifying diagnostics for unknown hooks, setting the last rule, executing the hook with context, and validating that the hook returns a boolean value.
12461	Same as readText but doesn't consume the stream.
12462	Read one byte from stream and increment position, return False if EOF reached otherwise True.
12463	Consumes a character from the stream if it matches the expected character 'c', advances the position indicator, and returns True. If the character doesn't match or end-of-file is reached, it restores the previous state and returns False. Uses stream context management for undo capability.
12464	Reads from the stream until end-of-file is reached, consuming all remaining data and validating the context. Returns True if validation passes, False otherwise.
12465	Consumes whitespace characters from the stream, returning True if any whitespace was consumed, False otherwise. Saves context before processing and validates the context after consumption.
12466	Sets the data type of hits and updates the cluster hits description by adding default fields that are not present in the input dtype. Initializes arrays with the new configuration.
12467	Sets the data type of the cluster by updating the cluster description with default fields if they don't already exist in the specified dtype, then reinitializes the arrays.
12468	Checks if the hit array has the correct data types and field names matching the clustered hit array, excluding specific hit information fields. Raises TypeError for missing required fields or mismatched data types, and logs warnings for additional unexpected fields.
12469	Create a tree.Rule object and assign it to the parser_tree attribute of ns_name, then return True.
12470	Add a parser tree to the rules dictionary with the rule name as key.
12471	Add a rule with its name and parser tree, returning True to indicate successful addition.
12472	Add a sequence to an existing sequence object by appending it to the parser tree structure, returning True upon successful completion.
12473	Adds an alternative to a parsing tree, creating a new Alt node if multiple alternatives exist, and returns True to indicate successful addition.
12474	Add a read_range primitive to the sequence's parser tree using the specified begin and end values.
12475	Add a repeater to the previous sequence, with error checking for lookahead and negated rules.
12476	Creates a tree.Capture object with the given sequence and capture value, then returns True.
12477	Creates a tree.Bind by getting the value of cpt, setting it as the parser_tree of sequence, and returning True.
12478	Summary: Adds a hook to a sequence by creating a Hook object with the hook's name and list parameters, then assigns it to the sequence's parser_tree attribute. Returns True to indicate successful completion.
12479	Parse an integer parameter from the parameter list and set it as a pair with its type.
12480	Parse a string parameter and set its pair value with stripped string and type.
12481	Parse a char in parameter list by setting param.pair to a tuple of stripped character value and str type, then return True.
12482	Parse a node name in parameter list by setting param.pair to a tuple of the evaluated value at index i and Node type, then return True.
12483	Parse a hook name and set its name attribute while initializing an empty list parameter.
12484	Parse a hook parameter by appending the parameter pair to the hook's listparam attribute and return True.
12485	Parse the DSL and return a dictionary of all resulting rules, handling parsing errors with diagnostic notifications.
12486	This method consumes comments and whitespace characters from the input stream. It handles both single-line comments (starting with "//") and multi-line comments (enclosed in "/* */"). The method skips whitespace characters and advances the stream position accordingly. It uses context saving and restoration to handle cases where comments are not properly closed, returning True if the context is valid and False otherwise. The method continues processing until no more comments or whitespace are found at the current position.
12487	Adds a state to the register with a unique identifier, mapping the state's id to its UID and the state itself in a dictionary.
12488	Generate a DOT graph representation of all states in the register with specified formatting and layout options.
12489	Writes a DOT format graph representation to a file.
12490	Writes a PNG file by converting the object's DOT representation to PNG format using the 'dot' command.
12491	Returns a string representation of the register with formatted states, events, named_events, and uid_events information.
12492	Manage state transition by handling different state types (State, StateEvent, StatePrecond, StateHook) and returning the appropriate new state or current state.
12493	Reset the living state by cleaning up living states on S0 and initializing all states. Removes living states that have finished or are not alive, marks remaining alive states as not alive, and initializes all states.
12494	Infers types for each sub-element in a block by creating an InferNode for each element and calling infer_type on it.
12495	Method `infer_subexpr` performs type inference on a given subexpression by creating a new inference node as a child of the current inference node and then inferring the type of the expression with an optional diagnostic parameter.
12496	Method `infer_id` infers the type of a given identifier by checking if it's declared in the current scope. If the identifier is found in the scope, it updates the type information using the matching declarations. If the identifier is not declared, it reports an error diagnostic stating that the identifier was never declared. The method takes an identifier name and an optional diagnostic object as parameters.
12497	Method `infer_literal` infers the type of a literal value by creating an evaluation context from the literal and its type, then adding it to the scope node's evaluation context collection. The method takes two parameters: `args` (containing the literal and its type) and an optional `diagnostic` parameter. It uses `EvalCtx.from_sig(Val(literal, t))` to create the evaluation context and adds it to `self.infer_node.scope_node.add()`.
12498	Dump tag,rule,id and value cache for debugging purposes, printing mappings from IDs to node names, tags to capture information, and node resolution with associated tags and cached values.
12499	Generates a Python function definition for a parsing rule. Takes a BasicParser and rule name as input, creates a function with the rule's code body and a return statement that always returns True. The function is structured as a method with 'self' as its only parameter.
12500	Create the appropriate scope exiting statement based on current context:
- Return Pass() if in optional context
- Return Raise(AltFalse()) if in try context  
- Return Break() if in loop context
- Return Return(False) otherwise
12501	Normalize a test expression into a statements list. If the input is already a list of statements, return it as-is. Otherwise, package the expression as an if-statement that returns False if the expression evaluates to a falsy value.
12502	Generates Python code for calling a function with the given parameters. Takes a Call node and returns an AST Call expression that calls a method on 'self' using the call object's name and string-converts the parameters.
12503	Generates Python code that calls a function and returns True by creating a lambda expression with a boolean OR operation between the function call and the value True.
12504	Generates Python code that calls a hook by creating an ast.Call node representing `self.evalHook('hookname', self.ruleNodes[-1])`. The hook name comes from the node's name attribute, and the second argument is the last element from self.ruleNodes accessed via negative indexing.
12505	Generates Python code that calls a rule by creating an AST Call node that invokes `self.evalRule('rulename')` with the rule name as a string argument.
12506	Generates Python code to capture text consumed by a parsing clause using beginTag and endTag methods, returning either a boolean operation combining all clauses or a list of statements depending on whether all clauses can be inlined.
12507	```python
def visit_Scope(self, node: parsing.Capture) -> [ast.stmt] or ast.expr:
    """Generates python code for a scope.
    
    if not self.begin():
        return False
    res = self.pt()
    if not self.end():
        return False
    return res
    """
    return ast.Name('scope_not_implemented', ast.Load())
    raise NotImplementedError()
```

The `visit_Scope` method generates Python code for a scope by returning a placeholder AST node representing an unimplemented scope, then raising a `NotImplementedError`. The method includes documentation describing the scope generation logic but ultimately doesn't implement the actual scope processing functionality.
12508	Generates Python code for alternatives using try/except blocks with AltTrue and AltFalse exceptions to handle alternative clauses, returning a boolean operation or try/except structure depending on the clause types.
12509	Generates Python code for sequence clauses by combining continuous clauses with 'and' operations, handling both expressions and statements appropriately.
12510	Generates Python code for an optional clause by visiting the node's pattern and wrapping expression results in a boolean operation with True, or returning statement results directly.
12511	Generates Python code for a clause repeated 0 or more times using a while loop structure. Returns an AST while statement that executes the clause repeatedly while True, with special handling for expression nodes that can be inlined directly.
12512	Generates Python code for a clause repeated 1 or more times, implementing a while True loop structure.
12513	Concatenates two strings while handling newlines for proper indentation. When a newline character is encountered in the source string, it applies the specified indentation level to the following character. The function converts non-string sources to strings before processing. Returns the concatenated result with adjusted indentation.
12514	Function `list_set_indent` recursively traverses a list and sets indentation level for objects that are indentable. It checks each element to see if it's an indentable object or a nested list, and applies the indentation recursively.
12515	Recursively processes a nested list structure to build a formatted string by converting indentable objects to strings, recursively processing nested lists, and concatenating string elements with proper indentation.
12516	Print nodes by converting Node objects to their string values and concatenating with other arguments, then print the result. Returns True.
12517	Function that connects sequence of MatchExpr objects by creating edges between states in a state register. For each MatchExpr in the sequence, it checks if an edge already exists for that event, and if not, creates a new edge and state connection. If the current element is a list (representing alternatives), it recursively processes each alternative. The last element in the sequence returns to the base state, while intermediate elements create new states.
12518	Function that creates a state for all instances of MatchExpr in the given list and connects them together. It creates a basic state, sets up a default state that loops on itself, and merges all sequences into one tree automata using Edge connections. Returns an Edge for debugging purposes.
12519	Builds a bottom-up tree automaton for a block of matching statements by processing each statement to create state sequences and populating a state register with State instances.
12520	Test if a node set with setint or setstr equals a certain value, handling type conversion between integers and strings.
12521	Create a Grammar from a string by building it with specified inheritance and scope parameters.
12522	Create a Grammar from a file by reading its contents and building the grammar with optional inheritance and entry point specification.
12523	Parse source using the grammar with optional source string and entry rule, returning a parsing Node.
12524	Parse a file using the grammar and return the parsed node. If no entry rule is specified, use the default entry rule. Raises ValueError if no entry rule is defined.
12525	Sets a destination node to match a source node by copying its properties. If the source is not a Node instance, copies the value directly. Otherwise, calls the source node's set method and manages caching based on object IDs. Returns True to indicate successful operation.
12526	Set a node's value to an integer value captured from another node and return True.
12527	Get the value of a subnode by evaluating an expression against the AST node. Returns True on success.
12528	Default serializer for JSON that handles datetime objects by converting them to ISO format or UTC timestamps based on their type.
12529	Get deposits with optional limiting and additional parameters.

**Parameters:**
- query: Search query for deposits
- from_date: Start date for filtering deposits
- limit: Maximum number of deposits to return (default: 0, meaning no limit)
- **kwargs: Additional keyword arguments

**Returns:**
- tuple: (total_depids, dep_generator) where total_depids is the count of deposits and dep_generator is an iterator over the deposits

**Note:** The actual count of depositions is hardcoded as 1 since it's difficult to determine programmatically. If a limit is specified, only that many items will be returned from the generator.
12530	Dumps a deposition object as a dictionary with serialized metadata including ID, timestamps, user ID, state, and SIP status.
12531	Get BibDocs for Invenio 1 by querying records modified on or after a given date.
12532	Get BibDocs for Invenio 2 by querying records modified on or after a specified date.
12533	Import BibDocFile by trying to import from invenio.bibdocfile first, and if that fails, fall back to importing from invenio.legacy.bibdocfile.api. Return the BibRecDocs and BibDoc classes.
12534	Dump all BibDoc metadata for a record, filtering by modification date. Returns list of BibDoc file versions with detailed metadata including checksum, size, timestamps, and file properties.
12535	Get bibdocs to check by returning a tuple containing the count of all bibdocs and a list of their IDs.
12536	Check if a bibdoc with given id exists and is accessible. If the bibdoc fails the check, display an error message in red color indicating the failed bibdoc ID.
12537	Dumps OAuth2 server tokens into a dictionary format with token details including ID, client ID, user ID, token types, access/refresh tokens, expiration timestamp, scopes, and internal flags.
12538	Get UserEXT objects by querying the database and return a tuple containing the count of objects and the objects themselves.
12539	Dumps UserEXT objects as a list of dictionaries containing id, method, and id_user fields.
12540	Get communities by returning the count and all featured communities from the database.
12541	Get record ids for Invenio 1 by querying bibrec table for records modified on or after from_date, returning a set of record ids and the search_pattern function.
12542	Get record IDs for Invenio 2 by filtering records modified on or after a given date, returning a set of record IDs and the search pattern function.
12543	Get all restrictions for a given collection, users and fireroles by querying database for role definitions and user associations.
12544	Get record revisions from the history table for a specific record ID and date range, returning job dates and MARCXML data ordered chronologically.
12545	Get all collections that a record belongs to, including both all collections and restricted collections with their restrictions.
12546	Dumps a JSON representation of a record from MARCXML data, first attempting to use the invenio modules API and falling back to bibfield if the import fails.
12547	Get record IDs matching a query and with changes since a specific date. Returns the count and set of record IDs.
12548	Dumps MARCXML and JSON representation of a record with specified options.

Parameters:
- recid: Record identifier
- from_date: Dump only revisions from this date onwards
- with_json: If True, generate JSON representation using old Record.create method
- latest_only: Dump only the last revision of the record metadata
- with_collections: If True, dump the list of collections the record belongs to

Returns:
List of versions of the record with metadata, files, and collections information.
12549	Dump remote account as dictionary with id, user_id, client_id, and extra_data fields.
12550	Helper function that loads JSON data into a model object by creating an instance with the data, adding it to the database session, and committing the transaction.
12551	Collect entry points from the 'invenio_migrator.things' group and return them as a dictionary mapping entry point names to their loaded objects.
12552	Initialize app context for Invenio 2.x by creating an app instance, pushing a test request context, and preprocessing the request, with ImportError handling.
12553	A decorator that implements memoization to cache the results of expensive function calls, storing them in a dictionary keyed by the function arguments to avoid recomputing identical calls.
12554	Imports and returns the `run_sql` function from either `invenio.dbquery` or `invenio.legacy.dbquery` depending on availability.
12555	Get roles connected to an action by querying the database for role information, compiling fire role definitions, and organizing the results into a dictionary structure containing role details, parameters, and associated users.
12556	Returns the count and list of action definitions matching the given query terms. Retrieves actions from database where action names match the query patterns, returning their ID, name, description, allowed keywords, and optional status. Uses slave database connection for read operations.
12557	```python
def dump(rt, from_date, with_json=True, latest_only=False, **kwargs):
    """Dump the remote tokens as a list of dictionaries.

    :param ra: Remote toekn to be dumped.
    :type ra: `invenio_oauthclient.models.RemoteToken [Invenio2.x]`
    :returns: Remote tokens serialized to dictionary.
    :rtype: dict
    """
    return dict(id_remote_account=rt.id_remote_account,
                token_type=rt.token_type,
                access_token=rt.access_token,
                secret=rt.secret)
```

Summary: The `dump` function serializes a remote token object into a dictionary containing its account ID, token type, access token, and secret. It takes a remote token object as input and returns a dictionary with these four key-value pairs. The function accepts additional parameters but ignores them, focusing solely on extracting the core token information.
12558	Load an OAuth2 server token from a data dump by converting the expiration date and using common loading logic.
12559	Import a record from a migration dump by creating a record dump object and loading it into the database, with options for source type (marcxml or json) and loading only the latest revision.
12560	Imports a configuration variable from the app's config using the provided import path, or returns a default value if the config variable is not set.
12561	```python
def dump(obj, from_date, with_json=True, latest_only=False, **kwargs):
    """Dump the oauth2server Client."""
    return dict(name=obj.name,
                description=obj.description,
                website=obj.website,
                user_id=obj.user_id,
                client_id=obj.client_id,
                client_secret=obj.client_secret,
                is_confidential=obj.is_confidential,
                is_internal=obj.is_internal,
                _redirect_uris=obj._redirect_uris,
                _default_scopes=obj._default_scopes)
```

**Summary:** The `dump` function serializes an oauth2server Client object into a dictionary containing all its key attributes including name, description, website, user ID, client credentials, confidentiality status, internal status, redirect URIs, and default scopes. The function accepts additional parameters but primarily focuses on extracting and returning the core client information.
12562	Get user accounts from Invenio 1 database, returning user data with decoded passwords and formatted nicknames.
12563	Get user accounts from Invenio 2 by querying the User model and returning a tuple containing the count of users and all user objects.
12564	Dumps user information as a dictionary containing id, email, password, password_salt, note, full_name (or formatted name from given_names and family_name), settings, nickname, and last_login timestamp.
12565	Loads raw JSON deposition data by creating record and PID, then creates files and SIP, finally committing the session.
12566	Create a deposit record metadata and persistent identifier from raw JSON data, returning the record object and its PID with proper timestamp handling and identifier registration.
12567	Load a single record into the database either synchronously or asynchronously based on the eager parameter and available post-processing tasks.
12568	Load records from migration dump files, either a specific record by ID or all records with progress indication.
12569	Function `inspectrecords(sources, recid, entity=None)` inspects records in migration dump files. It loads JSON data from sources, optionally filters by record ID, and displays record information with different formats based on the entity type (files, json, marcxml) or just record identifiers if no entity is specified. The function uses click for output formatting and can display records with indentation for better readability.
12570	Common helper function for loading simple objects from JSON source files. Supports both synchronous and asynchronous loading, with optional predicate filtering to load only a single item. Takes a list of source file paths, a load task function, and optional arguments to pass to the task. When a predicate is provided, it returns after loading the first item that matches the predicate. Otherwise, it processes all items in the dumps either asynchronously or synchronously based on the asynchronous flag.
12571	```python
def loadcommunities(sources, logos_dir):
    """Load communities."""
    from invenio_migrator.tasks.communities import load_community
    loadcommon(sources, load_community, task_args=(logos_dir, ))
```

Summary: Loads community data from sources using the load_community task, with logos directory as a task argument.
12572	Load users from given sources using the load_user task function in a synchronous manner to avoid racing conditions with duplicate emails and usernames.
12573	Loads deposit data from source files, optionally filtering by deposit ID. If a deposit ID is specified, it filters the deposit records to only load the one with the matching ID. Otherwise, it loads all deposit records from the source files. Uses the load_deposit task function and processes the data synchronously.
12574	Return profiler statistics sorted by specified key with optional filtering.

Parameters:
- sort (str): Dictionary key to sort by (default: "cum_time")
- count (int|None): Number of results to return (default: 20, None for all)
- strip_dirs (bool): If True strip directories from paths (default: True)

Returns:
- List of dictionaries containing function statistics including path, line number, function name, call counts, and timing information, sorted by the specified key in descending order.
12575	Run a sample test server using Tornado web framework on the specified port (default 8888) with profiling routes enabled.
12576	Dumps current profiler statistics to a file with an optional filename parameter, defaulting to 'dump.prof', then finishes the request.
12577	Clears profiler statistics and returns HTTP 204 response.
12578	Stop the profiler by disabling CProfileWrapper.profiler, set running status to False, and finish the request with HTTP status 204.
12579	Check if the profiler is running and return its status as a JSON response with HTTP 200.
12580	Disable timestamp update for a method by wrapping it with a context manager that corrects the date.
12581	Loads a user from a data dictionary, handling potential email and username duplicates by raising appropriate errors. It processes user data including password hashing, email confirmation, and nickname handling, ensuring data integrity through database transactions.
12582	Calculate image translations in parallel and return translation values for each image in the collection.
12583	Stitch regular spaced images into a single panoramic image.

This function takes a collection of images arranged in a grid pattern and stitches them together by aligning their translations. It calculates the median translation between images to determine the spacing, then merges the images into a single output image while averaging overlapping regions along the seams. The function returns the stitched image and the registered offset used for the alignment.

Parameters:
- images: ImageCollection or list of tuples containing (path, row, column) for each image

Returns:
- tuple: (stitched_image, offset) where stitched_image is the merged result and offset is the (y, x) translation values used for alignment

The stitching process handles images arranged in a grid where row 0, column 0 represents the top-left image. Images are merged with automatic seam averaging to create a seamless panorama.
12584	Adds a new dimension with ones to the input array by first expanding dimensions and then concatenating with a ones array along the new axis.
12585	Create a record based on the provided dump data, handling PID creation, record updates/creations, and file management. Returns the created or updated record.
12586	Creates a new record from a dump by reserving a record identifier, creating the record and recid PID in one operation, setting timestamps, inserting record identifier, creating persistent identifier, committing changes to database, and updating the record with revisions.
12587	Update an existing record by applying revisions and returning a new Record instance.
12588	Create persistent identifiers for a record by iterating through provided pids and registering each one with the database.
12589	Delete a record and its persistent identifiers, update the persistent identifier status to DELETED, delete the record's buckets, and commit the changes to the database.
12590	Creates files for a record within a bucket, handling bucket creation if none exists, and returns the bucket list.
12591	Creates a file with multiple versions in a bucket, sets each version's metadata including URI, size, and checksum, assigns creation timestamps, commits to database, and returns the latest version object.
12592	Delete all buckets associated with the given record's files by marking them as deleted.
12593	Filter persistent identifiers and return those that do not exist in the database.
12594	Prepare revisions data by iterating through records and applying revision preparation.
12595	Method `prepare_files` processes raw data files by organizing them into a dictionary grouped by their full names and sorting each group by version number. The method stores the organized files in the instance variable `self.files`.
12596	Prepare persistent identifiers by iterating through pid_fetchers, calling each fetcher with None and the last revision value, and appending non-null results to self.pids list.
12597	Check if a record is deleted by examining its collections for a 'deleted' flag.
12598	Load community from data dump and save its logo if available.

Parameters:
- data (dict): Dictionary containing community data
- logos_dir (str): Path to a local directory with community logos

Returns:
- None

The function creates a Community object from the provided data, adds it to the database session, and if a logo file exists in the logos directory, it saves and validates the logo. Finally, it commits the session to persist the changes.
12599	Load community featuring data from a dictionary into the database by creating a FeaturedCommunity object with the provided data and commiting it to the session.
12600	Dump data from Invenio legacy by querying specified items, processing them in chunks, and writing to JSON files with progress tracking.
12601	Check data in Invenio legacy by querying and validating specified items using entry point functions with progress tracking.
12602	Deletes resources of this widget that require manual cleanup, including actions, event handlers, and background. Removes all vertex lists from background to prevent visual artifacts. Currently experimental due to suspected memory leak issues.
12603	Returns the Euclidean magnitude (length) of a vector by calculating the square root of the sum of squared components.
12604	Normalizes a vector by dividing each component by the vector's magnitude, returning a unit vector with the same direction. Works with vectors of any number of dimensions.
12605	Transforms 2D texture coordinates to 3D coordinates using internal texture coordinate mapping. Takes input texture coordinates, fits them to the internal coordinate range, and outputs 3D coordinates with z=0. Input coordinates are expected to be divisible by 2 (representing u,v pairs) and should be in range [0,1] to avoid visual glitches. Returns a list of 3D coordinates.
12606	Helper method that ensures per-entity bone data is properly initialized. Called at the start of methods accessing per-entity data. Checks if "_bones" key exists in the data dictionary, creates it if missing, then verifies the specific entity's bone data exists under self.name, creating it with rotation and length data if necessary.
12607	Sets the length of a bone on the given entity by updating the bone's length property in the entity's data dictionary.
12608	Sets the parent bone and registers this bone as a child of the parent. Must be called before other methods to initialize internal state.
12609	Returns the pivot point coordinate of this bone relative to the entity by recursively calculating the parent's pivot point and adding its own offset.
12610	Initializes an animation on a specific actor by setting up animation data in the provided dictionary. Configures keyframe tracking, timing information, jump type, and phase settings for the animation transition.
12611	Sets the actor's state by translating the matrix to the actor's position using its object's coordinates.
12612	Resets the actor's state by translating the matrix back to its original position using the object's current position coordinates.
12613	Sets the state for the vertex region by enabling the material's texture target, binding the material's texture, and setting up bone rotation with the region's data.
12614	Resets the actor's state by disabling the material's texture target and unsetting bone rotation.
12615	Ensures that the given object has been initialized for use with this model by checking for `_modeldata` attribute and initializing if missing or incomplete.
12616	Redraws the model of the given object by updating vertex and texture coordinates in the model cache based on current region data.
12617	Method that draws an object's model to the render target, skipping drawing if the object's batch already exists.
12618	Sets the model for this actor and automatically initializes it while cleaning up any existing model.
12619	Writes a collection of reports to a specified path by reserving a file destination and writing XML-formatted report data to it.
12620	Converts a list of test reports into an XML string formatted for test suites, including test cases, failures, and errors with appropriate timestamps and duration tracking.
12621	Adds a menu to the list of menus and sends an event notification. If no menu is currently selected, the new menu will be made active.
12622	Redraws the text label by recalculating its position and updating its properties. Centers the label text based on the label's position and size, then updates the label's visual representation.
12623	Redraws the label by calculating and updating its position and dimensions. Centers the label based on its position and font size, then updates both the text and default label components to prevent rendering issues after resizing.
12624	Draws the submenu and its background, handling different background types (Layer, callable, list/tuple, Background, or blank) and ensuring proper OpenGL 2D state management. Redraws widgets that need updating and draws the batch content followed by custom widget draw methods.
12625	Deletes a widget by name and handles cleanup, though this feature is experimental due to a reported memory leak.
12626	Re-calculates and updates the position of the Label based on the widget's size and position coordinates.
12627	Registers motion and drag event handlers including specialized handling for mouse dragging events.
12628	Registers event handlers for crouch/jump controls and sets up 60fps window redraw schedule.
12629	Adds a main label widget to the dialog that is centered on screen, positioned at the center coordinates (sw/2-bw/2, sh/2-bh/2) with dynamic sizing based on the screen dimensions and label text height. The label is initialized with the provided label_main text and automatically adjusts its size to fit the text content.
12630	Adds an OK button to the dialog that triggers a click_ok action and exits the dialog when clicked. The button is positioned below the main label by twice its height and centered horizontally on the screen. The button size is dynamically calculated based on the label's font size.
12631	Helper method that exits the dialog by returning to the previous submenu if one exists, otherwise clears the previous submenu reference.
12632	Adds a confirm button to the dialog that triggers a "confirm" action and exits the dialog when clicked. The button is positioned below the main label and to the left of the cancel button.
12633	Adds a cancel button to the dialog that triggers a "cancel" action and exits the dialog when clicked. The button is positioned below the main label and to the right of the confirm button.
12634	Updates the progress bar by recalculating and formatting the progress label based on current values and properties.
12635	Renders the world in 3D mode by calling the render method on all actors in the world. The view parameter specifies the viewing angle, and the method can be overridden for custom terrain rendering while ensuring the original implementation is called to maintain actor rendering.
12636	Renders the 3D world by calling the parent class's render3d method and drawing the batch3d.
12637	Start a new step and return a context manager for reporting errors. Raises an exception if called within another step. Tracks step timing and handles exceptions by logging error details before re-raising.
12638	Returns whether or not the resource with the given name and extension exists by checking if the file path exists.
12639	Adds a new texture category with the given name, overriding existing categories. Creates associated cache and texture bin structures, then sends an event notification.
12640	Returns a placeholder texture for missing textures, loading from file if possible or creating a purple solid square pattern in-memory as fallback. Uses caching for the missing texture.
12641	Gets the model object by name, returning a cached version if available or loading and caching it if not.
12642	Loads a model by name, caches it, sends a load event, and returns the model object.
12643	Gets model data by name, returning cached version if available or loading and caching it if not.
12644	Loads model data from a JSON file by parsing materials, bones, regions, and animations, and caches the parsed data for future use. Handles version checking and sets default materials and animations. Returns the parsed model data or an empty dict on failure.
12645	Adds a widget to this container, ignoring attempts to add the container to itself to prevent recursion loops.
12646	Draws the submenu and its background, handling visibility checks and OpenGL scissor test settings for proper rendering.
12647	Redraws the background and child widgets by updating vertex lists and initializing/re-drawing background if needed.
12648	Redraws the background and contents including scrollbar, updates scrollbar position and size based on container dimensions, and calls parent redraw method. Adjusts content offset in opposite direction of slider movement and sets scrollbar maximum value based on content height.
12649	Function to check if mouse position collides with a rectangle using axis-aligned bounding box collision detection.
12650	Helper property that calculates and returns the percentage fill level of the slider as a value between 0 and 1, where 0 represents minimum value and 1 represents maximum value. The property is read-only and handles edge cases where min and max values might be equal.
12651	Adds a new layer to the stack at the specified z-index position, appending by default. Validates that the layer is an instance of Layer class.
12652	Map a buffer region using this attribute as an accessor, returning a contiguous array of component data elements that can be modified. For non-interleaved data, returns a direct buffer region, while for interleaved data, returns an IndirectArrayRegion to handle the interleaved memory layout.
12653	Draw vertices in the domain using specified OpenGL mode and optional vertex list. If no vertex list is provided, draws all vertices in the domain using the most efficient rendering method. If a vertex list is specified, only draws primitives in that list. Uses vertex buffer objects and handles different OpenGL versions for multi-draw operations.
12654	Adds a callback function to a specified action, storing it with its arguments for later execution.
12655	Helper method that executes all registered callbacks for a specified action by iterating through registered functions and their arguments.
12656	Registers a name to the registry with an optional forced ID, returning the assigned ID. Uses a lock for thread safety and generates a new ID automatically if none is provided.
12657	Adds a layer at the specified Z index position, inserting it in the correct order based on Z index values. If no Z index is provided, uses the layer's default Z index. The layer is stored in both a dictionary and a sorted list based on Z index values.
12658	Draws all layers of the LayeredWidget by calling the parent draw method and then drawing each layer's content using its _draw method.
12659	Deletes all layers within the LayeredWidget by calling delete() on each layer, then clears the layers list and dictionary before calling the parent class's delete method.
12660	Property to get and set the layer's border with immediate redraw effect. Returns a WatchingList that updates when the border changes.
12661	Property to get and set the layer's offset with immediate redraw on modification.
12662	Returns the size of the layer with border size subtracted from both dimensions.
12663	**Summary:** The `read_h5` function reads mesh data from an HDF5 file format. It loads elements, nodes, node sets, element sets, element surfaces, and fields from the HDF5 store into a Mesh object. The function is deprecated and should not be used in new code. It handles various data groups within the HDF5 structure including connectivity data, node coordinates, sets, surfaces, and field metadata and data, then returns the populated mesh object.
12664	Creates connectivity arrays for 2D and 3D structured grids using Numba-optimized pattern matching, returning element connectivity matrices with 4 or 8 nodes respectively.
12665	Sets the fields attribute of the object to a list containing the provided fields. If no fields are provided, initializes an empty list.
12666	Add fields to the list of fields. If fields parameter is provided, iterate through each field and append it to self.fields.
12667	Checks element definitions by validating that all element types in self.elements.type.argiope exist in the allowed ELEMENTS dictionary. Raises ValueError if any unknown element types are found, otherwise prints "<Elements: OK>".
12668	Returns the dimension of the embedded space for each element by mapping the element types to their respective spaces.
12669	Returns a dataframe containing volume and centroids of all elements, grouped by element type. For each element type, it calculates simplices volumes and centroids, then aggregates them into total volumes and weighted centroids for each element. The result is sorted by index and columns.
12670	Returns internal angles of all mesh elements along with associated statistics including max/min angles and angular deviations from optimal values.
12671	Returns the aspect ratio of all elements by calculating edge lengths and their ratios.
12672	Returns a concatenated DataFrame containing mesh quality and geometric statistics by combining centroids/volumes, angle statistics, and edge statistics.
12673	Creates a node set from an element set by extracting node indices from elements in the specified set and marking corresponding nodes as True in the nodes dataframe.
12674	Converts a node set to surface by creating a dummy node, extracting element surfaces, and assigning surface flags to elements based on node set membership.
12675	Creates element sets from a surface by iterating through surface faces and adding non-empty faces to element sets with formatted names based on the surface tag and face index.
12676	Returns fields metadata as a DataFrame by concatenating individual field metadata, transposing it, and sorting by step_num, frame, label, and position.
12677	Returns metadata as a pandas Series containing part, step_num, step_label, frame, frame_value, label, and position information.
12678	Creates the working directory if it doesn't already exist.
12679	Runs the post-processing script using the specified solver (currently only supports Abaqus). Executes a subprocess command to run the post-processor script, captures and prints the output in real-time, and measures the total execution duration. The method is designed to work with Abaqus solver and expects a specific Python post-processor script named after the label with "_abqpp.py" suffix.
12680	Runs gmsh to create a mesh by executing gmsh with specified parameters and reads the resulting mesh file.
12681	Reads an history output report from a CSV file and adds step information based on given time steps.
12682	Reads a field output report from a file and parses it into structured data including metadata, position information, and numerical data. The function extracts metadata and data sections based on specified flags, processes the data into a pandas DataFrame with grouped averages, and returns an instance of a field class with all parsed information.
12683	Converts a list-like object to a formatted string with specified line width and indentation. Takes a list, converts each element to string with trailing comma, and wraps the output at the specified width limit. Elements are separated by commas and newline characters are inserted when the line width is exceeded. Returns the formatted string with trailing comma removed.
12684	Returns an Abaqus INP formatted string for a given linear equation with specified nodes, degrees of freedom, and coefficients.
12685	Returns a string representation of a set with UNSORTED option, where the set label is specified by the 'label' parameter and the set members are derived from the DataFrame's index values. The resulting string follows the format "*NSET, NSET={label}, UNSORTED" followed by the formatted list of labels.
12686	Parses API response and raises appropriate errors based on status code and payload content. Returns response payload as dictionary, raising AuthenticationError for 401, ServerError for 500, and APIError for unsuccessful responses when raise_errors is True.
12687	Builds a URL for the specified method and arguments, sends a POST request with payload and files, and returns the response as a dictionary.
12688	Writes an XY report file containing data from history output variables. Takes an odb file, output path, list of tags (output variable names), column names, and steps as inputs, then creates XY data objects from the history output and writes them to a report file with scientific notation formatting.
12689	Writes a field report from an ODB file, rewrites it in a cleaner format with metadata and formatted data sections.
12690	Lists available components on the machine by type, displaying IDs for displays, datafeeds, filters, and notifications. When component_type is "all", lists all component types with their IDs. Uses a config loader to load components and click for output formatting.
12691	Return an error message for exceptions thrown by subclasses, formatting information about the field type, instance class name, attribute name, value type, and value when the field type condition is not satisfied.
12692	Return True if the last exception was thrown by a Descriptor instance by checking if 'self' in the traceback locals is an instance of Descriptor.
12693	This method sets up the data for a Series by creating X and Y variables from the data if they don't already exist, or validates existing axis objects and creates data points from their points. It raises exceptions if required axis data is missing.
12694	Returns the axis mode for the current series. If all series have TimeVariable objects for the specified axis, returns 'time', otherwise returns None.
12695	Sets graph plotting options by updating axis modes in the options dictionary.
12696	Creates a class object from a function and attributes, with a setter and optional initializer, and assigns documentation.
12697	Cycles through notifications by polling data feeds, processing messages into notifications, and drawing the notifications.
12698	Converts a value to a numeric type, raising ValueError if conversion is not possible or if the value is a boolean. Returns a float for numeric values or calls ForceNumeric.str_to_num for string representations of numbers.
12699	Converts a string representation of a number to its numeric type (int or float) by first attempting integer conversion, and falling back to float conversion if the integer conversion fails.
12700	This function `plot` is a Django template tag that generates graph plotting functionality. It parses template tokens to extract graph parameters, processes attributes like ID generation, and returns a `GraphRenderer` object with the specified graph configuration. The function automatically generates a random 5-character ID if none is provided, strips quotes from existing IDs, and constructs an attribute string for the graph renderer.
12701	Try really really hard to get a Unicode copy of a string.
First try BeautifulSoup.UnicodeDammit to try to force to Unicode; if that fails, assume UTF-8 encoding, and ignore all errors.
:param str raw: string to coerce
:return: Unicode approximation of `raw`
:returntype: :class:`unicode`
12702	Converts raw text to a clean, properly formatted HTML document with unicode characters and removes unwanted elements like scripts and styles.
12703	Method `is_matching_mime_type` implements MIME-type matching logic to determine whether to run `make_clean_html`. It returns `True` if no specific MIME types are configured for inclusion, `False` if the MIME type is None, or when the MIME type (case-insensitive) starts with any of the configured inclusion MIME types. The method uses `startswith` to handle cases where character encodings are appended to HTTP Content-Type headers.
12704	Extracts a lowercase, no-slashes domain name from a raw string that might be a URL. Handles URL parsing with fallback to raw string if parsing fails. Removes slashes and converts to lowercase. Returns empty string if no domain found.
12705	Returns a list of strings created by splitting the domain on '.' and successively cutting off the leftmost portion. For example, "example.com" becomes ["example.com", "com"].
12706	Get a Murmur hash and a normalized token, handling unicode strings by encoding them to UTF-8. Returns a pair of the normalized token and its hash, with special handling to remap the document count hash value (0) to a replacement value.
12707	Collect all words from a stream item for indexing by scanning configured tagger IDs, cleaning tokens, applying size limits, and filtering out stop words, returning a Counter of words to index.
12708	Records index entries for a single document by processing its clean visible content, counting tokens, and storing hash-based index information in multiple tables (term frequencies, frequencies, and keywords) based on constructor parameters.
12709	Get strings that correspond to some hash by scanning a hash keyword index table and decoding the results. Returns a list of unicode strings, excluding those corresponding to DOCUMENT_HASH_KEY which should use DOCUMENT_HASH_KEY_REPLACEMENT instead.
12710	Get document frequencies for a list of hashes, returning a map from hash to document frequency. Returns all zeros unless the index was written with `hash_frequencies` set. If `DOCUMENT_HASH_KEY` is included in hashes, returns the total number of documents indexed instead.
12711	Lookup stream IDs for a single hash value.

This method scans a kvlayer table for documents matching the given Murmur hash and yields stream IDs that can be used to retrieve the actual documents. It's designed for use with the streamcorpus_pipeline system where hashes are used as keys to locate document streams.

The method returns nothing unless the index was created with hash_docs enabled. It specifically excludes the DOCUMENT_HASH_KEY and instead uses DOCUMENT_HASH_KEY_REPLACEMENT for lookups. For common terms, this can return many stream IDs, so callers should be prepared to handle large result sets efficiently rather than blindly collecting them in lists.

:param h: Murmur hash value to look up
:returns: Generator yielding stream IDs corresponding to the hash
:rtype: generator of strings
12712	Lookup term frequencies for a single hash value, yielding pairs of stream IDs and their corresponding term frequencies from the hash-term frequency index table.
12713	Given a spinn3r feed, produces a sequence of valid StreamItems by reading protobuf data and filtering out None values.
12714	Creates a StreamItem from a spinn3r feed entry by extracting metadata, content, and other relevant information. Returns None if the item cannot be properly constructed.
12715	Create a ContentItem from a spinn3r data tree node, handling zlib compression and UTF-8 normalization.
12716	Reads a varint from the underlying file by reading up to 8 bytes, decoding it with _DecodeVarint, and unreadding any excess bytes. Returns the decoded varint value.
12717	Reads a protobuf-encoded object from a single file block and returns the parsed object.
12718	Serializes a StreamItem key into 20 bytes: 16-byte MD5 hash followed by 4-byte timestamp. Validates that the MD5 hash is exactly 16 bytes, otherwise raises ValueError. Uses big-endian byte order for packing.
12719	Extracts StreamItem parts for kvlayer key, converts StreamItem to blob for storage. Returns (kvlayer key tuple), data blob.
12720	A context manager that temporarily changes the working directory to the specified path and automatically restores the original directory when exiting the context, ensuring proper directory state management.
12721	Removes a specified prefix from a string if it exists. If the prefix is not present and strict mode is enabled, raises a WimpyError. Otherwise, returns the original string unchanged.
12722	Removes a specified suffix from a string if it exists at the end. If the suffix is not present and strict mode is enabled, raises a WimpyError; otherwise, returns the original string unchanged.
12723	**Summary:** Checks if all elements of `needle` appear in `haystack` in the same relative order, allowing other elements to appear between them. Returns `True` if `needle` is a subsequence of `haystack`, `False` otherwise.

**Example:** `is_subsequence([1, 3, 5], [1, 2, 3, 4, 5])` returns `True` because 1, 3, and 5 appear in order in the haystack, even though 2 and 4 are interspersed.
12724	Creates and returns a WSGI application with a default home page and error handling. The application responds to GET requests at the root path (/) with a simple "It works!" page, and provides generic error pages for HTTP errors. The returned Ice object can be used as a WSGI application.
12725	Run the application using a simple WSGI server on the specified host and port.
12726	Stop the simple WSGI server running the application by shutting down and closing the server connection, then set the server reference to None.
12727	Adds a route for any HTTP method by returning a decorator that registers the route pattern and callback with the router.
12728	Adds an error page callback decorator that registers error handlers for specific HTTP status codes or as fallback handlers.
12729	Send content of a static file as response, ensuring directory traversal prevention by validating that the file path is within the specified document root directory. Returns file content with appropriate Content-Type header based on media type or file extension, and handles 403 (for forbidden access) and 404 (for not found) status codes.
12730	Return an error page for the current response status by checking for specific error handlers, falling back to a generic handler, or returning a default plain text error response.
12731	Add a route with the specified HTTP method, pattern, and callback handler to the router. The pattern is normalized into literal, wildcard, or regex types and stored in the appropriate routing table.
12732	Resolve a request to a route handler by looking up the method and path in literal routes, falling back to non-literal route resolution if no exact match is found. Returns a tuple of (handler, positional args, keyword args) or None if no route matches.
12733	Resolve a request to a wildcard or regex route handler by iterating through wildcard and regex routes for the given HTTP method and path, returning the matching route handler with its arguments or None if no match is found.
12734	Normalize a route pattern by removing type prefixes and returning the pattern type and normalized pattern as a tuple.
12735	Return the HTTP response body as bytes, encoded from the stored body attribute using the specified charset, and add appropriate Content-Type and Content-Length headers before returning the encoded body within a list.
12736	Add an HTTP header to the response object by appending a (name, value) tuple to the internal headers list, but only if the value is not None.
12737	Adds a Set-Cookie header to the response object with the specified name, value, and attributes.
12738	Return the HTTP response status line in the format "code phrase" by combining the status code and its corresponding phrase from the responses dictionary.
12739	Return the value of Content-Type header field, combining media_type and charset for text media types, otherwise return media_type alone.
12740	Return the list of all values for the specified key. If the key does not exist, return the default value (which defaults to an empty list).
12741	Remove a directory tree recursively, with special handling for read-only files and symlinks. It attempts to use shutil.rmtree first, but falls back to a manual implementation that retries file removal operations and properly handles symbolic links. The function works around issues with NFS and Windows where standard rmtree fails due to read-only files.
12742	Returns a list of open file descriptors for the current process by querying the 'lsof' command. Works only on UNIX-like operating systems. Optionally provides verbose output showing all process information. Uses subprocess to execute system commands and filters the output to extract file descriptor information.
12743	Returns a transform function that analyzes file types from stream items by examining the first 250 characters of raw body content, identifying HTML, XML, PDF, or unknown file types based on content patterns and extensions.
12744	This function processes a work unit by fetching data from an S3 path, performing validation checks, and saving counts to a gzipped output file. It handles retries up to 20 times if the expected SI count doesn't match the actual count, and writes parsed data to a structured output file with tab-separated values including error information, counts, and stream IDs. The function uses UUID-based directory structure for organizing output files.
12745	This function attempts to fetch and process data from an S3 URL through a pipeline of wget, gpg decryption, and xz decompression. It executes this pipeline as a child process and iterates through the resulting stream, counting various metrics including stream items, serif sentences, and clean visible text statistics. The function handles errors gracefully, terminates the child process properly, and returns detailed processing statistics along with any encountered exceptions.
12746	Return a list of non-empty lines from the specified file by joining the current file's directory with the given filename, opening the file, reading all lines, splitting by newlines, and filtering out empty lines.
12747	Returns an ordered 2-tuple containing a species and a describer, where the describer can be either a prefix or suffix to the species.
12748	Returns an ordered 2-tuple of a species and a describer with optional length and stutter prevention constraints.
12749	Morphological analysis for Japanese text using Goolabs API. Takes a sentence or sentence file, applies optional filters for information and part-of-speech, and outputs either JSON formatted results or comma-separated word data. Supports request identification and handles both file-based and direct sentence input.
12750	### Summary ###

The `similarity` function calculates and outputs the similarity score between two words using the Goolabs API. It takes an application ID, a flag indicating whether to return JSON output, a pair of words to compare, and a request ID as inputs. The function cleans the application ID, makes an API call to compute the similarity score, and then outputs either the score formatted to 16 decimal places or the full JSON response, depending on the `json_flag` parameter.
12751	Convert Japanese text to Hiragana or Katakana using the Goolabs API, with options for JSON output format.
12752	Extract unique entity representations from a sentence using Goolabs API, with optional filtering and JSON output formatting.
12753	Summarizes reviews into a short summary using the Goolabs API. Takes an app ID, review text or file, summary length, and optional JSON flag. Returns either JSON formatted response or plain text summary.
12754	Extract keywords from an input document using the Goolabs API. The function processes the input document by cleaning the app ID and body content, then makes an API request to extract keywords based on the provided parameters. It can output the results either as JSON formatted data or as a comma-separated list of keywords and their scores. The function handles both file-based and text-based document inputs, and supports optional parameters like title, maximum number of keywords, focus area, and request ID.
12755	Extracts and normalizes date/time expressions from text using Goolabs API, with optional JSON output format.
12756	Create a pipeline stage by instantiating the given stage with its configuration. The stage can be provided as a callable or its name in the registry. The configuration is merged with pipeline-level settings, specifically adding `tmp_dir_path` (constructed from the top-level tmp_dir_path and a suffix) and `third_dir_path`. If no stage-specific configuration is provided, it's extracted from the pipeline configuration. Returns an instance of the stage.
12757	Creates a list of stage objects from a configuration list of stage names. Takes a configuration dictionary and a key name, looks up the list of stage names in the configuration, and returns instantiated stage objects for each name found. Returns an empty list if the key is not present in the configuration.
12758	Initialize all stages for the pipeline including reader, incremental transforms, batch transforms, post-batch incremental transforms, and writers, and return them along with a temporary directory path.
12759	Run the pipeline on input data, processing stream items through incremental and batch transforms, creating output chunks based on configured limits, and handling temporary files and resource cleanup.
12760	Run all writers on an intermediate chunk and return list of output file paths.
12761	Run transforms on a stream item incrementally, handling potential discards and writing successful items to the current output chunk. Returns the transformed item or None if discarded.
12762	Replace the top-level pipeline configurable object by investigating external stages paths and modules, then return a new sub-modules object.
12763	Creates a WSGI application that processes HTTP requests through HTTPie's core functionality, handling request preparation, output formatting, and response generation while managing environment variables and stream processing.
12764	Function `make_chains_with_names` creates coreference chains from token entities by mapping equivalent IDs to tokens and their cleaned name strings. It processes sentences and tokens, handling special cases where tokens have equiv_id of -1 by assigning them fake unique IDs. The function returns a dictionary where keys are equiv_ids and values are tuples of concatenated name strings and lists of tokens.
12765	Returns True if all target mention strings are found as substrings in any of the chain mentions, False otherwise.
12766	Returns True if any string in target_mentions appears as a substring in any string of chain_mentions, otherwise returns False.
12767	This function `look_ahead_match` iterates through a list of tokens to find matches against cleaned mention patterns from a rating object. It handles both literal strings and regular expressions, skipping empty tokens and managing tokens that produce multiple space-separated strings when cleaned. The function uses regex matching to identify sequences of tokens that correspond to the cleaned mention patterns, yielding unique matched tokens once a complete sequence is found. It ensures that all cleansed tokens are non-zero length and compiles regex patterns with appropriate flags for Unicode and case-insensitive matching. The algorithm looks ahead through tokens to find complete matches of mention patterns, handling edge cases like reaching the end of the token list or mismatched tokens.
12768	Function `multi_token_match` iterates through tokens in stream item sentences to find near-exact matches with strings in `si.ratings...mentions`. It constructs tuples of cleansed token strings and their corresponding Token objects, then matches these against ratings from annotators. For each match found, it adds annotations to tokens and logs the number of matched tokens. If no matches are found, it logs a warning. The function supports filtering by a required annotator ID and can update labels based on aligner data configuration.
12769	Method: `make_ner_file(self, clean_visible_path, ner_xml_path)`

Summary: Executes a named entity recognition (NER) tagger as a child process to annotate text in an XML file. The method formats and runs a command using a template specified by subclasses, handles memory management by forcing garbage collection, and manages various error conditions including out-of-memory errors, process exit codes, and exceptions. It returns the time taken to complete the tagging operation. The method requires the subclass to define a `template` property that provides the command format for running the tagger, and raises `NotImplementedError` if not implemented.
12770	Aligns NER XML data with input chunk items, fusing them into an output chunk by processing each filename entry in the NER XML, matching stream IDs, and populating taggings, sentences, relations, and attributes for each stream item.
12771	Sends SIGTERM to terminate the tagger child process if it exists, with error handling for cases where the child process is already gone.
12772	Returns a Pattern that matches exactly n repetitions of Pattern p using binary exponentiation algorithm.
12773	Replace all angle bracket emails with HTML entities in the given text.
12774	Generate sentence strings from cleaned visible text using sentence tokenization, handling label overlaps by adjusting sentence boundaries to avoid splitting labels, and yielding start position, end position, and sentence string for each sentence.
12775	Creates a sorted collection of labels from stream_item body labels, filtered by CHARS offset type, indexed by the first character offset position.
12776	Method: `make_sentences`

Summary: Assembles Sentence and Token objects from a stream item by tokenizing sentences and associating labels with tokens based on character offsets. Creates token objects with position and offset information, maps labels to tokens when they overlap, and assigns mention IDs to labeled tokens. Returns a list of Sentence objects containing Token objects with their associated labels and mention IDs.
12777	Convert HTML, XML, or numeric entities in text to Unicode characters. Handles named entities, numeric entities (decimal and hexadecimal), and XML entities. Can optionally pad converted entities with spaces to maintain original string length. Supports safe-only conversion mode where unsafe entities are left unchanged.
12778	Creates a temporary file containing cleansed text from a chunk of data, writing each item's stream_id and cleansed body wrapped in XML tags.
12779	Creates a NER (Named Entity Recognition) file by running a child process with specified parameters, measures the execution time, and includes error handling to ensure successful completion.
12780	Converts a string to lowercase, removes punctuation, replaces whitespace with single spaces, and trims leading/trailing whitespace.
12781	This function aligns NER (Named Entity Recognition) annotations with chunked data by processing XML files containing NER information. It iterates through input chunks and corresponding NER data, matches them by stream ID, applies John Smith entity labels based on coreference chains, and generates a new chunk with updated body sentences containing the NER annotations. The result is written to a specified output file path.
12782	Converts relative paths to absolute paths in a configuration dictionary. Takes a config dict with 'streamcorpus_pipeline' key, extracts root_path, and for all keys ending with '_path' that contain relative paths (not starting with '/'), converts them to absolute paths using the root_path. Handles nested dictionaries recursively and preserves URLs from conversion. Returns the modified config with absolute paths and root_path restored.
12783	Summary: The `instantiate_config` function configures and initializes pipeline settings by converting paths to absolute values, generating config hashes and JSON dumps, and dynamically loading Python modules specified in the configuration. It handles module loading with error handling and exits the program if module loading fails.
12784	Generates a chunk of StreamItem instances from the John Smith corpus, each containing cleaned text content, metadata, and labels. It iterates over 35 directories of text files, creates StreamItem objects with a fixed creation time (end of 1998), attaches body content, sets source as 'bagga-and-baldwin', and adds document-level annotations with labels indicating mentions of 'john' and 'smith'. Each StreamItem is yielded for use in a processing pipeline.
12785	Function `re_based_make_clean_visible` takes an HTML-like binary string and returns a binary string of the same length with all HTML tags replaced by whitespace. It specifically handles script and style tags, converting all existing whitespace to single spaces while preserving the original byte length. The function uses regex pattern matching which may occasionally cause performance issues. It includes assertions to verify that the output maintains the same length as the input, and handles any characters after the last tag by appending them to the result. Note that it does not convert HTML entities like &rsquo; and &nbsp; to avoid changing byte lengths.
12786	Function `make_clean_visible` takes an HTML-like Unicode string and returns a UTF-8 encoded string with all HTML tags replaced by whitespace. It uses a state machine iterator to process the input, converting all Unicode characters inside HTML tags to single whitespace characters while preserving existing whitespace as single spaces. The function handles email protection and tag stripping without using regexes, and returns the cleaned result as a UTF-8 encoded byte string.
12787	Creates a temporary XML file containing clean visible text from a chunk of data, with proper UTF-8 encoding handling and error logging. The function processes each item in the input chunk, extracts clean visible text if available, and writes it to an XML structure with FILENAME elements. It includes comprehensive error handling for UTF-8 decoding issues and logs critical errors when they occur. The function also writes a backup HTML file for inspection purposes.
12788	Convert a unicode string into a lowercase string with no punctuation and only spaces for whitespace, replacing PennTreebank escaped brackets with spaces.
12789	This code implements a manual test loop for the `make_clean_visible_from_raw` function. It reads an HTML file from command line argument, processes it character by character through `non_tag_chars_from_raw`, and compares each character with the original HTML string to ensure they match. If a mismatch is found, it triggers a debugger breakpoint. The cleaned characters are then written to standard output with UTF-8 encoding. The function appears to be used for testing and debugging the text cleaning process of HTML content.
12790	Try to load a stage module and add it to the stages dictionary, ignoring any errors. If the module or function cannot be loaded, a warning is logged but execution continues.
12791	Load external stages from a Python module file and add them to the current stages collection. The module must contain a 'Stages' dictionary mapping stage names to callable objects.
12792	Load external stages from a Python module into the current object's stages dictionary. If the module is provided as a string, it will be imported. The module must contain a 'Stages' dictionary mapping stage names to callables. Raises ImportError if the module cannot be loaded or doesn't contain 'Stages'.
12793	Constructs and configures a stage from known stages using the provided name and configuration.

Parameters:
- name (str): Name of the stage to construct
- config (dict): Parent object configuration dictionary

Returns:
- callable stage object

Raises:
- KeyError: If the specified stage name is not found

The method retrieves the stage constructor from self using the name, gets the subconfiguration for that stage from config, and returns an instantiated stage object using the constructor with the subconfiguration.
12794	Function `read_to` iterates through byte sequence `idx_bytes` until it encounters either a byte in `stop_bytes` or a byte not in `run_bytes`. It returns a tuple containing the index of the last processed byte, the accumulated bytes (including the terminal byte), and the terminal byte itself. The function uses a while loop with try-except to handle StopIteration exceptions when the iterator is exhausted.
12795	This method filters href links based on configuration criteria. It checks if the href is an absolute URL when required, accepts all domains if configured to do so, or filters based on domain substrings. Returns True if the href meets the criteria, False otherwise.
12796	Create labels for author annotations with filtered hrefs and anchors based on offset type.
12797	Generator function that yields all file paths recursively under the given input directory by walking through all subdirectories and files.
12798	Generate data objects for each task by iterating through tasks range, filtering by key prefix, parsing JSON task data, and yielding formatted task data with task_key included.
12799	Method: `get_random_available`

Summary: Retrieves a random key from the first `max_iter` rows in the available data set using a reservoir sampling algorithm. The method iterates through rows with a specified consistency level to ensure data consistency, particularly important for single-node setups. It uses random sampling to select one key from the limited sample set, with a default maximum iteration limit of 10,000 rows. The implementation includes logging for debugging and handles edge cases where the maximum iteration count is reached.
12800	Tokenizes words in a sentence while preserving NER labels from ENAMEX tags, handling both regular text and named entity mentions with their respective types and coreference IDs.
12801	Parse sentences and tokens from XML using LingPipeParser, returning sentences, relations, and attributes.
12802	A retry decorator for methods that need multiple attempts due to intermittent failures, particularly useful for AWS calls via boto. It handles various exception types differently - OSError is considered unrecoverable, FailedExtraction is passed through, FailedVerification can be suppressed based on configuration, and other exceptions trigger retries with exponential backoff. The decorator logs retry attempts and stops after exceeding the configured number of tries.
12803	Verifies that the MD5 hash of given data matches an expected MD5 hash. Returns True if verification succeeds, raises FailedVerification exception if hashes don't match. Optionally logs additional error messages if provided.
12804	Returns a boto.Bucket object by managing AWS configuration and credentials. Credentials are sourced first from config file paths, then from environment variables, and finally from default AWS locations. Raises ConfigurationError if bucket name is not provided in config.
12805	Method `_decode` takes raw S3 data and returns a generator for items contained in that data, based on the `input_format` configuration option. It supports multiple formats:
- 'spinn3r': Uses `_generate_stream_items` to process data
- 'streamitem': Creates and returns a `streamcorpus.Chunk` object with specified version validation
- 'featurecollection': Uses `FCChunk` if available to process data
- Raises `ConfigurationError` for invalid input formats or unsupported versions

The method handles chunked data efficiently using generators while supporting both chunked and non-chunked file formats.
12806	Retrieves and processes a chunk of data from an S3 bucket, handling decompression and decryption if needed, and verifies MD5 checksum if configured. Returns a Chunk object containing the processed records. Raises FailedExtraction if the key doesn't exist, contains no data, or fails MD5 verification.
12807	Converts a text stream ID to a kvlayer key tuple consisting of a decoded document ID and epoch ticks. The stream ID is expected to be in the format "epoch_ticks-doc_id" where epoch_ticks is a decimal number and doc_id is a hexadecimal string. Raises KeyError for malformed stream IDs.
12808	Convert a kvlayer key tuple to a text stream ID by combining epoch ticks with a lowercase base16-encoded absolute URL hash.
12809	Get a kvlayer key from a stream item by calculating a MD5 hash of the absolute URL and combining it with the stream time's epoch ticks as an integer.
12810	```python
def main(argv=sys.argv):
    """Main entry point that starts a Pony web server."""
    args = parse(argv)
    hostname = args.listen
    port = args.port
    print(
        "Making all your dreams for a pony come true on http://{0}:{1}.\n"
        "Press Ctrl+C to quit.\n".format(hostname, port))

    # Hush, werkzeug.
    logging.getLogger('werkzeug').setLevel(logging.CRITICAL)

    plugin_manager.load_installed_plugins()
    app = make_app()
    run_simple(hostname, port, app)
```

Summary: The `main` function serves as the entry point for a Pony web server application. It parses command-line arguments to determine the hostname and port, displays a welcome message, configures logging to suppress Werkzeug messages, loads installed plugins, creates the application, and starts the server using Werkzeug's simple run method.
12811	Builds and returns an argument parser for HTTPony HTTP server with options to set IP address and port.
12812	Add XPath character offsets to tokens in a stream item's sentences, mutably tagging each token with its XPath position when computable. Returns None for tokens without computable XPath offsets.
12813	Convert stream item sentences to character Offset tokens.
12814	Convert character offsets to character ranges by yielding start and end positions for each token's character offsets.
12815	Converts character offsets in HTML content to XPath offsets by processing tokens through a parser, handling edge cases like zero-length tokens and parsing progress issues, and yielding XpathRange objects or None for each token.
12816	Records that a tag has been seen at this depth, collapsing adjacent text nodes and maintaining a count of each tag appearance.
12817	Get an XPath fragment for this location in the form ``tag[n]`` where `tag` is the most recent element added and n is its position, or ``text()[n]`` if the last tag is TextElement.
12818	Returns the one-based index of the current text node, counting text nodes encountered so far and adjusting for the current position in the document structure.
12819	Generator function that yields all descendant elements of a given element in document order, recursively traversing through all child elements.
12820	Selects and yields only element objects from a source, handling both individual elements (yielding their children) and iterators (filtering for elements only).
12821	Returns a filter object that yields all elements with the specified name from the source iterator.
12822	Returns an iterator that filters elements from source, yielding only those whose xml_name matches the given regular expression pattern.
12823	Selects elements from source that have a specified attribute, optionally filtering by attribute value. Returns elements where the attribute exists (and matches the value if provided).
12824	Returns an iterator over sibling elements that come after the given element in document order, excluding the element itself.
12825	Summary: The `make_pretty` function enhances the readability of MicroXML by adding text nodes for spacing and indentation between descendant elements. It modifies the element in place by inserting newline and indentation text nodes where appropriate, making the XML structure easier to read. The function preserves existing non-whitespace text content but alters whitespace-only text nodes to achieve proper formatting. It returns the modified element.
12826	Call inkscape CLI with given arguments and return its exit status.

Parameters:
- args_strings: list of str - command line arguments for inkscape
- inkscape_binpath: str - optional path to inkscape binary file

Returns:
- int - exit status code from inkscape command execution

Raises:
- IOError - when inkscape binary cannot be found at specified path
12827	Exports an input file using Inkscape CLI with specified export parameters and DPI setting.
12828	Transforms an SVG file to a PDF file using either rsvg or inkscape based on unicode support requirement.
12829	Transforms an SVG file to a PNG file using Inkscape export functionality with specified DPI resolution.
12830	Return a Jinja2 environment for the directory containing the given file path. Raises IOError if the directory does not exist.
12831	Setup self.template by loading a template file using a template environment.

Parameters:
- template_file_path: str - Document template file path.

Side effects:
- Sets self._template_file to the template file path
- Sets self._template_env to the template environment
- Sets self.template to the loaded template

Raises:
- Propagates any exceptions that occur during template loading
12832	Fills the document template with provided content values, renders the template with the given dictionary of values, and returns the filled document content. Handles exceptions during rendering and logs errors appropriately.
12833	Save the content of the .txt file in a text file.

Parameters
----------
file_path: str
    Path to the output file.
12834	Factory function to create a specific document instance based on either a command parameter or the template file extension. It attempts to determine the document type using the command first, falling back to the file extension if that fails, and returns an instantiated document of the appropriate type.
12835	Fill the SVG document content by replacing special characters in doc_contents with XML codes before filling the template, then return the filled document string.
12836	Save the content of the .svg file in the chosen rendered format.

Parameters
----------
file_path: str
    Path to the output file.

Kwargs
------
file_type: str
    Choices: 'png', 'pdf', 'svg'
    Default: 'pdf'

dpi: int
    Dots-per-inch for the png and pdf.
    Default: 150

support_unicode: bool
    Whether to allow unicode to be encoded in the PDF.
    Default: False
12837	Save the content of the .text file as a PDF file.

Parameters:
----------
file_path: str
    Path to the output PDF file.
12838	Parse XML 1.0 input using expat parser and convert it to MicroXML format by invoking the provided handler for various XML events, returning the parsed MicroXML element and any extra information.
12839	Parse an HTML input source into an Amara 3 tree structure, returning the first element node from the parsed document. The function uses html5lib to parse the source and supports optional parameters for prefixes, model, encoding, and XHTML namespace usage. Note that when passing a string, it must be a byte string, not Unicode.
12840	Parse an HTML markup fragment and return a bindery node. Takes a source (either a string or inputsource) and optional encoding, parses it using the html parser, extracts the body element from the parsed document, and returns it as a bindery node. Warning: when passing strings, ensure they are byte strings and consider wrapping with amara.lib.inputsource.text for non-obvious XML/HTML content.
12841	Inserts text data into the current node either before a specified node or at the end of the node's text content.
12842	Inserts a node as a child of the current node before a specified reference node in the child list. Raises ValueError if the reference node is not a child of the current node.
12843	Return a shallow copy of the current node with the same name and attributes but no parent or child nodes.
12844	This function `execute(option)` takes a list of configuration options and uses them to generate input files, compile and run a benchmark program, and return the execution results. It processes options to create namelist and Makefile.include files from templates, writes these files to specific locations, compiles the code using make, runs the compiled program, captures its output, and extracts a timing value from the output. The function returns a tuple indicating success or failure and the extracted timing value.
12845	Returns the XPath-like string value of a node by recursively concatenating text content from all descendants. For element nodes, it collects text values from children and nested children, joining them into a single string when at the outermost level. For non-element nodes, returns the node's xml_value directly.
12846	Append a node as the last child, converting strings to text nodes; accepts optional index parameter.
12847	Parse configuration file to extract Google Calendar notification settings including secrets, credentials, start/end times, and message template, with error handling for missing files or required options.
12848	Get Google API credentials for user, handling authentication flow if requested or loading existing credentials.
12849	Create event start and end datetimes by adding configured minute offsets to current time, formatted with timezone information.
12850	Create a calendar event with SMS reminder by authorized Google Calendar API client, using provided options, config, and credentials. If successful, the event is inserted into the specified calendar with notifications sent. In case of error, writes error message to stderr and exits with code -1.
12851	Main function for processing notification calls that parses options and config, retrieves Google credentials, and creates an event when Google credentials are not requested.
12852	Return the extension of a file path. If check_if_exists is True, validate that the file exists before extracting the extension. Raises IOError if file doesn't exist when check_if_exists is True.
12853	Add file extension to filepath if it's not already present. If check_if_exists is True, verify the file exists after adding the extension. Returns the filepath with extension added if needed.
12854	Creates a temporary file with specified suffix in a given directory path, returning the file path. If no directory path is provided, uses the system's temporary directory.
12855	Remove all files with the specified extension from the given working directory.
12856	Converts a CSV file to JSON format by reading rows from the CSV and writing them as JSON objects to the output file, optionally skipping the first line.
12857	Replace occurrences of a substring in a file with a new substring, optionally limiting the number of replacements.
12858	Run all parsing functions including italic, strong, underline creation, span unwrapping, comment removal, token finding, and blacklisted tag removal on specific HTML elements.
12859	Method that checks if the next sibling tag is a link with the same href, and if so, combines them by appending the text content and adding the duplicate tag to a blacklist for removal.
12860	Method: create_italic
Description: Checks if a span tag has italic styling and wraps it with an em tag. Returns the modified tag with the em wrapper applied.
12861	Method name: create_strong
Summary: Checks if a span tag has bold styling (via font-weight:bold or font-weight:700) and wraps it with a strong tag if the condition is met.
12862	Method: create_underline
Parameters: self, tag
Returns: None
Description: Checks if a span tag has underline styling and wraps it with a u tag if the style contains 'text-decoration:underline'. The method examines the 'style' attribute of the tag and performs the wrapping operation using BeautifulSoup's new_tag and wrap methods.
12863	Parse and validate tag attributes against a whitelist, removing invalid attributes and processing valid ones through _parse_attr method.
12864	Method: clean_linebreaks
Parameters: self, tag
Returns: Unicode string with line breaks removed and extra spaces cleaned

Description: Removes all line break characters and replaces multiple whitespace characters with single spaces from the input tag content.
12865	Extract "real" URL from Google redirected url by getting `q` querystring parameter.
12866	Parse attribute by delegating href attributes to href parser, otherwise return value unchanged.
12867	Function `translate_key_values` modifies dictionary keys according to provided translations, replacing existing keys with new names while preserving values. It takes a dictionary and an iterable of 2-tuples specifying source-to-destination key mappings, optionally using a default value for missing keys. The function modifies the input dictionary in-place and returns it with updated keys. Keys not present in the translations remain unchanged.
12868	Converts object data to a JSON string representation.

Returns:
    JSON string containing object attributes and class name.
12869	Returns absolute paths of files that match the regex within folder_path and all its child folders, using re.match for pattern matching.
12870	Concatenates argument strings and yields the result.
12871	Yields one boolean indicating whether the first string starts with the second string.
12872	Yields one boolean indicating whether the first string contains the second string. Takes two string arguments and returns True if the second string is a substring of the first, False otherwise.
12873	Function `string_length` computes and yields the length of a given string. It accepts a context object and an optional string parameter. If no string is provided, it uses the context's node attribute. If the string parameter is callable, it computes the string from the callable. Finally, it yields the length of the string.
12874	Converts an object to a boolean value according to specific rules: returns false for empty sequences, boolean false, zero/negative zero/NaN numbers, or empty strings, and true for all other cases.
12875	**Summary:**

The `foreach_` function applies a given expression to each item in an input sequence and yields the results. It takes a context, sequence, and expression as parameters. The sequence is first computed if it has a `compute` method, then the expression is parsed and evaluated for each item in the sequence using a dynamically created inner context. The function is a generator that yields results one by one.

**Key aspects:**
- Processes sequences item-by-item
- Dynamically evaluates expressions using parsed expression trees
- Uses context copying for each iteration
- Returns a generator yielding computed results
- Handles sequences with computed values via `compute()` method
- Processes string arguments through `string_arg()` helper
12876	Lookup a value from a table in the context using the provided tableid and key, yielding the result or an empty sequence if unsuccessful.
12877	Replace special characters in SVG content with their corresponding SVG entities (&amp;, &gt;, &lt;, &quot;).
12878	Summary: The `_check_svg_file` function validates and processes SVG file input. It accepts either a file path (string) or an existing svgutils SVGFigure object. If a string is provided, it attempts to read and parse the SVG file using `sg.fromfile()`, raising an exception if the file cannot be read. If an SVGFigure object is provided, it returns the object directly. If the input is neither a string nor an SVGFigure object, it raises a ValueError with an appropriate error message.
12879	Merge two SVG files by placing the content of the second SVG at specified coordinates with optional scaling, returning the combined SVG document.
12880	Merge multiple PDF files into a single PDF file and return the output file path.
12881	Returns the ElementTree of the SVG content in `filepath` with embedded font content from `font_files`. If no font files are provided, returns the original tree unchanged. Creates FontFaceGroup and FontFace objects for each font file, then inserts the font definitions into the SVG tree before the first element.
12882	Writes embedded font content from TTF and OTF files into an SVG file and saves the result to an output file.
12883	Method `_check_inputs` performs basic validation on input objects to ensure they are valid. It first checks that the inputs are iterable by attempting to access the first element, raising a RuntimeError with a descriptive message if the inputs are not iterable. Then, it iterates through each input and verifies that every input is an instance of the Input class (or its subclass) from the melody.inputs module. If any input fails this type check, it raises a RuntimeError with details about the invalid input type and value. This method ensures that all inputs conform to the expected interface and type requirements before proceeding with further operations.
12884	Method `_check_function` performs basic validation on a provided function to ensure it is callable and has exactly one argument. It raises a RuntimeError if the function is not callable or if it doesn't have exactly one argument, printing the argument information when the argument count is incorrect.
12885	Internal recursion routine that generates all input combinations by iterating through available options for each input, then calls the function with each combination and prints the results.
12886	Creates an input file by rendering a Jinja2 template with provided options. Takes a list of option dictionaries, converts them to Jinja2 format, loads the specified template from a given location, fills the template with the options, and returns the rendered output as a string. Raises RuntimeError for invalid input formats or missing templates.
12887	This method recursively generates all combinations of input elements by exploring each possible selection at every depth level up to a maximum depth. It builds combinations incrementally, appending valid combinations to a results list when the maximum depth is reached. The recursion works by iterating through available inputs at each step, ensuring no element is reused within a single combination.
12888	Converts an arbitrary object or sequence to a string representation, handling various types including LiteralWrapper, iterables, strings, nodes, numbers, and booleans, with appropriate type checking and conversion logic.
12889	Converts an arbitrary object or sequence to a number type, handling various input types including None, strings, nodes, and numeric types, with special handling for LiteralWrapper objects and iterables.
12890	Converts an arbitrary object to a boolean value by handling different data types including LiteralWrapper, iterables, None, booleans, strings, node objects, and numeric types. Returns a boolean yield value based on the type and content of the input object. Raises RuntimeError for unknown types.
12891	Generate token strings that, when joined together, form a valid XPath serialization of the AST.
12892	Change the XML encoding entry in a file from source encoding to destination encoding.
12893	Save `text` in a QR code SVG image file with optional color customization.

Parameters:
- text (str): The string to be encoded in the QR code
- out_filepath (str): Path to the output SVG file
- color (str, optional): RGB color in 6 hexadecimal values for the QR code
- box_size (scalar, optional): Size of QR code boxes (default: 10)
- pixel_size (scalar, optional): Pixel size for the QR code (default: 1850)

The function generates a QR code from the input text and saves it as an SVG file. If a color is specified, it replaces the default black color with the specified color in the SVG file. The QR code uses error correction level L and has a border of 0.
12894	```python
def launch(option):
    '''Set the gromacs input data using the supplied input options, run
    gromacs and extract and return the required outputs.'''

    from melody.inputs import create_input
    _ = create_input(option, template_name="input.mdp")

    # save the input file in the appropriate place and launch gromacs using
    # longbow ...

    # determine if the run was successful
    success = True

    results = None
    if success:
        # extract the required outputs
        results = {"rate": {"value": 35, "units": "ns/day"}, }

    return success, results
```

Summary: The `launch` function sets up GROMACS simulation input files using provided options, executes the simulation, and returns the simulation results. It creates input files using `create_input`, runs the simulation (implementation details hidden), and if successful, returns a dictionary containing simulation rate data with value 35 and units "ns/day". The function returns a tuple of (success_status, results).
12895	Calls a CLI command with given arguments and returns its return value, handling both relative and absolute command paths with proper error logging and exception handling.
12896	Converts a TeX file to PDF or DVI format using PDFLatex, with optional output file specification and cleanup of auxiliary files.
12897	Returns all potential loop fusion options for the provided psy object by recursively exploring outer loops in each invoke's schedule and collecting fusion possibilities.
12898	Returns a transformed Geometry by reprojecting it to the specified spatial reference system. If the input geometry has no spatial reference, it raises an exception. The function handles both Geometry objects and Envelope objects, automatically assigning the target spatial reference to envelopes. It only performs transformation when the source and target spatial references differ.
12899	Returns an ogr.Geometry instance optionally created from a geojson string or dict, with optional spatial reference support.
12900	Expands this envelope by the given Envelope or tuple by updating the lower-left and upper-right coordinates with the minimum and maximum values respectively.
12901	Returns the intersection of this Envelope and another Envelope. If they intersect, the result is an Envelope with lower-left corner as the maximum of lower-left corners and upper-right corner as the minimum of upper-right corners. If they don't intersect, returns an empty Envelope with corners at (0,0).
12902	Returns true if this envelope intersects another envelope. Takes an Envelope or tuple of (minX, minY, maxX, maxY) as argument. Handles both Envelope objects and tuples by attempting attribute access and falling back to creating an Envelope from tuple data if needed.
12903	Returns an OGR Polygon geometry representing this envelope by creating a linear ring from the four corners (lower-left, lower-right, upper-right, upper-left) and closing the ring by repeating the first point.
12904	Creates a table from arrays Z, N and M by constructing a DataFrame with these arrays, setting 'Z' and 'N' as multi-index, and using 'M' as the data values. The resulting DataFrame is then used to initialize and return a new Table object with the specified name.
12905	Export the table contents to a file as comma separated values, first writing a header row 'Z   N   M' followed by the DataFrame data in tab-separated format.
12906	Selects nuclei from a table based on a specified condition function that can operate on mass (M), or on proton number (Z) and neutron number (N), or on all three parameters. Returns a new Table containing only the nuclei that satisfy the condition. The condition function determines which nuclei are selected by evaluating boolean expressions on Z, N, and/or M values.
12907	Return a selection of the Table at positions given by ``nuclei``

Parameters
----------
nuclei: list of tuples
    A list where each element is tuple of the form (Z,N)

Example
-------
Return binding energies at magic nuclei:

>>> magic_nuclei = [(20,28), (50,50), (50,82), (82,126)]
>>> Table('AME2012').binding_energy.at(magic_nuclei)
Z   N
20  28      416.014215
50  50      825.325172
    82     1102.876416
82  126    1636.486450
12908	Select nuclei which also belong to ``table``

Parameters
----------
table: Table, Table object

Example
----------
Table('AME2003').intersection(Table('AME1995'))
12909	Select nuclei not in table by finding the difference between table indices.

Parameters:
- table: Table object from where nuclei should be removed

Returns:
- Table object containing nuclei present in self but not in table

Example:
- Find new nuclei in AME2003 with Z,N >= 8: Table('AME2003').not_in(Table('AME1995'))[8:,8:].count returns 389
12910	Selects odd-even nuclei from the table where atomic number Z is odd and neutron number N is even.
12911	Selects even-odd nuclei from the table by filtering for nuclei where both proton number (Z) and neutron number (N) are odd. Returns a filtered table containing only even-odd nuclei.
12912	Selects even-even nuclei from the table by filtering for nuclei where both proton number (Z) and neutron number (N) are even. Returns a new table containing only these nuclei.
12913	Calculate error difference between this table and another mass table.

Parameters:
- relative_to: string, a valid mass table name (default: 'AME2003')

Returns:
- Table: A new table containing the error differences

Example:
- Table('DUZU').error(relative_to='AME2003')
12914	Calculate root mean squared error of the mass table relative to a specified mass table.
12915	Return binding energies instead of mass excesses by calculating the difference between the total mass of constituent particles and the actual mass, using proton mass (938.2723 MeV), electron mass (0.5110 MeV), neutron mass (939.5656 MeV), and atomic mass unit conversion (931.494028 MeV). The result is returned as a Table with binding energy values and name 'BE' + '(' + self.name + ')'.
12916	Return 2 neutron separation energy using the formula: -parent + daughter + 2 * neutron_mass_excess, where neutron_mass_excess = 8.0713171 MeV.
12917	Return 1 neutron separation energy using the formula: -parent + daughter + neutron_mass_excess, where neutron_mass_excess = 8.0713171 MeV.
12918	Return the 2-proton separation energy by calculating the energy difference between a parent nucleus and its daughter nucleus with 2 protons removed, using the formula: S2p = -Mp + Md + 2*M_P where Mp is the parent mass, Md is the daughter mass, and M_P is the proton mass excess (7.28897050 MeV).
12919	Return 1 proton separation energy using proton mass excess and derived quantity calculation.
12920	Helper function that calculates derived quantities by applying a formula to relative coordinates and returns a new Table with the computed values.
12921	A decorator function that manages database connections for class methods, ensuring proper session setup, commit/rollback transactions, and session cleanup. It automatically handles database session initialization, commits successful operations, rolls back on exceptions, and closes sessions regardless of outcome.
12922	Computes a key from a master password and salt using scrypt encryption with fixed parameters (N=16384, r=8, p=1). Returns the encoded key and logs the derivation time.
12923	Initialize a database at the given path or URI by creating the database engine and setting up all required tables using SQLAlchemy's metadata.
12924	Search the database for domains matching the given query with partial matching enabled.
12925	Modify an existing domain by optionally generating a new salt or changing the username, then return the modified Domain object.
12926	Creates a new domain entry in the database with specified parameters, handling exceptions by logging warnings and raising DuplicateDomainException.
12927	Extract messages from Handlebars templates by communicating with a pipe server, parsing JSON output, and yielding tuples containing line numbers, function names, message tuples, and empty comment lists.
12928	Returns a GDAL virtual filesystem prefixed path by combining file system type and URL scheme from the input path.
12929	Returns the EPSG ID as int if it exists, otherwise returns None.
12930	Main entry point for the CLI that parses arguments, executes the target command, logs the exit code, and exits with that code.
12931	Initializes loggers with console output formatting. Sets log levels to DEBUG if verbose is True, otherwise INFO/WARNING. Configures handlers for 'pwm' and 'requests.packages.urllib3' loggers with appropriate formatting and propagation settings. Enables HTTP debug output when verbose is True.
12932	Updates a file by downloading content from a URL, skipping comment lines, and printing a confirmation message.
12933	Returns a dictionary of enabled GDAL Driver metadata keyed by the 'ShortName' attribute.
12934	Returns the gdal.Driver for a given path based on file extension, or None if no matching driver is found.
12935	Converts an OGR polygon to a 2D NumPy array using rasterization.

**Parameters:**
- `geom`: OGR Geometry object to rasterize
- `size`: Array size in pixels as (width, height) tuple
- `affine`: AffineTransform object for spatial reference

**Returns:**
- 2D NumPy array with rasterized polygon (1s where polygon exists, 0s elsewhere)

**Process:**
1. Creates in-memory raster with specified size and affine transform
2. Sets spatial reference from geometry
3. Rasterizes the polygon geometry into the raster
4. Converts raster to NumPy array
5. Returns the resulting array
12936	Returns a Raster from layer features by rasterizing the layer over a target raster grid.
12937	Returns a Raster instance from a file path or file-like object, supporting both local/remote paths and in-memory data with specified access mode.
12938	Returns an in-memory raster initialized from a pixel buffer.

Arguments:
- data -- byte buffer of raw pixel data
- size -- two or three-tuple of (xsize, ysize, bandcount)
- bandtype -- band data type (default: gdal.GDT_Byte)
12939	Returns a copied Raster instance from a source Raster or file path to a destination file path, using the driver's CreateCopy method. Raises IOError if copying is not supported, or ValueError if source and destination are the same location. Automatically handles closing source Raster instances and returns a new Raster object.
12940	Returns a dictionary of driver-specific raster creation options by parsing XML metadata, caching the result for performance.
12941	Creates a new Raster instance by calling gdal.Driver.Create() with the specified parameters, returning a Raster object. Raises exceptions for invalid size, existing files, or creation failures.
12942	Sets the affine transformation for the dataset by intercepting the gdal.Dataset call, accepting either an AffineTransform object or a six-tuple of geotransformation values, and storing it as a property.
12943	Returns an NDArray from the dataset, optionally subsetting it by a spatial envelope. If an envelope is provided, it calculates the appropriate offset coordinates before reading the array data.
12944	Returns the minimum bounding rectangle as a tuple of min X, min Y, max X, max Y. Calculates and caches the envelope using raster dimensions and affine transformation if not already computed.
12945	Returns the underlying ImageDriver instance, creating it if necessary.
12946	Create a new Raster instance with specified size and affine transformation, copying properties from the original raster including projection, color table, and nodata values.
12947	Returns a MaskedArray using nodata values, optionally masked by a geometry. If no geometry is provided, returns the full masked array. If geometry is provided, it transforms the geometry to the array's spatial reference, intersects it with the array's envelope, creates a mask from the geometry, and combines it with the existing nodata mask.
12948	Returns read-only property for band nodata value, caching the result after first access.
12949	Returns raster data bytes for partial or full extent, overriding gdal.Dataset.ReadRaster() with full raster size by default.
12950	Returns a new instance resampled to provided size using the specified interpolation method. The method calculates scaling factors based on the target size versus current raster dimensions, adjusts the affine transformation accordingly, creates a new destination raster with the calculated parameters, and then reprojects the source data to the destination raster using GDAL's ReprojectImage function. The default interpolation method is nearest neighbor.
12951	Save this instance to the specified path and format using the given driver, raising an error if no suitable copy-supporting driver is found.
12952	Sets the spatial reference for a dataset by intercepting the gdal.Dataset call. Takes a SpatialReference object or any format supported by the SpatialReference constructor, and updates both the internal reference and the underlying dataset's projection.
12953	Returns a new reprojected instance by warping the current raster to a specified spatial reference system using GDAL's ReprojectImage function. The method supports various interpolation methods and can output to either memory or file destination. It automatically handles the creation of warped virtual raster and sets appropriate geotransform, projection, and nodata values for the output raster.
12954	Computes the ideal conversion ratio for a given alphabet size by finding the optimal number of bits and encoded length where the fractional part of the ratio is minimized. Returns a tuple of (binary_length, encoded_length) representing the chunk lengths for optimal encoding efficiency.
12955	Retrieves a named charset from presets or returns the input as a custom alphabet after validating its length.
12956	Encodes a chunk of data by converting it to a number and then encoding that number.
12957	Parses a chunk of bytes to an integer using big-endian representation.
12958	Partition data into chunks and return the chunk at the specified index.
12959	A decorator that caches function results by storing them in a dictionary, avoiding redundant computations for the same input filename.
12960	```python
def _regexp(filename):
    """Get a list of patterns from a file and make a regular expression."""
    lines = _get_resource_content(filename).decode('utf-8').splitlines()
    return re.compile('|'.join(lines))
```

Summary: Reads patterns from a file, splits them into lines, and compiles them into a single regular expression using OR operations.
12961	Normalize a date string or timestamp to a UTC timezone-aware datetime object. Converts integer timestamps to strings, parses string dates using dateutil, and handles timezone conversion from local timezone to UTC. Returns a timezone-aware datetime object in UTC timezone.
12962	Detects and returns the system's timezone. If locale information is unavailable, returns the default timezone 'America/New_York'. Otherwise, derives the timezone from the country code in the locale settings using pytz.
12963	Returns the model properties as a dictionary representation, handling nested objects and lists by converting them to dict format where possible.
12964	activates post-mortem debugging hook that opens pdb prompt when unhandled exceptions occur
12965	Formats and prints dictionary objects with optional alignment, or returns non-dictionary objects unchanged.
12966	Connects to a remote master server and continuously processes jobs by receiving calls, executing them through a job handler, and returning responses until interrupted or connection is lost. Handles connection errors and read exceptions gracefully.
12967	Starts an asyncio event loop to connect to the master and run jobs.
12968	Runs a pool of worker processes that connect to a remote HighFive master and execute jobs. Creates one worker process per CPU core (or specified max_workers) that runs the worker_main function with the provided job handler and connection details. All workers are started concurrently and the function waits for all of them to complete before returning.
12969	Sets the classification of the company after validating it against allowed values. Raises ValueError if classification is not valid.
12970	Adds a message to the queue and starts processing the queue in a new thread if no thread is currently running.
12971	**Summary:** Creates and sends a message to turn a light on with the specified device ID and name.
12972	Method: turn_on_switch
Description: Creates and sends a message to turn a switch on
Parameters: 
- device_id: identifier for the device
- name: name of the switch to turn on
Returns: None
Side effects: Sends a formatted message through self._send_message() with command "!{device_id}F1|Turn On|{name}"
12973	Turns on a device with specified brightness level by scaling the brightness value from 0-255 range to 1-32 range and sending an appropriate message command.
12974	Creates a message to turn off a light or switch and sends it using the device ID and name provided.
12975	Send all messages currently in the queue by processing each message with `_send_reliable_message`.
12976	Send a message to LightwaveRF hub with reliable delivery mechanism using UDP sockets, retrying up to 15 times until acknowledgment is received or timeout occurs. Returns True if successful, False otherwise.
12977	Creates a CMPH capable adapter for the given object, handling file locations, files, and sequence objects. Raises ValueError for unsupported object types.
12978	Sets the nature of the YearlyFinancials object to either "STANDALONE" or raises a ValueError for invalid values.
12979	Updates configuration section values using a dictionary, ignoring undefined options and optionally filtering by config-file settable options.
12980	Restore default values of options in this section by iterating through defaults and setting each option to its default value.
12981	Set the list of config files from given paths, stored as pathlib.Path objects in a tuple.
12982	Iterator over sections, option names, and option values. Yields tuples of (section, option, value) by iterating through all options in all sections.
12983	Iterator over sections, option names, and option metadata that yields tuples of section, option name, and Conf instance holding option metadata.
12984	Create a configuration file at the specified index path, optionally updating existing file with current configuration options.
12985	Updates configuration options with dictionary values, processing each section and its corresponding options while respecting config file constraints if specified.
12986	Reads a TOML config file and updates configuration values. Returns the config dictionary if successful, empty dict if file doesn't exist, or None if TOML parsing fails.
12987	Read config files and set config values accordingly.

Returns:
    (dict, list, list): respectively content of files, list of
    missing/empty files and list of files for which a parsing error
    arose.
12988	Returns a list of CLI argument strings for a given option, including long-form (--) and short-form (-) arguments, with special handling for switch-type options that support both - and + variants.
12989	Returns a list of configuration sections used by a specified command, including common sections, command-specific sections, and any command-specific configuration sections.
12990	Scans command-specific configuration options and updates the command options dictionary, handling option shadowing with warnings.
12991	Adds command line options to a parser based on configuration dictionary, setting appropriate types, defaults, and help text for each option.
12992	Builds a command line argument parser for the configuration manager, including main options, bare options, and subcommands with their respective options and defaults. Returns an ArgumentParser instance.
12993	Parse command-line arguments and update configuration options accordingly, returning the parsed argument namespace.
12994	Writes zsh _arguments compdef for a given command, handling help options and option completion rules based on command metadata and configuration.
12995	Writes a zsh compdef script for command completion. Generates completion functions for a command and its subcommands, with optional sourceable output that can be directly sourced to activate completion. The script includes subcommand listing with descriptions and argument completion for each subcommand.
12996	Build a list of all options for a given command, including optional help flag, by collecting CLI option strings from configuration based on command and section mappings.
12997	Write bash completion script for a command and its subcommands, including options and argument completion.
12998	Starts a HighFive master server on the specified host and port, returning a Master instance with a JobManager, worker set, and event loop.
12999	**Summary:** Sets up the protocol object when a remote worker connection is established, handles closed manager case, initializes transport, buffer, and worker objects, and adds the worker to the workers collection.
13000	Called when a complete line is received from the remote worker, decodes the JSON response, and passes it to the worker object's response_received method.
13001	Called when the connection to the remote worker is broken. Closes the worker and removes it from the workers list.
13002	Method `_job_loaded` is called when a worker finds a job to execute. It sends the job's RPC to a remote worker by serializing the job call object to JSON, encoding it to UTF-8, and writing it through the transport layer. If the worker is closed, it returns the job to the manager instead of processing it.

Key points:
- Handles job assignment to worker
- Serializes job call object to JSON format
- Sends serialized job through transport layer
- Gracefully handles closed worker state
- Returns unused jobs to manager when worker is closed
13003	Called when a job RPC response is received. Decodes the response, finalizes the result, and reports it to the job manager. Loads the next job if available.
13004	Closes the worker, preventing it from handling new jobs and returning any currently running job to the job manager.
13005	Runs a job set consisting of jobs in the provided iterable job list using the manager's add_job_set method. Raises RuntimeError if the master is closed.
13006	Closes the HighFive master by shutting down the server, canceling queued job sets, and closing all workers. Returns immediately if already closed.
13007	Method `_change` is called when a state change occurs. It notifies all waiters by setting their results to None and then clears the waiters list.
13008	Adds a new result to the collection if not complete, then signals a change event.
13009	Waits for the result set to change (either by adding a new result or completing). If already complete, returns immediately. Otherwise, creates a future waiter and awaits until notified of changes.
13010	Loads the next job from the job iterator if available, increments active job count, and handles StopIteration gracefully.
13011	Marks the job set as completed, completes results, and notifies all waiting tasks by setting their results to None while informing the manager of job completion.
13012	Adds a job result to the result list and decrements active job count, notifying completion when all jobs are finished.
13013	Cancels the job set by immediately finishing it, discarding all queued jobs, and clearing all job-related data structures.
13014	Waits for the job set to complete, returning immediately if already finished. If jobs are active, creates a future and waits for completion.
13015	Distributes available jobs from the active job set to waiting get_job callbacks by continuously checking for available jobs and pending callbacks, then invoking the callback with the retrieved job while tracking the job source.
13016	Adds a job set to the manager's queue. If no job set is running, activates it immediately; otherwise queues it. Returns a job set handle.
13017	**Summary:**

The `get_job` method registers a callback function to be executed when a job becomes available. It first validates that the object is not closed, then checks if there's an active job source with available jobs. If no jobs are available, it adds the callback to a list of ready callbacks. Otherwise, it retrieves the job from the active source, tracks the job source, and immediately calls the callback with the job.
13018	Returns a job to its source job set to be run again later, handling callbacks and cleanup appropriately.
13019	Adds a job result to its source job set's results list, removing the job from job_sources dictionary. Returns early if the object is closed.
13020	Called when a job set has been completed or cancelled. If the job set was active, the next incomplete job set is loaded from the job set queue and is activated.
13021	Closes the job manager, preventing new jobs from being assigned or job sets from being added, and cancels any queued or active job sets.
13022	Remove duplicates from a list while preserving order.
13023	Returns true if the regex matches the object, or a string in the object if it is some sort of container. Supports strings, dictionaries, and iterable objects containing strings.
13024	Lists all available instances with optional filtering, exclusion, and limiting capabilities. Returns a list of host entries based on the specified parameters.
13025	Returns the current AWS region by checking the AWS_DEFAULT_REGION environment variable, defaulting to "us-east-1" if not set. Validates that the region exists in the EC2 regions list and caches the result for subsequent calls. Raises ValueError if the specified region is invalid.
13026	Filters a list of host entries based on inclusion and exclusion regex patterns, returning only entries that match all inclusion filters and none of the exclusion filters.
13027	Returns the public DNS name of a running EC2 instance with the specified name by querying EC2 with filters. Raises an exception if no matching instance is found.
13028	Deserialize a HostEntry from a dictionary by extracting all required fields from the input dictionary and passing them to the HostEntry constructor. This method provides clearer error handling compared to directly using the constructor with dictionary unpacking, as missing keys will result in more descriptive errors. Returns a new HostEntry object populated with the data from the dictionary.
13029	Returns the value of a specified attribute from the entry, handling special 'tags.' prefixed attributes and optional string conversion. For tags, it looks up values in the tags dictionary, returning '<not set>' for missing tags when convert_to_str is True. For other attributes, it retrieves them from the object, with optional string conversion for empty values, lists, or single values. Raises AttributeError for invalid attributes.
13030	Sorts a list of entries by the given attribute using a key function that retrieves the attribute value and converts it to string.
13031	Returns a string representation of the host as a single line with specified columns joined by a separator. Supports showing additional columns, filtering specific columns, and customizing the column separator.
13032	Creates a HostEntry instance from a boto EC2 instance object by extracting various attributes like name, IP addresses, instance type, and tags from the boto instance.
13033	Returns whether the instance matches the given regex filter text, supporting both attribute-specific matching (using `attribute:value` format) and existence checking (using `attribute?` format).
13034	Returns the best name to display for this host by using the instance name if available, otherwise falling back to the public IP address.
13035	Renders a list of entries as a pretty-printed string, either as a table (if terminal is wide enough) or as a line-by-line representation. Supports additional columns, selective column display, and optional numbering. Returns the formatted string.
13036	Add a timestamp field to the event dictionary using unix epoch time.
13037	Setup a formatted logger with specified level and output destination, supporting both stdout and file outputs with optional Sentry error reporting.
13038	Configures and returns a new logger for hivy modules with optional JSON output, UUID, and timestamp features.
13039	Sets up a Celery task queue with Redis as the broker, configured for JSON serialization and optional timezone support. Returns a configured Celery app instance with default Redis connection settings and task serialization preferences.
13040	Return status report for a specific worker or all workers. If worker_id is 'all', returns reports for all workers. If worker_id exists in jobs, returns that worker's report. Otherwise, returns error message with 404 status.
13041	Stop and remove a worker by revoking it and removing from jobs dictionary. Returns JSON report with worker ID and revoked status, or error message if worker not found.
13042	Creates a boolean configuration option that can be toggled on/off in CLI using + or - prefix. Returns a ConfOpt object with specified default value, short name, and help message.
13043	Define a configuration section handling config file.

Returns:
    dict of ConfOpt: it defines the 'create', 'update', 'edit' and 'editor'
    configuration options.
13044	Sets configuration options from a list of 'section.option=value' formatted strings, handling type casting and boolean value conversion.
13045	Handle configuration command by creating/updating configuration files based on command line options and editing with specified editor if needed.
13046	Create completion files for bash and zsh using the provided CLI manager, directory path, and command names. The function generates zsh files with optional sourceable support and bash files for command completion.
13047	Renders a list of columns into a formatted string table with optional borders and coloring. Takes columns (list of lists of strings), optional border drawing, and column-specific coloring functions. Returns the formatted table as a string, with validation that column colors match the number of columns.
13048	Render the num-th row of each column in columns with specified widths and optional coloring.
13049	Renders a table by converting it into columns and applying optional formatting. Takes a table as a list of rows, processes each element with its `.str` method, handles jagged tables by expanding to maximum row length, and returns a formatted string with optional borders and column coloring.
13050	Prepare a 2D grid so all rows have the same length and contain only strings. Null values are converted to empty strings, and rows are padded with empty strings to match the maximum row length. Returns the modified table as a list of lists of strings.
13051	Returns a function that colors text with a specified number (0-255) using ANSI escape codes, with automatic compatibility checking for 256-color support and terminal output.
13052	Hashes a string using SHA1, converts the hash to an integer, maps it to a range between _min and _max, and returns a color value within that range.
13053	Returns a random color between the specified minimum and maximum values.
13054	Summary: Reads user input from stdin with error handling for interrupts and EOF, attempting integer conversion while supporting default values.
13055	Verify basic HTTP authentication by checking if a user exists with the given username and password credentials. Returns the user object if found, otherwise returns None.
13056	Verifies HTTP header token authentication by checking if a user exists with the provided API key token. Returns the user object if found, otherwise returns None.
13057	A Flask decorator that protects resources using token-based authentication. It extracts the Authorization token from request headers, validates it using a check_token function, and either returns an authentication failure response or proceeds with the original resource function after setting the user in the Flask global context.
13058	The `is_running` function checks if a process is currently running on the system. It uses the `pgrep` command to search for the specified process name. If `pgrep` finds the process, it returns successfully and the function returns `True`. If no process is found, `pgrep` raises an `ErrorReturnCode_1` exception, which the function catches and handles by returning `False`. The function essentially acts as a process existence checker.
13059	Function `dynamic_import` takes a module path string and optional object name, imports the module dynamically, reloads it to ensure it's up-to-date, and returns either the entire module or a specific object from the module if `obj_name` is provided. If the import fails, it raises a `DynamicImportFailed` error with details about the failure. If the specified object doesn't exist in the module, it also raises a `DynamicImportFailed` error.
13060	Returns the machine's IP address. If `public=True`, returns the public IP address by querying an external service, otherwise returns the local IP address by connecting to Google's DNS server. Raises an exception if both methods fail.
13061	Makes an HTTP request using the specified method and parameters, delegating to the appropriate RESTClient method based on the request type. Supports GET, HEAD, OPTIONS, POST, PUT, PATCH, and DELETE methods, raising a ValueError for invalid methods.
13062	Builds form parameters by combining normal form parameters and file parameters. Returns a dictionary of form parameters with files properly formatted, including filename, file data, and MIME type for each file.
13063	Configure server from CLI arguments and run it, handling logging and exceptions with optional debug mode.
13064	Include a hidden input to store the serialized upload value by rendering a template with the given name and value context.
13065	Streams a command in a subprocess, printing each line of output with optional formatting and stdin writing. Returns the process exit code.
13066	Runs a list of command dictionaries concurrently or sequentially using the `stream_command` function, with optional parallel execution support.
13067	Streams multiple commands with optional parallel execution, applying color coding to descriptions and formatting commands for execution.
13068	Returns the number of network days between two dates, excluding weekends and holidays based on the specified locale's calendar.
13069	Returns the system path to a command by querying bash, caching results in _PATHS dictionary.
13070	Builds an SSH command string using hostname, username, key file, and optional tunnel parameters, with strict host key checking disabled and 5-second connection timeout.
13071	Builds and returns an SCP command string for file transfer operations based on provided parameters including hostname, username, identity file, and file paths. Raises ValueError for empty hostname. Supports both get (download) and put (upload) operations.
13072	Copies files from local path to remote path using SCP command for multiple host entries. Builds SCP commands for each host entry using provided profile information and executes them in parallel. Returns a list of commands that were executed.
13073	Copies files from remote machines to local paths using SCP command. For each host entry, it formats the local path, ensures the destination directory exists, builds an SCP command to copy from the remote path to the formatted local path, and executes all commands. Raises ValueError if duplicate local paths are detected after formatting.
13074	Runs a given SSH command in parallel on multiple hosts specified by entries, with options for username, identity file, and tunneling support.
13075	Connects to a host via SSH using the provided credentials and options. Returns the exit status code from the SSH command execution. Raises ValueError if no valid host address (hostname, public IP, or private IP) is found, or if private IP is used without a tunnel. Uses _build_ssh_command to construct the SSH command and subprocess.Popen to execute it.
13076	Loads the user's LSI profile from ~/.lsi file, or returns a default profile if it doesn't exist. Supports loading specific profiles by name and profile inheritance through 'inherit' option. Returns a LsiProfile object with settings from the configuration file, including username, identity_file, command, filters, and exclude patterns. Raises LoadError if specified profile doesn't exist.
13077	Creates an LsiProfile instance from argparse arguments, handling explicit username/identity_file overrides or loading from a specified profile file, then applies additional command-line options and expands user paths for identity files.
13078	Create a relationship between this package component and a supplied part, validating that the part's name starts with the component's base name, then add and return the new Relationship object.
13079	Return a list of parts related to this one via the specified relationship type by looking up the relationships and resolving targets relative to the package base path.
13080	Load relationships from source XML by calling the load method on self.relationships with the source Part object and its data.
13081	Adds a part to the package with optional content-type handling, using either default or override behavior for content-type assignment.
13082	Load a part into this package based on its relationship type by finding the appropriate class, creating an instance, loading data into it, and storing it in the package.
13083	Get the correct content type for a given name by first searching overrides by name, then falling back to defaults by extension, returning None if unmatched.
13084	Creates a ContentType instance from an XML element by parsing the element tag to determine the subclass, validating the class exists, and constructing the appropriate ContentType subclass with name and key attributes from the element.
13085	Parses a DSL string using a parser and visitor pattern, returning the parsed results as a dictionary with optional name spacing through a prefix.
13086	Builds a JWT token with encrypted payload using the provided secret key, including claims like expiration, view identifiers, parameters, and attributes, with AES-128-GCM encryption and direct key encryption.
13087	Assigns force field parameters to atoms in an AMPAL object by matching atom properties with force field dictionaries, issuing warnings for unparameterized atoms, and storing force field IDs as atom tags.
13088	Finds the maximum radius and npnp values from force field parameters. Iterates through all residues and their parameters, tracking the maximum values found in positions 1 and 4 of the parameter arrays. Returns a tuple containing (maximum radius, maximum npnp distance).
13089	Makes a dictionary containing PyAtomData for the force field parameters, where each atom's parameters are converted into PyAtomData structs. Returns a nested dictionary with residue and atom keys mapping to PyAtomData objects. Raises ForceFieldParameterError if parameters are badly formatted.
13090	Return a zipped package as a readable stream by creating a BytesIO stream, storing the package data into it, and seeking to the beginning of the stream.
13091	Return a generator yielding each of the segments whose names match name.
13092	Copy objects from one directory in an S3 bucket to another directory in the same bucket, preserving metadata while allowing optional overrides for surrogate key, cache control, and surrogate control headers. The function also supports creating a directory redirect object and handles proper path validation to prevent conflicts.
13093	Open an S3 Bucket resource using boto3, with optional AWS credentials provided via access key ID, secret access key, or AWS profile. Returns a Boto3 S3 Bucket instance.
13094	Uploads a local directory of files to an S3 bucket, synchronizing the bucket contents with the source directory by overwriting existing files and deleting extraneous ones. Optionally uploads directory redirect objects for Fastly CDN support, and sets metadata headers like surrogate keys and cache controls for CDN and browser caching. Supports AWS authentication via access keys, secret keys, or AWS profiles.
13095	Upload a file to an S3 bucket with optional metadata, ACL, and cache control settings. The function automatically detects content type and encoding using mimetypes, and supports additional S3 object attributes through extra arguments. Returns nothing.
13096	Uploads an object to an S3 bucket with specified parameters including content, metadata, ACL, cache control, and content type. The function handles None-type keyword arguments by filtering them out before passing to the boto3 Object.put() method. Returns None.
13097	List all file names in a given directory within the bucket, returning them relative to the bucket root.
13098	List all directory names that exist at the root of a given bucket directory, handling S3's flat structure by inferring directories from object paths and filtering out non-root directories.
13099	Creates an absolute directory path in the bucket for a given dirname relative to the bucket root prefix directory, handling special cases for '.' and '/' directories by converting them to empty strings and stripping trailing slashes from the final path.
13100	Delete a file from the bucket by filtering and deleting objects with the specified filename path.
13101	**Summary:**

The `ensure_login` function verifies that a valid authentication token exists in the Click context object. If no token is present, it checks for username and password credentials. If either is missing, it raises a usage error requesting authentication. If credentials are available, it obtains a token from the LTD Keeper server using the provided credentials and stores it in the context. If a token already exists, it logs this fact and proceeds without action. The function ensures the Click context has a valid token for subsequent operations.
13102	Method `loud` converts text to uppercase using a language-specific method. It takes an optional `lang` parameter (defaulting to 'englist') to determine which language method to call. If the specified language method exists, it calls that method and converts the result to uppercase. If the language method doesn't exist, it defaults to calling `english()` and converts that to uppercase. The method effectively speaks text loudly in the specified language by returning it in uppercase format.
13103	Delete all objects in an S3 bucket directory. Returns nothing, but raises `ltdconveyor.s3.S3Error` if the S3 API returns an error.
13104	Get project's home URL based on settings.PROJECT_HOME_NAMESPACE. Returns None if PROJECT_HOME_NAMESPACE is not defined in settings or if the URL is invalid.
13105	Decorator to silence template tags if 'PROJECT_HOME_NAMESPACE' is not defined in settings. If the namespace is not set, the decorated function returns an empty string; otherwise, it executes the original function with the provided label or a default home label.
13106	Returns a Bootstrap 3 breadcrumb element for the project's home page with customizable label. Generates a list item with a link to the project home URL if available, otherwise returns a static list item. The label defaults to 'Home' but can be overridden by passing a string to the template tag. Requires PROJECT_HOME_NAMESPACE to be defined in settings.
13107	Returns a Bootstrap 4 breadcrumb item for the project's home page with configurable label. Gets the home URL from `home_url()` and formats it as a breadcrumb li-element with appropriate classes and attributes. If no URL is found, returns a non-link breadcrumb item. Can be customized with a label parameter or uses default 'Home' text.
13108	Calculates the interaction energy between AMPAL objects by applying a force field, finding interactions between objects, and scoring those interactions to return a BUFFScore object with detailed interaction information.
13109	Calculates the internal energy of an AMPAL object by applying a force field and scoring interactions.

Parameters:
- ampal_obj: Any AMPAL object with a `get_atoms` method
- ff: Optional BuffForceField to use for scoring (defaults to BUDE force field)
- assign_ff: Boolean indicating whether to update force field assignment on the AMPAL object

Returns:
BUFFScore object containing interaction information and atom details
13110	Get lines sampled across all threads, sorted from most to least sampled.
13111	Get a temporary auth token from LTD Keeper by authenticating with username and password against the specified host API endpoint. Returns the token on successful authentication, raises KeeperError on failure.
13112	Uploads a new site build to LSST the Docs, with optional Travis CI event filtering and AWS S3 upload functionality.
13113	Detect if the upload should be skipped based on the ``TRAVIS_EVENT_TYPE`` environment variable.

Returns
-------
should_skip : `bool`
    True if the upload should be skipped based on the combination of
    ``TRAVIS_EVENT_TYPE`` and user settings.
13114	Method: purge_key

Summary: Instantly purges URLs with a specified surrogate key from Fastly caches using the Fastly API.

Parameters:
- surrogate_key (str): Surrogate key header value of objects to purge
- service_id (str): Fastly service ID
- api_key (str): Fastly API key

Returns: None

Raises:
- FastlyError: When there's an error with Fastly API usage

Notes: Uses Fastly's /service/{service}/purge/{key} endpoint. Requires Fastly service ID and API key for authentication. Logs the purge operation before execution. Returns HTTP 200 on success, raises FastlyError for any other status codes.
13115	Register a new build for a product on LSST the Docs by making a POST request to the LTD Keeper API endpoint for builds, using the provided host, authentication token, product name, and Git references. Returns the build information if successful, otherwise raises a KeeperError.
13116	Confirm a build upload is complete by sending a PATCH request to the build URL with an 'uploaded': True flag. Raises KeeperError if the API communication fails.
13117	Deeply updates a dictionary with values from another dictionary. For nested dictionaries, it recursively updates them. For lists, it concatenates them while avoiding duplicate elements. For other value types, it simply overwrites the existing values. Returns the updated dictionary.
13118	Initializes the ltd command-line client for LSST the Docs, setting up logging configuration and establishing connection parameters for the LTD Keeper API. Configures a stream handler with formatted timestamps and log levels, creates a logger named 'ltdconveyor', and stores authentication credentials and API connection information in the Click context object for use by subcommands.
13119	Edit a part from an OOXML Package without unzipping it. Parse command line arguments for the part path and optional XML reformatting, then call part_edit with the provided arguments.
13120	List the contents of a subdirectory of a zipfile.
13121	Recursively splits a file path into all its components, handling drive letters and returning a list suitable for os.path.join.
13122	Function that finds a file given a path to a part in a zip file, returning the file path and part path. It tries different combinations of file and part paths by splitting the input path and checking which combination corresponds to an existing file.
13123	Returns the preferred editor command by checking environment variables XML_EDITOR and EDITOR, falling back to 'notepad' on Windows or 'edit' on other platforms if neither is set.
13124	Process an astroid node stream to validate file header against configured pattern, adding a message if header is invalid or missing.
13125	Generates an HTML chart from various data types (pandas DataFrame, dictionary, list, or Altair Data object) and optionally writes it to a file. Takes parameters for data fields, chart configuration, dimensions, styling, and HTML wrapping content, then returns the generated HTML.
13126	Generate HTML from an Altair chart object, optionally writing to file or returning the HTML string.
13127	Serializes data into an Altair chart object from various input types (pandas DataFrame, dictionary, list, or Altair Data object) with configurable encoding fields, chart type, and display options.
13128	Patches Altair-generated JSON to the latest Vega Lite specification by adding the schema URL, setting top-level width and height properties from config, and removing the cell configuration.
13129	Generates HTML code that embeds a Vega-Lite visualization chart into a webpage using the provided JSON data. The method creates a div container with a unique ID based on the slug parameter, and includes a script that initializes the Vega-Lite library to render the chart within that container using the given JSON specification data.
13130	Converts a dictionary to a pandas dataframe with specified field names for x and y coordinates.
13131	Writes a chart's HTML content to a specified file path, creating directories if they don't exist.
13132	Returns the appropriate chart class instance based on the specified chart type string, or None if the chart type is not supported.
13133	Encodes x and y fields into Altair visualization components with optional time unit and scaling options. Returns a tuple of X and Y encoding objects configured with field types, time units, axes, and scales based on provided parameters.
13134	Function `ghuser_role` creates a GitHub user link role for documentation. It takes role parameters including name, rawtext, text, lineno, and inliner, then generates a reference node pointing to the GitHub user profile at 'https://www.github.com/' + text. The function returns a tuple containing the created node and an empty list of system messages.
13135	Returns the tarball URL from app.json repository field, or None if not present.
13136	Brings up a Heroku app by creating and building it from a tarball URL, with optional environment variables and app name specification.
13137	Brings down a Heroku app by deleting it, with optional force flag and confirmation prompt. If no app name is provided, it attempts to read from file and warns about deprecation. Displays progress and confirmation messages throughout the deletion process.
13138	Decorator that implements the Iterator interface for a class by adding `__iter__` and `__next__` methods. The decorator takes an attribute name as parameter and makes the class iterable over that attribute's contents. It adds an iterator index to track position and raises `StopIteration` when exhausted. The decorated class will have `__iter__` and `__next__` methods dynamically added at runtime. Note that static type checkers like MYPY may not recognize the iterator interface due to runtime method addition.
13139	Returns a random binary string of specified length by generating a random number and converting it to binary representation, padding with leading zeros if necessary.
13140	Returns a string representing a random IP address, optionally excluding specified valid Class A networks from the generation.
13141	Get a random date between two dates by generating a random timestamp within the range and converting it back to a date object.
13142	Returns a prepared `Session` instance with JSON headers and optional authorization token.
13143	Sends an API request to Heroku with the specified method and endpoint, handling JSON serialization and error handling for non-OK responses.
13144	Creates an app-setup build by sending a POST request to the /app-setups endpoint with tarball URL and optional environment variables and app name overrides. Returns the response data as a dictionary.
13145	Checks the status of an app-setups build and returns True if succeeded, False if pending, raises BuildError for other status codes.
13146	Generator that returns unique strings by appending incrementing numbers to a given prefix, using a cache to track the last used number for each prefix.
13147	Decorator that caches function results in a dictionary for reuse with the same arguments.
13148	Wraps a function to ensure it produces unique results by caching previously returned values and retrying on collisions. The wrapper generates a key based on the function name and arguments, then repeatedly calls the function until a unique result is obtained or maximum attempts are reached. Returns a decorated version of the input function that enforces uniqueness of outputs.
13149	Adds subcommands to the argument parser by iterating through registered subcommands, creating subparsers for each, and registering their arguments and nested subcommands.
13150	Returns the root argument parser object with help description and formatter class configured.
13151	Returns the command description, using either the explicitly set description, the first sentence of the docstring, or an empty string if neither is available.
13152	Returns the help text for the command, using either the explicitly set help text, the class's docstring, or an empty string if neither is available.
13153	Runs the command with parsed arguments, executing subcommands if specified and returning the status code (0 on success).
13154	Encodes a dataset with maximum value, handling one or two dimensional data. Strings are ignored during encoding. Supports various data types including strings, integers, floats, and iterables. Returns a formatted string with encoding type, series, and encoded data.
13155	Get all available athletes from GC API, cached to prevent unnecessary calls. Returns a pandas DataFrame containing athlete data.
13156	Get the last n activities by retrieving their filenames from the activity list and loading each activity data.
13157	Method `_request_activity_list` fetches and processes an athlete's activity data from a CSV response. It performs the following operations:
1. Makes a GET request to the athlete endpoint
2. Parses the CSV response using pandas with custom date parsing
3. Normalizes column names to lowercase and handles numeric prefixes
4. Adds boolean flags indicating data availability for heart rate, speed, power, and cadence
5. Adds an empty 'data' column
6. Returns the processed activity list DataFrame

The method is memory-cached due to its slow request execution time.
13158	Requests activity data for given athlete and filename, processes JSON response into a DataFrame with translated column names and time index, then returns columns in specified order.
13159	Construct athlete endpoint URL by combining host and quoted athlete name.
13160	Construct activity endpoint URL using host, athlete name, and filename with URL encoding for athlete name.
13161	Method `_get_request(self, endpoint)` performs a GET request to the GoldenCheetah REST API with the specified endpoint. It handles request exceptions by raising `GoldenCheetahNotAvailable`, validates responses for specific error cases (unknown athlete and file not found), and returns the response object for successful requests. The method processes error responses to extract athlete names and filenames for more specific exception handling.
13162	Creates a Heroku app-setup build from a tarball URL and returns the build ID and app name.
13163	Creates a URL pattern with API authentication wrapper. Takes a regex pattern and view (which can be a string path, list/tuple for include, or view object) and returns a URL pattern with api_auth applied to the view. If view is a string, it's imported as a full path. If view is a list/tuple, it's treated as an include pattern. For view objects, api_auth is directly applied.
13164	Returns a random title based on specified languages and genders, defaulting to English and both genders. Supports language filtering and gender-based title selection.
13165	Returns a random tuple representing person information with format (first_name, last_name, title, gender). Supports optional language and gender parameters for localization and gender filtering. Uses random selection from available languages and genders, with default English language and both male/female genders. The title is generated based on the selected language and gender.
13166	Returns a random last name, optionally filtered by specified languages. If no languages are provided, defaults to English. Uses internal `_get_lastnames` function to retrieve last names for each language and randomly selects one to return with title case formatting.
13167	Render the axes data into the dict data by processing each option and its values, formatting them into specific key-value pairs in the object.
13168	Update the chart's dataset with new data and optional series information, supporting two-dimensional and string data formats.
13169	Renders the chart by updating context and axes, encoding data, validating size and chart type, and applying additional formatting like lines, markers, and fills.
13170	Check if the given type is valid and return the proper type. Returns the original type if it's in TYPES, otherwise looks up the type in a dictionary mapping type names to their proper forms. Raises an assertion error for invalid chart types.
13171	Returns the rendered URL of the chart by rendering the chart first and then constructing the URL using the API URL and joined URL parts with spaces replaced by plus signs.
13172	Shows the chart URL in a webbrowser by opening it with webbrowser.open, passing through any additional arguments.
13173	Save the chart as a PNG file with the specified filename or default to the chart title.
13174	Method `urlopen` attempts to open a PNG file from a URL and returns a readable file pointer. It handles HTTP errors by printing "The server couldn't fulfill the request." and URL errors by printing "We failed to reach a server." If successful, it returns the file pointer from the HTTP request.
13175	Returns a PngImageFile instance of the chart by opening the chart data from a URL using PIL's Image module. Raises ImportError if PIL is not installed. Uses cStringIO or StringIO for handling the image data buffer.
13176	Writes PNG image data in chunks to the given file pointer by reading from a URL source.
13177	Returns the SHA1 hexdigest of sorted chart URL parameter parts for unique identification, useful for unittesting.
13178	Returns a random floating-point number with specified decimal places within given range.
13179	A decorator that assigns an entity name to a class based on its own name (converted to underscore lowercase format), making it available as a class method. The entity name is set to the lowercase, underscored version of the class name and is accessible via `entity_name` class method.
13180	Returns a dictionary combining unprotected and protected claims, where verified information takes precedence over self-asserted information when conflicts occur. If a superclass exists, it merges claims from both current and superclass, prioritizing superclass values. Otherwise, returns the current claims directly.
13181	Build a JWKS (JSON Web Key Set) from the signing keys of the self signer, returning a dictionary containing the serialized keys. If no signing keys are found, it attempts to retrieve keys associated with the issuer.
13182	Unpacks and verifies metadata statements from either a JSON dictionary or JWT format, with optional filtering by FO identifiers. Raises an error if neither input is provided.
13183	Creates a signed JWT from a MetadataStatement instance with optional receiver, issuer, lifetime, and signature algorithm parameters.
13184	Evaluates a compounded metadata statement and returns a list of LessOrEqual instances representing the resulting metadata statement for each Federation Operator (FO). Handles nested metadata statements by processing them from innermost to outermost, validates expiration dates, and constructs LessOrEqual objects with appropriate issuer and expiration information. Raises exceptions if evaluation fails.
13185	Remove MS paths that are marked to be used for another usage.

:param metadata: Metadata statement as dictionary
:param federation_usage: In which context this is expected to used.
:return: Filtered Metadata statement.
13186	Add signed metadata statements to a request by separating them into inline statements and URI references, then include them in the request under appropriate keys.
13187	Parses command line arguments for a concordance generator application, accepting an input file, optional output file (defaulting to stdout), and an optional word parameter for displaying specific words in the concordance.
13188	Adds logging configuration options to an ArgumentParser, including commands for setting log levels and output files for individual loggers, along with a help option for logging details.
13189	Apply logging options by setting log levels and replacing handlers with file handlers.
13190	Logs a message at 'verbose' level, which is between debug and info levels, by calling the log method with logging.VERBOSE level.
13191	Creates a letter frequency map for a given word, returning a dictionary with each letter as key and its count as value.
13192	Finds anagrams of a given word using available letters and wildcards, with optional filtering by starting and ending characters. Returns tuples of (word, score) for each valid anagram found.
13193	Returns the exception's name in an AMP Command friendly format by converting the class name to uppercase and separating camelCase words with underscores.
13194	Transforms Go Metrics API timeseries data into a list of values for a specified time window. Takes a timeseries dictionary, start timestamp (and optional end timestamp) in microseconds, and returns a list of y-values from the specified window period. Data inclusion begins when start timestamp is encountered and continues until end timestamp is reached (if specified).
13195	Returns the most recent non-zero value from a timeseries data structure, or 0 if no non-zero values exist or the data is empty.
13196	Validate a 1-based page number by converting it to integer and checking if it's at least 1. Raises PageNotAnInteger if conversion fails, EmptyPage if number is less than 1.
13197	Get a specific page from an iterator with validation for page numbers, handling invalid inputs by defaulting to the first page, and returning a NoCountPage object with the requested items, page number, page size, and next page indicator.
13198	Function `chmod` changes file permissions using the `chmod` command. If `recursive` is True, it applies the changes recursively to directories and their contents. Otherwise, it only changes the permissions of the specified path directly. The function constructs the appropriate `chmod` command with the given mode and path, then executes it using the `sh` module and returns the result.
13199	Creates and returns an InternalSigningService instance by initializing a key jar from configuration parameters and using the provided entity identifier.
13200	Creates a SigningService instance based on the provided configuration and entity ID. Initializes a key jar from the configuration, then creates either an InternalSigningService or WebSigningServiceClient depending on the configuration type ('internal' or 'web'). Raises ValueError for unknown signer types.
13201	Creates a signed JWT using the specified parameters, selecting an appropriate signing algorithm if not provided, and returns the packed signed JWT. Raises NoSigningKeys if no signing keys are available.
13202	Creates a metadata statement signing request by sending a POST request to a signing service and returns the parsed response containing 'sms' and 'loc' keys.
13203	Updates a metadata statement using PUT request and returns parsed response with 'sms' and 'loc' keys.
13204	Updates signature by fetching a new metadata statement from the specified location and parsing the response.
13205	Yields bundle contents from a dictionary, returning either file paths (as strings) or bundle objects. Handles both list and dict input types for contents, converting string contents to tuples for consistent processing.
13206	Create a bundle instance from a dictionary of configuration options, including filters, output settings, debug flags, extra data, config options, and dependencies, then apply auto-filtering to the bundle.
13207	Returns a list of URLs needed to include all assets of the specified asset_type by combining dependent assets and self assets.
13208	Return HTML tags for URLs of the specified asset type by collecting tags from dependencies and rendering asset HTML tags for the current object.
13209	Return all HTML tags for all asset types by iterating through each asset type and concatenating their HTML tags with newlines.
13210	The `protocolise` function checks if a given URL has an associated protocol (like http or https). If no protocol is found, it prepends 'http://' to the URL and returns the protocolized URL. The function uses regex to detect common protocol patterns and the `urlparse` module to parse the URL structure.
13211	**Summary:**

The `find_links` function extracts all href destinations from links on a given URL. It first ensures the URL has a proper protocol, fetches the page content, parses the HTML, and collects all href attributes from anchor tags. It then normalizes relative URLs by prepending the base URL to them. The function returns a list of absolute URLs found on the page. Note that it may incorrectly handle certain cases, such as links from `bbc.co.uk/index.html`.
13212	**Summary:**

The `_connected` function handles the connection to an AMP server by starting a local listener. It creates a `ProxyingFactory` with the AMP client and a "hello" protocol, then initiates local listening using the provided `listeningEndpoint`, returning the result of the listening operation.
13213	Get modules by project_abspath and packages_scan, traverse all files under packages_scan folder and return all module names.
13214	Import the customer's service modules and log the import process, raising an ImportModulesError if any module fails to import.
13215	Converts a date string in various formats to a normalized and validated date range, returning a list with two elements (lower and upper date boundaries). Handles inputs like year-only, year-month, year-month-day, and date ranges with optional start/end limits.
13216	Selects specific fields from a document using dotted notation support and returns a new document with only the specified fields.
13217	Maps datetime fields in a document to strftime string representations using a provided format.
13218	Prints cursor data in CSV or JSON format based on the instance's format setting, returning the number of records processed.
13219	Method: output
Summary: Outputs all fields using the specified fieldNames list, with optional date field mapping and time formatting. The method delegates the actual printing to printCursor and returns the count of printed records.
13220	Returns tasks that must be performed in correct order based on dependency graph, using topological sorting.
13221	Add or create default departments for a given project by iterating through DEFAULT_DEPARTMENTS and creating Department objects with associated project relationships.
13222	Add or create default assettypes for a given project by iterating through predefined assettype definitions, retrieving or creating each assettype with its description, associating it with the project, and saving the changes.
13223	Add or create default sequences (global and research & development) for a given project if they don't already exist.
13224	Add a rnd shot for every user in the project, creating the shot if it doesn't exist and assigning all tasks in that shot to the user.
13225	Post-save handler for Project model that creates user-specific shots and default project elements. On project creation, it generates all default departments, asset types, and sequences. On existing project updates, it creates user random shots.
13226	Post-save handler that creates a global shot whenever a new sequence is saved. Skips creation if the sequence is being updated (not newly created) or if the sequence name matches RNDSEQ_NAME. The global shot is created with a descriptive name and links to the project and sequence that triggered the creation.
13227	Create all tasks for a given shot or asset by iterating through related departments and initializing tasks for each one.
13228	Method `pre_connect(self, peer)` ensures an open connection to a given peer by checking existing connections or establishing a new one. It returns a deferred that fires with the actual peer ID, which may differ from the input if the peer identifies itself differently (e.g., IP vs hostname). If connection already exists, it returns immediately with the peer ID; otherwise, it connects and returns the resolved peer ID.
13229	Sends a packet to a specified peer, establishing a connection if necessary. Returns a deferred that fires when the send operation completes.
13230	Reads a configuration value by section and key, returning it in the specified type. Raises ConfigError if section or key is not found.
13231	Summary: Decorator function that registers Nova notification event handlers, storing them in either a wildcard or regular event processing dictionary based on whether the event type contains wildcards.
13232	Summary: The `cinder` function is a decorator factory that registers functions to process Cinder notifications based on event types. It validates event types using `check_event_type`, then stores the decorated function in either `cinder_customer_process` (for exact matches) or `cinder_customer_process_wildcard` (for patterns containing wildcards). The decorator logs the registration and returns a wrapped version of the original function.
13233	Adds a function to process neutron notifications with optional wildcard event type support.
13234	The `glance` function is a decorator factory that registers functions to process Glance notification events. It takes event types as arguments and stores the decorated functions in either `glance_customer_process` (for exact event matches) or `glance_customer_process_wildcard` (for pattern matches with wildcards). The decorator validates event types using `check_event_type` and compiles wildcard patterns using `pre_compile`. It logs the registration of each function and returns a wrapper that preserves the original function's metadata.
13235	This function is a decorator that registers functions to process Swift notifications based on event types. It validates the event type using `check_event_type`, then stores the decorated function in either `swift_customer_process` (for exact matches) or `swift_customer_process_wildcard` (for patterns containing wildcards) dictionaries. The decorator also logs the registration and returns a wrapper function that maintains the original function's metadata and behavior.
13236	A Swift annotation decorator for processing Keystone notifications that registers functions to handle specific event types. It supports wildcard patterns in event types by compiling them into regular expressions and storing them in either a wildcard processing dictionary or a regular processing dictionary based on whether the event type contains wildcard characters. The decorator logs the registration of each function and returns a wrapped version of the original function.
13237	**Summary:**

The `heat` function is a decorator factory that registers heat notification processing functions. It takes event types as arguments and registers the decorated function to handle specific heat events. If the event type contains a wildcard "*", it stores the function in `heat_customer_process_wildcard` with a compiled pattern; otherwise, it stores it in `heat_customer_process` using the event type as key. The decorator logs the registration and returns a wrapped version of the original function.

**Parameters:**
- `*arg`: Event types for heat notifications

**Returns:**
- A decorator that registers the decorated function to process specified heat events

**Behavior:**
- Validates event types using `check_event_type`
- Compiles wildcard patterns using `pre_compile`
- Stores functions in appropriate dictionaries based on event type pattern
- Logs registration information
- Wraps the original function with functools.wraps
13238	Adds a factory to the collection and starts it. Called when a remote client wants to connect to a factory. The factory's doStart method is invoked to initialize it.
13239	Removes a factory by identifier, calls its doStop method, and returns the removed factory.
13240	Attempts to connect using a given factory by finding the factory, building a protocol, creating a transport, and storing the protocol with a unique identifier. Returns the connection identifier. Raises NoSuchFactory if factory doesn't exist, or ConnectionRefused if protocol building fails.
13241	Receives data for a given connection protocol and returns an empty dictionary. Raises NoSuchConnection if the connection doesn't exist.
13242	Disconnects the given protocol by removing it from _protocols dictionary, setting its transport to None, and returning an empty dictionary.
13243	Summary: Executes a remote command through the factory's AMP connection with optional keyword arguments.
13244	Creates a multiplexed stream connection to an AMP server by calling the Connect command with the remote factory identifier, then handles the connection callback when established.
13245	Stores connection reference, registers protocol with factory, sends buffered data if available, then clears the buffer.
13246	Method: dataReceived(self, data)
Summary: Handles incoming data from the local connection. If the multiplexed connection is established, it sends the data over that connection. Otherwise, it buffers the data until the connection is ready. Logs the amount of data received and the action taken.
13247	Sends data over the wire using a remote call with error handling.
13248	When connection is lost, removes the AMP connection from the factory's protocols dictionary if it exists.
13249	Method `getLocalProtocol` attempts to retrieve a local protocol using a connection identifier by iterating through local factories. It returns the protocol if found in any factory's protocols dictionary, otherwise raises `NoSuchConnection` exception.
13250	Method `remoteDataReceived` handles incoming data from a remote connection by finding the corresponding local protocol and forwarding the data to it. Returns an empty dictionary.
13251	Disconnects the specified connection by closing its transport protocol. Returns an empty dictionary.
13252	Centers a string within a specified width by padding it with a fill character on both sides. If no width is specified, uses the terminal width minus 1. Handles odd-length padding by adding extra padding to the right side. Returns the centered string.
13253	Aligns the given string with a right-aligned clock time, calculating appropriate padding based on terminal width.
13254	Takes the parts of a semantic version number and returns a nicely formatted string.
13255	Identifies the unit framework (astropy.units, pint, or quantities) that a target unit belongs to by checking its type and attributes against each framework's specific indicators. Returns the corresponding framework constant (ASTROPY, PINT, or QUANTITIES) if a match is found, otherwise raises a TraitError.
13256	Check that a value has physical type consistent with user-specified units for different unit frameworks (Astropy, Pint, Quantities).

Parameters:
- name (str): The name of the value to check (used for error messages)
- value (numpy.ndarray or subclass): The value to check
- target_unit (unit): The unit that the value should be convertible to
- unit_framework (str): The unit framework to use

Validates unit convertability without performing conversion, raising TraitError for inconsistent units.
13257	This function applies standard padding to byte data to make its length a multiple of the specified block size. It supports three padding styles: 'pkcs7' (default), 'x923', and 'iso7816'. The function calculates the required padding length and appends the appropriate padding bytes according to the chosen style. For 'pkcs7', it repeats the padding length byte; for 'x923', it uses null bytes followed by the padding length; for 'iso7816', it uses 0x80 followed by null bytes.
13258	Remove standard padding from data using specified padding style (pkcs7, iso7816, or x923). Validates padding integrity and raises ValueError for incorrect padding. Returns data with padding removed.
13259	Method: self_sign

Summary: Signs an extended request by creating signed metadata statements. The method handles two cases: when no metadata statement URIs or statements exist in the request (creates a new signed statement) or when they do exist (signs each existing statement individually). It returns an updated request with the signed metadata statements included.

Parameters:
- req: Request object (MetadataStatement instance) to be signed
- receiver: Intended user of the metadata statement (default: '')
- aud: List of intended receivers (default: None)

Returns: Updated request arguments with added metadata statements signed by the entity

Side effects: Modifies the input request object by adding signed metadata statements to it.
13260	Gathers metadata statements for a given context and returns them as a dictionary. If no context is provided, uses the instance's context. Handles both metadata statement URIs and actual metadata statements, organizing them by type in the returned dictionary. Raises ValueError if an invalid context is specified.
13261	Function `pretty_print` prints anagram results sorted by score or length. It takes a base word, an anagrams generator, and a boolean flag. If `by_length` is True, output is sorted by word length; otherwise by score. Results are displayed with appropriate labeling and format, including a check for valid Scrabble words.
13262	Parses command line arguments for the nagaram anagram finder program, returning a tuple containing the word list, SOWPODS flag, length sorting flag, starting characters filter, and ending characters filter. Raises SystemExit for help, version, or invalid arguments.
13263	Main command line entry point that processes word anagrams based on parsed arguments, printing results either grouped by length or in original order.
13264	This method processes incoming data packets by:
1. Adding received data to an unprocessed data queue
2. Attempting to extract complete packets from the queue based on header information
3. For each complete packet found:
   - Extracting packet length and type from header
   - Verifying sufficient data exists for the complete packet
   - Removing header data and extracting packet payload
   - Dispatching to appropriate handler methods based on packet type
4. Returning early if insufficient data exists to process complete packets

The method handles both registered and unregistered packet types through dedicated callback methods.
13265	Method called when a packet with an unregistered type is received. Logs the error message including the typekey and class name, then closes the connection.
13266	Creates a callable stub for invoking remote functions via anycall URLs, returning a deferred object. Raises ValueError for invalid URLs and asserts RPC system is open.
13267	Method `_ping` is called remotely to check if a call made to this node is still in progress. It verifies if the specified peer ID and call ID combination exists in the mapping of remote to local calls. If the combination doesn't exist, it logs a warning indicating there's no remote call with the specified ID from the given peer, suggesting the timing might be unfortunate.
13268	Get command regex string and completer dict for the given command group. Returns a tuple containing the regex pattern and a dictionary of completers for command options.
13269	Method `fromStringProto` defers to `amp.AmpList.fromStringProto` to process the input string with the given protocol, then extracts and returns the single element from the resulting list.
13270	Wraps the input object in a list and delegates to `amp.AmpList.toStringProto` to convert it to a protocol string representation.
13271	Verifies that a MetadataStatement instance adheres to specified restrictions, checking for mutually exclusive signing keys and metadata statements, and validates JWKS format. Returns True if verification passes, raises VerificationError otherwise.
13272	Parse HTTP response from JWKS or signed JWKS endpoint, handling both JSON and JWT content types. Returns parsed JSON data or None if parsing fails.
13273	Performs a pg_dump backup by executing the pg_dump command with specified parameters. It supports custom username, password, host, port, and dump format, and returns the command's status code and output.
13274	Returns a list of all database names on the server by querying the pg_database system table through a database connection.
13275	Returns a dictionary mapping relative file paths to their MD5 hashes for all files under the specified path.
13276	Syncs a local directory with an S3 bucket by comparing file hashes and uploading changed files. Does not delete files from S3 that are no longer in the local directory.
13277	A decorator factory that creates a decorator to check if required services are present in the user's session tokens. If any required service is missing, it redirects to a denied page; otherwise, it executes the decorated function.
13278	Displays the login form and handles the login action, including authentication, session management, and redirection.
13279	Builds a CLI dynamically by recursively iterating through package modules and registering commands or groups with the CLI based on the package structure.
13280	Return an already closed read-only instance of Fridge. Arguments are the same as for the constructor.
13281	Force reloads data from file, discarding in-memory dictionary. Called automatically by constructor.
13282	Create a signed JWT containing a JWKS, where the JWT is signed by one of the keys in the JWKS. The function takes a KeyJar instance, issuer, optional key ID, and lifetime as parameters, exports the JWKS from the keyjar, and returns a signed JWT containing the JWKS payload.
13283	Creates a signed JWT metadata statement using signing keys from a keyjar, with the signing keys either extracted from the request or fetched from the keyjar if missing.
13284	A decorator that wraps a unittest function with a library, ensuring the function is only called once, and registers the wrapped function in a global SINGLES list.
13285	```python
def descovery(testdir):
    """Discover and load greencard tests."""
    from os.path import join, exists, isdir, splitext, basename, sep
    if not testdir or not exists(testdir) or not isdir(testdir):
        return None

    from os import walk
    import fnmatch
    import imp

    for root, _, filenames in walk(testdir):
        for filename in fnmatch.filter(filenames, '*.py'):
            path = join(root, filename)
            modulepath = splitext(root)[0].replace(sep, '.')
            imp.load_source(modulepath, path)
```

**Summary:** The `descovery` function discovers and loads Python test modules from a specified directory. It validates the input directory, walks through its contents, finds all `.py` files using fnmatch pattern filtering, and dynamically loads each Python file as a module using `imp.load_source`. The function returns `None` if the test directory is invalid or doesn't exist.
13286	Command line entry point for a test runner that executes tests on each card in a librarian library, taking library database and test directory as arguments.
13287	Returns the Scrabble score of a letter by looking up its value in a score map. Raises TypeError for invalid characters.
13288	Function: word_score
Summary: Calculates the Scrabble score for a given word based on letter values, considering available letters and blanks. Returns the total score including bonus points for using all rack tiles.
Parameters: 
- word (string): The word to score
- input_letters (string): Available letters on the rack
- questions (integer): Number of blanks/tiles already on the board (default: 0)
Returns: Integer Scrabble score amount for the word
13289	Opens a word list file (TWL or SOWPODS) and yields words that match optional start and end character filters. Returns words one at a time from either 178,691 words (TWL) or 267,751 words (SOWPODS), with filtering applied based on start and/or end string parameters.
13290	Checks if a Scrabble word can be played with a full tile bag, accounting for blank tiles. Returns True if valid, False otherwise.
13291	This function takes command line arguments, processes a query by removing question marks, performs a search using SOSearch with the query and tags, retrieves the best answer's code from the first search result, and prints it. If no result is found or if an exception occurs, it prints a helpful message suggesting to add tags.
13292	Function to parse command line arguments for a StackOverflow code answer tool, taking a query and optional tags as input.
13293	Handle a JSON AMP dialect request by parsing JSON, converting dialect-specific values, finding and calling the appropriate responder function, and serializing the result.
13294	Gets the command class and matching responder function for the given command name by extracting them from a responder's closure contents using a locator.
13295	Parses request values according to JSON AMP dialect, handling special cases for ExposedResponderLocator and using decoders for other types.
13296	Run the responder function and handle its response or failure by adding an identifier to successful responses or serializing errors using the command's error handling.
13297	Writes a response object to transport by serializing it to JSON format.
13298	Method: connectionLost
Parameters: self, reason
Returns: basic.NetstringReceiver.connectionLost(self, reason)
Description: Stops the remote box receiver from receiving boxes when a connection is lost, then calls the parent class's connectionLost method to handle the standard cleanup procedures.
13299	Builds a bridge and associates it with an AMP protocol instance by creating a protocol from the factory and wrapping it with JSONAMPDialectReceiver.
13300	Converts a JSON Web Key Set (JWKS) string or dictionary to a KeyJar instance by parsing the JWKS and importing it into a new KeyJar object.
13301	Loads a bundle from an unsigned JSON document or dictionary, importing JWKS data for each issuer into a KeyJar and storing it in the bundle.
13302	This function processes Nova notifications by first checking for exact matches in customer processes, then falling back to wildcard pattern matching, and finally using a default process if no match is found. It acknowledges the message after processing.
13303	This function processes Cinder notifications by first checking for exact matches in customer_process, then falling back to wildcard pattern matching in customer_process_wildcard, and finally using a default process if no matches are found. It acknowledges the message after processing.
13304	This function handles neutron notifications by first looking up the event type in a customer process dictionary. If not found, it searches through wildcard patterns in another dictionary. If still not found, it falls back to a default process. The function acknowledges the message after processing.
13305	This function processes glance notifications by first checking for a direct match in customer_process, then trying wildcard patterns in customer_process_wildcard, and finally falling back to a default process if no match is found. It acknowledges the message after processing.
13306	This function processes Swift notifications by first looking up the event type in a direct process mapping. If no direct match is found, it searches through wildcard patterns in a secondary mapping. If neither matching approach finds a process, it falls back to a default process. Finally, it acknowledges the message.
13307	This function processes Keystone notifications by first looking up the event type in a customer process dictionary. If not found, it searches through wildcard patterns in another dictionary. If still no match, it falls back to a default process. The function acknowledges the message after processing.
13308	This function handles heat notifications by first checking for a direct match in customer_process, then falling back to wildcard matching in customer_process_wildcard, and finally using a default process if no match is found. It processes the notification based on the event type and acknowledges the message.
13309	Serve the application using wsgiref simple server on port 8000, or a provided custom server callable. If no server is provided, creates a default server that listens on 0.0.0.0:8000 and starts serving the application. Ensures the server socket is closed after serving.
13310	Print 'msg' to stdout, and optionally log it at info level using the provided log object.
13311	Print 'msg' to stderr, and optionally log it at error level using the provided log object.
13312	A class decorator that registers Command classes in the default set by storing them in Command._all_commands dictionary with their name as key, raising ValueError if command already exists.
13313	A class decorator that registers Command classes by their name and aliases in a registry, raising an error if a command already exists.
13314	Method `toString` checks if all constraints are satisfied with the given value and if so, delegates to the composed AMP argument's `toString` method.
13315	Converts a string to a value using the base argument and validates it against all constraints.
13316	Merges a dictionary of completers into an existing completer dictionary, handling duplicate keys by either raising an error or making them unique through UUID-based renaming when a regex pattern is provided.
13317	Start ternya work by importing customer service modules, initializing openstack mq, and maintaining an auto-reconnecting ternya connection.
13318	Initializes connection and consumer with OpenStack MQ, returns the connection object.
13319	Initializes and imports customer service modules based on configuration. Raises ValueError if no configuration is loaded. Uses ServiceModules class to handle the module importing process.
13320	Initializes OpenStack Nova message queue consumer by:
1. Checking if Nova notification listening is enabled
2. Creating multiple consumers based on configuration
3. Returning early if notifications are disabled
4. Logging debug information about the initialization status
13321	Initializes OpenStack Cinder message queue consumer by:
1. Checking if Cinder notification listening is enabled
2. Creating specified number of consumers if enabled
3. Logging the initialization status

Returns early if notification listening is disabled.
13322	Initializes OpenStack neutron message queue consumer by:
1. Checking if neutron notification listening is enabled
2. Creating multiple consumers based on configuration
3. Returning early if notifications are disabled
4. Logging debug information about the initialization status
13323	Initializes OpenStack Glance message queue consumer by:
1. Checking if glance notification listening is enabled
2. Creating multiple consumers based on configuration
3. Returning early if notifications are disabled
4. Logging debug information about the initialization status
13324	Initializes OpenStack Heat message queue consumer by:
1. Checking if heat notification listening is enabled
2. Creating specified number of consumers for heat notifications
3. Returning early if notifications are disabled

Parameters:
- mq: MQ class instance for message queue operations

Creates consumers using ProcessFactory for Openstack.Heat component with configured exchange and queue settings.
13325	Check if customer has enabled notification for a given OpenStack component.

**Parameters:**
- `openstack_component`: OpenStack component type to check

**Returns:** 
Boolean value indicating whether notification is enabled for the specified component

**Mapping:**
- Nova  listen_nova_notification
- Cinder  listen_cinder_notification  
- Neutron  listen_neutron_notification
- Glance  listen_glance_notification
- Swift  listen_swift_notification
- Keystone  listen_keystone_notification
- Heat  listen_heat_notification
13326	Get music information from Baidu Music API by song ID(s), returning a list of dictionaries containing song details like name, singer, lyrics link, audio link, and file size.
13327	Downloads a music file using multiple threads, splitting the file into parts and combining them after download.
13328	Execute a code object with optional global and local namespaces, handling both regular execution and generator cases with yield statements.
13329	Summary: Loads a name from either the globals dictionary or builtins, checking both locations in order and returning the found value.
13330	Implements the CALL_FUNCTION operation that executes a callable with given arguments, handling special built-in functions and managing the call stack.
13331	Performs a MySQL database dump backup using mysqldump command. Creates a backup file of the specified database with optional connection parameters and returns the command's status code and output.
13332	Renders ditaa code into a PNG output file by generating unique filenames, writing the code to an input file, executing the ditaa command with specified arguments, and handling errors appropriately. Returns the relative and full paths to the generated PNG file.
13333	Application._atexit() is invoked in the 'finally' block of Application.run and executes the registered atexit function if one exists.
13334	Runs the application's main method with given arguments, handles various exceptions including keyboard interrupt and system exit, logs appropriate messages, performs cleanup operations in finally block, and exits with the appropriate return code.
13335	A context manager function that temporarily changes the current working directory to the specified path and automatically returns to the original directory when exiting the context.
13336	Copies a directory tree from source to destination, merging files rather than requiring the destination to not exist. Supports symbolic links and preserves file metadata. If the destination directory doesn't exist, it's created. Handles errors gracefully by collecting them and raising a single Error exception at the end if any occurred.
13337	Function that provides debugging support by calling post_mortem if an exception is active, otherwise calling set_trace. Uses ipdb if available, otherwise falls back to pdb.
13338	Returns the last modification time of a file in nanoseconds, with retry logic in case the file is being written.
13339	Check if a file item has been modified since last observation by comparing modification times.

**Parameters:**
- item: A key representing a file

**Returns:**
- True if file has been modified or is new, False if unchanged

**Raises:**
- KeyError: If file cannot be accessed

**Behavior:**
- Tracks modification times in self.fmtime dictionary
- Returns True for new files or when modification time increases
- Updates stored modification time when changes are detected
- Logs error and raises KeyError for inaccessible files
13340	Method `sync` builds a local cache by iterating through directory contents, checking file modification times, and updating the database with file information when changes are detected or new files are encountered.
13341	Clears the entire database by resetting local cache and removing all files from the database directory.
13342	Method: scrape(ctx, url)
Summary: Retrieves and processes events from an RSS feed, normalizing the data and preparing it for storage. The method loads feed data from a URL, extracts relevant event information such as title, timestamp, location, and description, and performs data normalization including timezone handling and slug generation. The implementation is specifically tailored for the konfery.cz RSS feed format.
13343	Download an image from the URL, save it to the cache directory, and return the local file path.
13344	Method to check if an image has changed since last download by making a HEAD request to compare Last-Modified headers. Returns False if unchanged, True if modified or no modification information available.
13345	A function that compiles a template tag by parsing arguments and keyword arguments from a token, validating them against the tag's parameter signature, and returning an instance of the specified node class with the parsed values. It handles context arguments, keyword arguments, variable arguments, and keyword arguments, while performing validation to ensure correct usage of the template tag.
13346	Find the stack frame of the caller to determine the source file name, line number, and function name, optionally including stack information.
13347	Returns the defining component (C_C) where the given PE_PE is defined. Traverses up the model hierarchy through EP_PKG references if needed, or directly navigates to the component via C_C[8003]. Returns None if the input is None or no defining component can be found.
13348	Parse command line options and launch the prebuilder. The function sets up an option parser with verbosity and output path options, parses the command line arguments, configures logging based on verbosity level, loads a metamodel from the specified paths, runs prebuilding on the model, and persists the instances to the output path.
13349	Find a symbol in the symbol table by name, kind, or both. Returns the first matching symbol handle or None if not found.
13350	Determine if a PE_PE is contained within a EP_PKG or a C_C by recursively checking the containment relationship between the given PE_PE and the root element. Returns True if the PE_PE is contained in the root, False otherwise.
13351	Check if a PE_PE is globally defined (not inside a C_C). Returns True if globally defined, False otherwise. The function recursively traverses up the containment hierarchy until finding a global PE_PE or determining it's inside a C_C.
13352	Converts a BridgePoint data type to a pyxtuml meta model type by checking core type ranges, event data types, and user-defined types recursively.
13353	Returns two lists of attribute names that relate two classes in an association, where the first list contains attributes from one class and the second list contains attributes from the related class.
13354	Create a named tuple from a BridgePoint enumeration by extracting enumeration values, handling Python keywords by appending underscores, and returning a named tuple with the enumeration values as fields.
13355	Creates a Python function from a BridgePoint bridge by generating a lambda function that executes the bridge's action semantics with the given parameters.
13356	Create a python object from a BridgePoint external entity with bridges realized as python member functions. Returns a namedtuple with bridge functions as members.
13357	Creates a Python function from a BridgePoint function by wrapping the action semantics with interpretation logic.
13358	Create a Python value from a BridgePoint constant by converting the constant's literal string value to the appropriate Python type (boolean, integer, real, or string) based on the constant's data type.
13359	Creates a Python function that interprets BridgePoint class operation actions, returning either an instance method or class method based on whether the operation is instance-based.
13360	Creates a Python property that interprets the action of a BridgePoint derived attribute by retrieving the attribute and object information, constructing a label, and creating a property with a partial function that runs the derived attribute interpretation.
13361	Create a pyxtuml class from a BridgePoint class, including its attributes, unique identifiers, operations, and derived attributes. Skip derived attributes and unsupported types based on the derived_attributes flag.
13362	Create a pyxtuml association from a simple association in BridgePoint by retrieving relationship and object information, determining source and target attributes, and defining the association with appropriate properties including multiplicity, conditional constraints, and phrases.
13363	Creates pyxtuml associations from a linked association in BridgePoint by defining associations between source and target objects based on relationship attributes and phrases.
13364	Create a pyxtuml association from a R_REL in ooaofooa by dispatching to appropriate handler function based on the relationship type.
13365	Create a pyxtuml meta model from a BridgePoint model, optionally restricted to a specific component. Process classes, associations, functions, enums, constants, and external entities from the BridgePoint model and populate the target domain with corresponding pyxtuml constructs.
13366	Calls a function and sends results to the collector, supporting return, yield, and exception handling with proper channel management and reply socket handling.
13367	Sends an ACCEPT reply through the specified socket with optional info and channel parameters.
13368	Sends a REJECT reply over the specified socket with optional information, call ID, and topics.
13369	Sends a RAISE reply message containing exception information including exception type, message, filename, and line number. If the exception is a RemoteException, it extracts the original exception type. It also includes exception state if available. The reply is sent through the provided reply socket with the specified channel.
13370	Allocates a call ID, prepares and sends a call message through a socket, and establishes a response listener with optional retry logic. Returns a future-like object for handling the response.
13371	Waits for a call to be accepted by workers and collects results, handling rejections and retries within a specified timeout. Returns collected results or raises Rejected or WorkerNotFound exceptions if no results are obtained.
13372	This method dispatches replies to their appropriate result queues based on the reply method and call_id. For ACK messages, it handles ACCEPT and REJECT cases by either creating a RemoteResult object and adding it to the results dictionary, or putting None in the result queue respectively. For non-ACK messages, it retrieves the existing result and sets its reply data. The method manages the mapping between call_id and task_id to proper result queues and handles KeyError exceptions when dealing with unprepared calls.
13373	Function to determine the type name of a serialized value by matching it against patterns for boolean, real, integer, string, and unique ID types.
13374	Deserialize a value of some type, handling BOOLEAN, INTEGER, REAL, STRING, and UNIQUE_ID types with appropriate conversion logic.
13375	returns token with updated end position for left parenthesis
13376	Returns a token with updated end position for closing parenthesis.
13377	Retrieve a feature collection by content_id, optionally filtering by feature names. Returns None if not found, raises exceptions for other errors.
13378	Returns an iterable of feature collections for multiple content IDs. Efficiently retrieves feature collections corresponding to a list of content IDs, yielding tuples of (content_id, FC) where FC is None if not found. Supports optional feature name filtering with wildcards. Uses mget API call for efficient batch retrieval.
13379	Adds multiple feature collections to the store efficiently using bulk indexing, with optional indexing of specified features and full-text features, and stores them with generated IDs.
13380	Deletes the feature collection with the given content_id. If the collection doesn't exist, the operation is ignored (no-op).
13381	Deletes all feature collections by removing their mapping from the Elasticsearch index, while preserving the index itself. Handles the case where the mapping may already be deleted by catching TransportError exceptions.
13382	Deletes the underlying Elasticsearch index if it exists, using the connection object's indices.delete method. Only intended for advanced users as it destroys the entire index which may be shared by multiple ElasticStore instances.
13383	Scan for FCs in the given id ranges, yielding content_id and FC pairs. Supports bounded/unbounded key ranges and optional feature name filtering with wildcards.
13384	Scan for content IDs within specified ID ranges, yielding only the IDs (not full content) from the store. Supports bounded or unbounded ranges using empty tuples, and allows filtering by feature names (though features are not returned due to feature_names=False). If no ranges are specified, returns all content IDs in the store.
13385	Scan for FCs with a given prefix and yield content_id and FC pairs.
13386	Scan for content IDs with a given prefix and yield them.
13387	Fulltext search method that yields triples of (score, identifier, FC) from search results. Supports optional feature name filtering, order preservation, and wildcard feature retrieval. When preserve_order is False, scores are set to 0.0 and results are unordered for better performance.
13388	Fulltext search for identifiers that yields triples of (score, identifier) from search results. If preserve_order is True, results are scored and ordered by score with potential performance decrease. Otherwise, score is always 0.0 and results are unordered. Uses internal _fulltext_scan method with specified parameters.
13389	Keyword scan for feature collections that searches for FCs with terms in the query's indexed fields. Returns an iterable of (content_id, FC) tuples.
13390	Keyword scan for IDs using query_id or query_fc, yielding content_ids from matching records.
13391	Low-level keyword index scan for retrieving content identifiers based on feature name and value. Uses Elasticsearch scanning to find documents with matching feature values in indexed features, returning an iterable of content IDs.
13392	Maps feature names to ES's "_source" field, returning True if feature_names is None, the boolean value if feature_names is boolean, otherwise returns a mapped list with 'fc.' prefix added to each feature name.
13393	Creates Elasticsearch filters for key ranges used in scanning, handling string to eid conversion and inclusive range boundaries.
13394	Create an Elasticsearch index with specified shards and replicas, handling the case where the index already exists.
13395	Creates field type mappings for an index with specific configurations including dynamic templates, disabled _all field, and not_analyzed _id field, then waits for cluster health to become yellow status.
13396	Retrieve field mappings for debugging, including indexed features with 'not_analyzed' index type and fulltext indexed features with 'analyzed' index type.
13397	Retrieve the field types from Elasticsearch mapping for debugging purposes. Returns the properties mapping for the specified index and document type.
13398	Creates a disjunction for keyword scan queries by generating term-based search expressions for each feature name in the index, using the provided query feature collection and field name. Returns a list of disjunctive search terms.
13399	Take a feature collection in dict form and count its size in bytes.
13400	Count bytes of all feature collections whose key satisfies one of the predicates in `filter_preds`, with byte counts binned by filter predicate.
13401	Constructs a nicely formatted string representation of a feature collection (FC). Iterates through sorted feature items, and for StringCounter features, formats them with counts. Returns a newline-separated string with feature names and their values.
13402	Process command line options using docopt, handling both default ("here") and user-specified configurations for finding known secrets.
13403	Escapes the given error message and wraps it in a span element with the CSS class "error-message".
13404	Creates a human-readable representation of a link on the 'TO'-side by formatting attribute values according to the link's key mapping.
13405	Create a human-readable representation of a unique identifier by formatting the identifying attributes of an instance into a string pattern of "identifier(attribute1=value1, attribute2=value2, ...)".
13406	Check a model for uniqueness constraint violations by examining identifying attributes and indices across metaclasses, returning the count of violations found.
13407	Check model for integrity violations on an association in a particular direction, returning count of violations.
13408	Check model for integrity violations across a subtype association by verifying that each instance of the super kind has a valid subtype relationship, returning the count of violations.
13409	Returns an index creation function that generates index values for specified feature names from a feature collection. The returned function takes a transformation function and a (content_id, FeatureCollection) tuple, then yields transformed feature values for each specified feature name. It handles different feature types including unicode strings, string counters, and sparse/dense vectors by iterating through their values and applying the transformation function.
13410	A basic transform function that handles strings and integers by packing integers as big-endian 32-bit values and converting strings to lowercase UTF-8 encoding.
13411	Add feature collections to the store. Given an iterable of tuples containing content IDs and feature collections, this method adds each to the store, overwriting any existing entries. By default, it creates new indexes for each content object using all indexes defined on the store. Note that existing indexes are not updated. The method accepts an optional `indexes` parameter (defaulting to True) to control whether indexes are created.
13412	Deletes all storage content and index data by clearing both the main table and index table through the key-value store interface.
13413	Retrieves feature collections within specified ID ranges using a generator. Takes variable key ranges (start, end tuples) where empty tuples represent table boundaries. Returns generator of (content_id, FeatureCollection) pairs. If no ranges provided, yields all content objects. Converts keys to tuples and loads feature collections using fc_loads.
13414	Retrieves content IDs within specified ID ranges by scanning a storage table. Returns a generator of content IDs, where each ID range is defined by a tuple of (start_id, end_id), with empty tuples representing unbounded ranges. If no ranges are provided, returns all content IDs in the storage. Uses a key-value layer scanner internally to perform the range queries.
13415	Returns a generator of content identifiers that match an indexed value by scanning the index table with the transformed value and index name as key bounds.
13416	Returns a generator of content identifiers that have an entry in the specified index with a matching prefix. Takes an index name and prefix value as parameters, applies index transformations, and yields matching content IDs. Raises KeyError if the index is not registered. The implementation uses a lambda function to extract the third element of each key during scanning.
13417	Returns a generator of (index key, content identifier) pairs that match a prefix search in the specified index. Takes an index name and value prefix as parameters, applies index transformations, and yields tuples of matching index keys and their corresponding content identifiers. Raises KeyError if the index is not registered. The generator yields results in the format (index key, content identifier) where the index key matches the given prefix after index transformations are applied.
13418	Implementation for index scan prefix operations, parameterized on return value function. Scans index table for keys matching the given prefix and applies the return function to each key tuple.
13419	Adds an index to the store instance with the specified name, creation function, and transformation function. The index will be available in all index_* methods and automatically updated on put operations. If an index with the same name already exists, it will be overwritten. Note that indexes do not persist and must be re-defined for each Store instance. The idx_name must be UTF-8 encodable.
13420	Adds new index values for a given index name and pairs of content identifiers and FeatureCollections, storing them in the index table with default values.
13421	Add new raw index values by creating a key-value pair in the INDEX_TABLE with transformed values.
13422	Returns a generator of index triples (index_value, index_name, content_id) for given content IDs and FeatureCollections, with duplicate value deduplication to prevent duplicate primary key errors.
13423	Returns the index transforms for a given name, decoding the name from UTF-8 and looking up the transforms in the internal indexes dictionary, raising a KeyError if the index has not been registered.
13424	Check if a package name exists on PyPI by querying the PyPI registry using HTTP HEAD requests, handling URL redirections and PEP 503 normalization rules for case-insensitive package name matching. Returns True if package exists, False otherwise.
13425	Adds direction suffix to an element based on language directionality. Takes a value and optional argument ('rtl_only', 'both', or 'ltr_only') to determine when to add direction suffixes ('_rtl' for right-to-left, '_ltr' for left-to-right). Returns the original value or modified value with direction suffix based on language and argument.
13426	Returns the XSD name of a S_DT by checking associated S_CDT, S_EDT, and S_UDT objects in that order. Returns the S_DT's name if any of these associations exist with valid core types (1-5 for S_CDT) or if S_EDT/S_UDT associations exist.
13427	Get the referred attribute by recursively following reference chains through navigation paths, returning the final resolved attribute when no further references exist.
13428	Build an XSD simpleType element from a S_CDT object by mapping its data type name to corresponding XSD type names, returning the constructed simpleType element or None if no mapping exists.
13429	Build an XSD simpleType element from a S_EDT by creating a restriction with enumeration values based on the associated S_ENUM objects.
13430	Build an XSD complexType element from a S_SDT object by iterating through its members and adding attributes with appropriate types.
13431	Build an XSD simpleType element from a S_UDT by extracting the user-defined type and its base type, then creating a restriction-based simpleType with the base type as the restriction base.
13432	Build a partial XSD tree from a S_DT and its subtypes by checking for S_CDT, S_EDT, or S_UDT in order and returning the appropriate type builder result.
13433	Build an XSD complex element from an O_OBJ, including its O_ATTR attributes.
13434	Build an XSD complex element from a C_C object, including its packaged S_DT and O_OBJ by creating XML elements and populating them with class data.
13435	Build an XSD schema from a BridgePoint component by collecting global and scoped data types, building the component structure, and returning the complete schema element.
13436	Indent an XML string with four spaces and add line breaks after each node.
13437	Fetches the full list of bikes from the bikeregister site by making a POST request with form data and cookies. Extracts XSRF and session tokens from the initial GET request, then uses them to retrieve bike data. Raises ApiError on connection or JSON decoding errors. Returns a list of bike dictionaries.
13438	Sets positional information on a node including start/end coordinates and character stream data from parser tokens.
13439	A decorator that adds positional information to nodes returned by a function. It wraps the original function, captures its return value, checks if the first element of the input parameter is a Node instance with additional elements, and if so, sets positional information using the set_positional_info function before returning the result.
13440	Returns a token with endlexpos set to lexpos plus token length for double equals operator.
13441	Returns a token with end position set to lex position plus token length for NOT EQUAL operator.
13442	Summary: Sets the end position of a token to include the length of its value, then returns the token unchanged.
13443	Returns the less than or equal to symbol token with updated end position.
13444	Returns the token for the ">=" operator.
13445	Returns a token with endlexpos set to lexpos plus token value length.
13446	Returns a token with updated end position for dot characters.
13447	Returns the token with updated end position after the left bracket character.
13448	Returns a token with updated end position after matching a closing bracket character.
13449	Returns a token with updated end position, where the token value is a question mark character.
13450	Returns the less-than operator token with updated end position.
13451	Return the token with updated end position after the '>' character.
13452	Returns a token with updated end position for plus sign operator.
13453	Creates a message content and properties tuple for creating a queue using QMFv2 protocol. Takes queue name and optional parameters (strict, auto_delete, auto_delete_timeout) to build the content dictionary with proper QMFv2 structure. Returns tuple of (content, method_properties) where content contains queue creation parameters and method properties.
13454	Creates message content and properties to delete a queue using QMFv2 protocol. Takes a queue name as parameter and returns a tuple containing the message content dictionary and method properties. The message content includes object ID, method name ("delete"), and arguments specifying the queue type, name, and empty options dictionary.
13455	Create message content and properties to list all queues with QMFv2

Returns: Tuple containing content and query properties
13456	Create message content and properties to list all exchanges with QMFv2

Returns: Tuple containing content and query properties
13457	Create message content and properties to purge queue with QMFv2

**Parameters:**
- name (str): Name of queue to purge

**Returns:**
- Tuple containing content and method properties

**Details:**
Creates a message content dictionary with object_id pointing to the specified queue, method_name set to "purge", and arguments including queue type, name, and empty filter. The content is logged at debug level before returning a tuple of the content and method properties.
13458	Creates and formats an email message with optional attachments, returning it as a base64-encoded dictionary body.
13459	Returns the text from an image at a given url by checking if the image has changed, downloading and processing it if necessary, and returning the cached text result.
13460	Returns True if OCR process has read actual words, False otherwise. Checks if words contain meaningful content by verifying they are either numeric values or alphabetic words with length between 2-20 characters. Prevents non-meaningful OCR results from being added to the queue.
13461	Parse command line options to launch an interpreter that loads a model, finds a specified function in a component, and invokes it.
13462	Serializes a value from an xtuml metamodel instance based on the specified type, handling None values by using default values and applying appropriate formatting functions for different data types (BOOLEAN, INTEGER, REAL, STRING, UNIQUE_ID).
13463	Serialize an xtuml metamodel association into a CREATE ROP REF_ID statement with source and target specifications including cardinalities, metaclass kinds, keys, and phrases.
13464	Serialize an xtUML metamodel class into a SQL CREATE TABLE statement with properly formatted attributes.
13465	This function serves as the main command-line interface for a file search application that uses n-gram matching. It parses command line arguments to configure search parameters including the search path, file type filtering, verbosity level, and number of results to display. The function processes a search query, builds or updates an index of files, performs the search using n-gram matching, and displays the results through a handler. Key features include flexible file type filtering (any, images, documents, code, audio, video), verbose output for debugging, and configurable result limits. The application supports multi-word search queries and uses a minimum n-gram length based on the shortest word in the query for more efficient searching.
13466	Searches files satisfying a query by decomposing it into ngrams, scoring documents based on ngram overlap, and returning the top 10 matching documents sorted by relevance score.
13467	Partitions a list into two lists based on a condition function - one list for items that satisfy the condition and one for items that fail the condition.
13468	Runs the program with specified locations and options, supporting bike data, crime data, nearby articles, and API server functionality. Handles database initialization, bike updates, and CLI or API execution based on parameters.
13469	Adds BiDi (bidirectional) related variables to context including language direction, start/end layout positions, and language marker entities for HTML rendering.
13470	Find links between two instances that match the given relationship ID and phrase. Returns the instances and association if found, otherwise raises UnknownLinkException.
13471	Formalizes an association by exposing referential attributes on instances. Sets up referential attributes on the source class and identifying attributes on the target class. Creates property getters and setters for referential attributes that navigate to related instances, raising exceptions when direct assignment is attempted.
13472	Compute the lookup key for an instance by mapping attributes through key_map, handling null values and attribute access, and returning a frozenset representation of the key-value pairs.
13473	Compute the index key used to identify an instance on the link by collecting specified attributes from the instance and returning them as a frozenset tuple.
13474	Get the type of a specified attribute by case-insensitive name matching.
13475	Create and return a new instance with default values and assigned attributes, handling referential attributes through batch linking when possible.
13476	Return a generator that yields all instances from all metaclasses in the metamodel by iterating through each metaclass's storage.
13477	Define a new class in the metamodel and return its metaclass.
13478	Sends a message through a ZeroMQ socket containing header, payload, and topics.

Parameters:
- socket: a zmq socket
- header: a list of byte strings representing a message header  
- payload: the serialized byte string of a payload
- topics: a chain of topics (default: ())
- flags: zmq flags to send messages (default: 0)

Returns:
Result of sending multipart message through the socket with the specified flags.
13479	Receives a multipart message from a ZeroMQ socket, captures it using the provided function, and parses it into header, payload, and topics.
13480	This function analyzes dead code in a Python project using vulture. It executes vulture as a subprocess with the appropriate Python environment (either system Python or pipenv), writes the output to a file named "dead_code.txt", and checks if the number of dead code lines exceeds a 20-line threshold, exiting with an error if it does.
13481	Parse email addresses from string or list of strings using regex pattern matching.
13482	Marks a method as RPC with optional name parameter.
13483	Collects RPC methods from an application object by inspecting its attributes and filtering those with RPC specifications, returning a dictionary mapping RPC names to (method, spec) tuples.
13484	Async middleware that validates and normalizes UK postcodes in URL routes. If a postcode is present and valid, it converts it to uppercase without spaces. If the postcode is invalid, raises HTTP 404. If normalization is needed (uppercase with no spaces), redirects permanently to the normalized URL. If no postcode or "random" postcode is present, continues to the next handler without modification.
13485	Progress to the next identifier and return the current one.
13486	Method `accept_S_SYS` processes a system model instance by iterating through its top-level packages (accessed via EP_PKG[1401] relationship) and recursively accepts each child package.
13487	Accepts a Component instance and recursively processes its packageable elements by iterating through the PE_PE relationship with id 8003 and calling accept on each child.
13488	Accepts a package and processes its packageable elements by iterating through them and calling accept on each child.
13489	Return the average brightness of the image by converting it to grayscale and calculating the mean pixel value, caching the result if the image hasn't changed.
13490	Method: `match(self, *args)`

Summary: Determines whether to enter a case suite by matching the stored value against provided arguments. Raises a SyntaxError if no arguments are given. Returns the result of matching the internal value against the provided patterns.

Usage: Used within a switch statement context to check if a case should be executed based on pattern matching. Supports multiple pattern matching when multiple arguments are provided.
13491	Method `_find_match(self, position)` searches for matching brackets in a text document starting from a given position. It determines the corresponding bracket character and searches in the appropriate direction (forward or backward) while tracking bracket depth. Returns the position of the matching bracket or -1 if no match is found.
13492	Convenience method for selecting a character at the specified position in the text edit widget, returning a QTextEdit.ExtraSelection object with the character selected and formatted according to the instance's format.
13493	Updates document formatting based on cursor position by clearing old formatting and highlighting matching brackets when cursor is not in selection.
13494	Bypasses IronPython string exceptions by converting StringException objects to regular strings when running on IronPython (cli platform), ensuring compatibility with traceback checks that expect type(etype) == str.
13495	Creates an input hook for running the Qt4 application event loop, returning a Qt Application and inputhook pair. The inputhook processes pending Qt events and handles keyboard interrupts properly, while the pre_prompt_hook restores the hook after Ctrl-C interruptions. It reuses previously created hooks when possible and ensures exception handling in ctypes callbacks.
13496	Returns a Mapper instance with the given name, creating it if necessary. Uses a class-level dictionary to cache instances by name. Raises TypeError if name is not a string. Follows singleton pattern where multiple calls with the same name return the same instance.
13497	Decorator for registering a path pattern with optional method and type casting support.
13498	Decorator for registering a simple path with optional method and type casting support.
13499	Adds a new route pattern to the data store with optional method and type casting configuration.
13500	Function for registering a simple path with optional method and type casting support.
13501	Calls the first function matching the URL pattern and method, passing along any additional arguments. Parses the URL to extract path and query parameters, matches against registered patterns, applies type casting to parameters, and returns the function's result or None if no match is found.
13502	Summary: Executes code and stores command history, excluding empty or duplicate commands, while managing history index and edits.
13503	Method `_up_pressed` handles the up arrow key press event. It checks if the cursor is at the prompt line and manages history navigation. If history is locked and shift modifier is not pressed, it returns False to stop processing. Otherwise, it sets a search prefix based on cursor position, performs a history search, and adjusts the cursor position for seamless scrolling. Returns False if the cursor was at the prompt line, True otherwise.
13504	Called when the down key is pressed. Returns whether to continue processing the event. If the cursor is at the end of the buffer, it performs a history search and optionally adjusts cursor position, returning False to stop further processing. Otherwise, it returns True to continue processing.
13505	Sets the input buffer to a previous history item that matches an optional substring.

Parameters:
- substring (str, optional): Search for an item containing this substring
- as_prefix (bool, optional): If True, substring must match at beginning (default: True)

Returns:
- bool: True if input buffer was changed, False otherwise
13506	Move the input buffer to the next history item that matches an optional substring. Returns True if the buffer was changed.
13507	Handles execution replies for code execution, specifically managing session history length updates when save_magic commands are executed successfully.
13508	Returns whether history movement is locked based on history lock status, edited history difference from input buffer, and cursor position mismatch.
13509	Retrieves a history item with optional temporary edits, returning either the edited version, an empty unicode string for the next index, or the original history item.
13510	Replace the current history with a sequence of history items.
13511	Stores edits to the current input buffer in history if there are changes since the last stored edit.
13512	Event handler for button click that prints a farewell message, cleans up consoles, closes the window, and explicitly exits the application to handle IPython kernel shutdown issues.
13513	Generates a list of Record objects from a pandas DataFrame, where each Record contains a series attribute representing the row data. Optional keyword arguments can be included in each Record object. Returns a collection of Record instances, one for each row in the DataFrame.
13514	Converts a collection of Record objects back into a pandas DataFrame by concatenating their series representations.
13515	Summary: The `spin_frame` function processes a pandas DataFrame by applying a specified method to each row through the turntable library's batch processing system. It first converts the DataFrame into a collection, processes each record in the collection using the provided method, and then converts the processed collection back into a DataFrame. The function serves as a wrapper for the complete turntable workflow, allowing users to efficiently apply transformations to all rows in a DataFrame using a custom processing function.
13516	Initializes the given argument structure as properties of the class to be used by name in specific method execution.

Parameters:
kwargs (dict): Dictionary of extra attributes, where keys are attribute names and values are attribute values.
13517	Update the SUB socket's subscriptions by first unsubscribing from everything, then subscribing to all specified topics, or to everything if an empty string is in the topics list.
13518	Receive and parse a message, then log it. Validates message format, extracts topic and level, removes trailing newline from message, and logs with proper formatting.
13519	Merge sort implementation that performs an N-way merge operation on sorted lists, yielding elements in sorted order while maintaining stability. Takes multiple sorted iterables and merges them into a single sorted output using a heap-based approach with O(N lg N) complexity. Supports custom key functions for sorting.
13520	Return an iterator on an object living on a remote engine by executing iter() on the remote engine and yielding results one by one, handling StopIteration exceptions remotely.
13521	Converts a notebook from version 1 to v2 format.

Parameters:
- nb: NotebookNode - The Python representation of the notebook to convert
- orig_version: int - The original version of the notebook to convert (default: 1)

Returns:
- NotebookNode - The converted notebook in v2 format

Raises:
- ValueError - If the notebook cannot be converted from the specified version to v2
13522	Return the platform's maximum compatible version by detecting Mac OS X version when running on macOS, otherwise return the standard build platform.
13523	Retrieve a PEP 302 "importer" for the given path item, using path hooks and caching, with a fallback to ImpWrapper if no importer is found.
13524	Creates a thunk that dynamically loads either cStringIO or StringIO depending on availability, then returns a StringIO instance with the provided arguments.
13525	Converts a version string to a chronologically-sortable tuple key that handles both strict and loose version formats, padding numeric portions to 8 digits for numerical comparison while preserving string comparison behavior.
13526	Return True when distribute wants to override a setuptools dependency.

We want to override when the requirement is setuptools and the version is
a variant of 0.6.
13527	Adds a distribution to the working set, associating it with an entry. If the entry is not specified, it defaults to the distribution's location. The method ensures that only one distribution per project key is present unless `replace=True`. When added, it updates internal data structures and triggers callbacks via `_added_new()`.
13528	Find all activatable distributions in a plugin environment, resolving dependencies and handling errors. Returns a tuple of (distributions, error_info) where distributions are loadable plugins and their dependencies, and error_info maps unloadable plugins to their exception details. Supports fallback to older versions and can use a full environment for dependency resolution.
13529	Return the absolute cache path for a given archive name and optional names, creating the parent directory if needed. The method tracks generated paths for potential cleanup and should only be called by resource providers for intended extraction names.
13530	Parse a single entry point from string `src` following the format 'name=module:attrs [extras]', returning an EntryPoint object with parsed name, module, attributes, and extras.
13531	Parse and cache metadata, returning cached result if available or parsing new metadata from PKG_INFO if not.
13532	Recomputes the distribution's dependencies by parsing requirement specifications and organizing them by extra, handling conditional expressions through marker compilation. Returns a dependency map grouped by extras.
13533	Parse a notebook filename and return the filename, notebook name, and format (json/py). Supports extensions .ipynb, .json, .py, or no extension (defaults to .ipynb).
13534	Collapse leading whitespace from text based on header type, preserving newlines for 'description' header while normalizing whitespace for other headers.
13535	Method `hideEvent` is overridden to clean up signal handlers and event filters when the widget is hidden. It disconnects the `cursorPositionChanged` signal from the `_update_current` method and removes the widget's event filter from the associated text edit component.
13536	Method `showEvent` is overridden to connect signal handlers and install an event filter when the widget is shown. It connects the cursor position changed signal of the text edit to the update current method, and installs the widget itself as an event filter on the text edit.
13537	Returns a text cursor with text selected between the start position and current position.
13538	Updates the current item based on current text selection by finding matching items and setting the first match as current, otherwise hides the widget.
13539	Registers all models from the specified app with the Django admin site, excluding any models listed in excludeModels.
13540	Return disk partitions by fetching raw partition data from Windows system and converting it to named tuple format.
13541	Return system CPU times as a named tuple containing user, system, and idle time.
13542	Return system per-CPU times as a list of named tuples.
13543	Method `_stdin_raw_nonblock` uses the raw Win32 handle of `sys.stdin` to perform non-blocking reads. It checks if data is available using `WaitForSingleObject` with a 100ms timeout. If timeout occurs, it prints "." and returns `None`. If data is available, it reads up to 256 bytes using `ReadFile`, flushes the console input buffer, and returns the cleaned data with Windows-style line endings converted to Unix-style. The method includes error handling using `ctypes.WinError()` and is marked as experimental with potential inconsistencies.
13544	Method `_stdin_raw_block` performs a blocking read from standard input, replacing carriage returns with newlines. It handles Windows pipe closure errors gracefully by returning `None` when the specific `ERROR_NO_DATA` error occurs, while allowing other Windows errors to propagate.
13545	Method that updates the visibility of a tab bar based on the number of tabs: hides the tab bar when there are 0 or 1 tabs, shows it when there are 2 or more tabs, and closes the window when all tabs are removed.
13546	Creates a new frontend tab attached to the same kernel as the currently active tab, with a modified tab name indicating it's a slave copy.
13547	Adds a tab with the specified frontend to the tab bar with an optional name, updates tab bar visibility, makes the frontend visible, and connects the exit signal to close the tab.
13548	Add an action to both a menu and the current widget, making it available even when the menu bar is invisible. Optionally sets the shortcut context to WidgetShortcut to avoid conflicts with widget-specific shortcuts.
13549	Returns a function that executes the given magic command on the active frontend when called. The magic command is executed on the active frontend at the time the returned function is called, not when it's created. This is used to dynamically create menu items for magic commands.
13550	Populates the "All Magics..." menu by clearing existing items and adding new magic commands from a provided list. Takes a string representation of a list of magic command dictionaries, parses it, and creates menu actions for each magic command. Cell magics are prefixed with '%%' while line magics use '%'. Some magic commands are protected and get a '?' suffix. Creates dynamic actions that trigger the corresponding magic commands when selected.
13551	Closes the window and handles closing all tabs with optional confirmation dialog. If there are no tabs, it accepts the close event immediately. If there are tabs and confirmation is enabled, it shows a dialog asking whether to close all tabs and quit. If the user confirms, it closes all tabs one by one and accepts the close event; if canceled, it ignores the event.
13552	Generate a hashed password with salt for notebook configuration, using the specified hashing algorithm. If no password is provided, prompts the user to enter and verify a password. Returns the hashed password in the format 'algorithm:salt:hash'.
13553	Verify that a given passphrase matches its hashed version by comparing the digest of the concatenation of the passphrase and salt with the stored hash. Returns True if they match, False otherwise.
13554	Generate HTML snippet for displaying boolean values in Django admin with optional AJAX editing capability. Returns a checkbox input that toggles values via JavaScript when no override is specified, or a static boolean icon when override is provided.
13555	Generate a short title for an object with indentation based on hierarchy depth, including HTML markup for styling and editable status.
13556	Collects all fields marked as editable booleans to prevent unauthorized arbitrary field editing through AJAX requests. It processes fields in `list_display`, checks for `editable_boolean_field` attribute, and stores result functions for valid editable boolean fields.
13557	Handle an AJAX request to toggle a boolean attribute on a model object, with permission checks and JSON response containing updated HTML snippets.
13558	Method that checks if a user has change permission for an object, considering both global permissions and object-level permissions when TREE_EDITOR_OBJECT_PERMISSIONS is enabled, and combines this with the parent class's permission check.
13559	Method that checks if a user has delete permission for an object, considering both object-level permissions (when enabled via settings) and superclass permissions. Returns True if the user has permission to delete the object.
13560	Adds children recursively to a binary tree by creating nodes and edges from a parent node down to a specified level.
13561	Create a symmetrical binary tree with specified number of levels using NetworkX directed graph, where each node has at most 2 children and the root node is labeled '0'.
13562	Submit jobs via client where G describes the time dependencies, returning a dictionary mapping node names to their job results. Jobs are submitted in topological order respecting time dependencies, with each job submitted only after its predecessor jobs have completed.
13563	Validates that each job in a dependency graph executes after all its dependencies have completed by comparing start and completion timestamps.
13564	Builds a set of color attributes in a class by setting attributes based on color templates and a base format string.
13565	Return a full copy of the object, optionally renaming it. If no name is provided, the original name is used. The copy is created with the same colors dictionary as the original object.
13566	Add a new color scheme to the table, raising a ValueError if the input is not a ColorScheme instance.
13567	Set the currently active color scheme by name, with optional case-sensitive comparison. Raises ValueError for unrecognized schemes and updates internal active scheme attributes. Allows using empty string '' as an index for the active scheme.
13568	Return the lib directory under the 'home' installation scheme, using 'site-packages' for PyPy and 'lib/python' for other Python implementations.
13569	Method to process subscribe channel's messages from kernel, handling different message types including status, stream (stdout/stderr), and pyout outputs. For status messages, it tracks execution state. For stream messages, it prints content to appropriate standard streams. For pyout messages, it processes and displays output data with proper formatting and logging.
13570	Method to capture raw_input from stdin channel with timeout, handling SIGINT signals properly and sending input back to kernel only if no other messages are pending.
13571	Method to wait for a kernel to be ready by monitoring its heartbeat channel until it starts beating or timeout occurs.
13572	Sets the style to the specified Pygments style, accepting either a style object or style name string.
13573	Returns a QTextCharFormat for the given token, caching the result. Looks up the token in cached formats, and if not found, retrieves format from either the document or style based on availability.
13574	Returns a QTextCharFormat for a given token by formatting it with the internal formatter and extracting the character format from the resulting HTML document.
13575	Returns a QTextCharFormat for a token by reading a Pygments style, setting properties like color, background, font weight, italic, underline, and font style hints.
13576	Searches the PATH environment variable for a given command and returns its full path. Supports path extensions (like .exe on Windows) and handles various edge cases including commands with existing extensions. Raises BadCommand if the command cannot be found in any of the PATH directories.
13577	Normalize a path to its canonical, case-normalized, absolute version by expanding user home, resolving real path, and normalizing case.
13578	Verifies that namespace packages are valid by checking:
1. All namespace packages have corresponding contents in the distribution
2. Raises DistutilsSetupError if a namespace package has no contents
3. Warns if a namespace package is declared but its parent package is not included
13579	Verifies that the entry_points map is parseable by attempting to parse it with pkg_resources.EntryPoint.parse_map(). If parsing fails, raises a DistutilsSetupError with the original error message.
13580	Determine if the input source ends in a blank (newline or whitespace-only line). Returns True if the last line is empty or contains only whitespace, False otherwise.
13581	Determine if the input source ends in two blanks (newlines or whitespace-only lines). Handles edge cases like empty input and uses a two-step regex matching approach on the last two lines of the source after prepending a placeholder.
13582	Handle the `files = !ls` syntax by converting it to `%s = get_ipython().getoutput(%r)` format.
13583	Handles the `a = %who` syntax by transforming it into `a = get_ipython().magic('%who')`.
13584	Handle inputs that start with '>>> ' syntax by removing the prompt prefix if present, otherwise return the line unchanged.
13585	Transforms IPython prompt syntax by removing the prompt prefix from input lines. Returns the line with the IPython prompt (like "In [1]: ") stripped off if present, otherwise returns the line unchanged. Handles empty or whitespace-only lines by returning them as-is.
13586	Push one or more lines of Python input and determine if they form a complete execution block. Stores the input lines and returns True if the current input source (combined with prior inputs) forms a complete Python block, False otherwise. Handles compilation exceptions by returning True when syntax errors occur. Updates indentation and manages code compilation internally, storing the result in a private attribute `_is_complete` which can be queried at any time.
13587	Return whether a block of interactive input can accept more input, based on syntax completeness, indentation level, and blank line conditions.
13588	Find the new indentation level for a single line of Python code, returning both the new indent level and whether a full dedent occurs.
13589	Store one or more lines of input in the specified buffer, automatically appending a newline if missing, and update the source attribute with the combined content.
13590	Return input and raw source and perform a full reset.
13591	Processes cell magic lines that start with %%, storing the magic name and body for later execution, and determines if the input is complete.
13592	Appends new content for a cell magic in line mode, stores raw input for history, tracks cell magic parts, and determines if execution should terminate based on blank line patterns. Returns boolean indicating completion status.
13593	Process and translate a cell of input by resetting, pushing the cell, and returning the source reset.
13594	Pushes one or more lines of IPython input, processing them through transformations and returning whether the input forms a complete Python block. Handles cell magic commands and applies various transformations to the input lines before passing them to the parent class for processing. Returns a boolean indicating if the current input source forms a complete execution block.
13595	Initialize observer storage with empty sets for registered types and senders, and an empty dictionary for observers.
13596	Post notification to all registered observers.

The registered callback will be called as::

    callback(ntype, sender, *args, **kwargs)

Parameters
----------
ntype : hashable
    The notification type.
sender : hashable
    The object sending the notification.
*args : tuple
    The positional arguments to be passed to the callback.
**kwargs : dict
    The keyword argument to be passed to the callback.

Notes
-----
* If no registered observers, performance is O(1).
* Notification order is undefined.
* Notifications are posted synchronously.
13597	Find all registered observers that should receive a notification based on notification type and sender matching.
13598	Add an observer callback to this notification center that will be triggered when notifications of the specified type and sender are posted.
13599	Add a new background job and start it in a separate thread. Supports two job types: 1) expression-based jobs (passed to eval()) and 2) function-based jobs. Expression jobs require a string argument, while function jobs take a callable and optional arguments. Jobs can be configured as daemon threads. Returns the created job object.
13600	Updates the status of job lists by moving finished jobs to completed or dead lists, and copies them to corresponding report lists for tracking since last update.
13601	Reports summary for a given job group and returns True if the group had any elements. Prints job information if the group is not empty.
13602	Flush a given job group and return True if the group had any elements.
13603	Print status of newly finished jobs and return True if any new jobs were reported. Resets internal state after reporting.
13604	Prints a status report of all currently managed jobs, showing Running, Completed, and Dead job groups, and flushes the report queues.
13605	Initializes a BackgroundJob object with common attributes and settings. Sets up job status tracking, result placeholders, and traceback handling capabilities. Configures thread inheritance and validates required attributes exist.
13606	Inserts a value into the ListVariable at the specified index position, then rebuilds the internal state.
13607	Returns a shallow copy of the Environment object with its data, sensitive data, and current working directory.
13608	Declares an environment variable as a special variable with specified separator and class type, raising ValueError if already declared with different parameters.
13609	Declares an environment variable as a list-like special variable using the specified separator (defaults to os.pathsep).
13610	Declare an environment variable as a set-like special variable using the specified separator (defaulting to os.pathsep).
13611	Change the working directory that processes should be executed in.

:param value: The new path to change to. If relative, will be interpreted relative to the current working directory.
13612	Swaps two cities in the route by randomly selecting two positions and exchanging their values.
13613	Calculates the total energy (route length) of a given state by summing distances between consecutive cities in the route, using either a precomputed distance matrix or Euclidean distance between city coordinates.
13614	Creates an empty record dictionary with specified keys set to None values. If no keys are provided, uses the instance's _keys attribute. Returns a dictionary with all keys initialized to None.
13615	Check if database table exists and has correct structure, returning True if valid or False if there are key or type mismatches.
13616	Converts a list into a dictionary using specified keys, where each list element becomes a value for its corresponding key.
13617	Converts a MongoDB-style search dictionary into an SQL query string and corresponding arguments list, handling various operators and null value checks.
13618	Standard warning printer with level-based formatting and optional exit functionality. Outputs formatted messages to stderr with headers indicating warning level (WARNING, ERROR, FATAL ERROR) and can trigger program exit at level 4. Supports configurable exit value for fatal errors.
13619	Parse a configuration file with optional JSON schema validation and default value merging. Reads from a specified config file or defaults to config/app.yml, validates against specs if provided, and merges with default values from default_file if specified. Returns the loaded and validated configuration dictionary.
13620	Creates an HTML table from a 2D list of rows and columns, where each inner list represents a row and each element represents a cell value.
13621	Creates an HTML link tag with the given URL and optional attributes. Handles both absolute URLs and Django URL reversals with additional arguments. Supports custom classes, target attributes, and query parameters.
13622	```python
def jsfile(url):
    '''
    Output a script tag to a js file.
    '''
    if not url.startswith('http://') and not url[:1] == '/':
        url = settings.STATIC_URL + url

    return '<script type="text/javascript" src="{src}"></script>'.format(
        src=url)
```

Summary: Generates an HTML script tag for a JavaScript file, automatically prepending the static URL prefix for relative paths.
13623	Creates a CSS stylesheet link tag for a given URL, automatically prepending STATIC_URL for relative paths.
13624	Image tag helper that generates HTML img elements with optional attributes, automatically prepending STATIC_URL to relative paths.
13625	Subtract the arg from the value, with fallback handling for non-numeric types.
13626	Multiply the value by the argument, with fallback to direct multiplication if numeric conversion fails.
13627	Divide the arg by the value, with error handling for numeric conversion and fallback to direct division if needed.
13628	Returns the modulo of two values, with error handling for numeric conversion and type issues. If conversion fails, attempts direct modulo operation, returning empty string if both attempts fail.
13629	Return the verbose name of a model, handling both Model and ModelForm instances with optional capitalization.
13630	Split user input into initial whitespace, escape character, function part and the rest using a regex pattern match or default splitting behavior.
13631	Register command-line options for process management including number of processes, timeout duration, and worker restart settings.
13632	Add a built-in function/variable to the builtin namespace and save the original value. If the value is HideBuiltin, remove the built-in entirely. Otherwise, store the original value and replace it with the new value.
13633	Remove an added builtin and restore the original value. If the original is BuiltinUndefined, delete the builtin key from __builtin__.__dict__. Otherwise, restore the original value to the builtin key in __builtin__.__dict__.
13634	Remove any builtins added by add_builtins or restore overwritten ones to their previous values.
13635	Finds the true URL name of a package by resolving case-insensitive variations when the given name doesn't match exactly. Returns the actual package name if found, None otherwise.
13636	Yields all links with the specified relations (defaults to 'homepage' and 'download') by finding all anchor tags with rel and href attributes, checking for relationship intersections, and returning cleaned Link objects.
13637	Converts a command-line argument string into a list by splitting on commas, with special handling for Windows platform to strip single quotes from the input string. Returns None if the input string is empty.
13638	The main entry point for Coverage that handles command line arguments and manages different exception types during execution. It tracks execution time, handles exceptions during code execution, coverage errors, and system exits, returning appropriate status codes.
13639	Adds a specialized option with callback action to execute the specified action code.
13640	Callback for an option that adds to the `actions` list.
13641	The `command_line` method implements the main command-line interface for the Coverage tool. It processes command-line arguments, parses options using either a classic or command-specific parser, handles help and version requests, validates options, and executes various coverage actions such as executing code, combining data, and generating reports (report, annotate, HTML, XML). It returns appropriate status codes (OK, ERR, FAIL_UNDER) based on the success or failure of operations. The method supports parallel mode, debugging, and various coverage configuration options.
13642	Display an error message, or the named topic, or parser help text based on the provided parameters.
13643	Handle help requests and version display. Returns True if request was handled, False otherwise. Supports classic help, command-specific help, and version information.
13644	Check for conflicts and problems in the options. Returns True if everything is ok, or False if not. Ensures that 'erase' and 'execute' actions are not combined with 'annotate', 'html', 'report', or 'combine' actions. Verifies that at least one action is specified and that arguments are handled appropriately based on the specified actions.
13645	Implementation of 'coverage run' that executes Python code while collecting coverage data. Sets up the execution environment by modifying sys.path, runs either a Python module or file using the coverage instrumenter, handles exceptions by stopping coverage tracking, and restores the original sys.path after execution.
13646	Summary: The `do_debug` method implements the 'coverage debug' command that displays diagnostic information about coverage data and system status. It accepts arguments specifying what information to show ('sys' for system info, 'data' for coverage data). For 'sys', it prints system information using `info_formatter`. For 'data', it loads coverage data and displays the data file path, arc status, and a summary of covered files with line counts. Returns ERR for invalid arguments or OK for successful execution.
13647	Reconstructs an object from serialized data buffers by using pickle to deserialize the main object and then populating any missing data fields from the remaining buffers. Handles lists, tuples, and dictionaries differently based on their structure, and returns the reconstructed object along with any unused buffers.
13648	Sets the display hook to the instance's hook if it's different from the current display hook, storing the old hook for potential restoration.
13649	A decorator that logs unhandled exceptions in methods without letting them close the stream, useful for wrapping on_recv callbacks.
13650	Checks if a string is a valid ZMQ URL by verifying it contains a valid protocol (tcp, pgm, epgm, ipc, or inproc) followed by '://'. Returns True if valid, False otherwise.
13651	Validates a ZeroMQ URL string to ensure it follows the correct format and protocol. The function checks that the URL is a string, has a valid protocol (tcp, pgm, epgm, ipc, or inproc), and for TCP URLs, validates the address and port format. It returns True for valid URLs.
13652	Validates a potentially nested collection of URLs by checking if each element is a valid URL, recursively handling nested structures like dictionaries and iterables.
13653	Helper method for implementing `client.pull` via `client.apply` that retrieves values from global namespace by keys, raising NameError if any key is not defined.
13654	Selects and returns n random available ports by creating temporary sockets, binding them to available addresses, and collecting their port numbers while tracking used ports in a global set.
13655	Turns a function into a remote function that can be used for distributed computing. Can be used as a decorator with optional block and flag parameters to control execution behavior.
13656	Turns a function into a parallel remote function that can be used for distributed computing operations.
13657	Maps a function over sequences remotely, behaving like builtin map but returning AsyncMapResult when blocking is disabled.
13658	Get the last n items in readline history.
13659	Sets the autoindent flag with readline support checking. Toggles the flag if called without arguments, otherwise sets it to the specified value. Displays a warning on POSIX systems if readline is not available.
13660	Initialize logging based on command line arguments by calling the appropriate logstart magic command with specified file and mode options.
13661	Save the original state of sys module hooks and modules before user module creation.
13662	Restore the state of the sys module by reverting changes made during initialization. It restores original sys module attributes and resets sys.modules to its original state.
13663	Register a function to be called after code execution. Raises ValueError if the argument is not callable.
13664	Return a new 'main' module object for user code execution by initializing a fake module dictionary.
13665	Cache a main module's namespace to prevent Python from clearing it during script execution, storing a copy of the namespace keyed by the absolute file path to avoid memory leaks while preserving access to objects from the last execution.
13666	Initializes user-visible namespaces with minimum defaults, setting up essential variables and history references while ensuring certain variables are hidden from user listings.
13667	Get a list of references to all namespace dictionaries where IPython stores user-created objects, excluding the displayhook.
13668	Reset the interactive shell by clearing all internal namespaces and releasing references to user objects. If new_session is True, open a new history session. This involves clearing histories, resetting execution count, flushing cached output, clearing execution namespaces while preserving built-in keys, clearing hidden namespaces, reinitializing user namespaces, restoring aliases, clearing module references, and resetting the main module.
13669	Delete a variable from various namespaces by name or by object reference, removing all hidden references to the variable while avoiding deletion of built-in names.
13670	Clears selective variables from internal namespaces based on a regular expression pattern. If a regex is provided, searches through all namespaces and deletes variables whose names match the pattern. Raises TypeError if regex is not a string or compiled pattern.
13671	Pushes a group of variables into the IPython user namespace, with optional interactive visibility control. Takes variables as dict, string, or list/tuple, updates the user namespace, and manages visibility through the 'who' magic command.
13672	Find an object in the available namespaces, handling magic functions and aliases. Returns a dictionary with keys: found, obj, namespace, ismagic, isalias, parent.
13673	Method `_ofind_property` is the second part of an object finding process that searches for property details. It checks if the object was found and, if so, examines whether the object belongs to a class instance and is a property. If it is a property, it updates the object name to include the class reference and retrieves updated information using `_ofind`. The method returns either the modified info structure with property details or the original info if no object was found.
13674	Find an object by name and return a structured information object containing its properties.
13675	Generic interface to the inspector system that handles object inspection methods like pdoc and pinfo, with proper formatting and error handling for missing objects.
13676	Initializes the command history management system and configures automatic saving functionality.
13677	A defensive exception handler for GUI applications that calls sys.excepthook, which prints regular tracebacks using InteractiveTB instead of triggering the CrashHandler. This prevents GUI frameworks from appearing to crash IPython when they handle exceptions internally, while ensuring real IPython errors still trigger proper crash handling.
13678	Displays exception traceback information to the user, handling different exception types appropriately including SyntaxError and UsageError, while providing options for showing only the exception or the full traceback.
13679	Shows traceback by printing it to stdout using InteractiveTB.stb2text method.
13680	Displays the syntax error that just occurred without showing a stack trace. If a filename is provided and the error is a SyntaxError, it replaces the filename in the exception with the provided one. Then shows the structured traceback of the syntax error.
13681	Method `pre_readline` serves as a readline hook called at the start of each line, handling auto-indentation by inserting the appropriate indentation at the current position, and inserting any pending next input text if available.
13682	Return the completed text and a list of completions for the given text, line, and cursor position.

Parameters:
    text (str): A string of text to be completed on.
    line (str, optional): The complete line that text is part of.
    cursor_pos (int, optional): The position of the cursor on the input line.

Returns:
    tuple: A tuple containing the completed text and a sorted list of all possible completions.

This method provides text completion functionality similar to readline's TAB key behavior, but can be used in non-readline environments like GUIs. It wraps the underlying completion mechanism and injects names into __builtin__ for proper completion.
13683	Adds a new custom completer function at the specified position in the completers list.
13684	Sets the completer's namespace and global_namespace based on the provided frame or defaults to user namespaces.
13685	Executes a line magic function with the given name and arguments, handling cases where the magic function doesn't exist and providing helpful error messages. It expands variables in the input line, prepares arguments for the magic function call, and executes the function within a builtin trap context, returning the result.
13686	Find and return a magic of the given type by name, returning None if not found.
13687	Define a new macro with the given name and action. The macro action can be provided as either a string (which will be converted to a Macro object) or directly as a Macro instance. The macro is stored in the user namespace with the specified name. Raises ValueError if the macro action is neither a string nor a Macro instance.
13688	Executes a command in a subprocess using os.system with platform-specific handling for Windows UNC paths, stores the exit code in user namespace without triggering displayhook calls.
13689	Prints a rewritten version of the user's command to show automatic transformations, displaying the original command with a "->" prefix to indicate IPython's automatic rewriting behavior.
13690	Get a list of variable names from the user's namespace and return a dictionary with their string representations.
13691	Evaluate a dictionary of expressions in the user's namespace and return a dictionary with their string representations.
13692	Evaluates a Python expression in the user's namespace and returns the result.
13693	Executes a .ipy file with IPython syntax safely, handling file opening errors and adding the file's directory to sys.path for proper module resolution.
13694	Runs a cached cell magic by retrieving the stored cell body and executing the cell magic with the stored data.
13695	Run a complete IPython cell with the given code, handling prefiltering, compilation, execution, and post-execution functions, while managing history and silent execution modes.
13696	Run a sequence of AST nodes with specified interactivity mode ('all', 'last', 'last_expr', or 'none'). Executes nodes in either 'exec' or 'single' mode based on interactivity, handling compilation and code execution while managing exceptions and output display. Returns True if execution is interrupted, False otherwise.
13697	Activates pylab support at runtime by enabling matplotlib integration, preloading numpy and pylab into the interactive namespace, and configuring IPython to work with the GUI event loop. Optionally accepts a GUI backend parameter ('qt', 'osx', 'tk', 'gtk', 'wx', 'inline') to dictate matplotlib's GUI backend selection. Handles namespace management to prevent pollution and sets up GUI activation and modified %run behavior for plot updates.
13698	Expands Python variables in a string using the user's interactive namespace and local variables from the caller's frame, with optional depth control for frame walking. Returns the formatted string or the original if formatting fails.
13699	Create a temporary file with optional data writing and register it for cleanup.
13700	Extract input history lines based on a slice string specification and return them as a concatenated string. The function supports session numbering with ~n notation, Python-style slicing (N:M) and closed-endpoint slicing (N-M), and can return either processed or raw input history lines.
13701	Method: `find_user_code(self, target, raw=True, py_only=False)`

Summary: Retrieves a code string from various sources including command history, URLs, Python files, or the user namespace. It first attempts to extract code from input history, then checks if the target is a URL, file path, or evaluates to a string/macro in the user namespace. Supports options to retrieve raw history and restrict decoding to Python-only methods.

Parameters:
- `target` (str): Code identifier that is tried in order as history ranges, URLs, .py files, filenames, or user namespace expressions
- `raw` (bool, default=True): Whether to retrieve raw history 
- `py_only` (bool, default=False): Only try Python code fetching, skip alternative encoding methods

Returns: String containing code from the resolved source

Raises: 
- `ValueError`: When target cannot be found in any source or is unreadable
- `TypeError`: When target evaluates to an object that is neither string nor Macro
13702	This method performs cleanup operations at IPython exit time, including closing the history session, removing temporary files, clearing user namespaces, and running shutdown hooks.
13703	Broadcasts a message from one engine to all others using publish/subscribe pattern, where the sender engine publishes a message and all other engines consume it. Returns a list of messages for each executed command.
13704	Send a message from one engine to one-or-more engines. The message is sent asynchronously and received by the target engines. Returns the result of executing the received message on the target engines.
13705	**Summary:**

The `skipif` function is a decorator factory that conditionally skips tests based on a given condition. It accepts a `skip_condition` (which can be a boolean or callable) and an optional message. If the condition evaluates to True, the test will raise a `SkipTest` exception; otherwise, the test function is executed normally. The decorator handles both regular test functions and test generators, and uses dynamic import of the `nose` module to avoid hard dependencies. The decorator preserves the original function's metadata using `nose.tools.make_decorator`.
13706	Function `knownfailureif` creates a decorator that marks a test function as a known failure if the given condition is true. It accepts a `fail_condition` parameter (either a boolean or callable) and an optional error message. When the condition evaluates to True, the decorator raises a `KnownFailureTest` exception with the specified message. If the condition is False or not met, the original function is called normally. The decorator uses `nose.tools.make_decorator` to preserve the original function's metadata. The fail condition can be a static boolean value or a callable that's evaluated at runtime, allowing for dynamic failure determination.
13707	A decorator that filters DeprecationWarning's during test execution, useful for testing code that raises deprecation warnings while avoiding their display during test runs. It can be conditionally applied based on a boolean flag or callable condition, and ensures that the decorated test actually raises a DeprecationWarning.
13708	List profiles in a given root directory by finding subdirectories that start with 'profile_' prefix.
13709	List profiles that are bundled with IPython by scanning the profile directory and returning valid directory names.
13710	Find a distribution matching requirement `req`. If there is an active distribution for the requested project, return it as long as it meets the version requirement specified by `req`. If there is an active distribution for the project and it does not meet the `req` requirement, raise `VersionConflict`. If there is no active distribution for the requested project, return `None`.
13711	The `run` function executes a command in a subprocess, captures its output, and optionally returns the exit status. It supports timeout, event-driven interactions with the command (using patterns and responses), and can handle both string responses and callback functions. The function uses `spawn` internally to manage the subprocess and handles different types of events (patterns) that may occur during execution. If `withexitstatus` is True, it returns a tuple of (output, exitstatus); otherwise, it returns just the output string. The function is useful for automating command-line interactions and handling complex scenarios like password prompts or progress updates.
13712	Returns the full path to a executable file if found in the environment PATH, otherwise returns None.
13713	This method implements the iterator protocol for a file-like object by returning the next line when called. It reads the next line using readline() and raises StopIteration when reaching the end of the file (indicated by an empty buffer). This allows the object to be used in for-loops and other iterator contexts.

Example usage:
```python
for line in file_like_object:
    print(line)
```

The method supports iteration over file-like objects by providing the necessary `__next__` functionality that Python's iterator protocol requires. When the end of the file is reached, it raises `StopIteration` to signal the end of iteration, which is the standard Python way of indicating the end of an iterator.
13714	Sends a string to the child process and returns the number of bytes written. Writes data to log files if specified.
13715	Sends a SIGINT signal to the child process by retrieving the interrupt character from terminal settings and sending it.
13716	Method `_prepare_regex_pattern` takes a regex pattern object and recompiles unicode patterns as bytes patterns. If the pattern is unicode, it encodes it to UTF-8 and removes the UNICODE flag from the regex flags. Returns the recompiled pattern object.
13717	The `expect` method searches through a stream to find a match for a given pattern or list of patterns. It supports various pattern types including strings, EOF, TIMEOUT, and compiled regular expressions. The method returns the index of the first matching pattern from a list, with special handling for cases where multiple patterns could match. It sets instance attributes `before`, `after`, and `match` to provide information about the matched content. The method can handle timeouts and EOF conditions gracefully by including them in the pattern list. If a timeout value of -1 is specified, it uses the instance's default timeout. The implementation delegates to `expect_list` after compiling the patterns.
13718	Summary:

The `expect_loop` method implements the core looping logic for pattern matching in input streams. It searches for specific patterns using a provided searcher object (which can be either `searcher_re` or `searcher_string`) within the input buffer. The method handles timeouts, reads additional data when needed, and returns the index of the matched pattern. It also manages EOF and TIMEOUT conditions, updating instance variables like `before`, `after`, `match`, and `match_index` with the results of the search. The method continuously reads input until a match is found or an exception occurs.
13719	Recompiles bytes regexes as unicode regexes by decoding the pattern using the instance's encoding and recompiling with the same flags.
13720	This method searches for the first occurrence of any specified search string within a given buffer. It uses the `freshlen` parameter to optimize performance by avoiding re-searching already processed data. The method returns the index of the first matching string if found, otherwise returns -1. When a match is found, it sets the `start`, `end`, and `match` attributes to indicate the position and content of the match. The search can be limited by `searchwindowsize` to improve efficiency when dealing with large buffers.
13721	Searches the buffer for the first occurrence of any compiled regular expression patterns. Returns the index of the matching pattern or -1 if no match is found. Sets internal attributes 'start', 'end', and 'match' to the first match found. The search can be limited to a window of the buffer based on searchwindowsize parameter.
13722	Creates a progress monitor listener that logs updates to a specified logger with progress percentage and message.
13723	Unpacks a directory by copying its contents to a target directory, using the same interface as archive extraction. Raises UnrecognizedFormat if the input is not a directory. Supports progress filtering and ensures target directories exist during copy operations.
13724	Emits a message to the user either to stdout or stderr based on debug flag and verbosity levels. If debug is True, message goes to stderr only if debug attribute is True. If debug is False, message goes to stdout only if verbose attribute is >= level (defaults to 1). Returns early if conditions aren't met to suppress output.
13725	Get the error output of the last command executed. Raises RuntimeError if no commands were executed. Returns the error message of the last failed command, or 'no last error' if all commands succeeded.
13726	Wrapper for subprocess.check_output that executes a command and returns the output, raising CommandError if the command fails.
13727	Find the source for a given filename, returning the actual filename and source code. Handles cases where the file is non-source, exists locally, is in a zip/egg file, or cannot be found (raises NoSource exception). Returns None for source when file exists locally, otherwise returns the source code from zip/egg files.
13728	Returns a sorted list of executed arcs in the code, converting line numbers to first line numbers using the parser.
13729	Returns a sorted list of arcs that were not executed in the code. It compares all possible arcs with executed arcs and filters out those starting with nodes in 'no_branch', then returns the sorted missing arcs.
13730	Returns a sorted list of executed arcs that are missing from the possible arcs, excluding self-referencing arcs.
13731	Returns a list of line numbers that have more than one exit.
13732	Returns the total number of branches by summing exit counts greater than 1 from the parser's exit_counts method.
13733	Return arcs that weren't executed from branch lines as a dictionary mapping branch lines to their missing destination lines.
13734	Get statistics about branches including total exits and taken exits for each line number.
13735	Set the number of decimal places used to report percentages, with validation that precision is between 0 and 9 inclusive. Updates internal thresholds for near-zero and near-100 values based on the specified precision.
13736	Returns the percentage of code coverage, calculated as the ratio of executed statements and branches to total statements and branches, or 100% if there are no statements.
13737	Returns the percent covered as a string with specified precision, ensuring values don't round to exactly 0 or 100 unless they are truly zero or 100. Values near 0 are set to self._near0 and values near 100 are set to self._near100 before rounding.
13738	Highlights all occurrences of needles in haystack by wrapping them with a span tag that has the specified CSS class name. Supports word boundaries, case sensitivity options, and handles edge cases like empty inputs. Returns the modified string with highlights applied.
13739	Given a string and a list of keywords, this function highlights all occurrences of the keywords in the string by wrapping them with a HTML span tag with a specified CSS class name. If no keywords are provided, it returns the original string. If the string is empty, it returns an empty string. The default CSS class name for highlighting is 'highlighted'.
13740	Given a string and a list of keywords, this function highlights all matched keywords in the string with a specified CSS class. It uses a text tokenizer to identify keywords and applies highlighting, returning the modified string with highlighted keywords. If no keywords or empty string is provided, it returns the original string or empty string respectively.
13741	Run a function under OS sandboxing by temporarily replacing file-related built-in functions and restoring them after execution.
13742	Remove a single pair of quotes from the endpoints of a string if present.
13743	Indent a string by a given number of spaces or tabstops, with optional flattening to remove existing indentation.
13744	Return the input string centered in a 'marquee' with specified width and border character. If no text is provided, returns a line of border characters. The text is centered by calculating appropriate padding marks on both sides. Supports custom marking characters and handles edge cases where text is too long for the specified width.
13745	Format a string for screen printing by removing latex-type format codes, specifically paragraph continuation markers.
13746	Equivalent of textwrap.dedent that ignores unindented first line. This means it will still dedent strings like: '''foo\nis a bar\n'''. For use in wrap_paragraphs.
13747	Wrap multiple paragraphs of text to fit a specified width, handling empty line separators and preserving meaningful indentation. Returns a list of wrapped paragraphs.
13748	Function to calculate optimal columnization information for a list of strings, determining the best number of rows and columns that fit within a given display width, along with optimal separator widths and column dimensions.
13749	Returns the item at index `i` from `mylist`, or `default` if the index is out of bounds.
13750	Returns a nested list representation of items arranged in columns and corresponding information for columnizing.

Parameters:
- items: list of strings to be arranged in columns
- empty: default value to fill missing positions (default: None)
- *args, **kwargs: additional arguments passed to _find_optimal for determining column layout

Returns:
- tuple: (strings_matrix, dict_info) where strings_matrix is a nested list with items arranged in rows and columns, and dict_info contains metadata about the column layout including number of columns/rows, column widths, and optimal separator width

The function determines the optimal number of rows and columns to arrange the items within the specified display width, then creates a nested list where each inner list represents a row of items. Missing positions are filled with the empty value.
13751	Collect whitespace-separated fields from string list. Allows quick awk-like usage of string lists. If no fields are specified, splits each string in the list. If fields are specified, returns the requested fields joined by spaces, ignoring IndexErrors. Supports negative indexing.
13752	Builds and returns the argument vector to be passed to the kernel subprocess, inheriting the default configuration file from the frontend application.
13753	Initialize SSH tunnels for kernel connection. Sets up port forwarding through SSH server using provided key, updates connection information with tunnelled ports, and logs connection instructions for additional clients. Returns early if no SSH server or key is configured.
13754	Pretty prints an object's representation using a RepresentationPrinter and returns the formatted string output.
13755	Prints a pretty-formed representation of an object to stdout using the RepresentationPrinter class.
13756	Returns the method resolution order (MRO) for a class, handling both old-style and new-style classes by creating a fake new-style class when necessary.
13757	A default pretty printing function that handles object representation by:
1. Checking if the object has a custom __repr__ method
2. If not, creating a formatted representation showing the class name and memory address
3. In verbose mode, displaying non-private attributes and their values
4. Handling cyclic references by showing "..." when detected
5. Properly formatting the output with indentation and grouping for readability
13758	Factory that returns a pprint function useful for sequences. Used by the default pprint for tuples, dicts, lists, sets and frozensets.
13759	Factory that returns a pprint function used by the default pprint of dicts and dict proxies.
13760	Summary: The `_super_pprint` function provides a pretty-print representation for Python's `super` type objects. It formats the output as `<super: class, object>` where `class` is the class of the super object and `object` is the instance. The function uses a pretty printer (`p`) to properly format the output with grouping, text formatting, and breaking spaces for readability.
13761	This function provides a pretty-print format for regular expression pattern objects. It formats the regex pattern with appropriate string prefix (r, ur) and handles escaped backslashes correctly. If the pattern has flags set, it displays them in a readable format using OR operators (|) between flag names. The output mimics the standard `re.compile()` function call representation.
13762	This function provides pretty printing support for classes and types in Python. It formats the display of class/type names by combining the module name and class name, with special handling for built-in types to omit the module prefix. The function takes an object, a pretty printer instance, and a cycle detection flag as parameters, and outputs the formatted class name using the pretty printer's text method.
13763	Base pprint for all functions and builtin functions. Prints function name with module prefix if applicable, formatted as '<function module.name>'.
13764	Base pprint for all exceptions that formats exception objects with their module name and arguments in a grouped format.
13765	Add a pretty printer for a given type, returning the old printer if it exists.
13766	Add a pretty printer for a type specified by module and name rather than the type object itself. Returns the old printer function if one existed.
13767	Add literal text to the output by either appending it to the current text buffer or writing directly to the output stream, updating the respective width counters and breaking outer groups when necessary.
13768	Add a breakable separator to the output that inserts the specified separator (default space) when no automatic line breaking occurs at that position.
13769	Ends a group by reducing indentation, removing the group from the stack and queue, and optionally adding closing text.
13770	Flushes remaining data in the buffer by processing each item's output and clears the buffer.
13771	Pretty prints the given object with cycle detection and supports custom printers for different types.
13772	Return a color table with fields for exception reporting, containing color schemes for 'Linux', 'LightBG', and 'NoColor' with appropriate color mappings for traceback and exception display.
13773	Writes a row of translated data to a specific sheet and row number in an ODS file, applying alternating background colors to cells and escaping apostrophes in the content.
13774	Get the current clipboard's text on Windows using pywin32 extensions, with proper clipboard handling and error handling for missing dependencies.
13775	Get the clipboard's text on OS X by executing pbpaste command and replacing old Mac line endings with newlines.
13776	Get the clipboard's text using Tkinter. This is the default on systems that are not Windows or OS X. It may interfere with other UI toolkits and should be replaced with an implementation that uses that toolkit.
13777	Returns a safe build prefix directory path, creating it if necessary and verifying proper ownership on non-Windows systems. On Windows, returns the path directly since temporary directories are isolated. Raises InstallationError if the temporary folder is not owned by the current user or is a symlink on non-Windows systems.
13778	Rekeys a dictionary by converting string representations of integers and floats back to their numeric types, handling JSON-processed dictionaries where numeric keys were converted to strings. Raises KeyError if duplicate keys would result from the conversion.
13779	Extract ISO8601 dates from unpacked JSON by recursively traversing dictionaries, lists, and tuples, converting matching string dates to datetime objects while preserving the original data structure.
13780	squash_dates: Recursively converts datetime objects within nested data structures (dicts, lists, tuples) to ISO8601 string format, while preserving the original structure. For dictionaries, it creates a copy to avoid modification issues; for lists and tuples, it processes each element recursively; for datetime objects, it formats them using ISO8601 format string. Returns the modified object with all datetime objects converted to strings.
13781	A helper function that converts datetime objects to ISO 8601 format strings for JSON serialization, raising a TypeError for non-serializable objects.
13782	Clean an object to ensure it's safe to encode in JSON by converting mutable types and handling potential key collisions. Atomic types are returned unchanged, while sets, tuples, and generators are converted to lists. Lists and dictionaries are recursively cleaned, with dictionaries checked for key collision issues. Non-JSON-safe objects are converted to their string representations.
13783	Verify that the installation directory is a .pth-capable directory, check write permissions, and set up .pth file handling based on whether the directory is a site directory and multi-version installation settings.
13784	Write an executable script file to the specified installation directory with proper permissions and logging.
13785	A simple function that takes two arguments, prints a message with the id of the current process, flushes the output buffer, sleeps for a specified time, and returns the original arguments.
13786	Creates and returns an ArgumentParser instance for parsing command arguments, including version and custom arguments.
13787	Convert .pyx source files to .c source files by replacing .pyx extension with .c extension in the sources list.
13788	Watch iopub channel and print messages from Jupyter kernel, handling stream output and Python tracebacks.
13789	Creates and returns a PackageFinder instance configured with the specified options and session parameters for package installation.
13790	Adjusts the logging level when the log_level property changes, converting string level names to logging module constants and setting the new level on the logger object.
13791	Start logging for this application with default stdout logging using StreamHandler, setting log level from log_level attribute and using log_format for formatting, with special handling for pythonw.exe which directs output to os.devnull.
13792	Validates that the flags dictionary has correct structure with each value being a list of exactly 2 elements: first element must be a dict or Config object, second element must be a string.
13793	Print the alias part of the help text, showing how command-line aliases map to full configuration names and their help documentation.
13794	Print the flag portion of the help documentation, displaying each flag with its corresponding help text indented below it.
13795	Print the subcommand section of the help documentation, including subcommand names and their descriptions, formatted with proper indentation and spacing.
13796	Print help information for Configurable classes. If classes=False (default), only prints flags and aliases. If classes=True, prints detailed help for each class including class parameters and all configurable options. Also prints a message directing users to `--help-all` for seeing all available configurables.
13797	Print usage examples from the examples attribute, displaying them with proper indentation and formatting under an "Examples" header.
13798	Summary: Updates the configuration by merging a new config with the current one and triggers traits events through assignment to self.config.
13799	Initializes a subcommand with the given argv by importing the subapp if needed, clearing existing instances, creating a new instance, and initializing it with the provided arguments.
13800	```python
def flatten_flags(self):
    """Flatten flags and aliases to ensure command-line arguments override config files appropriately.
    
    This method resolves conflicts that occur when aliases point to different classes in the MRO
    hierarchy. Only aliases with exactly one descendant in the class list are promoted to avoid
    ambiguous references.
    
    Returns:
        tuple: A tuple containing (flattened_flags, flattened_aliases) where:
            - flattened_flags: Dictionary mapping flag keys to (updated_flag_dict, help_string)
            - flattened_aliases: Dictionary mapping alias names to updated 'Class.trait' strings
    """
```
13801	Parse command line arguments, handle subcommands, help flags, and version options, then load configuration and store unparsed arguments.
13802	Loads a Python configuration file by filename and path, handling exceptions during file loading and updating the configuration if successful.
13803	Generate a default configuration file by combining class configuration sections from Configurables. Returns a string containing the complete config file with header, config object declaration, and all class sections.
13804	Choose k random elements from array by sampling indices and returning corresponding elements.
13805	Format information into aligned text lines with labels and data, handling both single values and lists/tuples of data items.
13806	Write a line of debug output to the output stream, optionally prepending the process ID if enabled.
13807	Update class traits with config=True metadata by loading values from configuration sections, iterating through the method resolution order to find Configurable parent classes, validating trait names don't start with uppercase letters, and setting trait values with deep copying to prevent shared mutable objects between instances.
13808	Get the help string for a class in ReST format, optionally using instance trait values instead of class defaults.
13809	Get the help string for a single trait, including its header, current/default value, enum choices, and help text, with optional instance-specific values.
13810	Generate configuration section documentation for a class, including class description, parent class inheritance information, and detailed trait configurations with their help text and default values.
13811	Clears the singleton instance for the specified class and its parent classes in the method resolution order, but only removes instances that are actually instances of the calling class.
13812	Returns a global instance of the class, creating it if necessary. If an instance already exists, it returns the existing instance instead of creating a new one. The method passes any arguments and keyword arguments to the class's `__init__` method during instantiation. It ensures that subclasses share the same instance through the method resolution order (MRO), making it useful for implementing singleton patterns. If multiple incompatible subclass instances are detected, it raises a MultipleInstanceError.
13813	Add detail from traceback inspection to error message of a failure.
13814	A lightweight exception handler that prints the standard traceback followed by a configuration message. If running in an interactive shell environment, it shows IPython magic command examples; otherwise, it displays generic configuration syntax. The handler outputs a formatted message containing author email and configuration prefix to stderr.
13815	Reimplements the flush method to ensure immediate signal dispatching by processing Qt events after calling the parent flush method.
13816	Method `start_channels` reimplements the parent class method to emit a `started_channels` signal after starting channels.
13817	Read a notebook from a file like object by reading all content and processing it through reads method.
13818	Read from a pipe ignoring EINTR errors, necessary when reading from pipes with GUI event loops that may raise interrupts.
13819	Open a command in a shell subprocess and execute a callback, providing common scaffolding for subprocess.Popen() calls with proper cleanup and error handling.
13820	Split a command line's arguments in a shell-like manner, with support for unicode input and optional strict error handling. Returns a list of tokens, preserving quoted strings and handling parsing errors gracefully when strict=False.
13821	Compresses a directory history list to at most 20 entries by keeping the first 10 unique elements (removing duplicates) and the last 10 elements.
13822	Class decorator for Magics subclasses that registers line and cell magics by copying global magic data to class instance and clearing the global storage. Not thread-safe during subclass creation but safe for instantiation.
13823	Stores a function as a magic of a specific kind in a dictionary with 'line' and 'cell' subdicts, handling the special 'line_cell' case where the function is stored in both subdicts.
13824	Decorator factory for creating magic method decorators in Magics subclasses that can be called both with and without arguments, supporting both string names and function objects while maintaining proper documentation.
13825	Decorator factory for creating standalone magic functions in IPython. Takes a magic_kind parameter and returns a decorator that can be applied to functions to register them as IPython magic functions. The decorator can be used in two ways: as a naked decorator (@magic) or with arguments (@magic('name')). It validates that get_ipython() is available in the caller's namespace and registers the decorated function with the specified magic kind. The resulting decorator includes documentation about proper usage in IPython contexts.
13826	Return a dictionary containing documentation for magic functions, organized by magic type ('line' and 'cell'). Each magic type maps to a dictionary of magic names and their docstrings. If brief=True, only the first line of each docstring is returned. If a docstring is unavailable, the `missing` parameter value is used instead.
13827	Registers one or more magic classes or instances with IPython, making their decorated line and cell magic methods available using %x/%%x syntax. Validates that magic classes are properly decorated, instantiates classes if needed, and updates the registry and magic tables.
13828	Registers a standalone function as an IPython magic function (line, cell, or both) by creating a method in user_magics and recording it in the global magic table, with optional custom magic name.
13829	Format a string for LaTeX inclusion by escaping special characters, formatting magic commands and headers, and handling line breaks.
13830	Parse options from an argument string using getopt-like functionality, returning a Struct with options and remaining arguments. Handles both short and long options, supports POSIX mode, and allows for different return modes ('string' or 'list'). Processes quoted argument strings using shlex.split for variable expansion and globbing. Returns a tuple of (options_struct, remaining_args).
13831	Set an option string for a magic function in the options table.
13832	Function `page_guiref` displays a basic GUI Console reference guide using IPython's paging functionality. It optionally accepts an argument `arg_s` (default None) and shows the `gui_reference` content in a paginated format with auto HTML conversion enabled. The function imports and uses `IPython.core.page` module to handle the display.
13833	Factory function to create a properly initialized task with callable, label, schedule, userdata, and optional primary key override.
13834	Returns a task info dictionary from a given task label by retrieving the task object and parsing its function info JSON data.
13835	Find and return a callable object from a task info dictionary based on function type, handling instance methods, class methods, static methods, and regular functions.
13836	Calculate the next run time for this task based on its schedule, handling initial execution and subsequent runs with cron-like scheduling.
13837	Submits the task for immediate execution by sending it to the RUN_TASK_CHANNEL with the task's primary key and timestamp.
13838	This method executes a task callable within a worker process, handling task lifecycle management including iteration tracking, task disabling, and cleanup notifications. It processes a message by calling the configured callable with task metadata, then manages task continuation based on iteration count and scheduling constraints, sending kill signals to channels when tasks complete or exceed their iteration limits.
13839	Runs the task immediately, updates last run time, calculates next run time, saves the task, and submits it for execution.
13840	Class method to execute a callable function for a specified number of iterations with optional scheduling and timing controls.
13841	Runs a one-shot task immediately using the class's iteration runner method.
13842	Set the URL file path using the profile directory's security directory and URL file name when no URL file is initially provided.
13843	**bind_kernel(self, \*\*kwargs)**

Promotes the engine to a listening kernel that can be accessed by frontends. This method initializes and binds the necessary ZeroMQ sockets for shell, iopub, and stdin communication channels, sets up the kernel application instance, and writes the connection file.

**Key functionalities:**
- Checks if kernel is already bound (returns early if so)
- Configures kernel application with default parameters including config, log, profile_dir, and session
- Initializes connection file and binds three communication channels:
  * Shell ROUTER channel
  * IOPub PUB channel  
  * Stdin ROUTER channel
- Starts heartbeat and logs connection information

**Parameters:**
- `**kwargs`: Additional keyword arguments passed to IPKernelApp instantiation

**Side effects:**
- Creates and configures IPKernelApp instance
- Binds ZeroMQ sockets for kernel communication
- Writes connection file for frontend connections
- Sets up heartbeat monitoring

**Note:** Method only executes if `self.kernel_app` is None, preventing reinitialization.
13844	Executes a test described by a YAML file, optionally checking syntax or running extensions. It reads test steps, processes them sequentially, and returns an error message if any step fails, otherwise returns None.
13845	Creates an interrupt event handle for process communication on Windows, with inheritance permissions enabled, that can be used to send interrupts to child processes.
13846	Run the poll loop. This method never returns. It listens forever for events on configured handles (interrupt and parent handles) using Windows API WaitForMultipleObjects. When an event occurs, it either calls interrupt_main() for interrupt_handle or exits the process with os._exit(1) for parent_handle. If the wait fails, it issues a warning and returns.
13847	Filter a namespace dictionary by name pattern and item type, returning a dictionary of items that match the specified criteria.
13848	Return dictionary of all objects in a namespace dictionary that match type_pattern and filter, supporting nested filtering through dot notation.
13849	Check for mutually exclusive keys in a dictionary against provided pairs of exclusive options, raising ValueError if both options in any pair are present.
13850	This function handles drawing figures in interactive matplotlib environments by:

1. Getting the active figure from the current figure manager
2. Adding a `show()` method to figure objects if it doesn't exist (for backward compatibility)
3. Checking if matplotlib is in interactive mode to avoid duplicate plots when manually set to non-interactive
4. Managing a queue of figures to be drawn by removing duplicates and appending the current figure to a draw list
5. Setting a flag indicating that a draw operation has been called

The function ensures figures are properly queued for display in interactive sessions while preventing duplicate drawings when users manually disable interactive mode.
13851	## Summary

The `flush_figures()` function sends all changed figures in matplotlib. It's designed to be used as a post_execute callback in IPython to automatically display figures that were modified during code execution.

**Key behaviors:**
- If no drawing has occurred, it returns early
- If inline backend is configured to close figures, it draws and closes all figures
- Otherwise, it sends only active (non-closed) figures that have been marked for drawing
- Errors are handled gracefully in IPython by showing tracebacks rather than raising exceptions
- Clears tracking flags after processing

**Error handling:**
- In IPython environment: shows traceback for exceptions
- Outside IPython: allows exceptions to raise normally

**Purpose:**
Automatically manages figure display in interactive environments, particularly useful for Jupyter notebooks and IPython shells.
13852	Sends a figure as a PNG or SVG payload by drawing it and publishing it with the appropriate MIME type.
13853	Loads an IPython extension by module name and returns the result of its load_ipython_extension function if it exists.
13854	Unload an IPython extension by its module name by looking it up in sys.modules and calling mod.unload_ipython_extension(self).
13855	Generate a list of n random ports near the given port, where the first 5 ports are sequential and remaining ports are randomly selected in the range [port-2*n, port+2*n].
13856	Initialize Tornado webapp and HTTP server with SSL options, bind to available port, and handle port conflicts.
13857	Handles SIGINT signal by spawning a background thread to show confirmation dialog and registering a more forceful signal handler for consecutive ^C presses.
13858	Method `_confirm_exit(self)` confirms notebook server shutdown on Ctrl+C interruption. It prompts user for confirmation within 5 seconds, and if user answers 'y' or provides no answer, it stops the IOLoop and shuts down the server. Otherwise, it restores the original SIGINT handler. This functionality does not work on Windows.
13859	Shutdown all kernels explicitly to allow KernelManagers to cleanup connection files, copying the kernel_ids list to avoid modification during iteration.
13860	Price European and Asian options using Monte Carlo simulation, returning tuple of (European call, European put, Asian call, Asian put) prices.
13861	Function that replaces all occurrences of dictionary keys in given text with their corresponding values using regular expressions.
13862	Render a prompt without justification or width updates, supporting color formatting and different prompt types.
13863	Launches a localhost kernel by executing Python code with specified arguments and stream redirection, handling platform-specific considerations like Windows interrupt events and process group management. Returns a tuple containing the kernel process and port information.
13864	Creates a zipfile archive of the project and copies it to the working directory with version-specific naming.
13865	Fix the version in metadata.txt by updating the version line with the new version from context, if prerequisites are met.
13866	Returns True if an object is mappable (either a tuple or list, or an instance of any type in arrayModules), False otherwise.
13867	Returns the pth partition of q partitions of seq by calculating partition boundaries and slicing the sequence accordingly.
13868	This function patches the pexpect.spawn class's __del__ method to handle cases where it might be called during Python VM teardown. It prevents unhandled exceptions by adding a try-except block around the close() call, since built-in modules like 'os' may be reset to None during VM shutdown, causing os.close() to fail. The patch only applies to pexpect versions below 2.2, as the issue is already fixed in newer versions.
13869	Run a file interactively by opening it and executing its contents through run_source, then return the output if requested.
13870	Run the given source code interactively, with options to capture output and start interactive mode. Returns captured output if requested.
13871	Generate a Cobertura-compatible XML coverage report for the given modules/files and write it to the specified output file. Returns the overall coverage percentage.
13872	Adds a single file's coverage data to the XML report, including line and branch coverage statistics. Creates XML elements for the class, lines, and methods, populates them with coverage information, and updates package-level statistics. Handles both line coverage and branch coverage when enabled.
13873	The `fetch_pi_file` function downloads a segment of pi from super-computing.org if the specified file doesn't already exist locally. It checks for the file's existence using `os.path.exists()`, and if the file is missing, it downloads it using `urllib.urlretrieve()` from the FTP directory "ftp://pi.super-computing.org/.2/pi200m/".
13874	Add up a list of frequency counts to get the total counts.
13875	Read digits of pi from a file and compute the n digit frequencies.
13876	Reads digits of pi from a text file and yields them one by one as the specified type, skipping newline and space characters.
13877	Computes frequency counts of single digits from input digits, optionally normalizing the results to sum to 1.0. Takes an iterable of digits and a boolean flag for normalization, returns a numpy array of counts for digits 0-9.
13878	Function `two_digit_freqs` takes an iterator of digits and computes frequency counts of consecutive 2-digit combinations. It initializes a numpy array of zeros with size 100 (for digits 00-99), iterates through the input digits consuming pairs of consecutive digits, and increments the corresponding frequency counter for each 2-digit combination. If normalization is requested, it returns normalized frequencies; otherwise, it returns raw frequency counts. The function effectively tracks how often each 2-digit sequence appears in the input stream.
13879	Function `n_digit_freqs` computes frequency counts of n-digit sequences from a stream of digits. It maintains a sliding window of size n, updates frequency counts for each n-digit sequence, and optionally normalizes the counts to sum to 1. The function uses a numpy array to store frequency counts and processes digits sequentially, making it efficient for analyzing digit patterns in sequences like pi.
13880	Plot two digits frequency counts using matplotlib, displaying frequencies in a 10x10 matrix format with color mapping and digit labels on axes.
13881	Plots single digit frequency counts in pi using matplotlib with blue circles connected by lines, including title and axis labels.
13882	Prints the value of an expression from the caller's frame with debug information, showing the expression, its value, and the calling function name.
13883	User-friendly wrapper around Django's reverse function that supports query parameters. Takes view name and arguments, with an optional 'query' keyword argument containing GET parameters to append to the URL. Returns the reversed URL with query string if provided, otherwise just the reversed URL.
13884	Returns True if base begins with an underscore but does not both begin and end with double underscores, indicating a "private" name convention. Deprecated - use DocTestFinder.find() instead.
13885	Creates a unittest suite for one or more doctest files with various configuration options including module-relative paths, setup/teardown functions, global variables, and doctest options.
13886	Debugs a single doctest docstring by converting it to a script and then debugging that script.

**Parameters:**
- src: The doctest docstring to debug
- pm: Whether to enter post-mortem debugging mode (default: False)
- globs: Global namespace to use for execution (default: None)

**Returns:**
- None

**Side effects:**
- Executes the doctest code in debug mode
- May enter post-mortem debugging session if pm=True
13887	Debug a test script by writing it to a temporary file and executing it under the Python debugger (pdb). If the pm (post-mortem) flag is True, it executes the script and enters post-mortem debugging on exception; otherwise, it runs the script in pdb's interactive mode. The temporary file is cleaned up after execution.
13888	Debug a single doctest docstring by providing the module and object name, then execute the debug script with the test source code.
13889	Get all data contained in hashed category 'hashroot' as dict by iterating through hashed files, updating the result dictionary, handling corrupt files, and returning the combined data.
13890	Compresses a hash category by consolidating all its files into a single 'xx' file, then removes the individual files. This operation optimizes hset performance but causes hget to fail for compressed items when fast_only is True.
13891	Returns all keys in the database, or all keys matching an optional glob pattern. If no pattern is provided, returns all files in the root directory. If a pattern is provided, returns files matching that glob pattern. All returned paths are normalized.
13892	Returns whether a record should be printed based on filter rules. If no filters exist, returns True. Otherwise, returns True only if the record passes all allow rules and fails all deny rules.
13893	Returns True if `record` starts with any item in `matchers`, where a match occurs when `record` equals the matcher or starts with the matcher followed by a period.
13894	Add captured log messages to error output by formatting log records and appending them to the error message.
13895	The `embed` function creates and calls an IPython interactive shell instance at the current point in the program. It uses a global shell instance that's created on first invocation and reused for subsequent calls. The function accepts configuration parameters and an optional header string for the shell prompt. When called, it launches an interactive Python environment where users can inspect variables and execute code. The function supports customization through a config argument and automatically loads a default configuration if none is provided.
13896	Embeds IPython into a running Python program with specified namespaces and stack depth, handling deprecated global_ns parameter, updating user namespaces, setting up tab-completion, interacting with the user, and cleaning up temporary variables after interaction.
13897	Prepare new CSV writers for transaction and metadata files, write the title rows, and return the writers.
13898	Prepare locale directories for writing PO files by creating new directories if they don't exist. Returns a list of language codes.
13899	Write msgstr for every language with all needed metadata and comment. Metadata are parsed from string into dict, so read them only from gdocs.
13900	Writes a header to a PO file for a specific language, including metadata from settings file.
13901	Method to subscribe a user to a service by sending a POST request with the username to the subscribe_user endpoint.
13902	Initializes an option parser for command-line arguments with options for user credentials, recipient, label, title, callback URL, and message type, returning the parser, options, and arguments.
13903	Run a Python module as if executing `python -m name args...` by finding the module file and executing it with the provided arguments.
13904	Run a Python file as if it were the main program on the command line, setting up the appropriate module environment and sys.argv, then execute the file's code and handle exceptions properly.
13905	Returns a code object compiled from the source file specified by `filename`. Reads the source file, ensures it ends with a newline character, and compiles it using Python's `compile()` function in "exec" mode. Raises `NoSource` exception if the file cannot be opened.
13906	Extracts a code object from a .pyc file by reading its magic number header and marshaled code content. Raises NoCode exception if file is not found or has invalid magic number. Closes file handle properly in finally block.
13907	Returns an HTML table string from a 2D list of items, with optional header, footer, and selected cell highlighting.
13908	Sets the current cursor position and adjusts the visible range accordingly, ensuring the cursor stays within bounds and maintaining sticky alignment with min/max values when close to edges.
13909	Cancel the completion by resetting internal variables and clearing the temporary buffer in the console widget.
13910	Method `_select_index(self, row, col)` updates the selection index while ensuring it stays within valid bounds, implementing a toroidal (wrap-around) logic for navigation through a grid. The method handles six distinct cases for out-of-bounds indices:

1. When both row and column exceed maximum values  wraps to (0, 0)
2. When both row and column are below minimum values  wraps to (nr, nc) 
3. When row exceeds maximum  wraps to (0, col+1)
4. When row is below minimum  wraps to (nr, col-1)
5. When column exceeds maximum  wraps to (row+1, 0)
6. When column is below minimum  wraps to (row-1, nc)

For valid indices within bounds, it sets the internal `_index` attribute. Invalid cases raise `NotImplementedError`. The method uses a toroidal mapping where the grid wraps around both horizontally and vertically.
13911	Move cursor up by one row in the selection.
13912	Move cursor down by one row while maintaining current column position.
13913	Move cursor left by one position.
13914	Move cursor right by one column position.
13915	Updates the completion list display with optional highlighting of the currently selected item, showing a justified view with sliding interval and pagination indicators.
13916	Return a dictionary of words and word counts in a string, optionally reading from a file.
13917	Print the n most common words and their counts from a frequency dictionary, sorted in descending order by count.
13918	Return the string representation of the job description XML by converting the element tree to string, applying indentation, removing attribute ordering tokens, and adding XML declaration.
13919	Write the XML job description to a file by converting it to a string and saving it to the specified filename.
13920	Validates a pin against the defined schema and raises DocumentError if validation fails.
13921	Send a shared pin for the given topics by making a PUT request to the API endpoint, with optional validation. Raises DocumentError if validation fails and HTTPError if an HTTP error occurs. Requires api_key to be set.
13922	Delete a shared pin by its ID using a DELETE request, raising an HTTPError for any HTTP errors and requiring a valid API key.
13923	Send a user pin by making a PUT request to the API endpoint. Validates the pin data unless skip_validation is True. Raises DocumentError for validation failures and HTTPError for HTTP errors.
13924	Delete a user pin by sending a DELETE request to the API endpoint. Raises HTTPError if the request fails.
13925	Subscribe a user to the given topic using the provided user token. Raises HTTPError if an HTTP error occurs.
13926	Get the list of topics that a user is subscribed to using their authentication token.

**Parameters:**
- `user_token` (str): The user's authentication token

**Returns:**
- list: The list of topics the user is subscribed to

**Raises:**
- `requests.exceptions.HTTPError`: If an HTTP error occurs during the request

**Example:**
```python
topics = client.list_subscriptions("user_token_123")
print(topics)  # ['topic1', 'topic2', 'topic3']
```
13927	A decorator that automatically manages progress monitoring for functions by beginning and ending tasks on a progress monitor. The decorated function must have a 'monitor' parameter, and the decorator handles injecting a NullMonitor if none is provided. It uses the function's signature to locate the monitor parameter and manages the task lifecycle with a context manager.
13928	Initializes a progress monitor with total work amount, optional name, and message. Sets up the monitor state and displays initial progress.
13929	A context manager method that sets up and tears down a monitoring task with a specified total count, name, and message. It begins monitoring with the provided parameters, yields control to the enclosed code block, and ensures monitoring is properly ended even if an exception occurs.
13930	Create a submonitor with given units, yield it to the caller, and ensure proper cleanup by updating progress when the subtask completes or is abandoned.
13931	Update the progress monitor by incrementing worked units and notifying listeners.

This method increments the monitor's worked counter by the specified number of units (defaulting to 1) and optionally updates the progress message. It includes bounds checking to ensure worked units don't exceed the total, and triggers notifications to all registered listeners. The method raises an exception if called before the monitor has been initialized with a total.
13932	Creates a sub-monitor that represents a specified number of work units from this monitor. The sub-task must call .begin() before updating. Returns the new sub-monitor instance.
13933	Signal that this task is done by calling update with remaining work, using a default message if none provided.
13934	Page a string by sending it to IPython's payload system for display in a pager, with optional HTML conversion of reStructuredText input. The function handles negative start offsets by clamping them to 0, and supports automatic conversion of reStructuredText to HTML using docutils if requested. The actual paging is handled by IPython's payload system rather than traditional pagers.
13935	Moves a package from a temporary build directory to a more permanent location, creating the destination directory if needed and raising an error if a package already exists at the destination.
13936	Loads multiple Python configuration files from a specified path, merging them into a single configuration object. Returns the merged configuration.
13937	Load configuration from file and return it as a Struct by clearing current config, finding the config file, reading it as dictionary, converting it to config format, and returning the config.
13938	Load the config file into self.config with recursive loading support, allowing sub-configs to be loaded with load_subconfig() and providing access to current config via get_config().
13939	Load configuration flags from a dictionary or Config object, updating existing configuration sections rather than replacing them entirely. Raises TypeError for invalid flag types.
13940	Decode argv if bytes, using stdin.encoding, falling back on default enc.
13941	Parse configuration from command-line arguments and generate a Config object, handling key-value pairs, flags, and storing unrecognized arguments in extra_args.
13942	Load configuration by parsing command line arguments and return it as a Config object.
13943	Parses command-line arguments using the object's parser, decoding arguments to support unicode and storing parsed data and extra arguments.
13944	Convert parsed data to config format, handle subconfigs and extra arguments using KVLoader.
13945	Function `find_module` locates a Python module by name and returns its file path. It searches through specified paths or sys.path if no paths are provided. The function returns the full path to the module if found and has a .py or .pyc extension, otherwise it returns None. It handles ImportError exceptions and properly closes file handles when necessary.
13946	Registers a callback to be called with the launcher's stop_data when the process finishes. If the launcher is already in 'after' state, immediately calls the callback with stop_data. Otherwise, stores the callback for later execution.
13947	Method: notify_start(self, data)
Description: Triggers startup actions by logging process startup, setting state to 'running', and returning the provided data.
Parameters: 
- data: Startup data to be stored and returned
Returns: The input data parameter
Side effects: Logs debug message, stores data in self.start_data, sets self.state to 'running'
13948	Method `notify_stop(self, data)` triggers process stop actions by logging the stop event, storing the stop data, setting the process state to 'after', and executing all registered stop callbacks with the provided data. Returns the stop data.

**Key operations:**
1. Logs process stopping with debug level
2. Stores stop data in `self.stop_data`
3. Sets process state to 'after'
4. Executes all stop callbacks in reverse order
5. Returns the stop data
13949	Send SIGINT signal to the process, then after a specified delay send SIGKILL signal to terminate it. If the SIGINT signal fails, log a debug message and continue with the SIGKILL. The delay is specified in seconds and defaults to 2.0 seconds. The kill operation is scheduled using a delayed callback in the IOLoop.
13950	Build and return a list of command-line arguments by concatenating MPI command, process count, MPI arguments, program name, and program arguments.
13951	Start n instances of the program using mpiexec.
13952	Send a single file from local path to remote location via SCP, with retry logic waiting up to 10 seconds for the local file to exist.
13953	Fetch a single file from remote location to local path, with retry logic to wait up to 10 seconds for the remote file to exist.
13954	Method `engine_count` determines the total engine count from the `engines` dictionary by iterating through its values. For each value, if it's a tuple or list, it extracts the first element as the engine count; otherwise, it uses the value directly. It accumulates these counts and returns the total engine count.
13955	Start engines by profile or profile_dir. The `n` parameter is ignored and the `engines` config property is used instead. It iterates through engine configurations, handles user and host information, and launches engines with appropriate delays and arguments. Each engine launcher is configured with engine command, arguments, and callbacks, then started and stored in launchers dictionary. Finally, it notifies about the start and returns a list of deferred objects.
13956	Start n copies of the process using the Win HPC job scheduler by writing a job file, submitting it with specified arguments, parsing the job ID from the output, and notifying of the start.
13957	Returns a dictionary with default context values for basic keys (n=1, queue='', profile_dir='', cluster_id='').
13958	Parse the job ID from the submit command output using a regular expression. If successful, store and return the job ID; otherwise, raise a LauncherError.
13959	Writes a batch script to the work directory based on template priority (batch_template_file > batch_template > default_template), adds job array and queue settings if needed, formats the template with context, writes to file, and sets appropriate permissions.
13960	Start n copies of the process using a batch system, write batch script, execute with check_output, parse job ID, notify start, and return job ID.
13961	Returns a custom context menu for images with copy/save options, or the default menu if no image is present at the given position.
13962	Append raw JPG data to the widget.
13963	Append raw PNG data to the widget using a custom insertion method.
13964	Append raw SVG data to the widget.
13965	Adds a QImage to the document and returns a QTextImageFormat that references it.
13966	Copies the ImageResource with the specified name to the clipboard.
13967	Returns the QImage stored as the ImageResource with the specified name from the document's resources.
13968	Inserts a raw image (jpg or png) into the document at the current cursor position, handling invalid image data gracefully by inserting a placeholder text instead.
13969	Inserts raw SVG data into the widget by converting it to an image, adding it to the document, and storing the original SVG data. If the SVG data is invalid, inserts plain text error message instead.
13970	Saves an image resource by showing a save dialog and writing the image data to the selected file path.
13971	When `exit_now` changes to True, stops the event loop after a 0.1 second delay.
13972	Initialize and configure the environment variables for optimal terminal behavior and paging control. Sets TERM to 'xterm-color' and CLICOLOR to '1' for colored output, configures PAGER and GIT_PAGER to 'cat' to disable paging in subprocesses, and installs the payload version of page.
13973	Method `auto_rewrite_input` is called to display the auto-rewritten input for autocall functionality. It takes a command string as input, renders a rewrite prompt using the prompt manager, and creates a payload containing the transformed input. This payload is then written to the payload manager for frontend processing, though there's a FIXME comment indicating the frontend currently doesn't process this payload correctly.
13974	Method: ask_exit
Summary: Configures the shell to exit by setting the exit flag and writing a payload with exit information including source, exit status, and kernel retention settings.
13975	Sets the text to be displayed in the next input cell by sending it as a payload to the frontend.
13976	Read a filename as UTF-8 configuration data.
13977	Read a list of strings from a configuration file section. The value is treated as a comma- and newline-separated list of strings, with whitespace stripped from each value. Returns the list of strings.
13978	Reads a list of full-line strings from a configuration file section and option, where each line is treated as a separate string in the returned list. Returns the list of strings with whitespace stripped.
13979	Read configuration from the `env_var` environment variable, setting `self.timid` to True if '--timid' is found in the environment variable's value.
13980	Read config values from keyword arguments, converting string values to lists for keys specified in MUST_BE_LIST.
13981	Read configuration from a .rc file and parse it using HandyConfigParser, updating config_files, attributes, and paths accordingly.
13982	Sets an attribute on self from a ConfigParser option if it exists. Gets the option value using the specified type_ method and assigns it to the given attribute name.
13983	Expands '~'-style usernames in strings, similar to `os.path.expanduser`, but also returns additional information about the expansion. If the input string starts with '~', it expands the username and returns the expanded path, a boolean indicating whether expansion occurred, and the value that '~' was replaced with. If no '~' is present, it returns the original path with `tilde_expand` set to False.
13984	Sets the delimiters for line splitting by creating a regular expression pattern from the provided delimiters and compiling it for use in splitting lines.
13985	Split a line of text at the last delimiter before the cursor position, or at the end of the line if no cursor position is specified.
13986	Compute matches for a simple name by finding all keywords, built-in functions, and defined names that start with the given text from namespace and global_namespace.
13987	Compute attribute matches when text contains a dot by evaluating the expression before the last dot and using its attributes as possible completions, with support for greedy matching and limiting to __all__ entries.
13988	When greedy mode is changed, updates the splitter delimiters accordingly and syncs the readline completer delimiters if readline is active.
13989	Matches filenames, expanding ~USER strings, handling spaces and special characters in filenames. It manages quoted strings, protects filenames with spaces, and marks directories with trailing slashes.
13990	Matches internal system aliases that start with the given text, excluding cases where we're in the middle of a command (unless it's 'sudo'). Returns a list of matching aliases.
13991	Match attributes or global Python names, handling dotted names by using attribute matches with optional filtering of names starting with underscores, or global matches for simple names.
13992	Return the list of default arguments of a callable object, or empty list if not callable.
13993	Find completions for the given text and line context, returning the text actually used and a list of completion matches. The method handles optional parameters for text, line buffer, and cursor position, and uses custom completers and matchers to generate completions, finally returning sorted unique matches.
13994	Return the state-th possible completion for 'text' by using readline's completion system, handling special cases like whitespace-only lines and debugging options, and managing the completion matches array.
13995	Check if a specific record matches all tests by iterating through each key-test pair and returning False if any test fails, otherwise return True.
13996	Find all records that match the criteria specified in the check dictionary, where each key-value pair represents a field and its expected value. For dictionary values, use CompositeFilter for complex matching; for simple values, use equality comparison. Return a list of copies of matching records.
13997	Extract a subdictionary containing specified keys from a record, including the 'msg_id' key.
13998	Should we silence the display hook because of ';'? Checks if the current input cell ends with ';' to determine if output should be suppressed. Returns True if silencing is needed, False otherwise. Handles IndexError gracefully for edge cases.
13999	Writes the output prompt to stdout using the shell's separate_out and rendered 'out' prompt, with conditional caching support.
14000	Write format data dictionary to frontend by printing its plain text representation to stdout, handling multiline strings properly by managing prompt alignment and newlines according to IPython behavior standards.
14001	Logs the output by writing it to the logger if enabled, and stores the plain text representation in the history manager's output history.
14002	Raises `InvalidOperationException` if the object is frozen, providing a descriptive error message indicating the object's type and frozen state.
14003	Convert a MySQL TIMESTAMP to a Timestamp object by parsing the string format and handling different timestamp formats appropriately.
14004	Schedules a call to enter the event loop from the IOLoop after a 0.1 second delay when the event loop changes.
14005	Dispatches control requests by extracting identities, unserializing messages, logging received control messages, and routing to appropriate handlers based on message type. Unknown message types are logged as errors, and exceptions in handlers are caught and logged.
14006	Dispatches shell requests by handling message routing, logging, and execution. Processes incoming messages by:
1. Flushing control stream if exists
2. Parsing and validating messages using session
3. Logging message details for debugging
4. Handling aborted messages with reply status
5. Looking up and executing appropriate shell handlers
6. Managing SIGINT signal handling during execution
Returns early if message is aborted or handler is unknown, with proper error logging
14007	Register dispatchers for control and shell streams, setting up message handling callbacks for each stream.
14008	Summary: Executes a single iteration of the event loop by flushing control and shell streams, handling at most one request per shell stream.
14009	Publishes a code execution request to the pyin stream on IOPub.
14010	Abort a specific message by ID, adding it to aborted set and sending abort reply.
14011	Clears the shell namespace and sends a successful clear reply message.
14012	Returns the prefixed topic string for IOPub messages, formatted as "engine.INT_ID.topic" for valid integer IDs or "kernel.IDENT.topic" for negative IDs, with the result encoded as bytes.
14013	Method `_at_shutdown` performs cleanup actions at kernel shutdown by sending a shutdown message through the IOPub socket if one exists, and flushing all shell streams.
14014	Copy sys.modules onto my mod stack
14015	Restore sys.modules to its previous state by popping from mod stack and removing newly added modules.
14016	Return absolute, normalized path to directory, if it exists; None otherwise.
14017	A function that determines if a name is "file-like" based on four conditions: the name exists as a file path, has a directory component, ends with '.py' extension, or is not a valid Python identifier.
14018	Returns True if obj is a class, False otherwise. Unlike inspect.isclass, this function properly excludes objects that can't be subclasses of anything by checking if the object's type is in class_types or is a subclass of type.
14019	Check if a given path is a package directory by verifying it's a directory with a valid Python identifier name and contains __init__.py file.
14020	Finds the full dotted package name for a given Python source file or directory. Returns None for non-Python files. Handles various cases including regular modules, __init__.py files, and absolute paths. Works by traversing up the directory structure while checking for package boundaries.
14021	Draw a 70-character-wide divider with the given label centered in the middle. The divider consists of dashes on both sides of the label, evenly distributed to make the total width exactly 70 characters. If the label length (plus 2 for surrounding spaces) doesn't divide evenly into the available space, any extra padding is added to the right side.
14022	Sort key function factory that puts items matching a regular expression last by returning (1, obj) for matches and (0, obj) for non-matches, ensuring matching items appear after non-matching ones when sorted.
14023	Transplant a function from one module to another, making it appear as if it's located in the target module while maintaining the original function unchanged. The transplanted function acts as a wrapper that calls the original function.
14024	Make a class appear to reside in a different module by creating a subclass with the specified module name and name attributes.
14025	Return system CPU times as a namedtuple containing user, nice, system, and idle times.
14026	Return process command line as a list of arguments for the given process ID. Raises NoSuchProcess if the process does not exist.
14027	Return files opened by process. If process ID is 0, returns empty list. Otherwise, gets raw list of open files using OS X specific function, filters for valid files using isfile_strict, and returns list of named tuples containing file paths and file descriptors.
14028	Return network connections opened by a process as a list of namedtuples for the specified connection type.
14029	Check if a user belongs to a specific group, with optional superuser bypass functionality.
14030	Load a class from a fully qualified class path string by splitting the path and using __import__ to dynamically import and retrieve the class.
14031	Calculate percentage usage of 'used' against 'total', handling division by zero by returning 0. Optionally round the result to specified decimal places.
14032	A simple memoize decorator that caches function results in a dictionary, where the function's arguments are used as keys to store and retrieve previously computed values.
14033	A decorator that marks functions as deprecated, issuing a DeprecationWarning when the function is called and optionally suggesting a replacement function.
14034	Method `_login` attempts to authenticate user into Google Docs using ClientLogin with provided email, password, and source parameters. If authentication fails, it catches RequestError and raises PODocsError instead.
14035	Parse GDocs key from Spreadsheet url. Raises PODocsError if key is not found in the URL query parameters.
14036	Make sure temp directory exists and create one if it does not.
14037	Clear temporary directory by removing created CSV and ODS files during communicator operations.
14038	Uploads a file to a Google Docs spreadsheet with optional content type specification, handling request and IO errors by raising PODocsError.
14039	Synchronize local po files with translations on GDocs Spreadsheet by downloading CSV files, merging them, converting to PO files structure, and handling new msgids by uploading new content to GDocs.
14040	Downloads CSV files from GDocs and converts them into PO file structure.
14041	Upload all PO files to GDocs by converting them to ODS format and sending to Google Docs Spreadsheet, ignoring conflicts. Converts PO files to ODS using po_to_ods, uploads the ODS file to GDocs, then clears temporary files. Raises PODocsError on IO/OSError exceptions during conversion.
14042	Clears the GDoc Spreadsheet by uploading an empty CSV file and then removing the temporary file. Raises PODocsError if file operations fail.
14043	Start a new QtConsole connected to the kernel's connection file using the specified profile.
14044	Check if a URL is accessible and returns HTTP 200 OK, otherwise raise a ValidationError with a descriptive message. The function handles 'localhost' by converting it to 'http://127.0.0.1' and uses a specified timeout for the HTTP request.
14045	Check whether an HTML page contains specified content and return a boolean value.
14046	Visits a URL and returns the HTTP response code as an integer. Handles HTTP errors by returning the error code, and raises an exception if the URL cannot be reached. Uses a specified timeout value (default 10 seconds) for the request.
14047	Compares the content type header of a given URL with a specified content type and returns True if they match, False otherwise. Makes an HTTP request to the URL and checks the 'type' attribute of the response headers against the provided content type string. Returns False if the URL is inaccessible or an exception occurs during the request.
14048	Compare the HTTP response code of a given URL with a specified code and return True if they match, False otherwise. Handles HTTP errors gracefully by checking the error code against the expected code.
14049	Validate the display data by checking that source is a string, data is a dictionary, and metadata is either None or a dictionary.
14050	Clears the output of a cell by sending ANSI escape sequences to erase lines in stdout, stderr, and other output streams, with options to selectively clear each stream.
14051	Find absolute path to executable command in a cross-platform manner, using `which` on Unix/Linux/OS X and `win32api` on Windows. Returns the full path to the command line program, or raises FindCmdError if not found. If cmd is 'python', returns sys.executable path. Warning: do not use for finding IPython command line programs.
14052	Construct a list of CodeUnits from polymorphic inputs.

`morfs` is a module or a filename, or a list of same.

`file_locator` is a FileLocator that can help resolve filenames.

Returns a list of CodeUnit objects.
14053	Returns a flat filename base for this code unit by replacing dots with underscores in the module name, or processes the file path to create a flat name by replacing directory separators and dots with underscores.
14054	Return an open file for reading the source of the code unit by first checking if it exists as a regular file, then trying to locate it in a zip file, and raising a CoverageException if the source cannot be found.
14055	Determines if a file should likely contain Python code based on its extension. Returns True for files with '.py' extensions or no extension, False otherwise.
14056	```python
def _total_seconds(td):
    """timedelta.total_seconds was added in 2.7"""
    try:
        # Python >= 2.7
        return td.total_seconds()
    except AttributeError:
        # Python 2.6
        return 1e-6 * (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6)
```

**Summary:** A backward-compatible implementation of `timedelta.total_seconds()` that works with both Python 2.7+ (using the built-in method) and Python 2.6 (using manual calculation). Returns the total number of seconds in a timedelta object as a float.
14057	Return the result when it arrives, raising TimeoutError if timeout expires or RemoteError if the remote call raised an exception.
14058	Waits for the result to become available up to a specified timeout period. Returns None. If the result is ready, retrieves and processes the results, handling exceptions and metadata, then sets success/failure flags accordingly.
14059	Get the results as a dictionary keyed by engine_id, raising a ValueError if multiple jobs ran on the same engine.
14060	Abort my tasks by sending abort command to client, ensuring the task is not already completed.
14061	Elapsed time since initial submission, returning wall_time if ready, otherwise calculating based on the earliest submission timestamp among messages.
14062	Method that performs an interactive wait loop, periodically printing progress updates until all tasks are finished or timeout occurs. It clears output between updates and shows current progress, total tasks, and elapsed time. Returns when all tasks are ready or timeout is reached.
14063	Publish individual displaypub content dictionaries using IPython's display publication system, setting the engine metadata and handling cases where IPython is not available.
14064	Waits for all outputs to be ready by polling metadata until 'outputs_ready' is True for all entries, with optional timeout support. Returns immediately if operation was unsuccessful. Uses periodic polling with IOPub socket flushing.
14065	Wait for the result to complete by monitoring message IDs until they are ready or timeout occurs, then collect and process the results while handling exceptions.
14066	Return the absolute normalized form of `filename`.
14067	Prepare file patterns for use in a FnmatchMatcher by handling wildcards and making non-wildcard patterns absolute.
14068	Find the path separator used in a string, or return the OS default separator if none is found.
14069	Yields all importable Python files recursively from a given directory, skipping non-importable directories (those without `__init__.py`), and filtering files by typical Python filename extensions (.py or .pyw) while excluding editor temporary files.
14070	Return the relative form of `filename` normalized to the current directory when the `FileLocator` was constructed.
14071	Return a canonical filename for `filename` with absolute path, no redundant components and normalized case, using a cache to store previously computed results. If filename is not absolute, search for it in current directory and sys.path before computing canonical form.
14072	Get data from a zip file specified by filename. Returns the string data read from the zip file, or None if no zip file could be found or the specified file isn't in the zip. Returns an empty string if the file is empty.
14073	Does `fpath` indicate a file in one of our trees?
14074	Does `fpath` match one of our filename patterns?
14075	Maps a file path through defined aliases by matching against patterns and replacing the root accordingly, returning the transformed path or the original if no patterns match.
14076	Start a kernel with PyQt4 event loop integration by setting up a Qt application with timer-based kernel iteration.
14077	Start a kernel with wx event loop support by creating a wx.App with a timer-driven ZMQ event loop and handling signal interrupts properly.
14078	Starts a kernel with the Tk event loop by creating a Tkinter timer that repeatedly calls the kernel's do_one_iteration method at specified intervals.
14079	Starts a kernel and coordinates it with the GTK event loop using GTKEmbed.
14080	Starts the kernel and coordinates with Cocoa CFRunLoop event loop using matplotlib's MacOSX backend, with fallback to Tk if matplotlib version is too old. Uses TimerMac for periodic kernel iterations and handles interrupts gracefully.
14081	Enable integration with a given GUI by setting up the appropriate event loop. Raises ValueError if the GUI is not supported, or RuntimeError if no kernel is specified or if multiple GUI eventloops are attempted to be activated.
14082	Creates an NxN matrix from the Gaussian Orthogonal Ensemble by generating a random matrix, adding it to its transpose, and scaling by 1/2.
14083	Compute the eigenvalues of a matrix, sort them, and return the absolute difference between the two center eigenvalues.
14084	Returns num eigenvalue differences for the NxN Gaussian Orthogonal Ensemble (GOE) by generating random GOE matrices and computing centered eigenvalue differences.
14085	Initialize the item by calling its class constructor with context, name, configuration, and step address arguments.
14086	Parse a YAML file containing test steps, validating the structure and returning a list of Step objects. The method accepts an optional key to extract steps from a dictionary within the YAML file, and uses a step address for error reporting. It handles file reading, validation of data structure (dictionary or list), and parsing of individual steps.
14087	Parse a step dictionary into a list of steps, validating configurations and handling actions, modifiers, and step actions according to defined schemas and restrictions.
14088	Initialize a crash handler by setting up exception handling with sys.excepthook and register an exit handler to restore the original exception hook.
14089	Load configuration file with error handling. Attempts to load a base config file ('ipython_config.py') and a secondary config file specified by self.config_file_name. If config files are not found, warnings are logged depending on whether the default config was being used. If suppress_errors is False (for testing), exceptions are re-raised instead of being caught and logged as warnings.
14090	Initialize the profile directory by either finding an existing one or creating a new one based on configuration settings. The method first attempts to use an explicitly specified location, then falls back to finding/creating by profile name. It handles various error cases including when profiles don't exist and when automatic creation is disabled. Finally, it sets the profile directory and adds its location to the configuration file paths.
14091	Generate default configuration file and stage it into the profile directory, overwriting existing file if specified.
14092	Writes collected coverage data to a file with optional suffix for multiple/parallel execution.
14093	Erases the object's data both in memory (clearing lines and arcs dictionaries) and from file storage if file-based storage is being used.
14094	Return a dictionary mapping filenames to sorted lists of executed line numbers.
14095	Return a dictionary mapping filenames to sorted lists of line number pairs from the arcs data structure.
14096	Write coverage data to a file using pickle serialization, including line data, arc data (if available), collector information, and debug output.
14097	Read coverage data from a file and store lines and arcs information.
14098	Return the raw pickled data from `filename`.
14099	Return the stored coverage data from the given file, unpacking 'lines' and 'arcs' items into dictionaries with None values.
14100	Combine multiple data files with the same prefix into a single dataset, optionally remapping file paths using aliases, and clean up source files after combining.
14101	Add executed line data to the coverage object, updating line execution information for each file.
14102	Add measured arc data to the internal arcs dictionary, updating existing entries or creating new ones for each filename and arc pair.
14103	Adds filename's executed lines and arcs data to the provided MD5 hasher.
14104	Return a dictionary summarizing coverage data where keys are filenames (basename by default or full path if specified) and values are the count of executed lines.
14105	Summary: Generator function that yields lines of input from the user until a sentinel value is entered, with support for EOF termination.
14106	Start the mainloop that repeatedly calls interact() until interrupted by KeyboardInterrupt, with optional banner display and exception handling.
14107	Store multiple lines as a single entry in history by removing previous entries and adding the current source as one entry, but only if readline is available, multiline history is enabled, and there are changes to process.
14108	Reads a line from input with optional prompt, handling readline completer state, encoding conversion, EOF errors, and auto-indentation for pasted input. Returns the input line without trailing newline, exiting IPython if stdin/stdout are closed.
14109	Method `edit_syntax_error` handles syntax errors in the main loop by continuously retrying code execution until the error is fixed or canceled. It clears the last syntax error, checks if recompilation is needed, safely executes the file, and displays the file contents if successful, otherwise showing tracebacks for any exceptions.
14110	Method `_should_recompile` determines whether to recompile code after a syntax error. It returns `False` immediately if the error occurs in special filenames like IPython console or input streams. Otherwise, it prompts the user to decide whether to edit the syntax error, with a default "yes" response. It also handles potential EOF errors by returning `False`. The method then attempts to call an editor hook with error details (converting line number and offset to integers), handling exceptions by warning and returning `False`. If everything succeeds, it returns `True` to proceed with recompilation.
14111	Handle interactive exit by calling the ask_exit callback, with optional confirmation prompt based on the confirm_exit flag.
14112	Returns the repository URL and revision by parsing a VCS URL, splitting on '+' and '@' delimiters to extract components.
14113	Create and return a new frontend attached to a new kernel launched on localhost. The method sets up a kernel manager with a new connection file, starts the kernel and its channels, creates a widget with the specified configuration, initializes colors, and configures widget properties before returning it.
14114	Initialize and configure widget colors and styling based on configuration settings, handling different color schemes (light, dark, nocolor) and syntax styles, while supporting custom style sheets.
14115	Return the connection information for this object's sockets, including identity, URL, pub URL, and location.
14116	Converts an R object to a Python-friendly format, with special handling for data frames to return structured arrays with appropriate column names.
14117	Return the entire source file and starting line number for an object, handling modules, classes, methods, functions, tracebacks, frames, and code objects. Supports locating class definitions and function definitions with proper error handling.
14118	Sets the color table scheme and updates related color settings including debugger colors.
14119	Toggle between the currently active color scheme and NoColor by switching the active scheme and updating the Colors attribute accordingly.
14120	Return formatted traceback by converting structured traceback to text format.
14121	Return a color formatted string with the traceback info, including formatted exception and context lines.
14122	Formats a list of traceback entry tuples into printable strings with color coding, where all entries except the last are formatted normally and the last entry is emphasized with special coloring. Each string ends with a newline and may contain internal newlines if source text is available.
14123	Formats the exception part of a traceback by creating a list of strings that end in newlines. Handles special formatting for SyntaxError exceptions including file and line information, and includes color coding. Returns the formatted exception information as a list of strings.
14124	Shows only the exception type and message without traceback information by writing to the output stream.
14125	Call up the pdb debugger if desired, always clean up the tb reference. If the call_pdb flag is set, the pdb interactive debugger is invoked. In all cases, the self.tb reference to the current traceback is deleted to prevent lingering references which hamper memory management.
14126	Sets the current mode of the object, cycling through available modes if none specified. Validates the mode against valid modes and raises ValueError for unrecognized modes. Configures variable inclusion and traceback join character based on the selected mode.
14127	A view decorator that requires users to belong to a specific group for access. It can optionally skip the superuser requirement and accepts custom login URL and redirect field name parameters. Raises PermissionDenied if the user doesn't have the required group membership.
14128	Handles 'from module import a, b, c' imports by ensuring submodules are loaded, managing wildcard imports, and preventing endless recursion.
14129	Add a line of source code to the current code block, including proper indentation but without adding extra newlines or spaces.
14130	Add a section, a sub-CodeBuilder.
14131	Compile the code text and return the specified function by name from the executed namespace.
14132	Generate Python expression code from a string expression, handling piped functions and dotted attributes by recursively processing components and wrapping them in appropriate function calls.
14133	Renders the template by applying it to the provided context dictionary, combining the template's default context with the provided context, and returns the rendered result using the template's render function.
14134	This method evaluates dotted attribute access expressions on a value, handling both attribute access (with `getattr`) and item access (with `value[dot]`) when attributes are not found. If the resulting value is callable, it executes it. The method processes multiple dotted components sequentially, returning the final evaluated result.
14135	Renders a template with the given context and returns the output. Takes a template name or list of template names, attempts to load the first available template, and renders it with the provided context. Raises an exception if no template is found.
14136	Activate the default formatters by creating instances of various formatter classes and returning them in a dictionary keyed by their format types.
14137	Adds a format function for a given type and returns the old function if it existed.
14138	Add a format function for a type specified by its full dotted module and name. Returns the old function if replacement was made.
14139	Method `_float_precision_changed` handles changes to float precision settings by converting the input (either integer or format string) into an appropriate float format string. It validates the input, sets the float format accordingly, and updates numpy's print precision if numpy is imported. The method supports three cases: explicit format strings, integer precision (converted to '%.nf' format), and empty strings (which reset to default representations). The changes can be triggered via the '%precision' magic command.
14140	Return paths to existing user config files by filtering config_files against the filesystem.
14141	Configures the nose testing environment by parsing command line arguments and configuration files, setting up test options, paths, and filtering criteria. Initializes logging, plugin configuration, and test discovery parameters based on parsed options and environment variables.
14142	Configures logging for nose or other packages based on debug settings. Sets up a logging formatter and handler (file or stream), configures the 'nose' logger with appropriate level based on verbosity, and sets debug level for any specified loggers while avoiding duplicate handlers.
14143	Configure the working directory or directories for the test run. Sets the working directory to the first path provided, adds it to sys.path if it's a package, and appends subsequent paths to testNames while issuing a deprecation warning. Raises ValueError if the working directory is not found or not a directory.
14144	A simple text pager implementation that displays output in screens of specified height. It splits input text into lines, organizes them into screens (minus one line for pagination control), and displays them one screen at a time. For each screen, it prints the content and waits for user confirmation before proceeding to the next screen using a `page_more()` function. It also handles escape sequences by preserving the last escape code from each screen to maintain proper formatting when continuing to the next screen. The function takes a string, optional starting line, and screen height as parameters.
14145	Summary: The `page` function prints a string, automatically using a pager command when the string exceeds a specified number of terminal lines. It handles terminal size detection, respects reserved screen lines, and falls back to a simple Python-based pager if system pagers fail. The function also includes special handling for certain environments like Emacs and Windows, and supports custom pager commands or defaults to the `less` pager.
14146	Function `page_file` displays a file using a pager command with optional starting line. It first gets the pager command and starting line, then attempts to display the file using the pager. If that fails due to terminal environment or other issues, it falls back to a simple file reading approach. If all methods fail, it prints an error message indicating the file cannot be displayed.
14147	Return a pager command suitable for the operating system, defaulting to 'less -r' on POSIX systems and 'type' on Windows/DOS, with support for overriding via the PAGER environment variable.
14148	Returns the string for paging files with an offset (e.g., '+N') for 'less' and 'more' pagers, or empty string for other pagers.
14149	Print a string with middle section snipped to fit within specified width, with options for full display and pagination. Returns 1 if snipping occurred, 0 otherwise.
14150	A function to pretty print SymPy Basic objects with Unicode support, handling circular references by returning 'Basic(...)' when detected, and adding newlines when the pretty representation contains them.
14151	A function to display sympy expressions as inline style LaTeX in PNG format by converting the expression to LaTeX, cleaning up unsupported LaTeX commands, and generating a PNG image.
14152	A function that displays SymPy expressions as PNG images using LaTeX rendering with dvipng backend, converting the expression to plain mode LaTeX and wrapping it in display style math delimiters before generating the PNG output.
14153	Return True if type o can be printed with LaTeX, recursively checking container elements.
14154	A function to generate LaTeX representation of SymPy expressions, with dagger symbol correction and proper math mode formatting, falling back to string printer if LaTeX generation fails.
14155	Adds command-line options to a parser for plugin configuration, with deprecation warning and error handling for option conflicts.
14156	Validate that the input is a list of strings, raises ValueError if not.
14157	Validate that the input is a dict with string keys and values. Raises ValueError if not.
14158	Run the event loop while handling EINTR errors by continuing the loop, and break on normal termination or exceptions when exiting.
14159	Handles received messages by unpacking them and calling appropriate handlers with the unserialized data.
14160	Execute Python code in the kernel with optional variables and expressions retrieval.

Parameters:
- code (str): Python code to execute
- silent (bool): Execute quietly if True
- user_variables (list): Variable names to pull from user namespace
- user_expressions (dict): Expressions to evaluate in user namespace
- allow_stdin (bool): Allow stdin requests

Returns:
- msg_id (str): Message ID of the executed request

Validates input types and creates an execute request message sent through the session queue.
14161	Tab complete text in the kernel's namespace by sending a completion request message with the provided parameters and returning the message ID.
14162	Get metadata information about an object with specified detail level and return the message ID of the sent request.
14163	Get entries from the history list with specified access type and parameters.
14164	Requests an immediate kernel shutdown by sending a shutdown request message. Returns the message ID for tracking the request. The kernel will reply via Python's atexit module once shutdown is complete, ensuring all normal operations are finished before termination. If restart=True, the kernel will restart after shutdown.
14165	Immediately processes all pending messages on the SUB channel by calling the flush mechanism twice to ensure at least one full IOLoop poll cycle, with a configurable timeout parameter.
14166	Send a string of raw input to the kernel by creating an input_reply message and queuing it for sending.
14167	Starts the channels for this kernel, creating them if necessary and beginning communication on the specified channels (shell, subscription, stdin, and heartbeat). Raises RuntimeError if channels have been stopped and restarted.
14168	Stops all running channels (shell, sub, stdin, and heartbeat) for this kernel by checking if each channel is alive and calling stop() on it if so.
14169	Are any of the channels created and running?
14170	Loads connection information from a JSON file and sets up connection parameters including IP address and various port numbers.
14171	Writes connection information to a JSON file and updates port configurations.
14172	Starts a kernel process and configures the manager to use it. Validates local interface, writes connection file, and launches kernel with optional custom launcher.
14173	Method: `shutdown_kernel(self, restart=False)`

Attempts to cleanly stop the kernel process. On Windows, it directly kills the kernel due to ZMQ errors. For other platforms, it pauses the heartbeat channel, sends a shutdown message via shell channel, and waits up to 1 second for the kernel to shut down gracefully. If the kernel doesn't stop within the timeout, it kills the kernel. If not restarting and a connection file was written, it removes the connection file on shutdown.
14174	Restarts a kernel with the arguments that were used to launch it. If the old kernel was launched with random ports, the same ports will be used for the new kernel. If `now` is True, the kernel is forcefully restarted immediately without cleanup. Otherwise, the kernel is given 1s to clean up before a forceful restart. Any options specified in `**kw` will replace those used to launch the kernel. Raises RuntimeError if there was no previous call to 'start_kernel'. On Windows, a delay is added to prevent message dropping due to ZMQ bugs.
14175	Kill the running kernel by attempting to terminate it gracefully, handling platform-specific errors (Windows access denied, Unix ESRCH) when the process has already terminated, and pausing the heartbeat channel before killing. Raises RuntimeError if no kernel is running.
14176	Interrupts the kernel using platform-appropriate methods. On Windows, uses ParentPollerWindows to send interrupt via win32_interrupt_event. On other platforms, sends SIGINT signal to the kernel. Raises RuntimeError if no kernel is running.
14177	Sends a signal to the running kernel if available, raising an error if no kernel is running. Note: Only SIGTERM is supported on Windows, making this function Unix-specific.
14178	**Summary:** Checks if the kernel process is still running by first verifying if the kernel process is alive through `poll()`, and if not available, checking heartbeat channel status, defaulting to True if neither is available.
14179	Get the REQ socket channel object to make requests of the kernel. Creates and caches the shell channel if it doesn't already exist.
14180	Get the SUB socket channel object, creating it if it doesn't exist.
14181	Returns the heartbeat socket channel object for checking if the kernel is alive, creating it if it doesn't exist yet.
14182	Bind an Engine's Kernel to be used as a full IPython kernel, allowing it to work with QtConsole or other frontends. Returns immediately. Checks if IPKernelApp is already initialized (no-op case) or if IPEngineApp is initialized and calls its bind_kernel method. Raises RuntimeError if called outside of IPEngineApp context.
14183	Emit a debugging message to stderr if the current debug level meets or exceeds the specified level.
14184	Retrieve the extension classes in priority order by iterating over entrypoints and organizing them by priority, then return the sorted list of extension classes.
14185	Called prior to executing a step, this method iterates through all extensions and calls their pre_step method. If any extension returns True, the step is skipped and True is returned. Otherwise, False is returned to indicate the step should proceed.
14186	Called after executing a step, this method iterates through all extensions and calls their `post_step` method with the context, step, index, and result. It allows extensions to modify the result (e.g., setting an `ignore` attribute) and returns the (possibly modified) result for convenience.
14187	Called at the end of processing to allow extensions to emit additional data or alter the return value. Takes a context and result parameter, iterates through extensions calling their finalize method, and returns the final result.
14188	Walk an unpacked egg's contents, skipping the metadata directory.
14189	Scan a module to check if it uses unsafe-for-zipfile features. Returns True if safe, False if unsafe. Checks for unsafe symbols like __file__, __path__, and inspect module usage. Also warns about top-level modules that may be python -m scripts.
14190	Create and run the IPython controller, with special handling for Windows multiprocessing to prevent infinite controller instances from being started.
14191	Save a connection dictionary to a JSON file, determining the location IP address if not provided and setting proper file permissions.
14192	Method loads configuration from JSON connector files by reading engine and client configuration files, parsing connection details including transport, IP addresses, and ports, and setting up session keys and hub factory parameters while performing validation checks between engine and client configurations.
14193	Method `load_secondary_config` loads secondary configuration from JSON file when `reuse_files` is True, sets default values, and configures secure session key. If JSON loading fails, it logs an error. It also disables writing connection files when config is successfully loaded from JSON.
14194	Executes code cell in parallel across multiple engines. If block=True (default), waits for execution to complete and displays outputs grouped by specified criteria. If block=False, returns an AsyncResult object immediately for non-blocking execution. Supports optional saving of results to user namespace and verbose output reporting.
14195	Enable %autopx mode by saving the original run_cell method and replacing it with pxrun_cell, then set autopx flag to True and print confirmation message.
14196	Disables the %autopx magic by restoring the original InteractiveShell.run_cell method and sets the _autopx flag to False, then prints a confirmation message.
14197	Executes a code cell remotely instead of locally, handling preprocessing, history storage, syntax checking, and result display while managing exceptions and autopx magic commands.
14198	Process heartbeat messages from the CLOCK_CHANNEL to run scheduled tasks, discarding stale messages that are older than the heartbeat threshold.
14199	This function executes a task by retrieving it from the database and running it. If the task allows overlap, it runs immediately. Otherwise, it first checks if the task is already running. If not, it marks the task as running, executes it, and then marks it as not running again, ensuring only one instance runs at a time.
14200	Removes a task from the database based on the provided message containing the task ID.
14201	This function patches a protocol's `makeConnection` and `connectionLost` methods to make them compatible with what `Agent` expects. It wraps the original methods to add transport patching and handles connection termination logic by replacing `ConnectionDone` with `ConnectionAborted` when a fake connection abort has occurred. The patched methods ensure the protocol behaves correctly with the agent and other similar clients/servers.
14202	Patch a method onto an object if it isn't already there.
14203	Accepts a pending connection by creating a server protocol, wrapping it in a fake protocol wrapper, and returning a deferred that will fire when the connection is established.
14204	Reject a pending connection with an optional reason, raising an assertion error if the connection is not pending, and propagate the error through the connection's errback mechanism.
14205	Returns an IAgent that makes requests to this fake server using a ProxyAgentWithContext.
14206	Method `form_valid` handles the valid form submission by:
1. Saving the form object without committing to database
2. Calling pre-save hook and returning redirect response if hook aborts saving
3. Saving the object to database and handling many-to-many relationships
4. Calling post-save hook
5. Redirecting to success URL

The method follows a pipeline pattern where pre-save hook can interrupt the process, and both pre-save and post-save hooks are invoked during the save operation.
14207	Deletes an object by calling pre-delete and post-delete hooks, then redirects to success URL.
14208	Sets the user field on the instance to the current request user during pre-save, but only if the user is authenticated.
14209	Writes a coverage report summarizing statistics per module to the specified output file. Returns the total coverage percentage.
14210	Check whether modules need to be reloaded based on file modification times, handling both .py and .pyc files while skipping specified modules and main module.
14211	Opens the default editor at a given filename and line number, with support for custom editors and line markers.
14212	Open editor at specified location with error message, with special VIM support using quickfix functionality, falling back to default editor hook for other editors.
14213	Get text from the clipboard by trying multiple platform-specific methods in fallback order: win32_clipboard_get  tkinter_clipboard_get for Windows, osx_clipboard_get  tkinter_clipboard_get for macOS, and tkinter_clipboard_get only for other platforms.
14214	Adds a function to the command chain with specified priority, then sorts the chain by priority.
14215	Function `get_metadata` attempts to create a Distribution object from a given path or module. It handles multiple input types:

- If input is a module object, tries to create an `Installed` distribution
- If input is a string that's a valid module name, imports it and tries to create an `Installed` distribution
- If input is a file path, tries to create SDist, BDist, or Wheel distributions in that order
- If input is a directory path, tries to create a Develop distribution

Returns None if none of the attempts succeed. Handles ValueError and IOError exceptions gracefully during each attempt.
14216	Configures the plugin to determine which types of exceptions will trigger it based on debug options. Sets up internal flags to control debugging behavior for errors and failures.
14217	Import and return an object from a module given its full path name (e.g., 'foo.bar').

The function takes a string representing a full module path (like 'foo.bar') and returns the corresponding object. It splits the path into package and object name components, then uses Python's import system to import the module and retrieve the specified object. If the package part is empty, it imports the object directly from the top level. The function includes error handling for cases where the specified object doesn't exist in the imported module.

Original implementation used exec statements for importing, but the current version uses the standard `__import__` function and `fromlist` parameter for safer module importing.
14218	Attempts SSH connection without password using either OpenSSH or Paramiko backend, primarily for connecting multiple tunnels to the same server with single password prompt. Returns the result of the chosen backend function.
14219	Try passwordless SSH login using the shell ssh command with pexpect. Returns True if login succeeds (no password prompt), False if password prompt appears. Raises ImportError if pexpect is unavailable.
14220	Try passwordless SSH login using paramiko. Returns True if successful, False if authentication fails. Raises ImportError if paramiko is unavailable.
14221	Connects a socket to an address via an SSH tunnel by creating a tunnel to the remote server and connecting to the local port of that tunnel. Returns the tunnel object for cleanup.
14222	Opens a tunneled connection from a 0MQ url by creating a local port forward to a remote server, returning the forwarded url and tunnel object.
14223	Stop scheduling tasks when an engine unregisters from a pure ZMQ scheduler by closing the task socket and issuing a warning about disabled task farming.
14224	Unwraps an exception from content and remaps engine_id to integer format. If engine information exists, it retrieves the engine ID from the internal engines mapping using the engine UUID and updates the exception's engine_info with the integer engine ID. Returns the unwrapped exception with updated engine information.
14225	Registers a new engine by extracting its ID and queue from the message content, then updates the engines dictionary with this information.
14226	Unregisters a dead engine by removing its ID from tracking, removing its UUID mapping, handling any stranded messages from that engine, and stopping task scheduling if using pure task scheme.
14227	Handle execute reply messages by saving results, managing outstanding messages, updating metadata, and constructing appropriate result objects based on execution status.
14228	Flush notifications of engine registrations waiting in ZMQ queue by receiving messages from the notification socket and processing them with appropriate handlers.
14229	Flush task or queue results waiting in ZMQ queue by receiving messages in non-blocking mode and processing them with appropriate handlers based on message type.
14230	Flush replies from the control channel waiting in the ZMQ queue by ignoring them.
14231	Flushes ignored control replies by receiving from control socket until all ignored replies are processed.
14232	Flushes replies from the iopub channel waiting in the ZMQ queue, processing different message types (stream, pyerr, pyin, display_data, pyout, status) and updating metadata accordingly.
14233	Method `_spin_every` is a target function that continuously executes a spin operation at regular intervals until a stop signal is received. It takes an optional interval parameter (defaulting to 1 second) and runs in an infinite loop, sleeping for the specified interval before each spin operation. The method returns immediately when the `_stop_spinning` event is set, allowing for graceful termination of the spinning process.
14234	Stop the background spin thread if it exists by setting the stop flag, waiting for thread completion, and clearing the thread reference.
14235	Flushes all registration notifications and execution results waiting in the ZMQ queue by calling individual flush methods for each socket type.
14236	Waits on one or more jobs for up to a specified timeout period. Returns True if all jobs complete within the timeout, False otherwise. Supports jobs specified by index, message ID, or AsyncResult object(s). If no jobs specified, waits on all outstanding messages. Uses a spin loop with short delays to check job completion status.
14237	Send an apply request message through a socket for engine execution, validating inputs and tracking the message.
14238	Send an execute request via a socket with the given code and options, validating inputs and tracking the message ID for later reference.
14239	Retrieves a result by msg_id or history index, wrapped in an AsyncResult object. If the client already has the results, no request to the Hub will be made. Supports blocking execution and returns a single AsyncResult object. Handles both local and remote result retrieval, with remote results using AsyncHubResult subclass.
14240	Fetch the status of engine queues for specified targets with optional verbose output. Returns queue status information or raises an exception if the operation fails.
14241	Method: purge_results

Purpose: Tells the Hub to forget specified results by clearing individual message IDs or entire target histories.

Parameters:
- jobs: str, list of str, or AsyncResult objects representing msg_ids to forget (or 'all' to purge everything)
- targets: int/str/list of ints/strs representing targets whose entire history should be purged

Behavior:
- Validates that at least one of targets or jobs is specified
- Processes targets into proper format using _build_targets()
- Constructs msg_ids list from jobs parameter, handling both individual msg_ids and AsyncResult objects
- Sends purge request to Hub via query socket
- Receives and validates response, raising exceptions if purge fails

Returns: None (sends request and handles response)

Throws: ValueError (when no targets or jobs specified), TypeError (when invalid msg_id types provided)
14242	Get the Hub's history returning a list of message IDs ordered by task submission time.
14243	Query the Hub's TaskRecord database and return a list of task record dictionaries that match the given query, with optional key filtering.
14244	Return a set of opcodes by the names in `names`, ignoring any names that don't correspond to valid opcodes.
14245	Create a ByteParser instance on demand if it doesn't exist, otherwise return the existing one.
14246	Find the lines matching one of a list of regexes.

Returns a set of line numbers, the lines that contain a match for one
of the regexes in `regexes`.  The entire line needn't match, just a
part of it.
14247	Parse the source code to identify excluded lines, docstrings, multi-line statements, and statement starts by tokenizing the input text and updating relevant member fields.
14248	Return the first line number of the statement including the given line, accounting for multiline statements.
14249	Maps line numbers to their corresponding first statement lines, skipping ignored lines. Returns a set of unique first line numbers.
14250	Parse source text to find executable lines and excluded lines, returning sets of line numbers with proper normalization for multi-line statements. Handles tokenization errors by raising NotPython exception with detailed error information.
14251	Get information about available arcs in the code, returning a sorted list of normalized line number pairs.
14252	Get a mapping from line numbers to count of exits from that line, excluding specified lines and adjusting for class definitions.
14253	Return a list of ByteParser objects for all code objects nested within this one, including self as the first element.
14254	Map byte offsets to line numbers in `code` using co_lnotab, producing sequence of (byte_offset, line_number) tuples. Only includes byte offsets that correspond to actual line numbers.
14255	Find statements in `self.code` by yielding line numbers from child parsers' bytecode lines.
14256	Get a string representation of `block_stack` for debugging purposes, showing each block as "(opcode_name, offset)".
14257	Split the code object into a list of `Chunk` objects, where each chunk represents a basic block that is only entered at its first instruction. The method analyzes bytecodes to identify chunk boundaries based on source lines, jump targets, and opcode behavior, then assigns appropriate exits and lengths to each chunk. Returns a list of `Chunk` objects representing the structured code blocks.
14258	Validate that chunks have a single entrance by ensuring all exits point to valid entrances or are negative (indicating termination).
14259	Find executable arcs in the code by traversing chunks of bytecode. Yields pairs of (from, to) line numbers where from < 0 represents entrance arcs and to < 0 represents exit arcs. The method analyzes chunk exits to determine when the trace function is invoked, considering both forward and backward jumps to identify executable control flow arcs.
14260	Returns a list of `Chunk` objects for this code and its children by extending chunks from child parsers.
14261	Get the set of all arcs in this code object and its children by collecting arcs from all child parsers.
14262	Add command line options for coverage reporting including package filtering, statistics erasure, test inclusion, minimum percentage requirements, inclusive coverage, and various output formats (HTML, XML) with corresponding environment variable support.
14263	Begin recording coverage information by initializing the coverage instance, clearing previous statistics if needed, setting up exclusions, and starting the coverage collection.
14264	This method generates a code coverage report by:
1. Stopping and combining coverage data
2. Saving the coverage data
3. Identifying modules to cover based on configuration
4. Generating text report to the specified stream
5. Optionally generating HTML and XML coverage reports if configured
6. Validating minimum coverage percentage requirement and exiting with error if not met
14265	Returns True if inclusive coverage is enabled and the file is a Python source file in a wanted package, False otherwise.
14266	Generate alternative interpretations of a source distribution name by splitting the basename into parts and yielding Distribution objects with different name/version combinations, handling cases where the distribution might be a binary distribution rather than a source distribution.
14267	Open a URL with HTTP authentication handling, parse the URL to extract authentication info, create a request with appropriate headers, and return the response file pointer while preserving authentication for subsequent requests to the same host.
14268	Fetches a distribution that satisfies the given requirement, searching locally and online if necessary. Returns the matching distribution or None if not found. Supports options for forcing scans, considering only source distributions, and excluding development eggs.
14269	Get the parent object from a given object by traversing its qualified name hierarchy. Raises ValueError if the object is a local function. Returns the parent object by navigating through the module and qualified name components.
14270	Returns the root topic string for the engine, formatted as "engine.[id]" if the engine has an integer ID, otherwise returns "engine".
14271	Renders a context-aware template by taking template content and a context dictionary, then returns the rendered output using Django's Template and Context classes.
14272	Configure plugin. Plugin is enabled by default. If capture option is not set, plugin is disabled.
14273	Formats error reports by adding captured output to error information. Returns the original error if no output was captured, otherwise returns the error with captured output appended to the error value.
14274	Splits a list into sublists of specified size.

This function takes a list and breaks it into smaller sublists, each containing 'num' consecutive elements from the original list. The last sublist may contain fewer elements if the original list length is not evenly divisible by 'num'.

Parameters:
- data: The input list to be split
- num: The size of each sublist

Returns:
- A list of lists, where each inner list contains up to 'num' elements from the original list

Example:
splitBy([1,2,3,4,5,6], 2) returns [[1,2], [3,4], [5,6]]
splitBy([1,2,3,4,5], 3) returns [[1,2,3], [4,5]]
14275	Convert a notebook to v3 format, handling conversions from v1 and v2 notebooks. For v1 notebooks, first convert to v2, then to v3. For v2 notebooks, set the nbformat version to v3 and mark the original version. For v3 notebooks, update the minor version if needed. Raise ValueError for unsupported conversion sources.
14276	Convert a hex color to rgb integer tuple. Handles both 3-digit and 6-digit hex formats, returns False for invalid input.
14277	Constructs a dictionary of color keys for building a base stylesheet from a template. Retrieves style information by name, processes the foreground color to ensure proper hex format with '#' prefix if needed, and returns background color, highlight color, and processed foreground color.
14278	Return a QFont object of the requested family, using fallback as alternative if the requested family isn't found.
14279	Handles execute replies from the kernel, specifically supporting prompt requests by displaying interpreter prompts when a prompt-kind request is detected, otherwise delegating to the parent class implementation.
14280	Handles history reply messages from IPython kernel, processing history items and managing retry logic for aborted requests.
14281	Handles IPython-style "display hook" output messages by processing HTML and plain text data, appending formatted output with prompts and separators to the display.
14282	Handles ``display_data`` messages by logging and displaying HTML or plain text content from the same session, with a newline appended.
14283	Method `_started_channels` reimplements the parent class method to perform two key operations after channels are started: it loads the `%guiref` magic extension and requests kernel history. Specifically, it calls the parent's `_started_channels` method, loads the GUI reference magic, and then retrieves the last 1000 entries from the kernel's history using the shell channel's history method with `hist_access_type='tail'` parameter.
14284	Method: execute_file(self, path, hidden=False)

Summary: This method executes a file using the 'run' magic command. It handles cross-platform path normalization by converting backslashes to forward slashes on Windows systems. The method properly escapes filenames containing spaces, single quotes, or double quotes by wrapping them in double quotes with appropriate escaping. It then executes the file using the IPython magic command `%%run` with the specified path, optionally hiding the output based on the hidden parameter.
14285	Method `_process_execute_error` handles IPython-style traceback formatting by processing execution errors. It extracts the traceback from the message content and formats it either as HTML (with styled error names and proper line breaks) or as plain text with ANSI escapes, depending on a conditional flag. The HTML version would replace spaces with non-breaking spaces, newlines with `<br/>` tags, and wrap error names in styled span elements, while the plain text version simply appends the traceback as-is.
14286	Method `_process_execute_payload` dispatches payloads to handler methods based on the payload source. It looks up the appropriate handler in `self._payload_handlers` using the `item['source']` key. If a handler exists, it executes the handler with the item as parameter and returns `True`. If no handler is found, it returns `False` without processing the item.
14287	Sets the widget style to class defaults based on specified color scheme.

Parameters:
- colors: str, optional (default 'lightbg') - Color scheme to use ('lightbg', 'linux', or 'nocolor')

Raises:
- KeyError: If specified color scheme does not exist

Effects:
- Updates self.style_sheet and self.syntax_style with corresponding style sheets based on color scheme
14288	Opens a Python script for editing in an external editor. If a custom editor is configured, emits an edit request signal. Otherwise, uses the default editor if available, formatting the command with optional line number specification. Shows error messages if no editor is available or if the editor command fails.
14289	Given a prompt number, returns an HTML In prompt by formatting the in_prompt template with the number, falling back to the template without number if a TypeError occurs, and wrapping the result in a span with class "in-prompt".
14290	Creates an HTML continuation prompt by converting a plain text prompt into HTML format with appropriate spacing and styling.
14291	Set the style sheets of the underlying widgets, including the main widget, control document, and page control document, while updating the background color for ANSI processing.
14292	Sets the syntax highlighting style for the highlighter based on available style settings.
14293	Handles CloudStack API responses, including asynchronous calls by polling for final results using job IDs. Returns JSON response data or raises exceptions for errors.
14294	Method `_sign` generates a cryptographic signature for CloudStack API requests by:
1. Removing any existing signature from the url parameters
2. Sorting and converting url parameters to lowercase
3. Creating a URL-encoded request string
4. Generating an HMAC-SHA1 hash using the API secret
5. Encoding the hash in base64 and adding it as a 'signature' parameter
6. Returning the updated url parameters with the signature

The signature ensures API request authentication by following CloudStack's signing protocol which requires parameters to be lowercased and ordered alphabetically before hashing.
14295	Transforms CloudStack API response data by removing the top-level API identifier key, returning only the nested dictionary content.
14296	Returns system virtual memory information as a named tuple containing total, available, percentage used, used, free, active, inactive, buffers, cached, shared, and wired memory statistics.
14297	Return system per-CPU times as a named tuple containing user, nice, system, idle, and irq times.
14298	Return real, effective and saved user ids for the process.
14299	Return real, effective and saved group ids for the process.
14300	Return the number of threads belonging to the process as a list of named tuples containing thread_id, utime, and stime.
14301	Return files opened by process as a list of namedtuples, using native C implementation on FreeBSD >= 8 or falling back to lsof parser on other systems.
14302	Get short form of commit hash from either installation info or git repository. Returns tuple of (source_description, hash_string) where source can be "installation", "repository", or "(none found)".
14303	Return a dictionary containing package context information including IPython version, package path, git commit details, system information, and encoding details.
14304	Return useful information about IPython and the system as a formatted string.
14305	Return the number of active CPUs on a Darwin system by executing 'sysctl -n hw.ncpu' command and reading its output.
14306	Return the effective number of CPUs in the system as an integer, with cross-platform support for Linux, Darwin, Windows, and Microsoft systems, defaulting to Unix version for other platforms. Returns 1 if unable to determine a sensible answer.
14307	Advance to the next result set, fetching all current results first. Returns None if no more result sets exist, otherwise returns 1.
14308	Fetches a single row from the cursor. Returns the first element of the row if available, otherwise returns None. Raises an exception if the query hasn't been executed.
14309	Fetch up to size rows from the cursor, defaulting to cursor.arraysize if size is not specified. Updates rownumber and checks for warnings if no rows are returned.
14310	Fetches all available rows from the cursor, checks if execution occurred, retrieves rows, updates row number, performs warning check, and returns the results.
14311	This function establishes connections between engines by invoking the connect method on the provided communication object with specified peers, tree structure, publication URL, and root identifier.
14312	Reads a JSON notebook from a string and returns a NotebookNode object, handling different nbformat versions (1, 2, 3) by converting them to the current nbformat version.
14313	Reads a Python notebook from a string and returns the NotebookNode object by parsing the string and converting it to the appropriate notebook format version.
14314	Reads a notebook from a string in specified format and returns a NotebookNode object, supporting 'json','ipynb', and 'py' formats.
14315	Writes a notebook to a string in the specified format (json, ipynb, or py) using the current nbformat version, returning the notebook as a unicode string.
14316	Writes a notebook to a file-like object in the specified format, returning the written string.
14317	Converts Jupyter notebooks to include notebook metadata by reading each .ipynb file, extracting name metadata if present, and writing the updated notebook back to disk.
14318	Load value from dictionary by key, set to unset state if key doesn't exist.
14319	Does the name match my requirements?

To match, a name must match config.testMatch OR config.include
and it must not match config.exclude
14320	**Summary:**

The `wantClass` method determines whether a given class should be treated as a test class. It checks if the class is a subclass of `unittest.TestCase`, matches test name requirements, or has an explicit `__test__` attribute set to `True`. Classes starting with underscore are automatically excluded. Plugin overrides can also modify the decision. The method returns a boolean indicating if the class is wanted as a test class, with debug logging for tracking the decision process.
14321	Is the directory a wanted test directory?

All package directories match, so long as they do not match exclude. All other directories must match test requirements.

Returns:
    bool: True if the directory is wanted, False otherwise
14322	**Summary:**

The `wantFile` method determines whether a given file should be considered a test file based on several criteria. It first checks if the file matches any patterns in `ignoreFiles`, and if so, skips it. Then it verifies if the file is executable and skips it if `includeExe` is False. It checks if the file has a `.py` extension and matches the test patterns. Additionally, it consults plugins for their opinion on whether the file should be included. The method returns `True` if the file is a Python source file that matches the test criteria and is not ignored or executable, otherwise `False`.
14323	**Summary:**

The `wantFunction` method determines whether a given function should be treated as a test function. It checks if the function has a `compat_func_name` attribute (for compatibility), falls back to `__name__`, and handles cases where the object isn't a function. The method evaluates if the function should be tested based on:
1. An explicit `__test__` attribute 
2. If the function name doesn't start with underscore and matches certain criteria via `self.matches()`
3. Plugin overrides via `self.plugins.wantFunction()`

The final determination is logged and returned.
14324	**Summary:** Determines if a given method should be treated as a test method by checking various conditions including method name prefix, test declaration attribute, name matching rules, and plugin overrides. Returns a boolean indicating whether the method is wanted for testing.
14325	**wantModule(self, module)**

Determines if a module should be treated as a test module based on naming conventions and explicit declarations. Returns `True` if the module matches test requirements or is `__main__`, and respects plugin overrides.

**Parameters:**
- `module`: The module to check

**Returns:**
- `bool`: `True` if the module should be treated as a test module, `False` otherwise

**Logic:**
1. Checks for explicit `__test__` attribute on module
2. Falls back to testing if module name ends with test pattern or is `__main__`
3. Allows plugins to override the decision
4. Logs the final decision for debugging
5. Returns the final determination
14326	Return the contents of a named file as a list of lines.

This function never raises an IOError exception: if the file can't be
read, it simply returns an empty list.
14327	**Summary:** The `list_command_pydb` method is a list command handler that processes a list command argument using the parent class's `parse_list_cmd` method to extract filename, first, and last line numbers. If a filename is successfully parsed, it calls `print_list_lines` to display the specified range of lines from the file. This method serves as an alternative list command implementation for newer pydb versions.
14328	Prints lines from a specified range in a file with optional highlighting of the current line, using formatted templates and handling keyboard interrupts gracefully.
14329	The `do_pdef` method serves as a debugger interface for the `pdef` magic command, retrieving local and global namespace information from the current frame and passing it to the shell's `pdef` line magic with the provided argument.
14330	Generates a multiplying factor to convert between two currencies on a specific date by dividing the target currency's price by the source currency's price. Returns None if prices cannot be retrieved for either currency on the given date.
14331	Converts an amount of money from one currency to another on a specified date, handling different numeric types (float, Decimal, numpy floats) and returning the converted value with appropriate precision, or None for unsupported types.
14332	Compute the return of the currency between two dates using the specified rate type (MID, ASK, or BID). Raises ValueError for invalid rate types or date ranges. Returns the percentage return calculated as (end_price/start_price) - 1.0.
14333	Return the given stream's encoding or a default value. Checks if the stream has an encoding attribute and if it's truthy before returning it, otherwise returns the provided default (or None if not provided).
14334	Return IPython's guess for the default encoding for bytes as text by checking stdin.encoding first, then falling back to locale.getpreferredencoding() and finally sys.getdefaultencoding().
14335	Writes connection information to a JSON file, handling both relative and absolute file paths by placing relative files in the security directory.
14336	Starts the heartbeat mechanism for the kernel by creating a ZMQ context, initializing a Heartbeat object on a specified port, and beginning the heartbeat process. The method ensures the heartbeat operates independently of the GIL to prevent blocking during zero-copy message cleanup. It also logs the heartbeat port number and outputs connection instructions for connecting additional clients to the kernel.
14337	Displays connection information and stores port information. Extracts and formats connection file basename, logs the connection details using critical level, and creates a dictionary mapping port types to their respective port numbers.
14338	Initializes a session object with default security settings and a kernel username.
14339	Initialize input/output streams by redirecting stdout/stderr and setting up display hook for notebook communication.
14340	Initialize and create a kernel object using the specified kernel class, passing necessary configuration and socket connections.
14341	Initializes SSH tunneling connection handler that creates functions for establishing secure connections through SSH tunnels when SSH configuration is provided, otherwise uses direct connections. Returns a tuple of connect and maybe_tunnel functions for handling different connection scenarios.
14342	Method: register
Description: Sends a registration request to a controller using ZeroMQ. Initializes a DEALER socket with identity, connects to the specified URL, sets up a ZMQStream for message handling, and sends a registration request containing queue, heartbeat, and control identifiers.

Parameters: None
Returns: None
Side effects: Establishes connection to controller, sets up message handling callback, sends registration request message
14343	Converts HTML content to plain text using html2text library, preserving links.
14344	```python
def md_to_text(content):
    """ Converts markdown content to text """
    text = None
    html = markdown.markdown(content)
    if html:
        text = html_to_text(content)
    return text
```

**Summary:** Converts markdown content to text by first converting it to HTML using markdown.markdown(), then converting the HTML to plain text using html_to_text() function. Returns the resulting text or None if conversion fails.
14345	Returns a fully qualified app domain name by combining the given domain with its protocol (http or https).
14346	Summary: Defines command line options for the NoseExclude plugin, adding two new options: "--exclude-dir" to specify directories to exclude from test discovery (can be repeated) and "--exclude-dir-file" to specify a file containing directories to exclude. Both options support environment variable configuration through NOSE_EXCLUDE_DIRS and NOSE_EXCLUDE_DIRS_FILE respectively.
14347	Configures the plugin based on command line options and exclude directory settings. Loads exclude directories from file if specified, normalizes directory paths to absolute paths, and sets up exclusion mapping for later use during test discovery.
14348	Check if directory is eligible for test discovery. Returns False if directory is in exclude_dirs, otherwise returns None.
14349	Return True if 'ext' links to a dynamic library in the same package.
14350	Call each function in the given list with the provided arguments and return the result of the last function call, or None if the function list is empty.
14351	Calls each function in the reversed order of the provided function list with the given arguments and returns the result of the last function call, or None if the function list is empty.
14352	Appends a wrapped function with given arguments and keywords to the object.
14353	Inserts a function with given arguments and keywords at the specified index in the list.

The method takes a function and its arguments/keyword arguments, wraps them using `partial` to create a new function with pre-filled arguments, and inserts this wrapped function at the specified index in the current object (which appears to be a list-like structure). This allows for delayed execution of functions with preset parameters.

Parameters:
- index: Position where the wrapped function should be inserted
- func: Function to be wrapped and inserted
- *args: Positional arguments to be pre-filled in the function
- **kwargs: Keyword arguments to be pre-filled in the function

The wrapped function maintains the original function's interface but with some arguments already bound to the provided values.
14354	Formats usage message with proper newline handling based on whether parser description exists.
14355	Initializes the application by calling the parent's initialize method, changing to the working directory, and reinitializing logging.
14356	Creates a PID file in the specified directory containing the process ID. Raises PIDFileError if the file already exists and overwrite is False. Writes the current process ID to the file and logs the creation.
14357	Remove the pid file at shutdown, logging info about the removal or warnings if errors occur.
14358	Get the pid from the pid file. If the pid file doesn't exist a PIDFileError is raised.
14359	Constructs an argument parser for a magic function using its decorations, sets up the parser with appropriate help text formatted for IPython syntax, and returns the configured parser object.
14360	Find the real name of a magic function by extracting the name from the function object, removing the 'magic_' prefix if present, and returning the argcmd_name attribute if it exists, otherwise returning the processed magic name.
14361	Method: `highlightBlock(self, string)`

Summary: This method selectively highlights text blocks by first checking if highlighting is enabled. It retrieves the current block's plain text content and determines whether to use a regular or continuation prompt based on block position. If a prompt is identified, it skips highlighting the prompt itself and applies highlighting to the remaining text content using the parent class's highlighting functionality.
14362	Reimplements the block rehighlighting functionality by temporarily enabling highlighting if it was disabled, then restores the original highlighting state.
14363	Sets text formatting for a specified range with offset adjustment, extending the parent class functionality to support selective highlighting in a frontend highlighter.
14364	Copy the currently selected text to the clipboard, removing prompts.
14365	Executes the given source code through the kernel manager's shell channel, stores execution request information, and emits executing signal unless the execution is hidden.
14366	Method `_prompt_finished_hook` is called immediately after a prompt is completed, before processing input and displaying a new prompt. It resets the input splitter's buffer to ensure clean state for the next input cycle and disables highlighting if not currently reading input.

**Key actions:**
- Resets `self._input_splitter` to clear the input buffer
- Turns off highlighting when not in reading mode (`self._reading` is False)
14367	Handles tab key presses for text completion. Returns True if event should continue processing, False if completion occurred. Performs tab completion when cursor is in input buffer and there's non-whitespace text before cursor.
14368	Method `_context_menu_make` reimplements the context menu creation to add a raw copy action. It calls the parent's implementation, then searches for the Paste action in the menu. When found, it inserts the `_copy_raw_action` before the Paste action. Returns the modified menu with the new action added.
14369	Method `_event_filter_console_keypress` handles console keypress events for execution interruption and smart backspace functionality. It returns `True` to indicate handled events or calls the parent class method for unhandled events. Key features include: Ctrl+C to interrupt kernel execution, Ctrl+Period to restart kernel, and smart backspace that removes 4 spaces at cursor if conditions are met (cursor > 3, no selection, 4 spaces immediately left, and all characters left are whitespace).
14370	Inserts a continuation prompt with proper auto-indentation by calling the parent implementation and adding spaces based on the input splitter's indent settings.
14371	Handle tab completion replies by debugging the response, checking if the reply matches the current completion request and cursor position, then completing the text with available matches.
14372	Silently executes a given expression in the kernel without frontend output, then calls the provided callback function with the repr() of the result as its argument. Uses a UUID to track the request and stores the callback in a dictionary for later execution.
14373	Execute callback corresponding to msg reply by looking up the message id in callback dictionary, calling the callback with the expression result, and removing the callback from the dictionary.
14374	Handles replies for code execution by processing different execution statuses (ok, error, aborted), managing kernel communication, and updating the frontend state accordingly.
14375	Handles requests for raw_input by logging the input request, checking for hidden execution mode, flushing subprocess output, and initiating readline mode with a callback to send input back through the stdin channel.
14376	Handles kernel death by logging the event and either emitting a custom restart signal or showing a restart dialog to the user.
14377	Handle replies for call tips by extracting information from the response, checking if it matches the current cursor position and request ID, and displaying call tip information if available.
14378	Handles display hook output by logging and appending plain text content to output.
14379	Handles stdout, stderr, and stdin stream messages by logging them, checking if they're from the current session, converting tabs to spaces, appending the text to the console, and moving the cursor to the end.
14380	Handle shutdown signals from other consoles, with different behavior for local vs remote kernels: for local kernels, either exit or reset the console depending on restart flag; for remote kernels, show message boxes asking whether to close the console or clear it when kernel shuts down or resets.
14381	Executes a file at the given path using execfile(), with optional hidden execution that suppresses output.
14382	Attempts to interrupt a running kernel and resets the _reading flag to prevent runtime errors. If a custom interrupt is defined, emits a custom interrupt signal; otherwise, if the kernel manager has a kernel, interrupts it directly. If the kernel is remote or unspecified, displays a message indicating interruption is not possible.
14383	Resets the widget to its initial state. If `clear` parameter or `clear_on_kernel_restart` configuration is True, clears the widget and rewrites the banner. Otherwise, shows a visual indication of kernel restart without clearing traces. Also updates output marker positioning.
14384	Attempts to restart the running kernel with optional user confirmation and error handling for external kernels.
14385	Shows a call tip at the current cursor location if appropriate, by checking for enabled calltips, '(' character before cursor, and valid context, then sending an object info request to the kernel. Returns True if request is sent, False otherwise.
14386	Performs completion at the current cursor location by sending a completion request to the kernel with the current context and cursor position information.
14387	Process a reply for an execution request that resulted in an error, handling SystemExit cases specially for kernel exit behavior while logging other errors with traceback information.
14388	Process a reply for a successful execution request by iterating through the payload items and processing each one, printing a warning for any unknown payload types encountered.
14389	Method `_document_contents_change` is called when the document content changes and displays a call tip if the cursor position matches the current position after the change. The method adjusts the cursor position based on the text added and checks if the cursor should trigger a call tip display.
14390	Adds a plugin to the list of plugins to call if it has the specified attribute. If the attribute is 'loadTestsFromModule' and the method signature has 2 parameters, it wraps the method to accept only 1 parameter (module) and stores the plugin-method pair.
14391	Call plugins in a chain where each plugin's output is passed as input to the next plugin, returning the final result.
14392	Call all plugins, yielding each item in each non-None result, while handling exceptions by yielding Failure objects.
14393	Call all plugins, returning the first non-None result.
14394	Configures plugins with given options and config, removes disabled plugins from the list, and sorts the remaining enabled plugins.
14395	Load plugins by iterating the `nose.plugins` entry point, handling plugin loading exceptions gracefully and adding successfully loaded plugins to the manager.
14396	Load built-in plugins from nose.plugins.builtin and add them to the plugin manager.
14397	Render a LaTeX string to PNG using specified backend (mpl or dvipng), with optional base64 encoding for JSON compatibility. Returns None if backend is unavailable.
14398	Converts LaTeX string to HTML with embedded PNG image using data URI format, returning HTML img tag with base64 encoded image data and alternative text.
14399	Renders a mathematical expression as an image file using matplotlib's math rendering capabilities. Takes a math expression string, renders it in a tightly clipped bounding box, and saves it to the specified file path or object. Supports various output formats (png, pdf, svg, etc.) and allows customization of font properties and DPI settings. Returns the depth of the rendered math expression.
14400	Find an installed distribution that satisfies or conflicts with this requirement, and set self.satisfied_by or self.conflicts_with appropriately. Returns True if a distribution is found, False otherwise. Handles cases where the distribution is not found or there's a version conflict.
14401	Generator function that yields Process instances for all running processes on the local machine, with caching and automatic update of the process list based on PIDs.
14402	Return CPU utilization percentage as a float or list of floats. When interval > 0.0, it blocks for the specified time interval to calculate utilization. When interval is 0.0 or None, it returns immediately using cached values. If percpu=True, returns utilization for each CPU core as a list.
14403	Returns process information as a dictionary with specified attributes or all public read-only attributes. Handles AccessDenied and NotImplementedError exceptions by assigning a default value or skipping unsupported attributes. Excludes certain methods and private attributes from the result.
14404	Returns the process name, with special handling for UNIX systems where the name may be truncated. On UNIX, if the process name matches the beginning of the command line, the full command line name is returned instead for better clarity. The result is cached in `_process_name`.
14405	Returns the process executable path, guessing from cmdline[0] if necessary and handling AccessDenied exceptions.
14406	Return the children of this process as a list of Process objects. If recursive is True, return all parent descendants. The method first checks if the process is running, then iterates through all processes to find children based on parent PID. For recursive search, it builds a mapping table of processes by parent PID and traverses descendants breadth-first. Children are filtered by creation time to handle PID reuse scenarios. Returns a list of child Process objects.
14407	Return the current process CPU utilization as a percentage. When interval > 0.0, it blocks and compares process times to system CPU times over the interval. When interval is 0.0 or None, it compares to times elapsed since the last call and returns immediately. The result represents CPU usage across all CPUs, with a single CPU percentage calculated by multiplying by the number of CPUs. On non-POSIX systems, values above 100% are capped at 100%.
14408	Calculate process memory utilization as a percentage by comparing resident memory to total physical memory.
14409	Return process's mapped memory regions as a list of namedtuples. If 'grouped' is True, regions with the same path are grouped together with summed memory fields. If 'grouped' is False, every mapped region is shown as a separate entity including address space and permission set details.
14410	Return whether this process is running by comparing the process ID and creation time with the platform implementation's stored values, handling NoSuchProcess exceptions by marking the process as gone.
14411	Suspend process execution by sending SIGSTOP signal on POSIX systems or using platform-specific suspend method on Windows, with safety check to ensure the process is still running.
14412	Resume process execution by sending SIGCONT signal or using platform-specific resume method. Raises NoSuchProcess if process is no longer running.
14413	Kill the current process by sending SIGKILL signal on POSIX systems or using platform-specific implementation on other systems, with a safety check to ensure the process is still running before attempting to kill it.
14414	Wait for process to terminate and return its exit code if it's a child process, otherwise None. Raises ValueError if timeout is negative.
14415	Initializes the kernel inside GTK by hijacking GTK's main loop and setting up a timeout callback for kernel iteration, then returns False to prevent duplicate execution.
14416	Summary of `_hijack_gtk` method:

Hijacks key GTK functions (`gtk.main` and `gtk.main_quit`) to prevent blocking in IPython sessions. Replaces these functions with dummy implementations that do nothing, allowing users to run pyGTK scripts with `%run` without blocking the long-lived IPython session. Returns the original functions that were replaced.
14417	Check if a given identifier is defined in namespaces that shadow alias and magic namespaces, excluding the '.' character.
14418	Initializes default transformers by creating instances of each transformer class in `_default_transformers` with the shell, prefilter manager, and config parameters.
14419	Register a transformer instance if it's not already registered, then sort all transformers.
14420	Remove a transformer instance from the registered transformers list if it exists.
14421	Initialize default checkers by creating checker instances with shell, prefilter_manager, and config parameters.
14422	Register a checker instance if it's not already registered, then sort all checkers.
14423	Remove a checker instance from the registered checkers list if it exists.
14424	Initialize default handlers by creating empty dictionaries for regular and escape handlers, then iterate through default handlers and instantiate each one with shell, prefilter manager, and config parameters.
14425	Register a handler instance by name and associate it with escape strings for quick lookup.
14426	Unregister a handler instance by name and remove it from both main handlers and escape string handlers. If the handler name doesn't exist, silently ignore the error. For each escape string, remove the handler if it matches the provided handler instance.
14427	Prefilter a line converted to LineInfo object by finding the appropriate handler and returning its processed result.
14428	Finds an appropriate handler for the given line information by iterating through enabled checkers until a matching handler is found, returning the 'normal' handler as fallback if none match.
14429	Transforms a line of text by applying all enabled transformers in order of increasing priority.
14430	Prefilters a single input line by applying transformers and checkers/handlers. Handles empty lines, continuation prompts, and special line processing while maintaining input history tracking. Returns the prefiltered line content after processing through the normal handler or special handlers when applicable.
14431	Prefilters multiple input lines of text by calling `prefilter_line` for each line, handling cases where multiple lines are received as a single input (such as when recalling multiline history entries). Returns the prefitered output.
14432	Checks if an object in user namespace is an IPyAutocall instance and returns the auto handler if so, otherwise returns None.
14433	Check if multi-line special characters (! and !!) are allowed and return the appropriate handler, otherwise return None.
14434	Check for escape character in line_info and return appropriate handler for help escape sequence, or None if no escape char is found or if it's a shell escape sequence.
14435	Check if the initial identifier on the line is an alias, returning the alias handler if it is, otherwise returning None.
14436	Handle normal input lines by processing autoindent exit conditions. Returns an empty line when autoindent is enabled and specific whitespace patterns are detected that should terminate the input loop.
14437	Handles alias input lines by expanding aliases and transforming them into system calls while preserving leading whitespace for proper indentation support.
14438	Handles a line of code by executing it in a shell or processing magic commands. If the line starts with ESC_SH_CAP, it rewrites the line to properly handle shell commands with magic syntax and delegates to the magic handler. Otherwise, it formats the line for shell execution using IPython's system command. Returns the processed line for execution.
14439	Generate a command string to execute IPython magic functions with the given function name and arguments.
14440	Handles lines that can be auto-executed, with options for quoting or parenthesizing based on the input and context, returning the processed command string.
14441	Method `handle` attempts to provide help information for objects. It distinguishes between valid Python syntax and help queries (marked with ESC_HELP prefix/suffix). If the line is invalid syntax and contains help markers, it uses `pinfo` magic to show object information. If valid syntax, it processes normally through the regular handler. Returns empty string for help cases, delegates to normal handler otherwise.
14442	Summary: Overrides eventFilter to handle key press events (Enter, Return, Escape) and focus changes for a text edit widget, hiding the widget accordingly and returning True for Escape key to indicate event handling completion.
14443	Method `enterEvent` reimplements the parent's method to cancel the hide timer when the mouse enters the widget.
14444	Reimplements the paintEvent method to draw a tip label panel background using QStylePainter and QStyleOptionFrame, then calls the parent class's paintEvent method.
14445	Shows call line and docstring information at cursor location, truncating docstring if it exceeds maximum lines.
14446	Displays a tip widget at the current cursor location, adjusting its position to stay within screen boundaries.
14447	Updates the tip based on user cursor movement by checking if cursor position is within valid range and finding matching parenthesis to determine whether to hide the tip.
14448	Creates a property that proxies access to an attribute through a local attribute reference.
14449	Canonicalizes a path relative to a given working directory by converting it to absolute form. If the path is not absolute, it is joined with the working directory before converting to absolute form. Returns the absolute path.
14450	Schema validation helper that performs JSONSchema validation and raises a specified exception class with a simplified error message containing the validation path and original error message when validation fails.
14451	Returns a read-only subordinate mapping with stringified values and masked sensitive data, implementing the context manager protocol. Creates and caches the mapping on first access.
14452	Return True if in a virtual environment and no system site packages are allowed.
14453	Parallel word frequency counter that distributes file processing across multiple workers and aggregates results.
14454	Converts a function-based decorator into a class-based decorator for use on class-based views by monkey-patching the dispatch method.
14455	Return list of shell aliases to auto-define based on the operating system platform, including safe aliases for mkdir, rmdir, mv, rm, cp, cat, and ls (with platform-specific variations for Linux, BSD/OSX, and Windows).
14456	Defines an alias without raising an AliasError, instead logging an error message if the alias is invalid.
14457	Defines a new alias by validating it first, then storing it in the alias table with the number of arguments and command. Raises AliasError if validation fails.
14458	Validates an alias by checking if the name is valid (not a keyword/builtin) and if the command is a string. Returns the number of '%s' arguments in the command, raising InvalidAliasError for invalid names, non-string commands, or mutually exclusive '%s' and '%l' specifiers.
14459	Calls an alias by its name and rest of the line, transforms it, executes the resulting command, and shows traceback if execution fails.
14460	Transforms an alias into a system command string by expanding arguments and handling special characters. Takes an alias and optional rest string, looks up the alias in alias_table, handles file paths with spaces, expands %l special character, and formats positional arguments according to nargs. Raises AliasError if argument count doesn't match. Returns the formatted command string.
14461	Expand an alias in the command line by translating the first word (command) according to alias expansion rules, returning the modified command line with the alias replaced.
14462	Produces reStructuredText documentation from nose test help output, including options and their descriptions, formatted as an RST section node.
14463	Reset graphics attributes to their default values by resetting intensity to 0, italic to False, bold to False, underline to False, and clearing foreground and background colors.
14464	Splits a string into substrings, yielding parts with consistent escape code handling. Processes ANSI and special escape sequences, yielding text segments and handling actions like beep, carriage return, backspace, and newlines. Returns None for action-only segments and handles special characters like \r, \n, and \b. Accounts for strings ending with \r by treating them as \r\n. Processes CSI and OSC escape codes with parameter parsing.
14465	Returns a QColor for a given color code with optional intensity adjustment, or None if construction fails. Handles color mapping through color_map, supporting X11 color names and RGB tuples/lists.
14466	Returns a QTextCharFormat configured with the current style attributes including foreground color, background color, font weight, italic, and underline settings.
14467	Generate a JWT token with a specified age and additional payload data using a secret key for encoding.
14468	**Summary:**

The `mutex` decorator implements thread synchronization by acquiring a lock before executing the decorated method and releasing it afterward. It expects the first argument (self) to have a `lock` attribute. The decorator ensures thread-safe execution of methods by wrapping the original function with lock acquisition and release logic in a try/finally block to guarantee the lock is always released, even if an exception occurs.
14469	Clean up expired JWT tokens by removing those older than twice the allowed age.
14470	has this jwt been used?
14471	Validates a JWT token by checking its signature, expiration, and reuse prohibition. Returns the decoded token data if valid, raises JwtFailed exceptions for various validation failures including expired tokens, decoding errors, missing expiration or jti claims, and reused tokens.
14472	Creates a semaphore decorator that enforces thread safety by limiting concurrent access to a function. The semaphore uses either a regular Semaphore or BoundedSemaphore based on the bounded parameter, and the `with_it` function applies the semaphore locking mechanism to the decorated function.
14473	Get common prefix for completions, handling escape characters like IPython %magic functions. Returns longest common prefix of a list of strings, with special treatment for escape characters at the beginning of strings. Uses os.path.commonprefix for the core prefix calculation but applies special logic to handle escape sequences (like %magic commands) that might precede the actual completion text. The function first determines the common prefix of escape characters among all items, then finds the common prefix of the remaining text after stripping escape characters, and combines them to produce the final result.
14474	Summary: This method implements custom event filtering for a console widget to provide console-like behavior. It handles various event types including key presses (with Ctrl key remapping and console-specific handling), mouse button releases (for safe middle-click paste), resize events (with scrollbar adjustment), shortcut overrides, drag-and-drop operations (with safety measures), and scrolling events for a pager component. The method ensures proper text handling, prevents unwanted text deletion during drags, and maintains safe clipboard operations while preserving the parent class's event filtering for unhandled cases.
14475	Returns a suggested size hint of 80 characters wide and 25 lines high, accounting for margins, scrollbars, and split view requirements.
14476	Returns whether text can be cut to the clipboard based on cursor selection and buffer position constraints.
14477	Returns whether text can be pasted from the clipboard by checking if the control is editable and if there is text available in the clipboard.
14478	Clears the console output. If keep_input is True (default), preserves the input buffer content when clearing and showing a new prompt. Uses the internal control object to perform the clear operation and manages the input buffer state accordingly.
14479	**Method Summary:**

`cut()` - Copies the currently selected text to the clipboard and removes it from the input buffer if cutting is permitted.

**Behavior:**
- First copies the selected text to clipboard by calling `self.copy()`
- Checks if cutting is allowed via `self.can_cut()`
- If cutting is permitted, removes the selected text from the input buffer using `self._control.textCursor().removeSelectedText()`

**Usage:** Typically used for the standard "cut" operation in text editing interfaces.
14480	Executes the given source code or the input buffer, with options for hidden execution and interactive mode. Raises RuntimeError if incomplete input is provided in hidden mode. Returns a boolean indicating successful execution.
14481	Returns the text that the user has entered at the current prompt, accounting for execution state and continuation prompts. If currently executing, returns the stored executing input buffer unless forced. Strips continuation prompts from the result.
14482	Sets the text in the input buffer. If the console is executing, stores the text for later use. Otherwise, removes old text, inserts new text with continuation prompts, and moves cursor to end.
14483	Sets the base font for the ConsoleWidget to the specified QFont, updates font metrics, tab stop width, and emits font_changed signal.
14484	Pastes clipboard contents into the input region with optional clipboard mode control, removing trailing newlines and ensuring cursor stays within buffer bounds.
14485	Print the contents of the ConsoleWidget to the specified QPrinter, or show a print dialog if no printer is provided.
14486	Moves the prompt to the top of the viewport if not currently executing.
14487	Sets the font to the default fixed-width font for the current platform (Consolas/Courier for Windows, Monaco for macOS, Monospace for others) with optional custom font size, and applies it using the internal _set_font method.
14488	A low-level method for appending content to the buffer end, with optional insertion before the current prompt when enabled.
14489	Appends HTML content to the console buffer, optionally inserting it before the prompt.
14490	Appends HTML content and returns its plain text representation by utilizing a custom appending method with HTML insertion logic.
14491	Appends plain text content to the output, processing ANSI escape codes if text processing is enabled.
14492	Clears the temporary text buffer by removing all text following the prompt region and resets the undo/redo history to ensure the text is truly temporary.
14493	Completes text at cursor position using provided items, handling single item insertion or multiple item prefix completion with widget display.
14494	Fills the area below the active editing zone with provided text, maintaining the current cursor position and updating the temporary buffer flag.
14495	Returns whether the Control key is pressed given a KeyboardModifiers flags object, with special handling for Mac OS where Command key is treated as a synonym for Control when include_command=True.
14496	Creates and configures a text editing control (QPlainTextEdit or QTextEdit) with event filtering, signal connections, and specific terminal-like behavior by hijacking document size changes and adjusting scrollbars.
14497	Creates and configures a paging widget based on the specified kind ('plain' or 'rich') or uses a custom control, then sets it up with event filtering, read-only mode, and scroll bar policy.
14498	Filters key events for paging widget to create console-like interface, handling Ctrl/O, Alt/>, Alt/<, Q/Esc, Enter/Return/Tab, and Backspace keys with specific actions.
14499	Given a QTextBlock, return its unformatted text by creating a cursor, selecting the entire block, and extracting the plain text content.
14500	Returns a cursor positioned at the last character of the text control.
14501	Returns the cursor column position in the input buffer excluding the prompt length, or -1 if no prompt exists.
14502	Returns the text of the line containing the cursor in the input buffer,excluding the prompt prefix,or None if no such line exists.
14503	Returns a text cursor positioned at the prompt location.
14504	Returns a cursor with text selected between the specified start and end positions.
14505	Inserts a continuation prompt using the specified cursor, using either plain text or HTML format based on availability.
14506	Inserts HTML content using a cursor while preventing subsequent formatting issues by resetting the document's style state through careful cursor positioning and text insertion.
14507	Inserts HTML using the specified cursor and returns its plain text version.
14508	Inserts plain text using the specified cursor, processing ANSI codes if enabled. Handles various ANSI actions like erase, scroll, carriage-return, beep, backspace, and newline, while maintaining proper text formatting and cursor positioning. If ANSI codes are disabled, inserts text directly.
14509	Ensures cursor is within editing region by moving it to end if outside. Returns True if cursor was moved, False otherwise.
14510	Cancels the current editing task, similar to Ctrl-G in Emacs. If a temporary buffer is filled, it cancels completion and clears the temporary buffer. Otherwise, it clears the input buffer.
14511	Displays text using a pager when it exceeds viewport height, with optional HTML support. If text is longer than available space, it either emits a custom page request or shows the text in a dedicated page control. For shorter text, it appends the text directly to the main control.
14512	Called immediately after a new prompt is displayed. Temporarily disables maximum block count, enables undo/redo, works around QPlainTextEdit input method bug, calls prompt started hook, handles pending input buffer, and moves cursor to end.
14513	Reads one line of input from the user with optional prompt and callback functionality. If no callback is provided, reads synchronously and returns the input string with trailing newline stripped. If a callback is provided, reads asynchronously and executes the callback with the input when ready. Raises RuntimeError if widget is already reading or if synchronous read is attempted while widget is not visible.
14514	Sets the continuation prompt for additional input, storing it either as plain text or HTML format based on the html parameter.
14515	Scrolls the viewport to bring the specified cursor to the top visible position by moving the scrollbar to maximum value, temporarily setting the cursor to the target position, ensuring it's visible, then restoring the original cursor position.
14516	Writes a new prompt at the end of the buffer with optional HTML formatting and newline handling.
14517	Expands the vertical scrollbar beyond Qt's default range by adjusting its maximum value and page step based on document content. For QPlainTextEdit, it calculates maximum based on line count with line spacing steps, while for QTextEdit it uses document height with viewport-based steps. Includes compensation for automatic scrolling caused by text truncation due to maximum block count limits.
14518	Entry point for pkginfo tool that parses command line options, processes metadata from package files using specified format, and outputs formatted metadata information.
14519	Copy a default config file into the active profile directory, returning True if successful or False if the file already exists and overwrite is False.
14520	Create a profile directory by name and path.

Parameters:
- path: unicode - The directory path to create the profile directory in
- name: unicode - The profile name (default: 'default'), directory will be named "profile_<name>"
- config: object - Configuration object for the profile

Returns:
- ProfileDir instance with the specified location and config

Raises:
- ProfileDirError: If the specified path does not exist as a directory
14521	Find an existing profile directory by name and return its ProfileDir instance.

Searches for a profile directory with the pattern "profile_<name>" in the current working directory and IPython directory. Raises ProfileDirError if the directory is not found in either location.
14522	Converts a comparison function into a key function for sorting.
14523	Reads a file and returns its contents as a string, then closes the file.
14524	Take multiple lines of input and return them as a list, using a termination string (default '.') or EOF to stop. Supports line continuation with backslash (\) to join multiple lines into single entries.
14525	Make a temporary Python file, return filename and filehandle.

Parameters:
----------
src : string or list of strings (no need for ending newlines if list)
  Source code to be written to the file.
ext : optional, string
  Extension for the generated file.

Returns:
-------
(filename, open filehandle)
  It is the caller's responsibility to close the open file and unlink it.
14526	Close the file and restore the channel by flushing, restoring the original output stream, closing the file, and setting the closed flag to True.
14527	Write data to both the file and output stream channels, then flush the output stream.
14528	Adds a new handler for processing new heartbeats to the internal set of handlers.
14529	Adds a new handler for heart failure events to the failure handlers set, logging the addition at debug level.
14530	Handles pong messages from heartbeats, tracking response times and detecting missed heartbeats. Updates response tracking and logs warnings for delayed or invalid heartbeats.
14531	Converts a list into a list of lists with equal batch_size.

Parameters:
- sequence: list of items to be placed in batches
- batch_size: length of each sub list
- mod: remainder of list length divided by batch_size (default: 0)
- randomize: should the initial sequence be randomized before being batched (default: False)

Returns:
- list of lists with equal batch_size

Example:
>>> batch_list([1, 2, 3, 4, 5, 6], 2)
[[1, 2], [3, 4], [5, 6]]

>>> batch_list([1, 2, 3, 4, 5, 6], 2, randomize=True)
[[4, 1], [6, 2], [5, 3]] (randomized order)
14532	Function `path_to_filename` takes a path filename string and returns the split between the path and the filename. If filename is not given, filename = ''. If path is not given, path = './'.
14533	Generator for walking a directory tree, yielding paths of files that match a specified pattern. It can optionally recurse through subdirectories. Parameters include root directory path (default '.','), recursion flag (default True), and file pattern (default '*'). Returns a generator yielding matching file paths.
14534	Displays progress information including percentage completed, current count, and estimated time of arrival (ETA) when the current count matches the display interval. The function calculates average time per iteration and estimates total completion time, then formats and prints this information in human-readable time units. Returns None.
14535	The `timeUnit` function calculates appropriate time units (seconds, minutes, hours) for three different time values: elapsed time, average time, and estimated end time. It takes three parameters - `elapsed`, `avg`, and `est_end` - which represent time durations in seconds. The function returns a list of three tuples, where each tuple contains a time value converted to the most appropriate unit (secs, mins, or hr) based on the following logic:

- If time <= 3 minutes: display in seconds
- If time > 3 minutes and <= 3 hours: display in minutes  
- If time > 3 hours: display in hours

Each tuple in the returned list corresponds to the elapsed time, average time, and estimated end time respectively, with each time value converted to its most suitable unit of measurement.
14536	Extracts configuration data from a bdist_wininst .exe file and returns it as a ConfigParser.RawConfigParser object, or None if the file is not a valid wininst executable or doesn't contain the required configuration sections. The function reads the zipfile end record to locate the wininst data, validates the tag, and parses the configuration section to create a RawConfigParser object containing the metadata and Setup sections. Returns None if any validation fails or if required sections are missing.
14537	Function to clear cached zip directory information and sys.path importer cache for a given path to prevent stale data.
14538	Quote a command line argument according to Windows parsing rules by adding quotes and escaping backslashes and double quotes properly.
14539	```python
def check_conflicts(self, dist):
    """Verify that there are no conflicting "old-style" packages"""
    return dist  # XXX temporarily disable until new strategy is stable
```

The `check_conflicts` method is designed to verify that there are no conflicting "old-style" packages by checking for potential namespace conflicts in the installation directory. However, the actual conflict detection logic is currently disabled with a return statement that bypasses all the conflict checking code. The method would normally scan through paths and files to identify conflicting package files (like .pyc, .pyo files) and call `found_conflicts` if any are found.
14540	Sets fetcher options for easy_install by extracting fetch-related directives from easy_install options and writing them to a setup.cfg file for use when running bdist_egg on source distributions with setup_requires directives.
14541	Create directories under the user's home directory (~) based on configuration variables, making them with 0700 permissions if they don't already exist and are within the home directory.
14542	Return True if the given filename has an archive file extension (zip, tar.gz, tar.bz2, tgz, tar, or whl).
14543	Creates a mutable proxy for an object that allows modifications without affecting the original object. The proxy inherits from the original object's class and uses a custom `__getattribute__` method to handle attribute access, with `update_wrapper` preserving the original class's metadata. Returns an instance of the proxy class.
14544	Returns a readonly proxy for the given object that prevents modification. All attribute access works normally, but attempting to set attributes will raise an AttributeError if error_on_set=True. The proxy doesn't modify the original object.
14545	Create a new heading cell for a notebook with specified source, rendered content, level, and metadata.
14546	Create a new metadata node with optional name, authors, license, created date, modified date, and gistid parameters.
14547	Create a new author object with optional name, email, affiliation, and url parameters.
14548	Returns True if `path` is a directory and the user has write access to it.
14549	Remove leading and trailing quotes from filenames on Windows platform.
14550	Return a valid Python filename in the current directory by ensuring the file exists and has a .py extension if needed, with optional Windows filename handling.
14551	Find a file by searching through specified paths. If no paths are provided, searches in the current working directory. Returns the absolute path of the first occurrence of the file found, or raises IOError if not found. Supports path expansion using expandvars and expanduser.
14552	Return the 'home' directory as a unicode string, checking for frozen environments and ensuring writability if required.
14553	Return the XDG_CONFIG_HOME directory if it exists and is writable, otherwise return None. This function is designed for non-OS X posix systems (Linux, Unix, etc.) and uses the XDG base directory specification.
14554	Get the IPython directory for this platform and user, using either the XDG config directory or home directory with a fallback to a temporary directory if necessary.
14555	Get the base directory where IPython itself is installed.
14556	Find the path to an IPython module in this version of IPython, returning the path to the .py version of the module.
14557	Determine whether a target file is out of date compared to its dependencies.

target_outdated(target, deps) -> 1/0

deps: list of filenames which MUST exist.
target: single filename which may or may not exist.

If target doesn't exist or is older than any file listed in deps, return 1 (true), otherwise return 0 (false).
14558	Creates an MD5 hash of a file's contents while ignoring line ending differences by opening the file in universal newlines mode.
14559	Check for old IPython configuration files and warn users about the deprecated config system. If old config files exist, it either removes them if they haven't been modified (using MD5 hash comparison) or issues a warning about user modifications. If any old files are found, it provides information about the new config system and instructions for creating new configurations.
14560	Updates the suggestions dictionary for an object when a user visits its page, tracking viewed objects and creating dictionary entries for suggestion generation.
14561	Returns a list of suggestions for an object with a specified size, ordered by visits count in descending order. If size is specified, returns only that many suggestions; otherwise returns all suggestions for the object.
14562	Returns a list of all suggestions for a given object, ordered by visit count in descending order.
14563	Return this path as a relative path based from the current working directory.
14564	Return a list of path objects that match the pattern.
14565	Reads all lines from a file and returns them as a list. If no encoding is specified and retain is True, uses 'U' mode to read lines with universal newlines. Otherwise, reads as text and splits lines based on the retain parameter.
14566	Reads the entire file and calculates its MD5 hash, returning the digest.
14567	Create profile stats file and load profiler.
14568	Method: report(self, stream)

Summary: Outputs a profiler report to the specified stream. The method closes the profiler, loads statistics from the profile file, sorts them based on the configured sort order, and then prints the stats to the provided stream. It handles compatibility differences between Python versions 2.5 and earlier when managing stream output, ensuring the original stream is restored even if an exception occurs during printing. Optional restriction can be applied to limit the output to specific statistics.
14569	Cleans up the stats file if configured to do so by closing the profiler and removing the stats file.
14570	Method sends periodic heartbeat messages at specified frequency until interrupted by keyboard interrupt.
14571	Enable event loop integration with wxPython by setting the PyOS_InputHook for terminal-based applications like IPython. If no existing wx.App is provided or found, a new one is created. Returns the wx.App instance being used. Raises ValueError if wxPython version is less than 2.8.
14572	Disable event loop integration with wxPython by setting PyOS_InputHook to NULL and marking wxPython app as not in event loop.
14573	Disable event loop integration with PyQt4 by setting PyOS_InputHook to NULL and updating the Qt4 application's event loop status.
14574	Enable PyGTK event loop integration by setting the PyOS_InputHook. This allows PyGTK to work with terminal-based applications like IPython by making the GTK main loop interactive. The method handles both newer GTK versions (using gtk.set_interactive(True)) and older versions (using a ctypes-based input hook). The app parameter is ignored and exists only to maintain consistent call signatures across GUI activation methods.
14575	Enable event loop integration with Tk by creating or using a Tkinter.Tk widget and registering it with the InputHookManager.
14576	Enable event loop integration with pyglet by setting the PyOS_InputHook for pyglet, allowing it to integrate with terminal-based applications like IPython. This method configures the input hook for pyglet support and records the current GUI as PYGLET. The app parameter is ignored and only exists to maintain consistent call signatures across GUI activation methods.
14577	Save wave log by storing time and wave data in global history lists.
14578	Initialize database connection and create necessary tables (sessions, history, and output_history) if they don't already exist.
14579	Prepares and runs an SQL query on the history database, returning tuples with optional output data.
14580	Get information about a specific session by session number, returning session details including ID, start time, end time, command count, and remark. Sessions are indexed with 0 as current session, and negative numbers count backwards from current session. Returns None for end time and command count for running sessions or sessions that didn't exit cleanly.
14581	Get the last n lines from the history database, with options for raw output format and excluding the latest entry. Returns tuples similar to get_range method.
14582	Get lines of history from a string of ranges, as used by magic commands %hist, %save, %macro, etc. Parameters: rangestr (str) - A string specifying ranges, e.g. "5 ~2/1-4". raw, output (bool) - As get_range method. Returns: Tuples as get_range method.
14583	Get default history file name based on the Shell's profile, returning the path to 'history.sqlite' in the profile directory. The profile parameter is ignored for parent class compatibility.
14584	Give the current session a name in the history database by updating the sessions table with the provided name where the session number matches.
14585	Clears the session history by releasing all object references and optionally opens a new session. It clears output history, resets directory history to current working directory, and if requested, ends the current session and starts a new one with empty input histories.
14586	Get input and output history from the current session within a specified range, yielding tuples of (0, index, line) where line contains either input history or both input and output history depending on the output parameter.
14587	Stores database output logs by saving outputs from a specified line number to the database, but only if logging is enabled and the line number exists in the output history. It caches the output and sets a save flag when the cache size threshold is reached.
14588	Writes cached database entries to the database, handling integrity errors by creating new sessions for input cache and skipping output cache writes when duplicates occur.
14589	Stops the thread safely from the main thread by setting stop flag, triggering history save, and joining the thread.
14590	Return the number of CPUs on the system by trying multiple approaches: first using os.sysconf("SC_NPROCESSORS_ONLN"), then parsing /proc/cpuinfo, and finally parsing /proc/stat as a last resort. Raises RuntimeError if the number of CPUs cannot be determined.
14591	Return a list of namedtuple representing the CPU times for every CPU available on the system by parsing /proc/stat file and excluding the system-wide CPU stats line.
14592	Return mounted disk partitions as a list of namedtuples, optionally including non-physical devices.
14593	Returns a list of PIDs currently running on the system by listing all numeric directories in /proc.
14594	Make a nice string representation of a pair of numbers, returning just the number if they're equal, or a range format with dash if they're different.
14595	Formats a list of line numbers into a string, coalescing consecutive lines for printing. Takes two lists of integers (statements and lines), sorts them, and groups consecutive numbers into ranges like "1-5, 10-14". Returns a comma-separated string of these ranges.
14596	Return a string summarizing the call stack by extracting function names, file names, and line numbers from the current stack trace.
14597	A decorator that caches the result of expensive operations by storing the result in a cached attribute on the instance, avoiding recomputation for subsequent calls to the same method with no arguments.
14598	Combine a list of regexes into one that matches any of them by joining them with pipe operators, wrapping each regex in parentheses when multiple exist.
14599	Remove a file, and don't get annoyed if it doesn't exist. If the file doesn't exist (ENOENT error), silently ignore it. For other OSError exceptions, re-raise them.
14600	Add `v` to the hash, recursively if needed. Handles strings, None, numbers, tuples, lists, dicts, and objects with __dict__ by hashing their string representations and recursively processing their contents.
14601	Method `update_profiles` updates the cluster profiles by listing all profiles in the IPython directory and current working directory, then adds any new profiles to the `self.profiles` dictionary with their respective profile directory paths and initial status set to 'stopped'.
14602	Start a cluster for a given profile, handling cluster and engine set launchers with proper cleanup and status management.
14603	Stop a cluster for a given profile, raising an HTTPError if the cluster is not running, and return a dictionary with profile information and stopped status.
14604	Finds the full path to a command file (with extensions .exe, .com, .bat, .py) using win32api.SearchPath, searching through the system PATH environment variable. Raises ImportError if pywin32 is not installed, or OSError if the command is not found.
14605	Summary: The `_system_body` function is a callback that handles the output processing of a subprocess. It reads stdout and stderr from the process, decodes the output using the default encoding with replacement for invalid characters, and prints the lines to the corresponding standard output/error streams. Finally, it waits for the process to complete and returns the process's return code.
14606	Find the code units to report on by processing a list of modules or filenames, applying include/exclude patterns, and sorting the results.
14607	Runs a reporting function on multiple morfs, calling the function for each code unit with its corresponding analysis, while handling various exceptions and managing the output directory.
14608	A decorator that tests if a function raises one of the specified exceptions. If the function doesn't raise any of the expected exceptions, it raises an AssertionError with a descriptive message. The decorator accepts multiple exception types and validates that at least one of them is raised during function execution.
14609	Sets up proper stdout redirection and calls pdb.set_trace in the calling frame.
14610	A decorator that adds a time limit to test functions. If the decorated function takes longer than the specified limit to execute, it raises a TimeExpired exception. The decorator measures execution time using time.time() and compares it against the provided limit.
14611	Load all IPython extensions listed in IPythonApp.extensions using ExtensionManager, with error handling and logging for each extension load attempt.
14612	Initializes the code execution environment by running startup files, execution lines, execution files, command line code, and modules in sequence. Flushes stdout and stderr to ensure proper output handling and hides local variables from the shell's namespace to prevent them from appearing in %who etc. searches.
14613	Run lines of code from IPythonApp.exec_lines in the user's namespace, logging debug information and handling errors appropriately.
14614	Runs startup files from the profile's startup directory, executing all .py and .ipy files found, with error handling and logging.
14615	Run files from IPythonApp.exec_files, logging debug information and handling any errors that occur during execution.
14616	Run code or file specified at the command-line, with error handling and logging for both cases.
14617	Run the specified module with proper sys.argv setup for command-line execution.
14618	Creates a generic function dispatcher that supports method overloading based on type and object identity. Returns a dispatcher function with methods `when_type` and `when_object` for registering specialized implementations, along with `default`, `has_object`, and `has_type` utilities.
14619	Return the path to a data file by searching through STATIC_PATH directories, checking both root and pkgdir subdirectories if provided. Raises CoverageException if the file is not found.
14620	Return the contents of a data file by opening it, reading its contents, and ensuring it's properly closed using a try/finally block.
14621	HTML-escape the text in `t` by converting HTML special characters to HTML entities and replacing spaces with &nbsp;.
14622	Generate an HTML report for the given modules or filenames, handling settings validation, file processing, and creating report files including an index and static assets. Returns the percentage of covered code.
14623	Creates local copies of static files (CSS, etc.) needed for generating an HTML report by copying them from their source locations to the report directory.
14624	Writes HTML content to a file with proper ASCII encoding, replacing non-ASCII characters with XML character references.
14625	Computes a hash value for a file that changes when the file needs re-reporting, using a Hasher object and coverage data.
14626	Creates and writes an index.html file for the report using a template, including arcs, CSS, files data, and totals. Writes the generated HTML to the specified directory and updates status with the directory hash.
14627	Read the last status from a directory, validate it against format and version requirements, and load the status data if valid; otherwise reset the object.
14628	Writes the current status information to a file in the specified directory using pickle serialization.
14629	Sorts two lists and compares them for equality. By default modifies the original lists in place, but can create temporary copies if inplace=0 is specified.
14630	Returns a slice of a sequence with variable step size by mapping indices to elements.
14631	chops a sequence into chunks of specified size using lambda function and map.
14632	Read configuration from setup.cfg file and update global IGNORE list based on the 'check-manifest' section settings, including optional 'ignore-default-rules' and 'ignore' options.
14633	Reads configuration from MANIFEST.in file to determine what files/directories to ignore during packaging, updating global ignore lists. Returns early if MANIFEST.in doesn't exist.
14634	Converts a glob pattern to a regular expression, ensuring that * does not match / character. Uses fnmatch.translate() for basic conversion then modifies the result to prevent wildcard matching across directory boundaries. Handles Windows path separators correctly by replacing '.' with '[^\\]' pattern.
14635	Returns True if the filename matches any of the given patterns, False otherwise.
14636	List all files versioned by git in the current directory, handling UTF-8 encoding for Git for Windows and using locale encoding for POSIX systems.
14637	Start a new kernel with a unique ID, create a kernel manager, start the kernel and shell channel, then store the kernel manager in the internal kernels dictionary and return the kernel ID.
14638	Shutdown a kernel by its kernel uuid and remove it from the kernels dictionary.

Parameters:
kernel_id (uuid): The id of the kernel to shutdown.

Returns:
None

Side effects:
- Calls shutdown_kernel() on the kernel instance
- Removes the kernel from self._kernels dictionary
14639	Kill a kernel by its UUID and remove it from the kernels dictionary.

Parameters:
kernel_id (uuid): The id of the kernel to kill.

Returns:
None
14640	Get the KernelManager object for a kernel by its uuid.

Parameters:
kernel_id (uuid): The id of the kernel.

Returns:
KernelManager: The kernel manager object.

Raises:
KeyError: If no kernel is found with the given id.
14641	Return a dictionary of ports for a kernel, including shell_port, iopub_port, stdin_port, and hb_port.
14642	Return the notebook_id for a given kernel_id if exactly one match exists, otherwise return None.
14643	Start a kernel for a notebook and return its kernel_id. If a notebook_id is provided, associate the kernel with that notebook for persistent use. If a kernel already exists for the notebook, reuse it instead of starting a new one.
14644	Shutdown a kernel by ID, remove its notebook mapping, and log the action.
14645	Interrupts a kernel with the given kernel_id, performs validation, calls the parent interrupt method, and logs the interruption.
14646	Restart a kernel while keeping clients connected. If kernel restart fails, fall back to creating a new kernel and killing the old one. Return the kernel ID.
14647	Creates a new iopub stream for the specified kernel_id by first validating the kernel_id and then delegating to the parent class implementation.
14648	Creates a new shell stream for the specified kernel ID by first validating the kernel ID and then delegating to the parent class implementation.
14649	Creates a new heartbeat stream for the specified kernel by first validating the kernel ID and then delegating to the parent class implementation.
14650	Reset all OneTimeProperty attributes in the instance by removing them from the instance dictionary, causing them to be recomputed on next access.
14651	Exports the contents of a ConsoleWidget as HTML to a file, with optional inline or external image handling.
14652	Exports the contents of a ConsoleWidget as XHTML with inline SVGs to a specified file, optionally converting images using a provided tag function.
14653	Wrapper function that ensures image_tag returns UTF-8 encoded string on Python 2, while doing nothing on Python 3.
14654	Summary: The `fix_html` function transforms Qt-generated HTML strings into standards-compliant HTML by adding a UTF-8 charset declaration within the `<head>` section and replacing empty paragraph tags with line breaks. It takes a UTF-8 encoded HTML string as input and returns the modified string with proper encoding declaration and empty paragraph replacements.
14655	Displays a dialog for exporting HTML generated by Qt's rich text system. Returns the name of the saved file or None if no file was saved. Supports HTML with PNG figures or XHTML with inline SVG figures export options. Handles inline or external PNG images based on user preference.
14656	Returns a unique instance of `klass` or None if multiple instances exist or don't exist.
14657	Builds a query for included terms in a text search by creating OR queries for each field within each term, then ANDs all the OR queries together.
14658	Builds a text search query by combining included and excluded terms using boolean logic. Takes an input string and search fields, tokenizes the string into include/exclude terms, creates query objects for each, and combines them with AND/OR NOT operators. Returns a combined query object where included terms are required and excluded terms are forbidden.
14659	Returns a query filter for dates greater than or equal to a specified number of days ago.
14660	Returns a query filter for dates within a specified number of days from now, where the date_field is less than or equal to the future date. The query is constructed using Django's Q objects and ISO format for date comparison.
14661	Returns a query that matches records where the specified field is either null or blank by combining null and blank queries using OR operator.
14662	Converts case sensitive query fields to case insensitive by adding '__iexact' suffix for fields listed in CASE_INSENSITIVE_FIELDS attribute.
14663	Register command line options for test attribute filtering, including basic attribute matching and conditional evaluation.
14664	Validates whether a method has the required attributes by checking all attribute groups. Returns None if method matches all attributes in any group, False otherwise. Handles various value comparison cases including callable validators, boolean checks, list membership, and string comparisons (case-insensitive).
14665	Accept the method if its attributes match.
14666	Rotates the kill ring and yanks back the new top item, updating the previous yank text and cursor position.
14667	Backports patches from newer pyzmq versions to maintain compatibility with older versions. Specifically:
1. Adds missing `ioloop.install` function for pyzmq < 2.1.7
2. Adds missing DEALER/ROUTER aliases for pyzmq < 2.1.9
3. Fixes jsonlib compatibility issue by falling back to stdlib json for pyzmq >= 2.2.0
All patches are intended to be removable when minimum pyzmq version is bumped.
14668	Returns an XSD-schema-enabled lxml parser from a WSDL or XSD schema URL, along with version information. Supports both remote and local file paths. Handles version extraction with optional strict version requirement.
14669	Returns the websocket URL matching the current request by replacing 'http' with 'ws' in the protocol and using either the configured websocket host or the request host.
14670	Reserializes a ZMQ reply message to JSON format by extracting identities, unserializing the message, removing date fields from header and parent_header, removing buffers, and converting to JSON using date_default as the serialization default.
14671	Injects a cookie message for authentication by parsing it into a SimpleCookie object, handling unicode encoding if necessary, and logs warnings for parsing failures.
14672	Start heartbeating mechanism that monitors kernel health, sending periodic ping messages and calling callback when kernel dies. Uses IOLoop for periodic callbacks and handles kernel alive state tracking through stream events.
14673	Starts the heartbeat loop if the connection is still alive and not closed.
14674	Stop the heartbeating and cancel all related callbacks.
14675	Load file object by closing existing file object if present, then assigning either the provided file-like object or opening a new file from the source filename.
14676	Get the current block index, validating and checking status. Returns None if the demo is finished. If index is None and demo is finished, prints message and returns None. Otherwise, validates the index and returns it.
14677	Move the current seek pointer to the given block index, supporting negative indices similar to Python lists. Validates the index and resets the finished flag.
14678	Edit a block in the demonstration. If no index is provided, uses the last executed block. Opens the block content in an editor for in-memory modification without affecting the original source file. After editing, updates the source and colored block content, then re-executes the edited block.
14679	Show a single block on screen at the specified index, displaying the block title, index, and remaining count, followed by the colored source block content.
14680	Show entire demo on screen, block by block, displaying title, block number, and remaining blocks count, with silent blocks marked accordingly.
14681	Processes a collection of objects by applying a specified method to each item in series, with optional timing prints and verbose output. Returns the modified collection after processing all items.
14682	Processes a collection in parallel batches where each batch is processed serially on a single process, potentially more efficient than splitting across cores due to high IO requirements. Takes a collection and processes it using a specified method across multiple processes with configurable batch sizes.
14683	Summary: The `thread` function sets up a thread pool for parallel processing using the provided function and sequence. It creates a ThreadPool with the specified number of cores (or uses all available cores if none specified), then maps the function across the sequence in parallel. If parallel processing fails, it falls back to serial execution. The function also measures and prints the elapsed time, and returns the results. The `runSeries` parameter can force serial execution, and `quiet` suppresses timing output.
14684	Processes a collection in parallel by applying a given method to each element using multiple processes.

Parameters:
- collection: list of objects to process
- method: function to apply to each element
- processes: number of parallel processes (defaults to number of CPU cores, max 20)
- args: additional arguments to pass to the method
- kwargs: keyword arguments to pass to the method

Returns:
- list of results after processing all elements

Note: Lambda functions don't work in parallel. Uses multiprocessing pool with error handling for individual process failures.
14685	A decorator that wraps a function with a context manager, allowing the function to be executed within the context of the provided object (like a lock, file handle, etc.). The decorated function will automatically enter and exit the context manager around its execution.
14686	A decorator that enters multiple context managers on object attributes sequentially within an ExitStack, allowing multiple context managers to be entered before executing the decorated function.
14687	Function `tbsource(tb, context=6)` retrieves source code lines from a traceback object. It returns a tuple containing a list of context lines centered around the error line and the index of the current line within that list. The `context` parameter specifies how many lines of context to return. It handles edge cases like file I/O errors and Python version compatibility for line continuation handling. The function uses `inspect.findsource()` to locate the source code and adjusts the starting line to ensure proper context positioning.
14688	Find inspectable lines around a given position by walking back up to 3 lines and forward up to 3 lines, while preserving indentation levels and handling continued lines. Returns the list of inspectable lines and the index of the home line.
14689	Creates a countdown widget with optional progress bar functionality. Takes parameters for name, target date, description, ID, granularity, start date, and progress bar settings. Returns an HTML div element containing the countdown display and optional progress bar. The progress bar shows completion percentage between a start and end date, with options for inverse progress and percentage display. Uses Bootstrap-styled progress bar elements when enabled.
14690	Cleanup routine to shut down all subprocesses by sending SIGINT signals to engines and controller, then killing the controller.
14691	A modifier hook function called before invoking an Action, allowing modification of context or taking over action invocation. Returns a StepResult with SKIPPED state if condition evaluates to False, otherwise returns None.
14692	A modifier hook function called after executing an action step to optionally modify its result. It sets the `ignore` property of the step result based on a configured value, allowing modifiers to control whether the step should be ignored in subsequent processing. Returns the (optionally modified) step result.
14693	Keep our history and outstanding attributes up to date after a method call.
14694	Syncs relevant results from self.client to self.results attribute by comparing outstanding tasks before and after function execution, updating the outstanding tasks set to exclude completed tasks, and returning the original function result.
14695	Calls the provided function and then calls the spin method on the instance.
14696	Get all messages that are currently ready by repeatedly fetching messages with non-blocking calls until an Empty exception is raised, then return the list of retrieved messages.
14697	Gets a message from the input queue, optionally blocking until a message is available or timeout occurs.
14698	`prop` is a decorator that provides convenient syntax for creating properties with automatic backing field management. It can be used as a simple decorator without arguments to create a property with a private backing field, or with keyword arguments to customize behavior such as field name, getter/setter/deleter availability, default values, and type checking. When used without arguments, it automatically creates a property with a private field (prefixed with underscore) and handles get/set operations with optional type checking and default value support. When used with arguments, it allows fine-grained control over property behavior, including custom field names, enabling/disabling accessors, setting default values, and validating value types against specified types. The decorator returns a standard `property` object.
14699	`get_onlys` is a utility function that creates multiple properties dynamically from field names. It takes variable arguments of field names and returns a tuple of property objects. Each property accesses the corresponding field using `getattr`, providing a concise way to define simple getter properties without writing repetitive `@property` decorators.
14700	Parses a database URL into a configuration dictionary containing database connection parameters like name, user, password, host, and port, along with the database engine based on the URL scheme.
14701	Return the list containing the names of the modules available in the given folder.
14702	Returns a list of all module names available in the Python path, caching the result in IPython's database for future use.
14703	Creates a quick completer for a command by setting up a completion hook that returns specified completions when the command is used with tab completion.
14704	Returns a list containing completion possibilities for import lines, handling cases like 'from module import', 'import module', and 'from module.submodule import'.
14705	Complete files that end in .py or .ipy for the %run command.
14706	Completer function for cd command that returns only directory completions, with support for:
- Bookmark completions (when -b flag is used)
- Directory history navigation (using - or -- prefixes)
- Standard directory globbing with tilde expansion
- Bookmark fallback when no directories match
- Proper user home directory compression in completions
14707	Escapes an XML attribute by first making it XML-safe, encoding unicode strings if necessary, then using saxutils.quoteattr for proper XML attribute escaping.
14708	Configures the xunit plugin by calling the parent Plugin.configure method, storing the configuration, and initializing statistics and error tracking structures when the plugin is enabled. It also opens the specified xunit output file for writing with the specified encoding.
14709	Writes an Xunit-formatted XML report file containing test results including errors, failures, and skipped tests, and optionally displays the file path to the stream.
14710	Adds error output to Xunit report, handling skipped tests separately from regular errors, and formats the error information including traceback into XML testcase format.
14711	Adds failure information to Xunit report output. Records test failure details including classname, test name, execution time, error type, error message, and traceback information in XML format for reporting purposes.
14712	Add success output to Xunit report by recording test case information including classname, test name, and execution time.
14713	Pick two random indices from loads and return the smaller one (representing the LRU of the two).
14714	Pick two random items using inverse load as weight and return the less loaded of the two.
14715	Registers a new engine with given uid by adding it to targets and loads lists at position 0, initializing completion sets, and rescanning the graph.
14716	Method `_unregister_engine(self, uid)` handles the removal of an engine with identifier `uid` that has become unavailable. It performs the following steps:

1. Checks if this is the last engine in the system (does nothing if it is)
2. Flushes the engine stream to ensure all pending data is processed
3. Removes the engine from the targets and loads lists by index
4. If there are pending tasks for this engine, schedules a delayed cleanup in 5 seconds to allow for potential incoming results
5. If no pending tasks exist, cleans up completed and failed task lists for this engine

The method prevents the unregistered engine from receiving new work while managing cleanup of associated task data appropriately based on pending job status.
14717	Handle jobs that were resident in an engine that died by creating fake error replies for pending tasks and removing the engine from completed/failed lists.
14718	Method: dispatch_submission(self, raw_msg)

Summary: This method processes incoming job submission messages by validating and dispatching them to appropriate handlers. It handles message deserialization, dependency checking, timeout processing, and job scheduling. The method ensures targets are up to date, validates message integrity, processes time and location dependencies, and either executes jobs immediately or saves them for later execution based on dependency status. It also manages job failure cases and dependency validation errors.

Key operations:
- Validates and deserializes incoming messages
- Processes time and location dependencies 
- Handles job timeout conversion to datetime objects
- Checks for invalid dependencies and unreachable jobs
- Dispatches jobs for execution or saves them for future processing
- Manages job lifecycle through dependency validation and execution checks
14719	Audit all waiting tasks for expired timeouts, failing any that have exceeded their timeout limits.
14720	Method `fail_unreachable` handles the case when a task becomes unreachable by sending an error reply with `ImpossibleDependency` error. It removes the task from dependency tracking, cleans up graph connections, wraps the exception, marks the task as both completed and failed, sends reply messages to client and monitor streams, and updates the graph status.
14721	Check location dependencies and run job if requirements are met, handling targets, blacklist, HWM, and follow conditions with appropriate filtering and error handling.
14722	Save a message for later submission when its dependencies are met by tracking unmet dependencies in the graph structure.
14723	Submit a task to a target engine based on load balancing scheme, send the job data, update load tracking, and notify the hub of task assignment.
14724	Method: dispatch_result

Summary: Processes result replies from engines by dispatching tasks, handling successful/failed results, managing retries for unmet dependencies, and updating job status. The method validates incoming messages, identifies engine targets, and either relays successful results to clients or handles failed tasks by retrying or notifying dependencies. It also sends task completion updates to the Hub monitor.

Parameters:
- raw_msg: Raw message containing task result data

Returns: None (modifies internal state and sends messages)

Side effects: Updates job tracking, manages retries, sends messages to clients and Hub monitor, handles task failures and dependencies
14725	Handle a task result (success or failure) by relaying it to the client and updating internal data structures including pending, completed/failed sets, and graph information.
14726	Handle an unmet dependency by removing the failed engine from pending jobs, adding it to the job's blacklist, checking if the job can no longer be completed, and resubmitting if necessary. Update load information and graph if high water mark is reached.
14727	Method: `update_graph(self, dep_id=None, success=True)`

Summary: Updates the dependency graph when a job completes or when the entire graph needs refreshing. It processes jobs that depended on the completed job (identified by `dep_id`), checks if any new jobs can now run based on dependencies and completion status, and removes completed jobs from tracking. When `dep_id` is None, it triggers a full graph refresh. The method also handles unreachable jobs by marking them as failed and manages job execution by calling `maybe_run()` for eligible jobs.
14728	Starts a new log file with specified parameters, raising RuntimeError if log is already active. Supports different modes like append, backup, global, over, and rotate with appropriate file handling and timestamping options.
14729	Print a status message about the logger, showing log file details and current state.
14730	Write the sources to a log, using either the modified input line (if log_raw_input flag is False) or the original input line (if log_raw_input flag is True).
14731	Writes data to a log file with optional timestamp and output formatting if logging is active.
14732	Stop logging and close the log file. Requires a new logstart() call to begin logging again.
14733	Create a worksheet with an optional name and optional list of cells, returning a NotebookNode object.
14734	Adds a target string for dispatching by creating or retrieving a CommandChainDispatcher and adding the object with the specified priority.
14735	Adds a regular expression target for dispatching by creating or retrieving a CommandChainDispatcher and adding the object with specified priority.
14736	Get a sequence of Commandchain objects that match the given key, checking both exact string matches and regex patterns.
14737	Yields all 'value' targets from dispatch without priority information.
14738	Method that validates and creates a notebook directory when it changes, raising TraitError for invalid paths or creation failures.
14739	List all notebooks in the notebook directory, returning a sorted list of dictionaries containing notebook IDs and names.
14740	Generate a new notebook ID for a given name and store the mappings between the ID and name in both directions. Currently uses a random UUID4, with commented-out logic for stable URL-based IDs that could be reactivated later.
14741	Delete a notebook's id from the mapping dictionaries without deleting the actual notebook. Removes the entry from both forward mapping (notebook_id -> name) and reverse mapping (name -> notebook_id).
14742	Checks if a notebook exists by verifying its ID exists in the mapping and its corresponding file path is a valid file.
14743	Return the full path to a notebook given its notebook_id, raising a 404 error if the notebook doesn't exist.
14744	Return a full path to a notebook given its name by combining the notebook directory, filename, and extension.
14745	Get the representation of a notebook in the specified format by notebook_id, validating the format and returning the last modified timestamp, notebook name, and formatted data.
14746	Get the NotebookNode representation of a notebook by notebook_id, including last modified timestamp and notebook data.
14747	Save a new notebook with given data and return its ID. Validates format, reads notebook data, sets name from data or parameter, generates new ID, saves notebook object, and returns the ID. Raises HTTP errors for invalid format, bad JSON data, or missing name.
14748	Save an existing notebook by notebook_id with the given data and optional name, validating the format and handling JSON parsing errors.
14749	Save an existing notebook object by notebook_id, updating its name and file path if necessary, and optionally saving a corresponding Python script file. Raises HTTPError for missing notebooks, missing names, or unexpected errors during save operations. Handles cleanup of old files when name changes occur.
14750	Delete a notebook by its ID by removing the corresponding file from disk and cleaning up the notebook ID reference. Raises a 404 error if the notebook doesn't exist.
14751	Create a new notebook file with an incremented filename, generate a unique notebook ID, create notebook metadata, generate a new notebook object with that metadata, write the notebook to a JSON file at the specified path, and return the generated notebook ID.
14752	Copy an existing notebook with a '-Copy' suffix, generate a new notebook ID, save the copied notebook, and return the new notebook ID.
14753	Return all physical tokens, including line continuation backslashes. This function wraps tokenize.generate_tokens() to inject backslash tokens that indicate line continuations, ensuring a faithful representation of the original source code. It handles special cases like multiline strings and comments to avoid duplicate backslash tokens.
14754	Generate tokenized lines from source code, where each line contains token pairs of (token_class, token_text). Handles whitespace, newlines, and keywords while preserving token structure for reconstruction of the original source.
14755	Load the default configuration file from the IPython directory for embedded shells. If no IPython directory is specified, use the default one. Return the loaded configuration or an empty Config object if no config file is found.
14756	Returns a list of default classes including InteractiveShellApp, the current class, TerminalInteractiveShell, PromptManager, HistoryManager, ProfileDir, PlainTextFormatter, IPCompleter, and ScriptMagics.
14757	This method overrides the command line parsing to handle the deprecated `-pylab` flag by issuing a warning and converting it to the new `--pylab` syntax, while also supporting backend specification like `-pylab qt`.
14758	Initialize the TerminalIPythonApp by calling parent initialize, checking for subapp, handling old config files, setting up file execution, initializing path, shell, banner, GUI, extensions, and code execution.
14759	Initializes the InteractiveShell instance for the terminal-based application, creating a TerminalInteractiveShell with specific configuration settings including display_banner=False, and adds the current instance to the shell's configurables list.
14760	Initialize and display banner if conditions are met, then add space below banner.
14761	Return a string representation of a value and its type for readable error messages.
14762	Convert the name argument to a list of names, handling strings, lists, tuples, and None values. If name is a string, return it as a single-element list. If name is None, return ['anytrait']. If name is a list or tuple, validate that all elements are strings and return the name sequence. If name is anything else, raise an assertion error.
14763	Sets the default value for a trait on a per-instance basis by either using a deferred initializer method or static initialization, validating and storing the value in the object's trait values or dynamic initializers dictionary.
14764	Setup a handler to be called when a trait changes, supporting both dynamic installation and removal of trait change notifications.
14765	Get a list of all the traits of a class with optional metadata filtering.

This function retrieves all trait attributes from a given class, returning them as a dictionary mapping trait names to TraitType objects. It can optionally filter traits based on metadata key-value pairs using either exact value matching or custom evaluation functions.

Parameters:
- cls: The class to inspect for traits
- **metadata: Optional keyword arguments for filtering traits by metadata (key-value pairs or functions)

Returns:
- dict: A dictionary of trait names to TraitType objects, optionally filtered by metadata criteria

The function follows the same algorithm as the `traits` method but works on unbound classes. When metadata filtering is applied, it uses either direct value comparison or function evaluation to determine trait inclusion. If a metadata key doesn't exist, `get_metadata` returns None, which may affect filtering behavior.
14766	Get metadata values for a trait by key, raising TraitError if the trait doesn't exist.
14767	Validates that the value is a valid object instance, returning it if valid or raising an error if not.
14768	Instantiates a default value instance for a HasTraits class, creating a unique instance for each HasTraits instance by either generating a value using a DefaultValueGenerator or returning the default value directly.
14769	Check whether the dependencies have been met by comparing against completed and failed sets based on success, failure, and all flags.
14770	Return whether this dependency has become impossible based on completed and failed tasks. If no tasks exist, returns False. For unsuccessful dependencies, checks against completed tasks. For failed dependencies, also checks against failed tasks. For 'all' dependencies, returns True if any dependency is in the against set. For other dependencies, returns True if all dependencies are in the against set.
14771	Represent this dependency as a dict for JSON compatibility, containing dependencies list, all flag, success flag, and failure flag.
14772	Get the depth of an element in the tree by traversing up to the root node, counting the levels encountered.
14773	Prints a binary tree structure with proper indentation based on node depths.
14774	The function `disambiguate_dns_url` takes a URL and a location (either an IP address or DNS name) as input. If the location is not already an IP address (validated using `ip_pat.match`), it resolves the DNS name to an IP address using `socket.gethostbyname`. Finally, it calls `disambiguate_url` with the URL and resolved IP address, returning the result.
14775	Method: allreduce

Summary: Performs a parallel reduction operation followed by broadcasting the result to all processes in the distributed environment.

Parameters:
- f: Reduction function to apply
- value: Input value(s) to reduce
- flat: Boolean flag indicating whether to treat input as flat (default: True)

Returns: The reduced and broadcast result across all processes

Implementation: Delegates to the reduce method with all=True parameter to execute the allreduce operation.
14776	Convert valid targets argument into a list of integer ids, handling None defaults, single targets, string identities, and validating against registered engines.
14777	Handles incoming messages from ME, task queues, and IOPub traffic by routing them based on their topic to appropriate monitor handlers, logging errors for unrecognized topics or messages without proper formatting.
14778	Dispatches and routes query messages from clients, handling registration requests and various message types through registered handlers, with proper error handling and logging for malformed messages or unsupported message types.
14779	Handles new heartbeat events by checking if the heart is in incoming registrations and completing registration if valid.
14780	Handles heart failure by logging the event, checking if the heart belongs to a valid engine, and triggering unregistration if the engine is still alive.
14781	Save a task submission by deserializing the message, creating a record with client information and queue assignment, and either updating or adding the record to the database while handling potential conflicts and errors.
14782	Save the result of a completed task by processing the message, updating task status and database records.
14783	Save an iopub message into the database by deserializing it, extracting message metadata, ensuring the message ID exists in the database, and updating the record with relevant content based on message type (stream, pyerr, pyin, display_data, pyout, or status). Handles errors during deserialization and database operations.
14784	Handles client connection requests by sending back connection addresses and engine information to the connected client.
14785	Register a new engine by validating queue and heartbeat identifiers, ensuring they are unique. If valid, assign a new engine ID and set up necessary sockets and callbacks for registration completion. If registration fails due to duplicate identifiers, return an error message. Return the assigned engine ID upon successful registration.
14786	Unregisters an engine that requested to leave by removing its registration information, adding it to dead engines list, and scheduling handling of its stranded messages while notifying subscribers if a notifier is present.
14787	Finishes the engine registration process by completing the registration information, setting up engine connections, and notifying subscribers of the new engine connection.
14788	Handles shutdown request by sending reply to client, notifying other clients, and scheduling shutdown sequence to execute after 1 second.
14789	Method to purge message results from memory storage based on message IDs or all completed records, with error handling and engine validation.
14790	Extracts and decomposes a TaskRecord dictionary into structured result content and buffers for get_result method, separating I/O data into io_dict and organizing main content with result metadata.
14791	Get the result of 1 or more messages by processing message IDs, checking their status (pending/completed), retrieving associated records from database when needed, and sending back a result reply with content and buffers. Handles both status-only requests and full data retrieval, with proper error handling for missing messages.
14792	Get a list of all msg_ids from database records and send them in a history_reply message to the client. If database access fails, send an error response instead.
14793	Perform a raw query on the task record database, retrieve records based on query parameters, extract buffer information from records, and send back a formatted reply with optional buffer data.
14794	A context manager method that temporarily changes the working directory to `newdir`, executes the code within the `with` block, and then restores the original working directory.
14795	Method `decode_cmd_out` takes a completed command object and returns a `ParsedCompletedCommand` object with decoded stdout and stderr output, handling multiple encoding scenarios including UTF-8 and Big5, with fallbacks for different data types.
14796	Runs a command under the R root directory and returns the process result, optionally catching stdout and stderr.
14797	Execute an R script by running it with Rscript command and return the decoded output.
14798	Calls the frontend handler associated with the message type of the given message.
14799	Returns whether a kernel reply originated from requests sent by this frontend by comparing the session IDs in the message parent header with the current kernel session.
14800	Runs the report by calling `report_files` with `annotate_file` and the provided arguments.
14801	Annotate a single file by adding coverage information to each line. The function reads the source file, analyzes statement coverage, and writes an annotated version with markers indicating covered ('>'), uncovered ('!'), excluded ('-'), or blank ('  ') lines. The annotated file is saved with a '.py,cover' extension either in a specified directory or in the same location as the source file.
14802	Returns the installed version of a package using apt-cache policy, or None if the package is not installed. Uses regex to parse the version from command output and handles subprocess errors gracefully.
14803	Coerces unicode objects back to bytestrings by encoding unicode strings to UTF-8 and recursively processing dictionaries and lists. For dictionaries, it also handles unicode keys by re-encoding them and updating the dictionary with new keys. Returns the modified object with all unicode strings converted to UTF-8 bytestrings.
14804	Extracts and returns the header from a message or header object. If the input is already a header, it returns it directly. If the input is a full message, it extracts the 'header' field. If the input is neither, it raises an exception. The result is always returned as a dictionary.
14805	Method `_check_packers` verifies that the packer and unpacker functions properly handle binary data serialization and datetime support. It performs the following checks:

1. Tests basic serialization with a simple message dictionary
2. Ensures the packed output is of bytes type  
3. Verifies that unpacking is the inverse of packing
4. Tests datetime serialization support and falls back to date-handling functions if datetime support is missing

The method raises `ValueError` for any serialization/deserialization failures and updates the pack/unpack functions to handle datetime objects when needed.
14806	Return a nested message dictionary with specified type and content, handling default values for header, parent, and subheader parameters.
14807	Sign a message with HMAC digest using the provided message parts. Returns empty bytes if no authentication is set.
14808	Serialize message components to bytes list with identity, delimiter, signature, and packed message parts.
14809	Send a message via a ZMQ stream or socket with optional tracking and buffer support. The method constructs a message from the provided parameters, serializes it, and sends it using the specified stream. It supports sending with or without message tracking, and can handle multiple buffers. The message format follows a specific structure with identifiers, headers, content, and buffers. Returns the constructed message and optionally a MessageTracker if tracking is enabled. Raises TypeError for invalid stream types or when tracking is requested with a ZMQStream.
14810	Send a raw message via ident path using the specified ZMQ stream or socket, with optional identification and message signing.
14811	Receive and unpack a message from a ZMQ socket.

Parameters:
- socket: ZMQStream or Socket - The socket or stream to receive from
- mode: int - ZMQ receive mode (default: zmq.NOBLOCK)
- content: bool - Whether to unpack message content (default: True)
- copy: bool - Whether to copy received data (default: True)

Returns:
- [idents], msg - List of identity frames and unpacked message dictionary

Handles ZMQ socket receive operations with proper error handling for non-blocking mode (EAGAIN) and message deserialization. Returns None for both values when no message is available in non-blocking mode.
14812	Split identities from message list by DELIM delimiter, returning identities and remaining message list. If copy=True, operates on list of bytes/messages directly. If copy=False, searches for DELIM by comparing bytes attribute of messages. Raises ValueError if DELIM not found. Returns tuple of (idents, msg_list) where idents contains bytes identities and msg_list contains remaining messages.
14813	Unserializes a message list into a nested message dictionary. Takes a list of message parts including HMAC, header, parent header, content, and buffers. Verifies signature if authentication is enabled, then unpacks the header and parent header. Optionally unpacks the content dictionary. Returns a dictionary with keys 'header', 'msg_id', 'msg_type', 'parent_header', 'content', and 'buffers'.
14814	Prompts user to save an SVG document to disk. Takes a string containing SVG content and optional parent widget for the file dialog. Returns the saved filename or None if cancelled.
14815	Copies a SVG document from a Python string to the system clipboard by encoding it as UTF-8, creating QMimeData with the 'image/svg+xml' MIME type, and setting it to the application's clipboard.
14816	Converts an SVG document string to a QImage object. Takes optional size parameter for image dimensions, uses Qt's SVG renderer with error handling for invalid SVG data, returns QImage with ARGB32 format.
14817	Creates an object information dictionary with all predefined fields initialized to None, then updates with any provided keyword arguments.
14818	**Summary:**

A stable wrapper function around `inspect.getdoc()` that safely retrieves documentation strings from objects. It first attempts to call a custom `getdoc()` method on the object (for objects using non-standard docstring mechanisms), then falls back to `inspect.getdoc()`, and finally returns `None` if all methods fail. The function is designed to be robust against attribute errors and inspection failures, particularly useful for objects like Pyro proxies or SWIG-wrapped extensions.
14819	Wrapper around inspect.getsource that handles binary objects and decorated functions. Returns None for binary objects, extracts source from decorated functions by unwrapping them, and falls back to class source extraction for TypeError cases.
14820	Get the names and default values of a function's arguments, returning a tuple of (args, varargs, varkw, defaults). Handles functions, methods, and callable objects, with modified behavior from Python's standard library inspect.getargspec.
14821	Extracts call tip data from an oinfo dictionary.

Parameters:
- oinfo: dict containing object information
- format_call: bool, optional (default True) - if True, returns formatted call string; if False, returns (name, argspec) tuple

Returns:
- call_info: None, str, or (str, dict) tuple depending on format_call parameter
- docstring: str or None containing relevant documentation

The function processes callable object information by:
1. Extracting argspec and formatting call line (removing 'self' argument for callable objects)
2. Prioritizing docstrings in order: call docstring  init docstring  regular docstring
3. Returning formatted call information and corresponding docstring
14822	Find the absolute path to the file where an object was defined, handling decorated objects and instances gracefully. Returns None if no file can be found.
14823	Finds the line number in a file where a Python object was defined by wrapping `inspect.getsourcelines`. Handles decorated objects by using their unwrapped version and falls back to the class object for instances. Returns None if the source cannot be found.
14824	Return the definition header for any callable object, returning None if an exception occurs.
14825	Return a header string with proper colors by combining the active header color, input header string, and normal color from the color table.
14826	Generic message printer when no information is found, displaying "No [msg] found" and optionally "for [oname]" if object name is provided.
14827	Prints the definition header for callable objects, including class constructors. Handles special cases for class initialization and instance types, then formats and displays the definition information.
14828	Print the docstring for any object, including class docstrings, constructor docstrings, and calling docstrings, with optional formatting. If no documentation is found, display a "no information" message.
14829	Prints the source code for an object by retrieving it using getsource() and displaying it through the page() method, with cache flushing handled for freshness. If source retrieval fails, displays "source" information indicating unavailability.
14830	Show the complete file where an object was defined, handling binary files and non-existent files appropriately.
14831	Formats a list of fields for display by pairing field titles with their content, applying header formatting to multi-line content, and padding titles to a specified width. Returns a formatted string with all fields concatenated.
14832	Show detailed information about an object, including its fields, namespace, source or docstring, and constructor information for classes.
14833	Search namespaces with wildcards for objects, supporting type specification, case-insensitive matching, and filtering options.
14834	Start the Twisted reactor in a separate thread if not already running, and return the reactor along with the thread object. The thread is set as a daemon and will be automatically destroyed when all tests are completed.
14835	A decorator that allows test functions to return Twisted Deferred objects, making the test wait for the deferred to be triggered. The decorator runs the entire test function inside the Twisted event loop and supports an optional timeout parameter. If the deferred's callback is triggered, the test passes; if the errback is triggered or the timeout expires, the test fails. The decorator ensures proper exception handling and provides helpful error messages for common usage mistakes.
14836	Function `find_best_string` searches for the best matching substring of a query within a corpus using a two-stage approach. First, it scans the corpus with a specified step size to find potential matches, then it fine-tunes the match by adjusting the substring boundaries within a flexible range. It returns the best matching substring and its match ratio. The function includes optional case-insensitive matching and includes bounds checking for the flex parameter.
14837	Encodes the stored data to XML and returns a string. If indent is False, returns a condensed value. If declaration is False, skips the XML declaration.
14838	Encodes stored data to XML and returns an lxml.etree value. Updates the document with data if present, then returns the document.
14839	Loads all modules recursively from a package or set of packages and returns a list of unique module objects.
14840	Helper function for merge that inverts a dictionary mapping keys to lists, creating a new dictionary where each element in the original lists becomes a key mapping back to the original key.
14841	Merge two Structs with customizable conflict resolution, allowing for flexible data combination through user-defined policies or predefined options like preserve, update, add, add_flip, and add_s.
14842	Converts an object to primitive types (dict, list, int, float, bool, str, None) for serialization. Handles None, primitive types directly, lists/sets/frozensets recursively, dicts recursively, and objects by converting them to their __dict__ representation.
14843	Formats and colors source code with optional output to file or string, handling different color schemes and tokenization errors.
14844	Get a list of matplotlib figures by figure numbers. If no arguments are given, all available figures are returned. If the argument list contains references to invalid figures, a warning is printed but the function continues processing further figures. Parameters: figs - a tuple of ints giving the figure numbers of the figures to return.
14845	Convert a matplotlib figure to SVG or PNG format for inline display, with special handling for empty figures and temporary color restoration.
14846	Factory function that returns a matplotlib-enabled runner for %run magic command, which wraps safe_execfile to handle matplotlib's interactive rendering properly by temporarily disabling interactive mode during script execution and then restoring the original setting.
14847	Selects the figure format for inline matplotlib backend, setting either 'png' or 'svg' as the active format and ensuring only one format is active at a time.
14848	Function that takes a GUI string and returns the corresponding GUI and matplotlib backend as a tuple. Supports GUI options ('tk','gtk','wx','qt','qt4','inline') and returns matching backend names ('TkAgg','GTKAgg','WXAgg','Qt4Agg','module://IPython.zmq.pylab.backend_inline'). If no GUI is specified or 'auto' is given, it uses the current matplotlib backend configuration and maps it back to an appropriate GUI selection.
14849	Activates a specified matplotlib backend, enables interactive mode, and configures pylab for proper show behavior with call detection.
14850	Configures an IPython shell object for matplotlib use with inline backend support. Sets up inline backend, registers post-execution functions for figure handling, configures matplotlib parameters, and adds display functions to the user namespace. Handles ImportError gracefully if inline backend is not available.
14851	Activates pylab mode by loading and initializing numpy, matplotlib, and friends into the user's namespace. Configures matplotlib with the specified GUI backend, imports pylab components, and sets up inline support for IPython. Returns the actual GUI backend used for configuring IPython's GUI integration.
14852	A tracer function for Python's sys.settrace that tracks code execution events including function calls, line executions, returns, and exceptions. It maintains a stack of execution contexts and records execution arcs or line numbers based on the tracing configuration. The tracer handles exception tracking by storing back references and manages file data storage by filename. It supports both arc-based and line-based tracing modes, storing execution data in a structured manner with proper context management.
14853	Starts the Tracer by setting up a trace function for the current thread. Returns a Python function suitable for use with sys.settrace().
14854	Stop this Tracer by setting the stopped flag and clearing the trace function. If called from a different thread, only sets the flag since self-unhooking isn't possible. If called from the same thread and tracing is active, verifies the trace function matches expected value and then disables tracing.
14855	Starts a new Tracer object with configured attributes and stores it in self.tracers, then returns the tracer's start function.
14856	This method is a trace function that removes itself from the trace callback chain, installs the actual tracer by calling `_start_tracer()`, invokes the real trace function with the current event to prevent event loss, and returns the new trace function to continue tracing in the current scope. It's designed to handle thread installation by replacing the temporary trace function with the real one.
14857	Start collecting trace information by adding current collector to stack, installing tracer on current thread, handling existing trace functions, and setting up installation tracer for threading support.
14858	Stop collecting trace information by pausing current collector, clearing tracers, removing itself from collectors stack, and resuming the previous collector if exists.
14859	Pause tracing of all tracers and display coverage statistics, then disable tracing at the thread level.
14860	Resumes tracing by starting all tracers and setting the installation trace function.
14861	Return the line data collected, converting branch data to line data if branch measurement was enabled. Data format is { filename: { lineno: None, ...}, ...}.
14862	Collect exceptions from a result dictionary or list, raising a CompositeError if any exist, otherwise returning the original data structure.
14863	Renders one or all tracebacks as a list of lines. If no exception index is provided, renders all tracebacks from the exception list. If an exception index is provided, renders only that specific traceback. Each traceback is preceded by engine information and empty lines separating multiple tracebacks. Returns a list of strings representing the formatted traceback content.
14864	**Summary:** Initializes coverage measurement at Python startup if the `COVERAGE_PROCESS_START` environment variable is set. It starts coverage tracking using the specified configuration file and disables certain warnings. This function is typically called from `sitecustomize.py` or a `.pth` file during Python initialization.
14865	Return the canonical directory of the module or file `morf` by extracting the directory path from its canonical filename.
14866	Return the source file for `filename`, handling special cases like Jython's $py.class extension and ensuring proper Python file extension.
14867	Decide whether to trace execution in a given filename, returning the canonicalized filename if tracing is enabled or None if not, along with a reason for the decision.
14868	Decides whether to trace execution in a given filename by calling `_should_trace_with_reason` and returning only the decision. Writes debug information about the tracing decision if debugging is enabled.
14869	Method `_warn(self, msg)` adds a warning message to the internal warnings list and writes the message to standard error output with a "Coverage.py warning:" prefix.
14870	Update the source_match matcher with latest imported packages by checking sys.modules for packages in source_pkgs, finding their file paths, and adding valid source files to source and source_match collections while removing found packages from source_pkgs.
14871	Start measuring code coverage by initializing matchers for tracking code execution, loading data if auto_data is enabled, and beginning collection. Sets up various matchers for source, coverage directories, Python library directories, include, and omit patterns. Writes configuration and system debug information if debugging is enabled. Finally, starts the collector and marks the measurement as started.
14872	Clean up on process shutdown by stopping the process if started and saving data if auto_data is enabled.
14873	Exclude source lines from execution consideration by adding regex patterns to specified lists ('exclude' or 'partial') that determine how lines are treated during reporting.
14874	Return a compiled regex for the given exclusion list, caching the result in self._exclude_re for future use.
14875	Save the collected coverage data to the data file, generating a unique filename suffix with hostname, test name (if available), process ID, and random number when data_suffix is True.
14876	Combine together similarly-named coverage data files by reading all files that start with `data_file` and merging their measurements into current coverage data, while handling path aliases if configured.
14877	Get collected data and reset the collector, while warning about problems like unimported packages and missing data.
14878	Returns the analysis results without the excluded line numbers.
14879	Analyze a module to determine its coverage statistics, returning filename, executable statements, excluded statements, missing statements, and formatted missing line numbers.
14880	Analyzes a single morf or code unit by first harvesting data, converting non-CodeUnit items using a factory, and returning an Analysis object initialized with self and the processed code unit.
14881	Writes a summary coverage report to a file, showing statement counts and missing lines for each module. Returns the total percentage covered.
14882	Annotate a list of modules by generating coverage-annotated source files with markers indicating line coverage status (">" for covered, "-" for excluded, "!" for missing).
14883	Generate an HTML coverage report in the specified directory with optional CSS and title. Returns the total coverage percentage.
14884	Generate an XML report of coverage results compatible with Cobertura format. Takes optional parameters for source files, output destination (stdout or file), and filtering options. Returns the total coverage percentage. Handles file I/O and error cleanup automatically.
14885	Displays a Python object in all frontends by computing all representations and sending them to frontends, with optional inclusion/exclusion of specific format types.
14886	Display the HTML representation of an object or raw HTML data. If raw=False (default), formats Python objects for display. If raw=True, displays raw HTML data directly using publish_html().
14887	Display the SVG representation of an object or raw SVG data. If raw=True, displays the SVG data directly; otherwise, formats Python objects before display.
14888	Display the PNG representation of an object or raw PNG data. If raw=False (default), formats Python objects before display; if raw=True, displays raw PNG data directly. Uses publish_png for raw data or display with image/png mime type for formatted objects.
14889	Display the JPEG representation of an object or raw JPEG data. If raw=False (default), formats Python objects before display. If raw=True, displays raw JPEG data directly. Uses publish_jpeg() for raw data or display() with image/jpeg MIME type for formatted objects.
14890	Display the LaTeX representation of Python objects or raw LaTeX data. If raw=False (default), formats Python objects for display. If raw=True, displays raw LaTeX data directly. Uses publish_latex for raw data and display with text/plain/text/latex include for formatted objects.
14891	Display the JSON representation of an object(s), supporting both raw JSON data and Python objects that need formatting.
14892	Displays the JavaScript representation of Python objects or raw JavaScript data. If raw=True, displays raw JavaScript data directly. Otherwise, formats Python objects and displays them with both text/plain and application/javascript MIME types.
14893	Reload the raw data from file or URL. If filename is provided, read from file using read flags. If URL is provided, fetch data from URL using urllib2, extract encoding from response headers, and decode data accordingly. If any error occurs during URL fetching, set data to None.
14894	Find the full path to a command using the 'which' utility and return it as a string.
14895	Execute a command in a subshell and return the child's exit status. Uses pexpect to spawn a shell process, handle output printing with proper encoding, and manage timeouts/EOF conditions. Handles KeyboardInterrupt by sending ^C to the process and ensuring proper termination. Returns the exit status of the executed command.
14896	Forward read events from an FD over a socket by wrapping a file in a socket pair that can be polled for read events by select/zmq.eventloop.ioloop. Returns a PULL socket for receiving forwarded events.
14897	Loop through lines in self.fd, and send them over self.sock. Handle unicode mode files by using send_unicode when needed. Close both file descriptor and socket when EOF is reached.
14898	Find and return a launcher class for a given class name and kind.

Parameters:
- clsname (str): The full name of the launcher class, either with or without the module path, or an abbreviation (MPI, SSH, SGE, PBS, LSF, WindowsHPC)
- kind (str): Either 'EngineSet' or 'Controller'

Returns:
- The imported launcher class object

The function handles both abbreviated names (like 'PBS', 'MPI') and full module paths by automatically constructing the appropriate module path when needed.
14899	Start the app for the stop subcommand. Attempts to read PID file and check if cluster is running. If running, sends signal to stop the cluster on POSIX systems or uses taskkill on Windows. Handles errors appropriately and removes PID file if cluster is not running or if stopping fails.
14900	builds and returns a Launcher instance by importing the specified class and instantiating it with configured parameters.
14901	Start the IPython cluster engines subcommand, log the start event, handle daemonization if requested, schedule engine startup via delayed callback, and begin the event loop with proper error handling for keyboard interrupts and ZMQ errors.
14902	Start the ipcluster application for the start subcommand. Check if cluster is already running by examining the PID file and exit if it is. Log and daemonize if requested, then start the controller and engines with a delay. Write the new PID file after forking, start the event loop, and clean up by removing the PID file when done.
14903	Create a new wx app or return an existing one, ensuring redirect is set to False if not specified.
14904	Check if the wx event loop is currently running by examining the application's event loop state.
14905	Start the wx event loop in a consistent manner, checking if it's already running and managing the event loop state properly.
14906	Create a new Qt4 application or return an existing one. Returns the existing QApplication instance if it exists, otherwise creates a new one with the provided arguments and keyword arguments.
14907	**Summary:** Checks if the Qt4 event loop is currently running by examining the `_in_event_loop` attribute of a Qt4 application instance. Returns `True` if the event loop is running, `False` otherwise. If no application instance is provided, it creates a new one using `get_app_qt4([''])`.
14908	Starts the Qt4 event loop in a consistent manner, creating a new application instance if needed and ensuring the event loop is only started if it's not already running.
14909	Creates a blank canvas for annotation with specified dimensions and returns it as a Canvas object.
14910	Draw a cross on the canvas at the specified position with given color and radius. The cross consists of horizontal and vertical lines centered at the position, with the specified radius determining the line length. Coordinates are checked for bounds to prevent out-of-range access.
14911	Draw a line between two positions on the canvas using skimage's line drawing function and set the pixels along the line to the specified color.
14912	Writes text at a specified position on the display with optional centering, color, size, and antialiasing support.
14913	Convert a grayscale image to a color canvas by distributing the grayscale values across specified channels.

Parameters:
- im: single channel image array
- channels_on: tuple of boolean values indicating which RGB channels to populate with the input image data

Returns:
- Canvas object with the grayscale image distributed across the specified channels

The function creates a 3-channel RGB canvas and copies the input grayscale image to the channels specified in channels_on, leaving other channels zeroed out.
14914	Returns a unique ID of specified length using UUID1 (local machine based) or UUID4 (random) algorithms, with version 1 being the default for system-specific uniqueness.
14915	Create a unique cache key from GET parameters by combining the current site domain with encoded GET data, then hash it using MD5.
14916	Returns the domain name portion of a URL by parsing the hostname from the URL, automatically adding 'http://' prefix if it's missing.
14917	Returns a dictionary of URL query parameters from a given URL.
